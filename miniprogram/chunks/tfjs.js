"use strict";const EPSILON_FLOAT32$1=1e-7;const EPSILON_FLOAT16$1=1e-4;class DataStorage{constructor(backend,dataMover){this.backend=backend;this.dataMover=dataMover;this.data=new WeakMap;this.dataIdsCount=0}get(dataId){if(!this.data.has(dataId)){this.dataMover.moveData(this.backend,dataId)}return this.data.get(dataId)}set(dataId,value){this.dataIdsCount++;this.data.set(dataId,value)}has(dataId){return this.data.has(dataId)}delete(dataId){this.dataIdsCount--;return this.data.delete(dataId)}numDataIds(){return this.dataIdsCount}}class KernelBackend{refCount(dataId){return notYetImplemented("refCount")}incRef(dataId){return notYetImplemented("incRef")}timerAvailable(){return true}time(f){return notYetImplemented("time")}read(dataId){return notYetImplemented("read")}readSync(dataId){return notYetImplemented("readSync")}numDataIds(){return notYetImplemented("numDataIds")}disposeData(dataId,force){return notYetImplemented("disposeData")}write(values,shape,dtype){return notYetImplemented("write")}move(dataId,values,shape,dtype,refCount){return notYetImplemented("move")}memory(){return notYetImplemented("memory")}floatPrecision(){return notYetImplemented("floatPrecision")}epsilon(){return this.floatPrecision()===32?EPSILON_FLOAT32$1:EPSILON_FLOAT16$1}dispose(){return notYetImplemented("dispose")}}function notYetImplemented(kernelName){throw new Error(`'${kernelName}' not yet implemented or not found in the registry. `+`This kernel may not be supported by the tfjs backend you have chosen`)}function shuffle(array){let counter=array.length;let temp=0;let index=0;while(counter>0){index=Math.random()*counter|0;counter--;temp=array[counter];array[counter]=array[index];array[index]=temp}}function shuffleCombo(array,array2){if(array.length!==array2.length){throw new Error(`Array sizes must match to be shuffled together `+`First array length was ${array.length}`+`Second array length was ${array2.length}`)}let counter=array.length;let temp,temp2;let index=0;while(counter>0){index=Math.random()*counter|0;counter--;temp=array[counter];temp2=array2[counter];array[counter]=array[index];array2[counter]=array2[index];array[index]=temp;array2[index]=temp2}}function clamp(min,x,max){return Math.max(min,Math.min(x,max))}function nearestLargerEven(val){return val%2===0?val:val+1}function sum$2(arr){let sum=0;for(let i=0;i<arr.length;i++){sum+=arr[i]}return sum}function randUniform(a,b){const r=Math.random();return b*r+(1-r)*a}function distSquared(a,b){let result=0;for(let i=0;i<a.length;i++){const diff=Number(a[i])-Number(b[i]);result+=diff*diff}return result}function assert(expr,msg){if(!expr){throw new Error(typeof msg==="string"?msg:msg())}}function assertShapesMatch(shapeA,shapeB,errorMessagePrefix=""){assert(arraysEqual(shapeA,shapeB),(()=>errorMessagePrefix+` Shapes ${shapeA} and ${shapeB} must match`))}function assertNonNull(a){assert(a!=null,(()=>`The input to the tensor constructor must be a non-null value.`))}function flatten(arr,result=[],skipTypedArray=false){if(result==null){result=[]}if(Array.isArray(arr)||isTypedArray(arr)&&!skipTypedArray){for(let i=0;i<arr.length;++i){flatten(arr[i],result,skipTypedArray)}}else{result.push(arr)}return result}function sizeFromShape(shape){if(shape.length===0){return 1}let size=shape[0];for(let i=1;i<shape.length;i++){size*=shape[i]}return size}function isScalarShape(shape){return shape.length===0}function arraysEqual(n1,n2){if(n1===n2){return true}if(n1==null||n2==null){return false}if(n1.length!==n2.length){return false}for(let i=0;i<n1.length;i++){if(n1[i]!==n2[i]){return false}}return true}function isInt(a){return a%1===0}function tanh$2(x){if(Math.tanh!=null){return Math.tanh(x)}if(x===Infinity){return 1}else if(x===-Infinity){return-1}else{const e2x=Math.exp(2*x);return(e2x-1)/(e2x+1)}}function sizeToSquarishShape(size){const width=Math.ceil(Math.sqrt(size));return[width,Math.ceil(size/width)]}function createShuffledIndices(n){const shuffledIndices=new Uint32Array(n);for(let i=0;i<n;++i){shuffledIndices[i]=i}shuffle(shuffledIndices);return shuffledIndices}function rightPad(a,size){if(size<=a.length){return a}return a+" ".repeat(size-a.length)}function repeatedTry(checkFn,delayFn=(counter=>0),maxCounter){return new Promise(((resolve,reject)=>{let tryCount=0;const tryFn=()=>{if(checkFn()){resolve();return}tryCount++;const nextBackoff=delayFn(tryCount);if(maxCounter!=null&&tryCount>=maxCounter){reject();return}setTimeout(tryFn,nextBackoff)};tryFn()}))}function inferFromImplicitShape(shape,size){let shapeProd=1;let implicitIdx=-1;for(let i=0;i<shape.length;++i){if(shape[i]>=0){shapeProd*=shape[i]}else if(shape[i]===-1){if(implicitIdx!==-1){throw Error(`Shapes can only have 1 implicit size. `+`Found -1 at dim ${implicitIdx} and dim ${i}`)}implicitIdx=i}else if(shape[i]<0){throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`)}}if(implicitIdx===-1){if(size>0&&size!==shapeProd){throw Error(`Size(${size}) must match the product of shape ${shape}`)}return shape}if(shapeProd===0){throw Error(`Cannot infer the missing size in [${shape}] when `+`there are 0 elements`)}if(size%shapeProd!==0){throw Error(`The implicit shape can't be a fractional number. `+`Got ${size} / ${shapeProd}`)}const newShape=shape.slice();newShape[implicitIdx]=size/shapeProd;return newShape}function parseAxisParam(axis,shape){const rank=shape.length;axis=axis==null?shape.map(((s,i)=>i)):[].concat(axis);assert(axis.every((ax=>ax>=-rank&&ax<rank)),(()=>`All values in axis param must be in range [-${rank}, ${rank}) but `+`got axis ${axis}`));assert(axis.every((ax=>isInt(ax))),(()=>`All values in axis param must be integers but `+`got axis ${axis}`));return axis.map((a=>a<0?rank+a:a))}function squeezeShape(shape,axis){const newShape=[];const keptDims=[];const isEmptyArray=axis!=null&&Array.isArray(axis)&&axis.length===0;const axes=axis==null||isEmptyArray?null:parseAxisParam(axis,shape).sort();let j=0;for(let i=0;i<shape.length;++i){if(axes!=null){if(axes[j]===i&&shape[i]!==1){throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`)}if((axes[j]==null||axes[j]>i)&&shape[i]===1){newShape.push(shape[i]);keptDims.push(i)}if(axes[j]<=i){j++}}if(shape[i]!==1){newShape.push(shape[i]);keptDims.push(i)}}return{newShape:newShape,keptDims:keptDims}}function getTypedArrayFromDType(dtype,size){let values=null;if(dtype==null||dtype==="float32"){values=new Float32Array(size)}else if(dtype==="int32"){values=new Int32Array(size)}else if(dtype==="bool"){values=new Uint8Array(size)}else{throw new Error(`Unknown data type ${dtype}`)}return values}function getArrayFromDType(dtype,size){let values=null;if(dtype==null||dtype==="float32"){values=new Float32Array(size)}else if(dtype==="int32"){values=new Int32Array(size)}else if(dtype==="bool"){values=new Uint8Array(size)}else if(dtype==="string"){values=new Array(size)}else{throw new Error(`Unknown data type ${dtype}`)}return values}function checkConversionForErrors(vals,dtype){for(let i=0;i<vals.length;i++){const num=vals[i];if(isNaN(num)||!isFinite(num)){throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`)}}}function isValidDtype(dtype){return dtype==="bool"||dtype==="complex64"||dtype==="float32"||dtype==="int32"||dtype==="string"}function hasEncodingLoss(oldType,newType){if(newType==="complex64"){return false}if(newType==="float32"&&oldType!=="complex64"){return false}if(newType==="int32"&&oldType!=="float32"&&oldType!=="complex64"){return false}if(newType==="bool"&&oldType==="bool"){return false}return true}function isTypedArray(a){return a instanceof Float32Array||a instanceof Int32Array||a instanceof Uint8Array}function bytesPerElement(dtype){if(dtype==="float32"||dtype==="int32"){return 4}else if(dtype==="complex64"){return 8}else if(dtype==="bool"){return 1}else{throw new Error(`Unknown dtype ${dtype}`)}}function bytesFromStringArray(arr){if(arr==null){return 0}let bytes=0;arr.forEach((x=>bytes+=x.length));return bytes}function isString(value){return typeof value==="string"||value instanceof String}function isBoolean(value){return typeof value==="boolean"}function isNumber(value){return typeof value==="number"}function inferDtype(values){if(Array.isArray(values)){return inferDtype(values[0])}if(values instanceof Float32Array){return"float32"}else if(values instanceof Int32Array||values instanceof Uint8Array){return"int32"}else if(isNumber(values)){return"float32"}else if(isString(values)){return"string"}else if(isBoolean(values)){return"bool"}return"float32"}function isFunction(f){return!!(f&&f.constructor&&f.call&&f.apply)}function nearestDivisor(size,start){for(let i=start;i<size;++i){if(size%i===0){return i}}return size}function computeStrides(shape){const rank=shape.length;if(rank<2){return[]}const strides=new Array(rank-1);strides[rank-2]=shape[rank-1];for(let i=rank-3;i>=0;--i){strides[i]=strides[i+1]*shape[i+1]}return strides}function createNestedArray(offset,shape,a,isComplex=false){const ret=new Array;if(shape.length===1){const d=shape[0]*(isComplex?2:1);for(let i=0;i<d;i++){ret[i]=a[offset+i]}}else{const d=shape[0];const rest=shape.slice(1);const len=rest.reduce(((acc,c)=>acc*c))*(isComplex?2:1);for(let i=0;i<d;i++){ret[i]=createNestedArray(offset+i*len,rest,a,isComplex)}}return ret}function toNestedArray(shape,a,isComplex=false){if(shape.length===0){return a[0]}const size=shape.reduce(((acc,c)=>acc*c))*(isComplex?2:1);if(size===0){return[]}if(size!==a.length){throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex?" for a complex tensor":""}.`)}return createNestedArray(0,shape,a,isComplex)}function makeOnesTypedArray(size,dtype){const array=makeZerosTypedArray(size,dtype);for(let i=0;i<array.length;i++){array[i]=1}return array}function makeZerosTypedArray(size,dtype){if(dtype==null||dtype==="float32"||dtype==="complex64"){return new Float32Array(size)}else if(dtype==="int32"){return new Int32Array(size)}else if(dtype==="bool"){return new Uint8Array(size)}else{throw new Error(`Unknown data type ${dtype}`)}}function makeZerosNestedTypedArray(shape,dtype){const size=shape.reduce(((prev,curr)=>prev*curr),1);if(dtype==null||dtype==="float32"){return toNestedArray(shape,new Float32Array(size))}else if(dtype==="int32"){return toNestedArray(shape,new Int32Array(size))}else if(dtype==="bool"){return toNestedArray(shape,new Uint8Array(size))}else{throw new Error(`Unknown data type ${dtype}`)}}function assertNonNegativeIntegerDimensions(shape){shape.forEach((dimSize=>{assert(Number.isInteger(dimSize)&&dimSize>=0,(()=>`Tensor must have a shape comprised of positive integers but got `+`shape [${shape}].`))}))}function locToIndex(locs,rank,strides){if(rank===0){return 0}else if(rank===1){return locs[0]}let index=locs[locs.length-1];for(let i=0;i<locs.length-1;++i){index+=strides[i]*locs[i]}return index}function indexToLoc(index,rank,strides){if(rank===0){return[]}else if(rank===1){return[index]}const locs=new Array(rank);for(let i=0;i<locs.length-1;++i){locs[i]=Math.floor(index/strides[i]);index-=locs[i]*strides[i]}locs[locs.length-1]=index;return locs}function isPromise(object){return object&&object.then&&typeof object.then==="function"}const TENSORFLOWJS_FLAGS_PREFIX="tfjsflags";class Environment{constructor(global){this.global=global;this.flags={};this.flagRegistry={};this.urlFlags={};this.getQueryParams=getQueryParams;this.populateURLFlags()}setPlatform(platformName,platform){if(this.platform!=null){console.warn(`Platform ${this.platformName} has already been set. `+`Overwriting the platform with ${platform}.`)}this.platformName=platformName;this.platform=platform}registerFlag(flagName,evaluationFn,setHook){this.flagRegistry[flagName]={evaluationFn:evaluationFn,setHook:setHook};if(this.urlFlags[flagName]!=null){const flagValue=this.urlFlags[flagName];console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);this.set(flagName,flagValue)}}async getAsync(flagName){if(flagName in this.flags){return this.flags[flagName]}this.flags[flagName]=await this.evaluateFlag(flagName);return this.flags[flagName]}get(flagName){if(flagName in this.flags){return this.flags[flagName]}const flagValue=this.evaluateFlag(flagName);if(isPromise(flagValue)){throw new Error(`Flag ${flagName} cannot be synchronously evaluated. `+`Please use getAsync() instead.`)}this.flags[flagName]=flagValue;return this.flags[flagName]}getNumber(flagName){return this.get(flagName)}getBool(flagName){return this.get(flagName)}getFlags(){return this.flags}get features(){return this.flags}set(flagName,value){if(this.flagRegistry[flagName]==null){throw new Error(`Cannot set flag ${flagName} as it has not been registered.`)}this.flags[flagName]=value;if(this.flagRegistry[flagName].setHook!=null){this.flagRegistry[flagName].setHook(value)}}evaluateFlag(flagName){if(this.flagRegistry[flagName]==null){throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`)}return this.flagRegistry[flagName].evaluationFn()}setFlags(flags){this.flags=Object.assign({},flags)}reset(){this.flags={};this.urlFlags={};this.populateURLFlags()}populateURLFlags(){if(typeof this.global==="undefined"||typeof this.global.location==="undefined"||typeof this.global.location.search==="undefined"){return}const urlParams=this.getQueryParams(this.global.location.search);if(TENSORFLOWJS_FLAGS_PREFIX in urlParams){const keyValues=urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");keyValues.forEach((keyValue=>{const[key,value]=keyValue.split(":");this.urlFlags[key]=parseValue(key,value)}))}}}function getQueryParams(queryString){const params={};queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((s,...t)=>{decodeParam(params,t[0],t[1]);return t.join("=")}));return params}function decodeParam(params,name,value){params[decodeURIComponent(name)]=decodeURIComponent(value||"")}function parseValue(flagName,value){value=value.toLowerCase();if(value==="true"||value==="false"){return value==="true"}else if(`${+value}`===value){return+value}throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`)}function env(){return ENV$2}let ENV$2=null;function setEnvironmentGlobal(environment){ENV$2=environment}let globalNameSpace;function getGlobalNamespace(){if(globalNameSpace==null){let ns;if(typeof window!=="undefined"){ns=window}else if(typeof global!=="undefined"){ns=global}else if(typeof process!=="undefined"){ns=process}else if(typeof self!=="undefined"){ns=self}else{throw new Error("Could not find a global object")}globalNameSpace=ns}return globalNameSpace}function getGlobalMap(){const ns=getGlobalNamespace();if(ns._tfGlobals==null){ns._tfGlobals=new Map}return ns._tfGlobals}function getGlobal(key,init){const globalMap=getGlobalMap();if(globalMap.has(key)){return globalMap.get(key)}else{const singleton=init();globalMap.set(key,singleton);return globalMap.get(key)}}const Abs="Abs";const Acos="Acos";const Acosh="Acosh";const Add="Add";const AddN="AddN";const All="All";const Any="Any";const ArgMax="ArgMax";const ArgMin="ArgMin";const Asin="Asin";const Asinh="Asinh";const Atan="Atan";const Atanh="Atanh";const Atan2="Atan2";const AvgPool="AvgPool";const AvgPoolGrad="AvgPoolGrad";const AvgPool3D="AvgPool3D";const AvgPool3DGrad="AvgPool3DGrad";const BatchMatMul="BatchMatMul";const BatchToSpaceND="BatchToSpaceND";const Bincount="Bincount";const BroadcastTo="BroadcastTo";const Cast="Cast";const Ceil="Ceil";const ClipByValue="ClipByValue";const Complex="Complex";const ComplexAbs="ComplexAbs";const Concat="Concat";const Conv2D="Conv2D";const Conv2DBackpropFilter="Conv2DBackpropFilter";const Conv2DBackpropInput="Conv2DBackpropInput";const Conv3D="Conv3D";const Conv3DBackpropFilterV2="Conv3DBackpropFilterV2";const Conv3DBackpropInputV2="Conv3DBackpropInputV2";const Cos="Cos";const Cosh="Cosh";const Cumsum="Cumsum";const CropAndResize="CropAndResize";const DenseBincount="DenseBincount";const DepthToSpace="DepthToSpace";const DepthwiseConv2dNative="DepthwiseConv2dNative";const DepthwiseConv2dNativeBackpropFilter="DepthwiseConv2dNativeBackpropFilter";const DepthwiseConv2dNativeBackpropInput="DepthwiseConv2dNativeBackpropInput";const Diag="Diag";const Dilation2D="Dilation2D";const Dilation2DBackpropInput="Dilation2DBackpropInput";const Dilation2DBackpropFilter="Dilation2DBackpropFilter";const RealDiv="RealDiv";const Einsum="Einsum";const Elu="Elu";const EluGrad="EluGrad";const Erf="Erf";const Equal="Equal";const Exp="Exp";const ExpandDims="ExpandDims";const Expm1="Expm1";const FFT="FFT";const Fill="Fill";const FlipLeftRight="FlipLeftRight";const Floor="Floor";const FloorDiv="FloorDiv";const FusedBatchNorm="FusedBatchNorm";const GatherV2="GatherV2";const GatherNd="GatherNd";const Greater="Greater";const GreaterEqual="GreaterEqual";const Identity="Identity";const IFFT="IFFT";const Imag="Imag";const IsFinite="IsFinite";const IsInf="IsInf";const IsNan="IsNan";const LeakyRelu="LeakyRelu";const Less="Less";const LessEqual="LessEqual";const LinSpace="LinSpace";const Log="Log";const Log1p="Log1p";const LogicalAnd="LogicalAnd";const LogicalNot="LogicalNot";const LogicalOr="LogicalOr";const LogSoftmax="LogSoftmax";const LRN="LRN";const LRNGrad="LRNGrad";const Max="Max";const Maximum="Maximum";const MaxPool="MaxPool";const MaxPoolGrad="MaxPoolGrad";const MaxPool3D="MaxPool3D";const MaxPool3DGrad="MaxPool3DGrad";const MaxPoolWithArgmax="MaxPoolWithArgmax";const Mean="Mean";const Min="Min";const Minimum="Minimum";const MirrorPad="MirrorPad";const Mod="Mod";const Multinomial="Multinomial";const Multiply="Multiply";const Neg="Neg";const NotEqual="NotEqual";const NonMaxSuppressionV3="NonMaxSuppressionV3";const NonMaxSuppressionV4="NonMaxSuppressionV4";const NonMaxSuppressionV5="NonMaxSuppressionV5";const OnesLike="OnesLike";const OneHot="OneHot";const Pack="Pack";const PadV2="PadV2";const Pool="Pool";const Pow="Pow";const Prelu="Prelu";const Prod="Prod";const Range="Range";const Real="Real";const Reciprocal="Reciprocal";const Relu="Relu";const Reshape="Reshape";const ResizeNearestNeighbor="ResizeNearestNeighbor";const ResizeNearestNeighborGrad="ResizeNearestNeighborGrad";const ResizeBilinear="ResizeBilinear";const ResizeBilinearGrad="ResizeBilinearGrad";const Relu6="Relu6";const Reverse="Reverse";const Round="Round";const Rsqrt="Rsqrt";const ScatterNd="ScatterNd";const Select="Select";const Selu="Selu";const Slice="Slice";const Sin="Sin";const Sinh="Sinh";const Sign="Sign";const Sigmoid="Sigmoid";const Softplus="Softplus";const Sqrt="Sqrt";const Sum="Sum";const SpaceToBatchND="SpaceToBatchND";const SplitV="SplitV";const Softmax="Softmax";const SparseFillEmptyRows="SparseFillEmptyRows";const SparseReshape="SparseReshape";const SparseToDense="SparseToDense";const SquaredDifference="SquaredDifference";const Square="Square";const StridedSlice="StridedSlice";const Sub="Sub";const Tan="Tan";const Tanh="Tanh";const Tile="Tile";const TopK="TopK";const Transform="Transform";const Transpose="Transpose";const Unique="Unique";const Unpack="Unpack";const UnsortedSegmentSum="UnsortedSegmentSum";const ZerosLike="ZerosLike";const Step="Step";const FromPixels="FromPixels";const RotateWithOffset="RotateWithOffset";const _FusedMatMul="_FusedMatMul";const FusedConv2D="FusedConv2D";const FusedDepthwiseConv2D="FusedDepthwiseConv2D";const kernelRegistry=getGlobal("kernelRegistry",(()=>new Map));const gradRegistry=getGlobal("gradRegistry",(()=>new Map));function getKernel(kernelName,backendName){const key=makeKey(kernelName,backendName);return kernelRegistry.get(key)}function getGradient(kernelName){return gradRegistry.get(kernelName)}function getKernelsForBackend(backendName){const it=kernelRegistry.entries();const result=[];while(true){const{done:done,value:value}=it.next();if(done){break}const[key,config]=value;const[backend]=key.split("_");if(backend===backendName){result.push(config)}}return result}function registerKernel(config){const{kernelName:kernelName,backendName:backendName}=config;const key=makeKey(kernelName,backendName);if(kernelRegistry.has(key)){console.warn(`The kernel '${kernelName}' for backend `+`'${backendName}' is already registered`)}kernelRegistry.set(key,config)}function registerGradient(config){const{kernelName:kernelName}=config;if(gradRegistry.has(kernelName)){if(env().getBool("DEBUG")){console.warn(`Overriding the gradient for '${kernelName}'`)}}gradRegistry.set(kernelName,config)}function unregisterKernel(kernelName,backendName){const key=makeKey(kernelName,backendName);if(!kernelRegistry.has(key)){throw new Error(`The kernel '${kernelName}' for backend `+`'${backendName}' is not registered`)}kernelRegistry.delete(key)}function unregisterGradient(kernelName){if(!gradRegistry.has(kernelName)){throw new Error(`The gradient '${kernelName}' for backend is not registered`)}gradRegistry.delete(kernelName)}function copyRegisteredKernels(registeredBackendName,newBackendName){const kernels=getKernelsForBackend(registeredBackendName);kernels.forEach((kernelConfig=>{const newKernelConfig=Object.assign({},kernelConfig,{backendName:newBackendName});registerKernel(newKernelConfig)}))}function makeKey(kernelName,backendName){return`${backendName}_${kernelName}`}function createScalarValue(value,dtype){if(dtype==="string"){return encodeString(value)}return toTypedArray([value],dtype)}function noConversionNeeded(a,dtype){return a instanceof Float32Array&&dtype==="float32"||a instanceof Int32Array&&dtype==="int32"||a instanceof Uint8Array&&dtype==="bool"}function toTypedArray(a,dtype){if(dtype==="string"){throw new Error("Cannot convert a string[] to a TypedArray")}if(Array.isArray(a)){a=flatten(a)}if(env().getBool("DEBUG")){checkConversionForErrors(a,dtype)}if(noConversionNeeded(a,dtype)){return a}if(dtype==null||dtype==="float32"||dtype==="complex64"){return new Float32Array(a)}else if(dtype==="int32"){return new Int32Array(a)}else if(dtype==="bool"){const bool=new Uint8Array(a.length);for(let i=0;i<bool.length;++i){if(Math.round(a[i])!==0){bool[i]=1}}return bool}else{throw new Error(`Unknown data type ${dtype}`)}}function now(){return env().platform.now()}function fetch$1(path,requestInits){return env().platform.fetch(path,requestInits)}function encodeString(s,encoding="utf-8"){encoding=encoding||"utf-8";return env().platform.encode(s,encoding)}function decodeString(bytes,encoding="utf-8"){encoding=encoding||"utf-8";return env().platform.decode(bytes,encoding)}var util=Object.freeze({__proto__:null,createScalarValue:createScalarValue,toTypedArray:toTypedArray,now:now,fetch:fetch$1,encodeString:encodeString,decodeString:decodeString,shuffle:shuffle,shuffleCombo:shuffleCombo,clamp:clamp,nearestLargerEven:nearestLargerEven,sum:sum$2,randUniform:randUniform,distSquared:distSquared,assert:assert,assertShapesMatch:assertShapesMatch,assertNonNull:assertNonNull,flatten:flatten,sizeFromShape:sizeFromShape,isScalarShape:isScalarShape,arraysEqual:arraysEqual,isInt:isInt,tanh:tanh$2,sizeToSquarishShape:sizeToSquarishShape,createShuffledIndices:createShuffledIndices,rightPad:rightPad,repeatedTry:repeatedTry,inferFromImplicitShape:inferFromImplicitShape,parseAxisParam:parseAxisParam,squeezeShape:squeezeShape,getTypedArrayFromDType:getTypedArrayFromDType,getArrayFromDType:getArrayFromDType,checkConversionForErrors:checkConversionForErrors,isValidDtype:isValidDtype,hasEncodingLoss:hasEncodingLoss,isTypedArray:isTypedArray,bytesPerElement:bytesPerElement,bytesFromStringArray:bytesFromStringArray,isString:isString,isBoolean:isBoolean,isNumber:isNumber,inferDtype:inferDtype,isFunction:isFunction,nearestDivisor:nearestDivisor,computeStrides:computeStrides,toNestedArray:toNestedArray,makeOnesTypedArray:makeOnesTypedArray,makeZerosTypedArray:makeZerosTypedArray,makeZerosNestedTypedArray:makeZerosNestedTypedArray,assertNonNegativeIntegerDimensions:assertNonNegativeIntegerDimensions,locToIndex:locToIndex,indexToLoc:indexToLoc,isPromise:isPromise});class Profiler{constructor(backendTimer,logger){this.backendTimer=backendTimer;this.logger=logger;if(logger==null){this.logger=new Logger}}profileKernel(kernelName,inputs,f){let outputs;const holdResultWrapperFn=()=>{outputs=f()};let timer;const start=now();if(this.backendTimer.timerAvailable()){timer=this.backendTimer.time(holdResultWrapperFn)}else{holdResultWrapperFn();for(const output of outputs){output.dataSync()}timer=Promise.resolve({kernelMs:now()-start})}if(env().getBool("CHECK_COMPUTATION_FOR_ERRORS")){for(let i=0;i<outputs.length;i++){const output=outputs[i];output.data().then((tensorVals=>{checkComputationForErrors(tensorVals,output.dtype,kernelName)}))}}const kernelProfile={kernelName:kernelName,outputs:outputs,inputs:inputs,timeMs:timer.then((timing=>timing.kernelMs)),extraInfo:timer.then((timing=>timing.getExtraProfileInfo!=null?timing.getExtraProfileInfo():""))};return kernelProfile}logKernelProfile(kernelProfile){const{kernelName:kernelName,outputs:outputs,timeMs:timeMs,inputs:inputs,extraInfo:extraInfo}=kernelProfile;outputs.forEach((result=>{Promise.all([result.data(),timeMs,extraInfo]).then((valueContainer=>{this.logger.logKernelProfile(kernelName,result,valueContainer[0],valueContainer[1],inputs,valueContainer[2])}))}))}}function checkComputationForErrors(vals,dtype,kernelName){if(dtype!=="float32"){return false}for(let i=0;i<vals.length;i++){const num=vals[i];if(isNaN(num)||!isFinite(num)){console.warn(`Found ${num} in the result of '${kernelName}'`);return true}}return false}class Logger{logKernelProfile(name,result,vals,timeMs,inputs,extraInfo){const time=typeof timeMs==="number"?rightPad(`${timeMs}ms`,9):timeMs["error"];const paddedName=rightPad(name,25);const rank=result.rank;const size=result.size;const shape=rightPad(result.shape.toString(),14);let inputShapesDescription="";for(const name in inputs){const input=inputs[name];if(input!=null){const inputShape=input.shape||result.shape;const inputRank=inputShape.length;inputShapesDescription+=`${name}: ${inputRank}D ${inputRank>0?inputShape:""} `}}console.log(`%c${paddedName}\t%c${time}\t%c${rank}D ${shape}\t%c${size}\t%c${inputShapesDescription}\t%c${extraInfo}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function getFilteredNodesXToY(tape,xs,y){const tensorsFromX={};const nodesFromX={};for(let i=0;i<xs.length;i++){tensorsFromX[xs[i].id]=true}for(let i=0;i<tape.length;i++){const node=tape[i];const nodeInputs=node.inputs;for(const inputName in nodeInputs){const input=nodeInputs[inputName];let anyInputFromX=false;for(let j=0;j<xs.length;j++){if(tensorsFromX[input.id]){node.outputs.forEach((output=>tensorsFromX[output.id]=true));anyInputFromX=true;nodesFromX[node.id]=true;break}}if(anyInputFromX){break}}}const tensorsLeadToY={};tensorsLeadToY[y.id]=true;const nodesToY={};for(let i=tape.length-1;i>=0;i--){const node=tape[i];const nodeInputs=node.inputs;for(let j=0;j<node.outputs.length;j++){if(tensorsLeadToY[node.outputs[j].id]){for(const inputName in nodeInputs){tensorsLeadToY[nodeInputs[inputName].id]=true;nodesToY[node.id]=true}break}}}const filteredTape=[];for(let i=0;i<tape.length;i++){const node=tape[i];if(nodesFromX[node.id]&&nodesToY[node.id]){const prunedInputs={};for(const inputName in node.inputs){const nodeInput=node.inputs[inputName];if(tensorsFromX[nodeInput.id]){prunedInputs[inputName]=nodeInput}}const prunedNode=Object.assign({},node);prunedNode.inputs=prunedInputs;prunedNode.outputs=node.outputs;filteredTape.push(prunedNode)}}return filteredTape}function backpropagateGradients(tensorAccumulatedGradientMap,filteredTape,tidy,add){for(let i=filteredTape.length-1;i>=0;i--){const node=filteredTape[i];const dys=[];node.outputs.forEach((o=>{const gradTensor=tensorAccumulatedGradientMap[o.id];if(gradTensor!=null){dys.push(gradTensor)}else{dys.push(null)}}));if(node.gradient==null){throw new Error(`Cannot compute gradient: gradient function not found `+`for ${node.kernelName}.`)}const inputGradients=node.gradient(dys);for(const inputName in node.inputs){if(!(inputName in inputGradients)){throw new Error(`Cannot backprop through input ${inputName}. `+`Available gradients found: ${Object.keys(inputGradients)}.`)}const dx=tidy((()=>inputGradients[inputName]()));if(dx.dtype!=="float32"){throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input `+`${inputName} must have 'float32' dtype, but has '${dx.dtype}'`)}const x=node.inputs[inputName];if(!arraysEqual(dx.shape,x.shape)){throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input `+`'${inputName}' has shape '${dx.shape}', which does not match `+`the shape of the input '${x.shape}'`)}if(tensorAccumulatedGradientMap[x.id]==null){tensorAccumulatedGradientMap[x.id]=dx}else{const curGradient=tensorAccumulatedGradientMap[x.id];tensorAccumulatedGradientMap[x.id]=add(curGradient,dx);curGradient.dispose()}}}}const FORMAT_LIMIT_NUM_VALS=20;const FORMAT_NUM_FIRST_LAST_VALS=3;const FORMAT_NUM_SIG_DIGITS=7;function tensorToString(vals,shape,dtype,verbose){const strides=computeStrides(shape);const padPerCol=computeMaxSizePerColumn(vals,shape,dtype,strides);const rank=shape.length;const valsLines=subTensorToString(vals,shape,dtype,strides,padPerCol);const lines=["Tensor"];if(verbose){lines.push(`  dtype: ${dtype}`);lines.push(`  rank: ${rank}`);lines.push(`  shape: [${shape}]`);lines.push(`  values:`)}lines.push(valsLines.map((l=>"    "+l)).join("\n"));return lines.join("\n")}function computeMaxSizePerColumn(vals,shape,dtype,strides){const n=sizeFromShape(shape);const numCols=strides[strides.length-1];const padPerCol=new Array(numCols).fill(0);const rank=shape.length;const valuesOrTuples=dtype==="complex64"?createComplexTuples(vals):vals;if(rank>1){for(let row=0;row<n/numCols;row++){const offset=row*numCols;for(let j=0;j<numCols;j++){padPerCol[j]=Math.max(padPerCol[j],valToString(valuesOrTuples[offset+j],0,dtype).length)}}}return padPerCol}function valToString(val,pad,dtype){let valStr;if(Array.isArray(val)){valStr=`${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + `+`${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`}else if(isString(val)){valStr=`'${val}'`}else if(dtype==="bool"){valStr=boolNumToString(val)}else{valStr=parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString()}return rightPad(valStr,pad)}function boolNumToString(v){return v===0?"false":"true"}function subTensorToString(vals,shape,dtype,strides,padPerCol,isLast=true){const storagePerElement=dtype==="complex64"?2:1;const size=shape[0];const rank=shape.length;if(rank===0){if(dtype==="complex64"){const complexTuple=createComplexTuples(vals);return[valToString(complexTuple[0],0,dtype)]}if(dtype==="bool"){return[boolNumToString(vals[0])]}return[vals[0].toString()]}if(rank===1){if(size>FORMAT_LIMIT_NUM_VALS){const firstValsSize=FORMAT_NUM_FIRST_LAST_VALS*storagePerElement;let firstVals=Array.from(vals.slice(0,firstValsSize));let lastVals=Array.from(vals.slice((size-FORMAT_NUM_FIRST_LAST_VALS)*storagePerElement,size*storagePerElement));if(dtype==="complex64"){firstVals=createComplexTuples(firstVals);lastVals=createComplexTuples(lastVals)}return["["+firstVals.map(((x,i)=>valToString(x,padPerCol[i],dtype))).join(", ")+", ..., "+lastVals.map(((x,i)=>valToString(x,padPerCol[size-FORMAT_NUM_FIRST_LAST_VALS+i],dtype))).join(", ")+"]"]}const displayVals=dtype==="complex64"?createComplexTuples(vals):Array.from(vals);return["["+displayVals.map(((x,i)=>valToString(x,padPerCol[i],dtype))).join(", ")+"]"]}const subshape=shape.slice(1);const substrides=strides.slice(1);const stride=strides[0]*storagePerElement;const lines=[];if(size>FORMAT_LIMIT_NUM_VALS){for(let i=0;i<FORMAT_NUM_FIRST_LAST_VALS;i++){const start=i*stride;const end=start+stride;lines.push(...subTensorToString(vals.slice(start,end),subshape,dtype,substrides,padPerCol,false))}lines.push("...");for(let i=size-FORMAT_NUM_FIRST_LAST_VALS;i<size;i++){const start=i*stride;const end=start+stride;lines.push(...subTensorToString(vals.slice(start,end),subshape,dtype,substrides,padPerCol,i===size-1))}}else{for(let i=0;i<size;i++){const start=i*stride;const end=start+stride;lines.push(...subTensorToString(vals.slice(start,end),subshape,dtype,substrides,padPerCol,i===size-1))}}const sep=rank===2?",":"";lines[0]="["+lines[0]+sep;for(let i=1;i<lines.length-1;i++){lines[i]=" "+lines[i]+sep}let newLineSep=",\n";for(let i=2;i<rank;i++){newLineSep+="\n"}lines[lines.length-1]=" "+lines[lines.length-1]+"]"+(isLast?"":newLineSep);return lines}function createComplexTuples(vals){const complexTuples=[];for(let i=0;i<vals.length;i+=2){complexTuples.push([vals[i],vals[i+1]])}return complexTuples}class TensorBuffer{constructor(shape,dtype,values){this.dtype=dtype;this.shape=shape.slice();this.size=sizeFromShape(shape);if(values!=null){const n=values.length;assert(n===this.size,(()=>`Length of values '${n}' does not match the size `+`inferred by the shape '${this.size}'.`))}if(dtype==="complex64"){throw new Error(`complex64 dtype TensorBuffers are not supported. Please create `+`a TensorBuffer for the real and imaginary parts separately and `+`call tf.complex(real, imag).`)}this.values=values||getArrayFromDType(dtype,this.size);this.strides=computeStrides(shape)}set(value,...locs){if(locs.length===0){locs=[0]}assert(locs.length===this.rank,(()=>`The number of provided coordinates (${locs.length}) must `+`match the rank (${this.rank})`));const index=this.locToIndex(locs);this.values[index]=value}get(...locs){if(locs.length===0){locs=[0]}let i=0;for(const loc of locs){if(loc<0||loc>=this.shape[i]){const msg=`Requested out of range element at ${locs}. `+`  Buffer shape=${this.shape}`;throw new Error(msg)}i++}let index=locs[locs.length-1];for(let i=0;i<locs.length-1;++i){index+=this.strides[i]*locs[i]}return this.values[index]}locToIndex(locs){if(this.rank===0){return 0}else if(this.rank===1){return locs[0]}let index=locs[locs.length-1];for(let i=0;i<locs.length-1;++i){index+=this.strides[i]*locs[i]}return index}indexToLoc(index){if(this.rank===0){return[]}else if(this.rank===1){return[index]}const locs=new Array(this.shape.length);for(let i=0;i<locs.length-1;++i){locs[i]=Math.floor(index/this.strides[i]);index-=locs[i]*this.strides[i]}locs[locs.length-1]=index;return locs}get rank(){return this.shape.length}toTensor(){return trackerFn().makeTensor(this.values,this.shape,this.dtype)}}let trackerFn=null;let opHandler$1=null;function setTensorTracker(fn){trackerFn=fn}function setOpHandler(handler){opHandler$1=handler}class Tensor{constructor(shape,dtype,dataId,id){this.kept=false;this.isDisposedInternal=false;this.shape=shape.slice();this.dtype=dtype||"float32";this.size=sizeFromShape(shape);this.strides=computeStrides(shape);this.dataId=dataId;this.id=id;this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const vals=await this.data();return opHandler$1.buffer(this.shape,this.dtype,vals)}bufferSync(){return opHandler$1.buffer(this.shape,this.dtype,this.dataSync())}async array(){const vals=await this.data();return toNestedArray(this.shape,vals,this.dtype==="complex64")}arraySync(){return toNestedArray(this.shape,this.dataSync(),this.dtype==="complex64")}async data(){this.throwIfDisposed();const data=trackerFn().read(this.dataId);if(this.dtype==="string"){const bytes=await data;try{return bytes.map((b=>decodeString(b)))}catch(_a){throw new Error("Failed to decode the string bytes into utf-8. "+"To get the original bytes, call tensor.bytes().")}}return data}dataSync(){this.throwIfDisposed();const data=trackerFn().readSync(this.dataId);if(this.dtype==="string"){try{return data.map((b=>decodeString(b)))}catch(_a){throw new Error("Failed to decode the string bytes into utf-8. "+"To get the original bytes, call tensor.bytes().")}}return data}async bytes(){this.throwIfDisposed();const data=await trackerFn().read(this.dataId);if(this.dtype==="string"){return data}else{return new Uint8Array(data.buffer)}}dispose(){if(this.isDisposed){return}trackerFn().disposeTensor(this);this.isDisposedInternal=true}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed){throw new Error(`Tensor is disposed.`)}}print(verbose=false){return opHandler$1.print(this,verbose)}clone(){this.throwIfDisposed();return opHandler$1.clone(this)}toString(verbose=false){const vals=this.dataSync();return tensorToString(vals,this.shape,this.dtype,verbose)}cast(dtype){this.throwIfDisposed();return opHandler$1.cast(this,dtype)}variable(trainable=true,name,dtype){this.throwIfDisposed();return trackerFn().makeVariable(this,trainable,name,dtype)}}Object.defineProperty(Tensor,Symbol.hasInstance,{value:instance=>!!instance&&instance.data!=null&&instance.dataSync!=null&&instance.throwIfDisposed!=null});function getGlobalTensorClass(){return getGlobal("Tensor",(()=>Tensor))}getGlobalTensorClass();class Variable extends Tensor{constructor(initialValue,trainable,name,tensorId){super(initialValue.shape,initialValue.dtype,initialValue.dataId,tensorId);this.trainable=trainable;this.name=name}assign(newValue){if(newValue.dtype!==this.dtype){throw new Error(`dtype of the new value (${newValue.dtype}) and `+`previous value (${this.dtype}) must match`)}if(!arraysEqual(newValue.shape,this.shape)){throw new Error(`shape of the new value (${newValue.shape}) and `+`previous value (${this.shape}) must match`)}trackerFn().disposeTensor(this);this.dataId=newValue.dataId;trackerFn().incRef(this,null)}dispose(){trackerFn().disposeVariable(this);this.isDisposedInternal=true}}Object.defineProperty(Variable,Symbol.hasInstance,{value:instance=>instance instanceof Tensor&&instance.assign!=null&&instance.assign instanceof Function});var Rank;(function(Rank){Rank["R0"]="R0";Rank["R1"]="R1";Rank["R2"]="R2";Rank["R3"]="R3";Rank["R4"]="R4";Rank["R5"]="R5";Rank["R6"]="R6"})(Rank||(Rank={}));var UpcastInt32AndMap;(function(UpcastInt32AndMap){UpcastInt32AndMap["float32"]="float32";UpcastInt32AndMap["int32"]="int32";UpcastInt32AndMap["bool"]="int32";UpcastInt32AndMap["complex64"]="complex64"})(UpcastInt32AndMap||(UpcastInt32AndMap={}));var UpcastBoolAndMap;(function(UpcastBoolAndMap){UpcastBoolAndMap["float32"]="float32";UpcastBoolAndMap["int32"]="int32";UpcastBoolAndMap["bool"]="bool";UpcastBoolAndMap["complex64"]="complex64"})(UpcastBoolAndMap||(UpcastBoolAndMap={}));var UpcastFloat32AndMap;(function(UpcastFloat32AndMap){UpcastFloat32AndMap["float32"]="float32";UpcastFloat32AndMap["int32"]="float32";UpcastFloat32AndMap["bool"]="float32";UpcastFloat32AndMap["complex64"]="complex64"})(UpcastFloat32AndMap||(UpcastFloat32AndMap={}));var UpcastComplex64AndMap;(function(UpcastComplex64AndMap){UpcastComplex64AndMap["float32"]="complex64";UpcastComplex64AndMap["int32"]="complex64";UpcastComplex64AndMap["bool"]="complex64";UpcastComplex64AndMap["complex64"]="complex64"})(UpcastComplex64AndMap||(UpcastComplex64AndMap={}));const upcastTypeMap={float32:UpcastFloat32AndMap,int32:UpcastInt32AndMap,bool:UpcastBoolAndMap,complex64:UpcastComplex64AndMap};function upcastType(typeA,typeB){if(typeA==="string"||typeB==="string"){if(typeA==="string"&&typeB==="string"){return"string"}throw new Error(`Can not upcast ${typeA} with ${typeB}`)}return upcastTypeMap[typeA][typeB]}function sumOutType(type){return upcastType(type,"int32")}function makeTypesMatch(a,b){if(a.dtype===b.dtype){return[a,b]}const dtype=upcastType(a.dtype,b.dtype);return[a.cast(dtype),b.cast(dtype)]}function assertTypesMatch(a,b){assert(a.dtype===b.dtype,(()=>`The dtypes of the first(${a.dtype}) and`+` second(${b.dtype}) input must match`))}function isTensorInList(tensor,tensorList){return tensorList.some((x=>x.id===tensor.id))}function getTensorsInContainer(result){const list=[];const seen=new Set;walkTensorContainer(result,list,seen);return list}function walkTensorContainer(container,list,seen){if(container==null){return}if(container instanceof Tensor){list.push(container);return}if(!isIterable(container)){return}const iterable=container;for(const k in iterable){const val=iterable[k];if(!seen.has(val)){seen.add(val);walkTensorContainer(val,list,seen)}}}function isIterable(obj){return Array.isArray(obj)||typeof obj==="object"}var tensor_util=Object.freeze({__proto__:null,makeTypesMatch:makeTypesMatch,assertTypesMatch:assertTypesMatch,isTensorInList:isTensorInList,getTensorsInContainer:getTensorsInContainer});function isRegisteredKernelInvocation(kernelInvocation){return kernelInvocation.kernelName!=null}class EngineState{constructor(){this.registeredVariables={};this.nextTapeNodeId=0;this.numBytes=0;this.numTensors=0;this.numStringTensors=0;this.numDataBuffers=0;this.gradientDepth=0;this.kernelDepth=0;this.scopeStack=[];this.numDataMovesStack=[];this.nextScopeId=0;this.tensorInfo=new WeakMap;this.profiling=false;this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map((k=>k.name))))}}}dispose(){for(const variableName in this.registeredVariables){this.registeredVariables[variableName].dispose()}}}class Engine{constructor(ENV){this.ENV=ENV;this.registry={};this.registryFactory={};this.pendingBackendInitId=0;this.state=new EngineState}async ready(){if(this.pendingBackendInit!=null){return this.pendingBackendInit.then((()=>{}))}if(this.backendInstance!=null){return}const sortedBackends=this.getSortedBackends();for(let i=0;i<sortedBackends.length;i++){const backendName=sortedBackends[i];const success=await this.initializeBackend(backendName).success;if(success){await this.setBackend(backendName);return}}throw new Error(`Could not initialize any backends, all backend initializations `+`failed.`)}get backend(){if(this.pendingBackendInit!=null){throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make `+`sure to await tf.ready() or await tf.setBackend() before calling `+`other methods`)}if(this.backendInstance==null){const{name:name,asyncInit:asyncInit}=this.initializeBackendsAndReturnBest();if(asyncInit){throw new Error(`The highest priority backend '${name}' has not yet been `+`initialized. Make sure to await tf.ready() or `+`await tf.setBackend() before calling other methods`)}this.setBackend(name)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(backendName){if(!(backendName in this.registry)){if(backendName in this.registryFactory){const{asyncInit:asyncInit}=this.initializeBackend(backendName);if(asyncInit){return null}}else{return null}}return this.registry[backendName]}findBackendFactory(backendName){if(!(backendName in this.registryFactory)){return null}return this.registryFactory[backendName].factory}registerBackend(backendName,factory,priority=1){if(backendName in this.registryFactory){console.warn(`${backendName} backend was already registered. `+`Reusing existing backend factory.`);return false}this.registryFactory[backendName]={factory:factory,priority:priority};return true}async setBackend(backendName){if(this.registryFactory[backendName]==null){throw new Error(`Backend name '${backendName}' not found in registry`)}this.backendName=backendName;if(this.registry[backendName]==null){this.backendInstance=null;const{success:success,asyncInit:asyncInit}=this.initializeBackend(backendName);const result=asyncInit?await success:success;if(!result){return false}}this.backendInstance=this.registry[backendName];this.setupRegisteredKernels();this.profiler=new Profiler(this.backendInstance);return true}setupRegisteredKernels(){const kernels=getKernelsForBackend(this.backendName);kernels.forEach((kernel=>{if(kernel.setupFunc!=null){kernel.setupFunc(this.backendInstance)}}))}disposeRegisteredKernels(backendName){const kernels=getKernelsForBackend(backendName);kernels.forEach((kernel=>{if(kernel.disposeFunc!=null){kernel.disposeFunc(this.registry[backendName])}}))}initializeBackend(backendName){const registryFactoryEntry=this.registryFactory[backendName];if(registryFactoryEntry==null){throw new Error(`Cannot initialize backend ${backendName}, no registration found.`)}try{const backend=registryFactoryEntry.factory();if(backend&&!(backend instanceof KernelBackend)&&typeof backend.then==="function"){const promiseId=++this.pendingBackendInitId;const success=backend.then((backendInstance=>{if(promiseId<this.pendingBackendInitId){return false}this.registry[backendName]=backendInstance;this.pendingBackendInit=null;return true})).catch((err=>{if(promiseId<this.pendingBackendInitId){return false}this.pendingBackendInit=null;console.warn(`Initialization of backend ${backendName} failed`);console.warn(err.stack||err.message);return false}));this.pendingBackendInit=success;return{success:success,asyncInit:true}}else{this.registry[backendName]=backend;return{success:true,asyncInit:false}}}catch(err){console.warn(`Initialization of backend ${backendName} failed`);console.warn(err.stack||err.message);return{success:false,asyncInit:false}}}removeBackend(backendName){if(!(backendName in this.registryFactory)){throw new Error(`${backendName} backend not found in registry`)}if(this.backendName===backendName&&this.pendingBackendInit!=null){this.pendingBackendInitId++}if(backendName in this.registry){this.disposeRegisteredKernels(backendName);this.registry[backendName].dispose();delete this.registry[backendName]}delete this.registryFactory[backendName];if(this.backendName===backendName){this.pendingBackendInit=null;this.backendName=null;this.backendInstance=null}}getSortedBackends(){if(Object.keys(this.registryFactory).length===0){throw new Error("No backend found in registry.")}return Object.keys(this.registryFactory).sort(((a,b)=>this.registryFactory[b].priority-this.registryFactory[a].priority))}initializeBackendsAndReturnBest(){const sortedBackends=this.getSortedBackends();for(let i=0;i<sortedBackends.length;i++){const backendName=sortedBackends[i];const{success:success,asyncInit:asyncInit}=this.initializeBackend(backendName);if(asyncInit||success){return{name:backendName,asyncInit:asyncInit}}}throw new Error(`Could not initialize any backends, all backend initializations `+`failed.`)}moveData(backend,dataId){const info=this.state.tensorInfo.get(dataId);const srcBackend=info.backend;const values=this.readSync(dataId);const refCount=srcBackend.refCount(dataId);srcBackend.disposeData(dataId,true);info.backend=backend;backend.move(dataId,values,info.shape,info.dtype,refCount);if(this.shouldCheckForMemLeaks()){this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}}tidy(nameOrFn,fn){let name=null;if(fn==null){if(typeof nameOrFn!=="function"){throw new Error("Please provide a function to tidy()")}fn=nameOrFn}else{if(typeof nameOrFn!=="string"&&!(nameOrFn instanceof String)){throw new Error("When calling with two arguments, the first argument "+"to tidy() must be a string")}if(typeof fn!=="function"){throw new Error("When calling with two arguments, the 2nd argument "+"to tidy() must be a function")}name=nameOrFn}let result;return this.scopedRun((()=>this.startScope(name)),(()=>this.endScope(result)),(()=>{result=fn();if(result instanceof Promise){console.error("Cannot return a Promise inside of tidy.")}return result}))}scopedRun(start,end,f){start();try{const res=f();end();return res}catch(ex){end();throw ex}}nextTensorId(){return Engine.nextTensorId++}nextVariableId(){return Engine.nextVariableId++}clone(x){const y=ENGINE.runKernel(Identity,{x:x});const inputs={x:x};const grad=dy=>({x:()=>{const dtype="float32";const gradInputs={x:dy};const attrs={dtype:dtype};return ENGINE.runKernel(Cast,gradInputs,attrs)}});const saved=[];this.addTapeNode(this.state.activeScope.name,inputs,[y],grad,saved,{});return y}runKernel(kernelName,inputs,attrs){const hasKernel=getKernel(kernelName,this.backendName)!=null;if(!hasKernel){throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`)}return this.runKernelFunc({kernelName:kernelName,inputs:inputs,attrs:attrs})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(kernelName,numDataIdsBefore,outInfos){const numDataIdsAfter=this.backend.numDataIds();let numOutputDataIds=0;outInfos.forEach((info=>{numOutputDataIds+=info.dtype==="complex64"?3:1}));const numMoves=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1];const dataIdsLeaked=numDataIdsAfter-numDataIdsBefore-numOutputDataIds-numMoves;if(dataIdsLeaked>0){throw new Error(`Backend '${this.backendName}' has an internal memory leak `+`(${dataIdsLeaked} data ids) after running '${kernelName}'`)}}runKernelFunc(kernelParams){let outputs;let saved=[];const isTapeOn=this.isTapeOn();const startingBytecount=this.state.numBytes;const startingNumTensors=this.state.numTensors;if(this.shouldCheckForMemLeaks()){this.state.numDataMovesStack.push(0)}let kernelFunc;if(this.backendName==null){this.backend}let out;const kernelOrScopeName=isRegisteredKernelInvocation(kernelParams)?kernelParams.kernelName:this.state.activeScope!=null?this.state.activeScope.name:"";if(isRegisteredKernelInvocation(kernelParams)){const{kernelName:kernelName,inputs:inputs,attrs:attrs}=kernelParams;if(this.backendName==null){this.backend}const kernel=getKernel(kernelName,this.backendName);assert(kernel!=null,(()=>`Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`));kernelFunc=()=>{const numDataIdsBefore=this.backend.numDataIds();out=kernel.kernelFunc({inputs:inputs,attrs:attrs,backend:this.backend});const outInfos=Array.isArray(out)?out:[out];if(this.shouldCheckForMemLeaks()){this.checkKernelForMemLeak(kernelName,numDataIdsBefore,outInfos)}const outTensors=outInfos.map((outInfo=>{if(outInfo.rank!=null){return outInfo}const{dataId:dataId,shape:shape,dtype:dtype}=outInfo;return this.makeTensorFromDataId(dataId,shape,dtype)}));if(isTapeOn){const tensorsToSave=this.getTensorsForGradient(kernelName,inputs,outTensors);saved=this.saveTensorsForBackwardMode(tensorsToSave)}return outTensors}}else{const{forwardFunc:forwardFunc}=kernelParams;const saveFunc=tensors=>{if(!isTapeOn){return}saved=tensors.map((tensor=>this.keep(this.clone(tensor))))};kernelFunc=()=>{const numDataIdsBefore=this.backend.numDataIds();out=this.tidy((()=>forwardFunc(this.backend,saveFunc)));const outs=Array.isArray(out)?out:[out];if(this.shouldCheckForMemLeaks()){this.checkKernelForMemLeak(kernelOrScopeName,numDataIdsBefore,outs)}return outs}}const{inputs:inputs,attrs:attrs}=kernelParams;const backwardsFunc=isRegisteredKernelInvocation(kernelParams)?null:kernelParams.backwardsFunc;let kernelProfile;this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{if(!this.ENV.getBool("DEBUG")&&!this.state.profiling){outputs=kernelFunc()}else{kernelProfile=this.profiler.profileKernel(kernelOrScopeName,inputs,(()=>kernelFunc()));if(this.ENV.getBool("DEBUG")){this.profiler.logKernelProfile(kernelProfile)}outputs=kernelProfile.outputs}}));if(isTapeOn){this.addTapeNode(kernelOrScopeName,inputs,outputs,backwardsFunc,saved,attrs)}if(this.state.profiling){this.state.activeProfile.kernels.push({name:kernelOrScopeName,bytesAdded:this.state.numBytes-startingBytecount,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-startingNumTensors,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(inputs).map((key=>inputs[key]!=null?inputs[key].shape:null)),outputShapes:outputs.map((item=>item.shape)),kernelTimeMs:kernelProfile.timeMs,extraInfo:kernelProfile.extraInfo})}return Array.isArray(out)?outputs:outputs[0]}saveTensorsForBackwardMode(tensors){const saved=tensors.map((tensor=>this.keep(this.clone(tensor))));return saved}getTensorsForGradient(kernelName,inputs,outputs){const gradConfig=getGradient(kernelName);if(gradConfig!=null){const inputsToSave=gradConfig.inputsToSave||[];const outputsToSave=gradConfig.outputsToSave||[];let inputTensorsToSave;if(gradConfig.saveAllInputs){assert(Array.isArray(inputs),(()=>"saveAllInputs is true, expected inputs to be an array."));inputTensorsToSave=Object.keys(inputs).map((key=>inputs[key]))}else{inputTensorsToSave=inputsToSave.map((inputName=>inputs[inputName]))}const outputTensorsToSave=outputs.filter(((_,i)=>outputsToSave[i]));return inputTensorsToSave.concat(outputTensorsToSave)}return[]}makeTensor(values,shape,dtype,backend){if(values==null){throw new Error("Values passed to engine.makeTensor() are null")}dtype=dtype||"float32";backend=backend||this.backend;let backendVals=values;if(dtype==="string"&&isString(values[0])){backendVals=values.map((d=>encodeString(d)))}const dataId=backend.write(backendVals,shape,dtype);const t=new Tensor(shape,dtype,dataId,this.nextTensorId());this.trackTensor(t,backend);if(dtype==="string"){const info=this.state.tensorInfo.get(dataId);const newBytes=bytesFromStringArray(backendVals);this.state.numBytes+=newBytes-info.bytes;info.bytes=newBytes}return t}makeTensorFromDataId(dataId,shape,dtype,backend){dtype=dtype||"float32";const t=new Tensor(shape,dtype,dataId,this.nextTensorId());this.trackTensor(t,backend);return t}makeVariable(initialValue,trainable=true,name,dtype){name=name||this.nextVariableId().toString();if(dtype!=null&&dtype!==initialValue.dtype){initialValue=initialValue.cast(dtype)}const v=new Variable(initialValue,trainable,name,this.nextTensorId());if(this.state.registeredVariables[v.name]!=null){throw new Error(`Variable with name ${v.name} was already registered`)}this.state.registeredVariables[v.name]=v;this.incRef(v,this.backend);return v}trackTensor(a,backend){this.state.numTensors++;if(a.dtype==="string"){this.state.numStringTensors++}let bytes=0;if(a.dtype!=="complex64"&&a.dtype!=="string"){bytes=a.size*bytesPerElement(a.dtype)}this.state.numBytes+=bytes;if(!this.state.tensorInfo.has(a.dataId)){this.state.numDataBuffers++;this.state.tensorInfo.set(a.dataId,{backend:backend||this.backend,dtype:a.dtype,shape:a.shape,bytes:bytes})}if(!(a instanceof Variable)){this.track(a)}}incRef(a,backend){this.trackTensor(a,backend);this.backend.incRef(a.dataId)}removeDataId(dataId,backend){if(this.state.tensorInfo.has(dataId)&&this.state.tensorInfo.get(dataId).backend===backend){this.state.tensorInfo.delete(dataId);this.state.numDataBuffers--}}disposeTensor(a){if(!this.state.tensorInfo.has(a.dataId)){return}const info=this.state.tensorInfo.get(a.dataId);this.state.numTensors--;if(a.dtype==="string"){this.state.numStringTensors--;this.state.numBytes-=info.bytes}if(a.dtype!=="complex64"&&a.dtype!=="string"){const bytes=a.size*bytesPerElement(a.dtype);this.state.numBytes-=bytes}if(info.backend.disposeData(a.dataId)){this.removeDataId(a.dataId,info.backend)}}disposeVariables(){for(const varName in this.state.registeredVariables){const v=this.state.registeredVariables[varName];this.disposeVariable(v)}}disposeVariable(v){this.disposeTensor(v);if(this.state.registeredVariables[v.name]!=null){delete this.state.registeredVariables[v.name]}}memory(){const info=this.backend.memory();info.numTensors=this.state.numTensors;info.numDataBuffers=this.state.numDataBuffers;info.numBytes=this.state.numBytes;if(this.state.numStringTensors>0){info.unreliable=true;if(info.reasons==null){info.reasons=[]}info.reasons.push("Memory usage by string tensors is approximate "+"(2 bytes per character)")}return info}async profile(query){this.state.profiling=true;const startBytes=this.state.numBytes;const startNumTensors=this.state.numTensors;this.state.activeProfile.kernels=[];this.state.activeProfile.result=await query();this.state.profiling=false;this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((d=>d.totalBytesSnapshot)));this.state.activeProfile.newBytes=this.state.numBytes-startBytes;this.state.activeProfile.newTensors=this.state.numTensors-startNumTensors;for(const kernel of this.state.activeProfile.kernels){kernel.kernelTimeMs=await kernel.kernelTimeMs;kernel.extraInfo=await kernel.extraInfo}return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&this.state.kernelDepth===0}addTapeNode(kernelName,inputs,outputs,gradientsFunc,saved,attrs){const tapeNode={id:this.state.nextTapeNodeId++,kernelName:kernelName,inputs:inputs,outputs:outputs,saved:saved};const gradConfig=getGradient(kernelName);if(gradConfig!=null){gradientsFunc=gradConfig.gradFunc}if(gradientsFunc!=null){tapeNode.gradient=dys=>{dys=dys.map(((dy,i)=>{if(dy==null){const output=outputs[i];const vals=makeZerosTypedArray(output.size,output.dtype);return this.makeTensor(vals,output.shape,output.dtype)}return dy}));return gradientsFunc(dys.length>1?dys:dys[0],saved,attrs)}}this.state.activeTape.push(tapeNode)}keep(result){result.kept=true;return result}startTape(){if(this.state.gradientDepth===0){this.state.activeTape=[]}this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(name){const scopeInfo={track:[],name:"unnamed scope",id:this.state.nextScopeId++};if(name){scopeInfo.name=name}this.state.scopeStack.push(scopeInfo);this.state.activeScope=scopeInfo}endScope(result){const tensorsToTrackInParent=getTensorsInContainer(result);const tensorsToTrackInParentSet=new Set(tensorsToTrackInParent.map((t=>t.id)));for(let i=0;i<this.state.activeScope.track.length;i++){const tensor=this.state.activeScope.track[i];if(!tensor.kept&&!tensorsToTrackInParentSet.has(tensor.id)){tensor.dispose()}}const oldScope=this.state.scopeStack.pop();this.state.activeScope=this.state.scopeStack.length===0?null:this.state.scopeStack[this.state.scopeStack.length-1];tensorsToTrackInParent.forEach((tensor=>{if(!tensor.kept&&tensor.scopeId===oldScope.id){this.track(tensor)}}))}gradients(f,xs,dy,allowNoGradients=false){assert(xs.length>0,(()=>"gradients() received an empty list of xs."));if(dy!=null&&dy.dtype!=="float32"){throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`)}const y=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",f)));assert(y instanceof Tensor,(()=>"The result y returned by f() must be a tensor."));const filteredTape=getFilteredNodesXToY(this.state.activeTape,xs,y);if(!allowNoGradients&&filteredTape.length===0&&xs.length>0){throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure "+"that the f you passed encloses all operations that lead from x "+"to y.")}return this.tidy("backward",(()=>{const accumulatedGradientMap={};accumulatedGradientMap[y.id]=dy==null?ones$1(y.shape):dy;backpropagateGradients(accumulatedGradientMap,filteredTape,(f=>this.tidy(f)),add$1);const grads=xs.map((x=>accumulatedGradientMap[x.id]));if(this.state.gradientDepth===0){this.state.activeTape.forEach((node=>{for(const tensor of node.saved){tensor.dispose()}}));this.state.activeTape=null}return{value:y,grads:grads}}))}customGrad(f){assert(isFunction(f),(()=>"The f passed in customGrad(f) must be a function."));return(...inputs)=>{assert(inputs.every((t=>t instanceof Tensor)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be "+"tensors"));let res;const inputMap={};inputs.forEach(((input,i)=>{inputMap[i]=input}));const forwardFunc=(_,save)=>{res=f(...[...inputs,save]);assert(res.value instanceof Tensor,(()=>"The function f passed in customGrad(f) must return an "+"object where `obj.value` is a tensor"));assert(isFunction(res.gradFunc),(()=>"The function f passed in customGrad(f) must return an "+"object where `obj.gradFunc` is a function."));return res.value};const backwardsFunc=(dy,saved)=>{const gradRes=res.gradFunc(dy,saved);const grads=Array.isArray(gradRes)?gradRes:[gradRes];assert(grads.length===inputs.length,(()=>"The function f passed in customGrad(f) must return an "+"object where `obj.gradFunc` is a function that returns "+"the same number of tensors as inputs passed to f(...)."));assert(grads.every((t=>t instanceof Tensor)),(()=>"The function f passed in customGrad(f) must return an "+"object where `obj.gradFunc` is a function that returns "+"a list of only tensors."));const gradMap={};grads.forEach(((grad,i)=>{gradMap[i]=()=>grad}));return gradMap};return this.runKernelFunc({forwardFunc:forwardFunc,backwardsFunc:backwardsFunc,inputs:inputMap})}}readSync(dataId){const info=this.state.tensorInfo.get(dataId);return info.backend.readSync(dataId)}read(dataId){const info=this.state.tensorInfo.get(dataId);return info.backend.read(dataId)}async time(query){const start=now();const timingInfo=await this.backend.time(query);timingInfo.wallMs=now()-start;return timingInfo}track(result){if(this.state.activeScope!=null){result.scopeId=this.state.activeScope.id;this.state.activeScope.track.push(result)}return result}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++;this.state.dispose();this.ENV.reset();this.state=new EngineState;for(const backendName in this.registry){this.disposeRegisteredKernels(backendName);this.registry[backendName].dispose();delete this.registry[backendName]}this.backendName=null;this.backendInstance=null;this.pendingBackendInit=null}}Engine.nextTensorId=0;Engine.nextVariableId=0;function ones$1(shape){const values=makeOnesTypedArray(sizeFromShape(shape),"float32");return ENGINE.makeTensor(values,shape,"float32")}function getOrMakeEngine(){const ns=getGlobalNamespace();if(ns._tfengine==null){const environment=new Environment(ns);ns._tfengine=new Engine(environment)}setEnvironmentGlobal(ns._tfengine.ENV);setTensorTracker((()=>ns._tfengine));return ns._tfengine}const ENGINE=getOrMakeEngine();function add$1(a,b){const inputs={a:a,b:b};return ENGINE.runKernel(Add,inputs)}function _isNavigatorDefined(){return typeof navigator!=="undefined"&&navigator!=null}function isMobile(nav){if(nav||_isNavigatorDefined()){if(!nav){nav=navigator}if(nav.product==="ReactNative"){return true}const a=nav.userAgent||nav.vendor||window.opera;return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))}return false}function isBrowser(){return typeof window!=="undefined"&&window.document!=null||typeof WorkerGlobalScope!=="undefined"}var device_util=Object.freeze({__proto__:null,isMobile:isMobile,isBrowser:isBrowser});const ENV$1=env();ENV$1.registerFlag("DEBUG",(()=>false),(debugValue=>{if(debugValue){console.warn("Debugging mode is ON. The output of every math call will "+"be downloaded to CPU and checked for NaNs. "+"This significantly impacts performance.")}}));ENV$1.registerFlag("IS_BROWSER",(()=>isBrowser()));ENV$1.registerFlag("IS_NODE",(()=>typeof process!=="undefined"&&typeof process.versions!=="undefined"&&typeof process.versions.node!=="undefined"));ENV$1.registerFlag("IS_CHROME",(()=>typeof navigator!=="undefined"&&navigator!=null&&navigator.userAgent!=null&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)));ENV$1.registerFlag("PROD",(()=>false));ENV$1.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>ENV$1.getBool("DEBUG")));ENV$1.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>true));ENV$1.registerFlag("IS_TEST",(()=>false));ENV$1.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",(()=>true));ENV$1.registerFlag("WRAP_TO_IMAGEBITMAP",(()=>false));function inferShape(val,dtype){let firstElem=val;if(isTypedArray(val)){return dtype==="string"?[]:[val.length]}if(!Array.isArray(val)){return[]}const shape=[];while(Array.isArray(firstElem)||isTypedArray(firstElem)&&dtype!=="string"){shape.push(firstElem.length);firstElem=firstElem[0]}if(Array.isArray(val)&&env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")){deepAssertShapeConsistency(val,shape,[])}return shape}function deepAssertShapeConsistency(val,shape,indices){indices=indices||[];if(!Array.isArray(val)&&!isTypedArray(val)){assert(shape.length===0,(()=>`Element arr[${indices.join("][")}] is a primitive, `+`but should be an array/TypedArray of ${shape[0]} elements`));return}assert(shape.length>0,(()=>`Element arr[${indices.join("][")}] should be a primitive, `+`but is an array of ${val.length} elements`));assert(val.length===shape[0],(()=>`Element arr[${indices.join("][")}] should have ${shape[0]} `+`elements, but has ${val.length} elements`));const subShape=shape.slice(1);for(let i=0;i<val.length;++i){deepAssertShapeConsistency(val[i],subShape,indices.concat(i))}}function assertDtype(expectedDtype,actualDType,argName,functionName){if(expectedDtype==="string_or_numeric"){return}if(expectedDtype==null){throw new Error(`Expected dtype cannot be null.`)}if(expectedDtype!=="numeric"&&expectedDtype!==actualDType||expectedDtype==="numeric"&&actualDType==="string"){throw new Error(`Argument '${argName}' passed to '${functionName}' must `+`be ${expectedDtype} tensor, but got ${actualDType} tensor`)}}function convertToTensor(x,argName,functionName,parseAsDtype="numeric"){if(x instanceof Tensor){assertDtype(parseAsDtype,x.dtype,argName,functionName);return x}let inferredDtype=inferDtype(x);if(inferredDtype!=="string"&&["bool","int32","float32"].indexOf(parseAsDtype)>=0){inferredDtype=parseAsDtype}assertDtype(parseAsDtype,inferredDtype,argName,functionName);if(x==null||!isTypedArray(x)&&!Array.isArray(x)&&typeof x!=="number"&&typeof x!=="boolean"&&typeof x!=="string"){const type=x==null?"null":x.constructor.name;throw new Error(`Argument '${argName}' passed to '${functionName}' must be a `+`Tensor or TensorLike, but got '${type}'`)}const inferredShape=inferShape(x,inferredDtype);if(!isTypedArray(x)&&!Array.isArray(x)){x=[x]}const skipTypedArray=true;const values=inferredDtype!=="string"?toTypedArray(x,inferredDtype):flatten(x,[],skipTypedArray);return ENGINE.makeTensor(values,inferredShape,inferredDtype)}function convertToTensorArray(arg,argName,functionName,parseAsDtype="numeric"){if(!Array.isArray(arg)){throw new Error(`Argument ${argName} passed to ${functionName} must be a `+"`Tensor[]` or `TensorLike[]`")}const tensors=arg;return tensors.map(((t,i)=>convertToTensor(t,`${argName}[${i}]`,functionName,parseAsDtype)))}const OP_SCOPE_SUFFIX="__op";function op(f){const keys=Object.keys(f);if(keys.length!==1){throw new Error(`Please provide an object with a single key `+`(operation name) mapping to a function. Got an object with `+`${keys.length} keys.`)}let opName=keys[0];const fn=f[opName];if(opName.endsWith("_")){opName=opName.substring(0,opName.length-1)}opName=opName+OP_SCOPE_SUFFIX;const f2=(...args)=>{ENGINE.startScope(opName);try{const result=fn(...args);if(isPromise(result)){console.error("Cannot return a Promise inside of tidy.")}ENGINE.endScope(result);return result}catch(ex){ENGINE.endScope(null);throw ex}};Object.defineProperty(f2,"name",{value:opName,configurable:true});return f2}function complex_(real,imag){const $real=convertToTensor(real,"real","complex");const $imag=convertToTensor(imag,"imag","complex");assertShapesMatch($real.shape,$imag.shape,`real and imag shapes, ${$real.shape} and ${$imag.shape}, `+`must match in call to tf.complex().`);const inputs={real:$real,imag:$imag};return ENGINE.runKernel(Complex,inputs)}const complex$1=op({complex_:complex_});function makeTensor(values,shape,inferredShape,dtype){if(dtype==null){dtype=inferDtype(values)}if(dtype==="complex64"){throw new Error(`Cannot construct a complex64 tensor directly. `+`Please use tf.complex(real, imag).`)}if(!isTypedArray(values)&&!Array.isArray(values)&&typeof values!=="number"&&typeof values!=="boolean"&&typeof values!=="string"){throw new Error("values passed to tensor(values) must be a number/boolean/string or "+"an array of numbers/booleans/strings, or a TypedArray")}if(shape!=null){assertNonNegativeIntegerDimensions(shape);const providedSize=sizeFromShape(shape);const inferredSize=sizeFromShape(inferredShape);assert(providedSize===inferredSize,(()=>`Based on the provided shape, [${shape}], the tensor should have `+`${providedSize} values but has ${inferredSize}`));for(let i=0;i<inferredShape.length;++i){const inferred=inferredShape[i];const flatDimsDontMatch=i===inferredShape.length-1?inferred!==sizeFromShape(shape.slice(i)):true;assert(inferredShape[i]===shape[i]||!flatDimsDontMatch,(()=>`Error creating a new Tensor. Inferred shape `+`(${inferredShape}) does not match the provided `+`shape (${shape}). `))}}if(!isTypedArray(values)&&!Array.isArray(values)){values=[values]}shape=shape||inferredShape;values=dtype!=="string"?toTypedArray(values,dtype):flatten(values,[],true);return ENGINE.makeTensor(values,shape,dtype)}function tensor(values,shape,dtype){const inferredShape=inferShape(values,dtype);return makeTensor(values,shape,inferredShape,dtype)}const DTYPE_VALUE_SIZE_MAP={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8};const NUM_BYTES_STRING_LENGTH=4;async function encodeWeights(tensors,group){const specs=[];const dataPromises=[];const names=Array.isArray(tensors)?tensors.map((tensor=>tensor.name)):Object.keys(tensors);for(let i=0;i<names.length;++i){const name=names[i];const t=Array.isArray(tensors)?tensors[i].tensor:tensors[name];if(t.dtype!=="float32"&&t.dtype!=="int32"&&t.dtype!=="bool"&&t.dtype!=="string"&&t.dtype!=="complex64"){throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`)}const spec={name:name,shape:t.shape,dtype:t.dtype};if(t.dtype==="string"){const utf8bytes=new Promise((async resolve=>{const vals=await t.bytes();const totalNumBytes=vals.reduce(((p,c)=>p+c.length),0)+NUM_BYTES_STRING_LENGTH*vals.length;const bytes=new Uint8Array(totalNumBytes);let offset=0;for(let i=0;i<vals.length;i++){const val=vals[i];const bytesOfLength=new Uint8Array(new Uint32Array([val.length]).buffer);bytes.set(bytesOfLength,offset);offset+=NUM_BYTES_STRING_LENGTH;bytes.set(val,offset);offset+=val.length}resolve(bytes)}));dataPromises.push(utf8bytes)}else{dataPromises.push(t.data())}if(group!=null){spec.group=group}specs.push(spec)}const tensorValues=await Promise.all(dataPromises);return{data:concatenateTypedArrays(tensorValues),specs:specs}}function decodeWeights(buffer,specs){const out={};let float16Decode;let offset=0;for(const spec of specs){const name=spec.name;const dtype=spec.dtype;const shape=spec.shape;const size=sizeFromShape(shape);let values;if("quantization"in spec){const quantization=spec.quantization;if(quantization.dtype==="uint8"||quantization.dtype==="uint16"){if(!("min"in quantization&&"scale"in quantization)){throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} `+`doesn't have corresponding metadata min and scale.`)}}else if(quantization.dtype==="float16"){if(dtype!=="float32"){throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} `+`which only supports weights of type float32 not ${dtype}.`)}}else{throw new Error(`Weight ${spec.name} has unknown `+`quantization dtype ${quantization.dtype}. `+`Supported quantization dtypes are: `+`'uint8', 'uint16', and 'float16'.`)}const quantizationSizeFactor=DTYPE_VALUE_SIZE_MAP[quantization.dtype];const byteBuffer=buffer.slice(offset,offset+size*quantizationSizeFactor);const quantizedArray=quantization.dtype==="uint8"?new Uint8Array(byteBuffer):new Uint16Array(byteBuffer);if(dtype==="float32"){if(quantization.dtype==="uint8"||quantization.dtype==="uint16"){values=new Float32Array(quantizedArray.length);for(let i=0;i<quantizedArray.length;i++){const v=quantizedArray[i];values[i]=v*quantization.scale+quantization.min}}else if(quantization.dtype==="float16"){if(float16Decode===undefined){float16Decode=getFloat16Decoder()}values=float16Decode(quantizedArray)}else{throw new Error(`Unsupported quantization type ${quantization.dtype} `+`for weight type float32.`)}}else if(dtype==="int32"){if(quantization.dtype!=="uint8"&&quantization.dtype!=="uint16"){throw new Error(`Unsupported quantization type ${quantization.dtype} `+`for weight type int32.`)}values=new Int32Array(quantizedArray.length);for(let i=0;i<quantizedArray.length;i++){const v=quantizedArray[i];values[i]=Math.round(v*quantization.scale+quantization.min)}}else{throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`)}offset+=size*quantizationSizeFactor}else if(dtype==="string"){const size=sizeFromShape(spec.shape);values=[];for(let i=0;i<size;i++){const byteLength=new Uint32Array(buffer.slice(offset,offset+NUM_BYTES_STRING_LENGTH))[0];offset+=NUM_BYTES_STRING_LENGTH;const bytes=new Uint8Array(buffer.slice(offset,offset+byteLength));values.push(bytes);offset+=byteLength}}else{const dtypeFactor=DTYPE_VALUE_SIZE_MAP[dtype];const byteBuffer=buffer.slice(offset,offset+size*dtypeFactor);if(dtype==="float32"){values=new Float32Array(byteBuffer)}else if(dtype==="int32"){values=new Int32Array(byteBuffer)}else if(dtype==="bool"){values=new Uint8Array(byteBuffer)}else if(dtype==="complex64"){values=new Float32Array(byteBuffer);const real=new Float32Array(values.length/2);const image=new Float32Array(values.length/2);for(let i=0;i<real.length;i++){real[i]=values[i*2];image[i]=values[i*2+1]}const realTensor=tensor(real,shape,"float32");const imageTensor=tensor(image,shape,"float32");out[name]=complex$1(realTensor,imageTensor);realTensor.dispose();imageTensor.dispose()}else{throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`)}offset+=size*dtypeFactor}if(dtype!=="complex64"){out[name]=tensor(values,shape,dtype)}}return out}function concatenateTypedArrays(xs){if(xs===null){throw new Error(`Invalid input value: ${JSON.stringify(xs)}`)}let totalByteLength=0;const normalizedXs=[];xs.forEach((x=>{totalByteLength+=x.byteLength;normalizedXs.push(x.byteLength===x.buffer.byteLength?x:new x.constructor(x));if(!(x instanceof Float32Array||x instanceof Int32Array||x instanceof Uint8Array)){throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`)}}));const y=new Uint8Array(totalByteLength);let offset=0;normalizedXs.forEach((x=>{y.set(new Uint8Array(x.buffer),offset);offset+=x.byteLength}));return y.buffer}const useNodeBuffer=typeof Buffer!=="undefined"&&(typeof Blob==="undefined"||typeof atob==="undefined"||typeof btoa==="undefined");function stringByteLength(str){if(useNodeBuffer){return Buffer.byteLength(str)}return new Blob([str]).size}function arrayBufferToBase64String(buffer){if(useNodeBuffer){return Buffer.from(buffer).toString("base64")}const buf=new Uint8Array(buffer);let s="";for(let i=0,l=buf.length;i<l;i++){s+=String.fromCharCode(buf[i])}return btoa(s)}function base64StringToArrayBuffer(str){if(useNodeBuffer){const buf=Buffer.from(str,"base64");return buf.buffer.slice(buf.byteOffset,buf.byteOffset+buf.byteLength)}const s=atob(str);const buffer=new Uint8Array(s.length);for(let i=0;i<s.length;++i){buffer.set([s.charCodeAt(i)],i)}return buffer.buffer}function concatenateArrayBuffers(buffers){if(buffers.length===1){return buffers[0]}let totalByteLength=0;buffers.forEach((buffer=>{totalByteLength+=buffer.byteLength}));const temp=new Uint8Array(totalByteLength);let offset=0;buffers.forEach((buffer=>{temp.set(new Uint8Array(buffer),offset);offset+=buffer.byteLength}));return temp.buffer}function basename(path){const SEPARATOR="/";path=path.trim();while(path.endsWith(SEPARATOR)){path=path.slice(0,path.length-1)}const items=path.split(SEPARATOR);return items[items.length-1]}function getModelArtifactsInfoForJSON(modelArtifacts){if(modelArtifacts.modelTopology instanceof ArrayBuffer){throw new Error("Expected JSON model topology, received ArrayBuffer.")}return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:modelArtifacts.modelTopology==null?0:stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),weightSpecsBytes:modelArtifacts.weightSpecs==null?0:stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),weightDataBytes:modelArtifacts.weightData==null?0:modelArtifacts.weightData.byteLength}}function computeFloat16MantisaTable(){const convertMantissa=i=>{let m=i<<13;let e=0;while((m&8388608)===0){e-=8388608;m<<=1}m&=~8388608;e+=947912704;return m|e};const mantisaTable=new Uint32Array(2048);mantisaTable[0]=0;for(let i=1;i<1024;i++){mantisaTable[i]=convertMantissa(i)}for(let i=1024;i<2048;i++){mantisaTable[i]=939524096+(i-1024<<13)}return mantisaTable}function computeFloat16ExponentTable(){const exponentTable=new Uint32Array(64);exponentTable[0]=0;exponentTable[31]=1199570944;exponentTable[32]=2147483648;exponentTable[63]=3347054592;for(let i=1;i<31;i++){exponentTable[i]=i<<23}for(let i=33;i<63;i++){exponentTable[i]=2147483648+(i-32<<23)}return exponentTable}function computeFloat16OffsetTable(){const offsetTable=new Uint32Array(64);for(let i=0;i<64;i++){offsetTable[i]=1024}offsetTable[0]=offsetTable[32]=0;return offsetTable}function getFloat16Decoder(){const mantisaTable=computeFloat16MantisaTable();const exponentTable=computeFloat16ExponentTable();const offsetTable=computeFloat16OffsetTable();return quantizedArray=>{const buffer=new ArrayBuffer(4*quantizedArray.length);const bufferUint32View=new Uint32Array(buffer);for(let index=0;index<quantizedArray.length;index++){const float16Bits=quantizedArray[index];const float32Bits=mantisaTable[offsetTable[float16Bits>>10]+(float16Bits&1023)]+exponentTable[float16Bits>>10];bufferUint32View[index]=float32Bits}return new Float32Array(buffer)}}class IORouterRegistry{constructor(){this.saveRouters=[];this.loadRouters=[]}static getInstance(){if(IORouterRegistry.instance==null){IORouterRegistry.instance=new IORouterRegistry}return IORouterRegistry.instance}static registerSaveRouter(saveRouter){IORouterRegistry.getInstance().saveRouters.push(saveRouter)}static registerLoadRouter(loadRouter){IORouterRegistry.getInstance().loadRouters.push(loadRouter)}static getSaveHandlers(url){return IORouterRegistry.getHandlers(url,"save")}static getLoadHandlers(url,loadOptions){return IORouterRegistry.getHandlers(url,"load",loadOptions)}static getHandlers(url,handlerType,loadOptions){const validHandlers=[];const routers=handlerType==="load"?IORouterRegistry.getInstance().loadRouters:IORouterRegistry.getInstance().saveRouters;routers.forEach((router=>{const handler=router(url,loadOptions);if(handler!==null){validHandlers.push(handler)}}));return validHandlers}}const registerSaveRouter=loudRouter=>IORouterRegistry.registerSaveRouter(loudRouter);const registerLoadRouter=loudRouter=>IORouterRegistry.registerLoadRouter(loudRouter);const getSaveHandlers=url=>IORouterRegistry.getSaveHandlers(url);const getLoadHandlers=(url,loadOptions)=>IORouterRegistry.getLoadHandlers(url,loadOptions);const DATABASE_NAME="tensorflowjs";const DATABASE_VERSION=1;const MODEL_STORE_NAME="models_store";const INFO_STORE_NAME="model_info_store";function getIndexedDBFactory(){if(!env().getBool("IS_BROWSER")){throw new Error("Failed to obtain IndexedDB factory because the current environment"+"is not a web browser.")}const theWindow=typeof window==="undefined"?self:window;const factory=theWindow.indexedDB||theWindow.mozIndexedDB||theWindow.webkitIndexedDB||theWindow.msIndexedDB||theWindow.shimIndexedDB;if(factory==null){throw new Error("The current browser does not appear to support IndexedDB.")}return factory}function setUpDatabase(openRequest){const db=openRequest.result;db.createObjectStore(MODEL_STORE_NAME,{keyPath:"modelPath"});db.createObjectStore(INFO_STORE_NAME,{keyPath:"modelPath"})}class BrowserIndexedDB{constructor(modelPath){this.indexedDB=getIndexedDBFactory();if(modelPath==null||!modelPath){throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.")}this.modelPath=modelPath}async save(modelArtifacts){if(modelArtifacts.modelTopology instanceof ArrayBuffer){throw new Error("BrowserLocalStorage.save() does not support saving model topology "+"in binary formats yet.")}return this.databaseAction(this.modelPath,modelArtifacts)}async load(){return this.databaseAction(this.modelPath)}databaseAction(modelPath,modelArtifacts){return new Promise(((resolve,reject)=>{const openRequest=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);openRequest.onupgradeneeded=()=>setUpDatabase(openRequest);openRequest.onsuccess=()=>{const db=openRequest.result;if(modelArtifacts==null){const modelTx=db.transaction(MODEL_STORE_NAME,"readonly");const modelStore=modelTx.objectStore(MODEL_STORE_NAME);const getRequest=modelStore.get(this.modelPath);getRequest.onsuccess=()=>{if(getRequest.result==null){db.close();return reject(new Error(`Cannot find model with path '${this.modelPath}' `+`in IndexedDB.`))}else{resolve(getRequest.result.modelArtifacts)}};getRequest.onerror=error=>{db.close();return reject(getRequest.error)};modelTx.oncomplete=()=>db.close()}else{const modelArtifactsInfo=getModelArtifactsInfoForJSON(modelArtifacts);const infoTx=db.transaction(INFO_STORE_NAME,"readwrite");let infoStore=infoTx.objectStore(INFO_STORE_NAME);const putInfoRequest=infoStore.put({modelPath:this.modelPath,modelArtifactsInfo:modelArtifactsInfo});let modelTx;putInfoRequest.onsuccess=()=>{modelTx=db.transaction(MODEL_STORE_NAME,"readwrite");const modelStore=modelTx.objectStore(MODEL_STORE_NAME);const putModelRequest=modelStore.put({modelPath:this.modelPath,modelArtifacts:modelArtifacts,modelArtifactsInfo:modelArtifactsInfo});putModelRequest.onsuccess=()=>resolve({modelArtifactsInfo:modelArtifactsInfo});putModelRequest.onerror=error=>{infoStore=infoTx.objectStore(INFO_STORE_NAME);const deleteInfoRequest=infoStore.delete(this.modelPath);deleteInfoRequest.onsuccess=()=>{db.close();return reject(putModelRequest.error)};deleteInfoRequest.onerror=error=>{db.close();return reject(putModelRequest.error)}}};putInfoRequest.onerror=error=>{db.close();return reject(putInfoRequest.error)};infoTx.oncomplete=()=>{if(modelTx==null){db.close()}else{modelTx.oncomplete=()=>db.close()}}}};openRequest.onerror=error=>reject(openRequest.error)}))}}BrowserIndexedDB.URL_SCHEME="indexeddb://";const indexedDBRouter=url=>{if(!env().getBool("IS_BROWSER")){return null}else{if(!Array.isArray(url)&&url.startsWith(BrowserIndexedDB.URL_SCHEME)){return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length))}else{return null}}};IORouterRegistry.registerSaveRouter(indexedDBRouter);IORouterRegistry.registerLoadRouter(indexedDBRouter);function browserIndexedDB(modelPath){return new BrowserIndexedDB(modelPath)}function maybeStripScheme$1(key){return key.startsWith(BrowserIndexedDB.URL_SCHEME)?key.slice(BrowserIndexedDB.URL_SCHEME.length):key}class BrowserIndexedDBManager{constructor(){this.indexedDB=getIndexedDBFactory()}async listModels(){return new Promise(((resolve,reject)=>{const openRequest=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);openRequest.onupgradeneeded=()=>setUpDatabase(openRequest);openRequest.onsuccess=()=>{const db=openRequest.result;const tx=db.transaction(INFO_STORE_NAME,"readonly");const store=tx.objectStore(INFO_STORE_NAME);const getAllInfoRequest=store.getAll();getAllInfoRequest.onsuccess=()=>{const out={};for(const item of getAllInfoRequest.result){out[item.modelPath]=item.modelArtifactsInfo}resolve(out)};getAllInfoRequest.onerror=error=>{db.close();return reject(getAllInfoRequest.error)};tx.oncomplete=()=>db.close()};openRequest.onerror=error=>reject(openRequest.error)}))}async removeModel(path){path=maybeStripScheme$1(path);return new Promise(((resolve,reject)=>{const openRequest=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);openRequest.onupgradeneeded=()=>setUpDatabase(openRequest);openRequest.onsuccess=()=>{const db=openRequest.result;const infoTx=db.transaction(INFO_STORE_NAME,"readwrite");const infoStore=infoTx.objectStore(INFO_STORE_NAME);const getInfoRequest=infoStore.get(path);let modelTx;getInfoRequest.onsuccess=()=>{if(getInfoRequest.result==null){db.close();return reject(new Error(`Cannot find model with path '${path}' `+`in IndexedDB.`))}else{const deleteInfoRequest=infoStore.delete(path);const deleteModelData=()=>{modelTx=db.transaction(MODEL_STORE_NAME,"readwrite");const modelStore=modelTx.objectStore(MODEL_STORE_NAME);const deleteModelRequest=modelStore.delete(path);deleteModelRequest.onsuccess=()=>resolve(getInfoRequest.result.modelArtifactsInfo);deleteModelRequest.onerror=error=>reject(getInfoRequest.error)};deleteInfoRequest.onsuccess=deleteModelData;deleteInfoRequest.onerror=error=>{deleteModelData();db.close();return reject(getInfoRequest.error)}}};getInfoRequest.onerror=error=>{db.close();return reject(getInfoRequest.error)};infoTx.oncomplete=()=>{if(modelTx==null){db.close()}else{modelTx.oncomplete=()=>db.close()}}};openRequest.onerror=error=>reject(openRequest.error)}))}}const PATH_SEPARATOR="/";const PATH_PREFIX="tensorflowjs_models";const INFO_SUFFIX="info";const MODEL_TOPOLOGY_SUFFIX="model_topology";const WEIGHT_SPECS_SUFFIX="weight_specs";const WEIGHT_DATA_SUFFIX="weight_data";const MODEL_METADATA_SUFFIX="model_metadata";function getModelKeys(path){return{info:[PATH_PREFIX,path,INFO_SUFFIX].join(PATH_SEPARATOR),topology:[PATH_PREFIX,path,MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),weightSpecs:[PATH_PREFIX,path,WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),weightData:[PATH_PREFIX,path,WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),modelMetadata:[PATH_PREFIX,path,MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)}}function getModelPathFromKey(key){const items=key.split(PATH_SEPARATOR);if(items.length<3){throw new Error(`Invalid key format: ${key}`)}return items.slice(1,items.length-1).join(PATH_SEPARATOR)}function maybeStripScheme(key){return key.startsWith(BrowserLocalStorage.URL_SCHEME)?key.slice(BrowserLocalStorage.URL_SCHEME.length):key}class BrowserLocalStorage{constructor(modelPath){if(!env().getBool("IS_BROWSER")||typeof window==="undefined"||typeof window.localStorage==="undefined"){throw new Error("The current environment does not support local storage.")}this.LS=window.localStorage;if(modelPath==null||!modelPath){throw new Error("For local storage, modelPath must not be null, undefined or empty.")}this.modelPath=modelPath;this.keys=getModelKeys(this.modelPath)}async save(modelArtifacts){if(modelArtifacts.modelTopology instanceof ArrayBuffer){throw new Error("BrowserLocalStorage.save() does not support saving model topology "+"in binary formats yet.")}else{const topology=JSON.stringify(modelArtifacts.modelTopology);const weightSpecs=JSON.stringify(modelArtifacts.weightSpecs);const modelArtifactsInfo=getModelArtifactsInfoForJSON(modelArtifacts);try{this.LS.setItem(this.keys.info,JSON.stringify(modelArtifactsInfo));this.LS.setItem(this.keys.topology,topology);this.LS.setItem(this.keys.weightSpecs,weightSpecs);this.LS.setItem(this.keys.weightData,arrayBufferToBase64String(modelArtifacts.weightData));const result={format:modelArtifacts.format,generatedBy:modelArtifacts.generatedBy,convertedBy:modelArtifacts.convertedBy};if(modelArtifacts.signature!=null){result.signature=modelArtifacts.signature}if(modelArtifacts.userDefinedMetadata!=null){result.userDefinedMetadata=modelArtifacts.userDefinedMetadata}if(modelArtifacts.modelInitializer!=null){result.modelInitializer=modelArtifacts.modelInitializer}this.LS.setItem(this.keys.modelMetadata,JSON.stringify(result));return{modelArtifactsInfo:modelArtifactsInfo}}catch(err){this.LS.removeItem(this.keys.info);this.LS.removeItem(this.keys.topology);this.LS.removeItem(this.keys.weightSpecs);this.LS.removeItem(this.keys.weightData);this.LS.removeItem(this.keys.modelMetadata);throw new Error(`Failed to save model '${this.modelPath}' to local storage: `+`size quota being exceeded is a possible cause of this failure: `+`modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, `+`weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, `+`weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`)}}}async load(){const info=JSON.parse(this.LS.getItem(this.keys.info));if(info==null){throw new Error(`In local storage, there is no model with name '${this.modelPath}'`)}if(info.modelTopologyType!=="JSON"){throw new Error("BrowserLocalStorage does not support loading non-JSON model "+"topology yet.")}const out={};const topology=JSON.parse(this.LS.getItem(this.keys.topology));if(topology==null){throw new Error(`In local storage, the topology of model '${this.modelPath}' `+`is missing.`)}out.modelTopology=topology;const weightSpecs=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(weightSpecs==null){throw new Error(`In local storage, the weight specs of model '${this.modelPath}' `+`are missing.`)}out.weightSpecs=weightSpecs;const metadataString=this.LS.getItem(this.keys.modelMetadata);if(metadataString!=null){const metadata=JSON.parse(metadataString);out.format=metadata["format"];out.generatedBy=metadata["generatedBy"];out.convertedBy=metadata["convertedBy"];if(metadata["signature"]!=null){out.signature=metadata["signature"]}if(metadata["userDefinedMetadata"]!=null){out.userDefinedMetadata=metadata["userDefinedMetadata"]}if(metadata["modelInitializer"]!=null){out.modelInitializer=metadata["modelInitializer"]}}const weightDataBase64=this.LS.getItem(this.keys.weightData);if(weightDataBase64==null){throw new Error(`In local storage, the binary weight values of model `+`'${this.modelPath}' are missing.`)}out.weightData=base64StringToArrayBuffer(weightDataBase64);return out}}BrowserLocalStorage.URL_SCHEME="localstorage://";const localStorageRouter=url=>{if(!env().getBool("IS_BROWSER")){return null}else{if(!Array.isArray(url)&&url.startsWith(BrowserLocalStorage.URL_SCHEME)){return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length))}else{return null}}};IORouterRegistry.registerSaveRouter(localStorageRouter);IORouterRegistry.registerLoadRouter(localStorageRouter);function browserLocalStorage(modelPath){return new BrowserLocalStorage(modelPath)}class BrowserLocalStorageManager{constructor(){assert(env().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser"));assert(typeof window==="undefined"||typeof window.localStorage!=="undefined",(()=>"Current browser does not appear to support localStorage"));this.LS=window.localStorage}async listModels(){const out={};const prefix=PATH_PREFIX+PATH_SEPARATOR;const suffix=PATH_SEPARATOR+INFO_SUFFIX;for(let i=0;i<this.LS.length;++i){const key=this.LS.key(i);if(key.startsWith(prefix)&&key.endsWith(suffix)){const modelPath=getModelPathFromKey(key);out[modelPath]=JSON.parse(this.LS.getItem(key))}}return out}async removeModel(path){path=maybeStripScheme(path);const keys=getModelKeys(path);if(this.LS.getItem(keys.info)==null){throw new Error(`Cannot find model at path '${path}'`)}const info=JSON.parse(this.LS.getItem(keys.info));this.LS.removeItem(keys.info);this.LS.removeItem(keys.topology);this.LS.removeItem(keys.weightSpecs);this.LS.removeItem(keys.weightData);return info}}const URL_SCHEME_SUFFIX="://";class ModelStoreManagerRegistry{constructor(){this.managers={}}static getInstance(){if(ModelStoreManagerRegistry.instance==null){ModelStoreManagerRegistry.instance=new ModelStoreManagerRegistry}return ModelStoreManagerRegistry.instance}static registerManager(scheme,manager){assert(scheme!=null,(()=>"scheme must not be undefined or null."));if(scheme.endsWith(URL_SCHEME_SUFFIX)){scheme=scheme.slice(0,scheme.indexOf(URL_SCHEME_SUFFIX))}assert(scheme.length>0,(()=>"scheme must not be an empty string."));const registry=ModelStoreManagerRegistry.getInstance();assert(registry.managers[scheme]==null,(()=>`A model store manager is already registered for scheme '${scheme}'.`));registry.managers[scheme]=manager}static getManager(scheme){const manager=this.getInstance().managers[scheme];if(manager==null){throw new Error(`Cannot find model manager for scheme '${scheme}'`)}return manager}static getSchemes(){return Object.keys(this.getInstance().managers)}}function parseURL(url){if(url.indexOf(URL_SCHEME_SUFFIX)===-1){throw new Error(`The url string provided does not contain a scheme. `+`Supported schemes are: `+`${ModelStoreManagerRegistry.getSchemes().join(",")}`)}return{scheme:url.split(URL_SCHEME_SUFFIX)[0],path:url.split(URL_SCHEME_SUFFIX)[1]}}async function cloneModelInternal(sourceURL,destURL,deleteSource=false){assert(sourceURL!==destURL,(()=>`Old path and new path are the same: '${sourceURL}'`));const loadHandlers=IORouterRegistry.getLoadHandlers(sourceURL);assert(loadHandlers.length>0,(()=>`Copying failed because no load handler is found for source URL ${sourceURL}.`));assert(loadHandlers.length<2,(()=>`Copying failed because more than one (${loadHandlers.length}) `+`load handlers for source URL ${sourceURL}.`));const loadHandler=loadHandlers[0];const saveHandlers=IORouterRegistry.getSaveHandlers(destURL);assert(saveHandlers.length>0,(()=>`Copying failed because no save handler is found for destination `+`URL ${destURL}.`));assert(saveHandlers.length<2,(()=>`Copying failed because more than one (${loadHandlers.length}) `+`save handlers for destination URL ${destURL}.`));const saveHandler=saveHandlers[0];const sourceScheme=parseURL(sourceURL).scheme;const sourcePath=parseURL(sourceURL).path;const sameMedium=sourceScheme===parseURL(sourceURL).scheme;const modelArtifacts=await loadHandler.load();if(deleteSource&&sameMedium){await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)}const saveResult=await saveHandler.save(modelArtifacts);if(deleteSource&&!sameMedium){await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)}return saveResult.modelArtifactsInfo}async function listModels(){const schemes=ModelStoreManagerRegistry.getSchemes();const out={};for(const scheme of schemes){const schemeOut=await ModelStoreManagerRegistry.getManager(scheme).listModels();for(const path in schemeOut){const url=scheme+URL_SCHEME_SUFFIX+path;out[url]=schemeOut[path]}}return out}async function removeModel(url){const schemeAndPath=parseURL(url);const manager=ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);return manager.removeModel(schemeAndPath.path)}async function copyModel(sourceURL,destURL){const deleteSource=false;return cloneModelInternal(sourceURL,destURL,deleteSource)}async function moveModel(sourceURL,destURL){const deleteSource=true;return cloneModelInternal(sourceURL,destURL,deleteSource)}class PlatformBrowser{fetch(path,init){return fetch(path,init)}now(){return performance.now()}encode(text,encoding){if(encoding!=="utf-8"&&encoding!=="utf8"){throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`)}if(this.textEncoder==null){this.textEncoder=new TextEncoder}return this.textEncoder.encode(text)}decode(bytes,encoding){return new TextDecoder(encoding).decode(bytes)}}if(env().get("IS_BROWSER")){env().setPlatform("browser",new PlatformBrowser);try{ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME,new BrowserLocalStorageManager)}catch(err){}try{ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME,new BrowserIndexedDBManager)}catch(err){}}const getNodeFetch={importFetch:()=>require("node-fetch")};let systemFetch;class PlatformNode{constructor(){this.util=require("util");this.textEncoder=new this.util.TextEncoder}fetch(path,requestInits){if(env().global.fetch!=null){return env().global.fetch(path,requestInits)}if(systemFetch==null){systemFetch=getNodeFetch.importFetch()}return systemFetch(path,requestInits)}now(){const time=process.hrtime();return time[0]*1e3+time[1]/1e6}encode(text,encoding){if(encoding!=="utf-8"&&encoding!=="utf8"){throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`)}return this.textEncoder.encode(text)}decode(bytes,encoding){if(bytes.length===0){return""}return new this.util.TextDecoder(encoding).decode(bytes)}}if(env().get("IS_NODE")){env().setPlatform("node",new PlatformNode)}function buffer(shape,dtype="float32",values){dtype=dtype||"float32";assertNonNegativeIntegerDimensions(shape);return new TensorBuffer(shape,dtype,values)}function cast_(x,dtype){const $x=convertToTensor(x,"x","cast");if(!isValidDtype(dtype)){throw new Error(`Failed to cast to unknown dtype ${dtype}`)}if(dtype==="string"&&$x.dtype!=="string"||dtype!=="string"&&$x.dtype==="string"){throw new Error("Only strings can be casted to strings")}const inputs={x:$x};const attrs={dtype:dtype};return ENGINE.runKernel(Cast,inputs,attrs)}const cast$1=op({cast_:cast_});function clone_(x){const $x=convertToTensor(x,"x","clone","string_or_numeric");const inputs={x:$x};return ENGINE.runKernel(Identity,inputs)}const clone=op({clone_:clone_});function print(x,verbose=false){console.log(x.toString(verbose))}getOrMakeEngine();const opHandler={buffer:buffer,cast:cast$1,clone:clone,print:print};setOpHandler(opHandler);const DEFAULT_FILE_NAME_PREFIX="model";const DEFAULT_JSON_EXTENSION_NAME=".json";const DEFAULT_WEIGHT_DATA_EXTENSION_NAME=".weights.bin";function defer(f){return new Promise((resolve=>setTimeout(resolve))).then(f)}class BrowserDownloads{constructor(fileNamePrefix){if(!env().getBool("IS_BROWSER")){throw new Error("browserDownloads() cannot proceed because the current environment "+"is not a browser.")}if(fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)){fileNamePrefix=fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length)}if(fileNamePrefix==null||fileNamePrefix.length===0){fileNamePrefix=DEFAULT_FILE_NAME_PREFIX}this.modelTopologyFileName=fileNamePrefix+DEFAULT_JSON_EXTENSION_NAME;this.weightDataFileName=fileNamePrefix+DEFAULT_WEIGHT_DATA_EXTENSION_NAME}async save(modelArtifacts){if(typeof document==="undefined"){throw new Error("Browser downloads are not supported in "+"this environment since `document` is not present")}const weightsURL=window.URL.createObjectURL(new Blob([modelArtifacts.weightData],{type:"application/octet-stream"}));if(modelArtifacts.modelTopology instanceof ArrayBuffer){throw new Error("BrowserDownloads.save() does not support saving model topology "+"in binary formats yet.")}else{const weightsManifest=[{paths:["./"+this.weightDataFileName],weights:modelArtifacts.weightSpecs}];const modelTopologyAndWeightManifest={modelTopology:modelArtifacts.modelTopology,format:modelArtifacts.format,generatedBy:modelArtifacts.generatedBy,convertedBy:modelArtifacts.convertedBy,weightsManifest:weightsManifest};if(modelArtifacts.signature!=null){modelTopologyAndWeightManifest.signature=modelArtifacts.signature}if(modelArtifacts.userDefinedMetadata!=null){modelTopologyAndWeightManifest.userDefinedMetadata=modelArtifacts.userDefinedMetadata}if(modelArtifacts.modelInitializer!=null){modelTopologyAndWeightManifest.modelInitializer=modelArtifacts.modelInitializer}const modelTopologyAndWeightManifestURL=window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)],{type:"application/json"}));const jsonAnchor=this.jsonAnchor==null?document.createElement("a"):this.jsonAnchor;jsonAnchor.download=this.modelTopologyFileName;jsonAnchor.href=modelTopologyAndWeightManifestURL;await defer((()=>jsonAnchor.dispatchEvent(new MouseEvent("click"))));if(modelArtifacts.weightData!=null){const weightDataAnchor=this.weightDataAnchor==null?document.createElement("a"):this.weightDataAnchor;weightDataAnchor.download=this.weightDataFileName;weightDataAnchor.href=weightsURL;await defer((()=>weightDataAnchor.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:getModelArtifactsInfoForJSON(modelArtifacts)}}}}BrowserDownloads.URL_SCHEME="downloads://";class BrowserFiles{constructor(files){if(files==null||files.length<1){throw new Error(`When calling browserFiles, at least 1 file is required, `+`but received ${files}`)}this.files=files}async load(){const jsonFile=this.files[0];const weightFiles=this.files.slice(1);return new Promise(((resolve,reject)=>{const jsonReader=new FileReader;jsonReader.onload=event=>{const modelJSON=JSON.parse(event.target.result);const modelTopology=modelJSON.modelTopology;if(modelTopology==null){reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));return}if(weightFiles.length===0){resolve({modelTopology:modelTopology})}const weightsManifest=modelJSON.weightsManifest;if(weightsManifest==null){reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));return}let pathToFile;try{pathToFile=this.checkManifestAndWeightFiles(weightsManifest,weightFiles)}catch(err){reject(err);return}const weightSpecs=[];const paths=[];const perFileBuffers=[];weightsManifest.forEach((weightsGroup=>{weightsGroup.paths.forEach((path=>{paths.push(path);perFileBuffers.push(null)}));weightSpecs.push(...weightsGroup.weights)}));weightsManifest.forEach((weightsGroup=>{weightsGroup.paths.forEach((path=>{const weightFileReader=new FileReader;weightFileReader.onload=event=>{const weightData=event.target.result;const index=paths.indexOf(path);perFileBuffers[index]=weightData;if(perFileBuffers.indexOf(null)===-1){const result={modelTopology:modelTopology,weightSpecs:weightSpecs,weightData:concatenateArrayBuffers(perFileBuffers),format:modelJSON.format,generatedBy:modelJSON.generatedBy,convertedBy:modelJSON.convertedBy};if(modelJSON.signature!=null){result.signature=modelJSON.signature}if(modelJSON.userDefinedMetadata!=null){result.userDefinedMetadata=modelJSON.userDefinedMetadata}if(modelJSON.modelInitializer!=null){result.modelInitializer=modelJSON.modelInitializer}resolve(result)}};weightFileReader.onerror=error=>reject(`Failed to weights data from file of path '${path}'.`);weightFileReader.readAsArrayBuffer(pathToFile[path])}))}))};jsonReader.onerror=error=>reject(`Failed to read model topology and weights manifest JSON `+`from file '${jsonFile.name}'. BrowserFiles supports loading `+`Keras-style tf.Model artifacts only.`);jsonReader.readAsText(jsonFile)}))}checkManifestAndWeightFiles(manifest,files){const basenames=[];const fileNames=files.map((file=>basename(file.name)));const pathToFile={};for(const group of manifest){group.paths.forEach((path=>{const pathBasename=basename(path);if(basenames.indexOf(pathBasename)!==-1){throw new Error(`Duplicate file basename found in weights manifest: `+`'${pathBasename}'`)}basenames.push(pathBasename);if(fileNames.indexOf(pathBasename)===-1){throw new Error(`Weight file with basename '${pathBasename}' is not provided.`)}else{pathToFile[path]=files[fileNames.indexOf(pathBasename)]}}))}if(basenames.length!==files.length){throw new Error(`Mismatch in the number of files in weights manifest `+`(${basenames.length}) and the number of weight files provided `+`(${files.length}).`)}return pathToFile}}const browserDownloadsRouter=url=>{if(!env().getBool("IS_BROWSER")){return null}else{if(!Array.isArray(url)&&url.startsWith(BrowserDownloads.URL_SCHEME)){return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length))}else{return null}}};IORouterRegistry.registerSaveRouter(browserDownloadsRouter);function browserDownloads(fileNamePrefix="model"){return new BrowserDownloads(fileNamePrefix)}function browserFiles(files){return new BrowserFiles(files)}function monitorPromisesProgress(promises,onProgress,startFraction,endFraction){checkPromises(promises);startFraction=startFraction==null?0:startFraction;endFraction=endFraction==null?1:endFraction;checkFraction(startFraction,endFraction);let resolvedPromise=0;const registerMonitor=promise=>{promise.then((value=>{const fraction=startFraction+ ++resolvedPromise/promises.length*(endFraction-startFraction);onProgress(fraction);return value}));return promise};function checkPromises(promises){assert(promises!=null&&Array.isArray(promises)&&promises.length>0,(()=>"promises must be a none empty array"))}function checkFraction(startFraction,endFraction){assert(startFraction>=0&&startFraction<=1,(()=>`Progress fraction must be in range [0, 1], but `+`got startFraction ${startFraction}`));assert(endFraction>=0&&endFraction<=1,(()=>`Progress fraction must be in range [0, 1], but `+`got endFraction ${endFraction}`));assert(endFraction>=startFraction,(()=>`startFraction must be no more than endFraction, but `+`got startFraction ${startFraction} and endFraction `+`${endFraction}`))}return Promise.all(promises.map(registerMonitor))}async function loadWeightsAsArrayBuffer(fetchURLs,loadOptions){if(loadOptions==null){loadOptions={}}const fetchFunc=loadOptions.fetchFunc==null?env().platform.fetch:loadOptions.fetchFunc;const requests=fetchURLs.map((fetchURL=>fetchFunc(fetchURL,loadOptions.requestInit,{isBinary:true})));const fetchStartFraction=0;const fetchEndFraction=.5;const responses=loadOptions.onProgress==null?await Promise.all(requests):await monitorPromisesProgress(requests,loadOptions.onProgress,fetchStartFraction,fetchEndFraction);const bufferPromises=responses.map((response=>response.arrayBuffer()));const bufferStartFraction=.5;const bufferEndFraction=1;const buffers=loadOptions.onProgress==null?await Promise.all(bufferPromises):await monitorPromisesProgress(bufferPromises,loadOptions.onProgress,bufferStartFraction,bufferEndFraction);return buffers}async function loadWeights(manifest,filePathPrefix="",weightNames,requestInit){const fetchWeights=fetchUrls=>loadWeightsAsArrayBuffer(fetchUrls,{requestInit:requestInit});const loadWeights=weightsLoaderFactory(fetchWeights);return loadWeights(manifest,filePathPrefix,weightNames)}function weightsLoaderFactory(fetchWeightsFunction){return async(manifest,filePathPrefix="",weightNames)=>{const groupIndicesToFetchMap=manifest.map((()=>false));const groupWeightsToFetch={};const weightsFound=weightNames!=null?weightNames.map((()=>false)):[];const allManifestWeightNames=[];manifest.forEach(((manifestGroupConfig,groupIndex)=>{let groupOffset=0;manifestGroupConfig.weights.forEach((weightsEntry=>{const rawDtype="quantization"in weightsEntry?weightsEntry.quantization.dtype:weightsEntry.dtype;const weightsBytes=DTYPE_VALUE_SIZE_MAP[rawDtype]*sizeFromShape(weightsEntry.shape);const enqueueWeightsForFetchingFn=()=>{groupIndicesToFetchMap[groupIndex]=true;if(groupWeightsToFetch[groupIndex]==null){groupWeightsToFetch[groupIndex]=[]}groupWeightsToFetch[groupIndex].push({manifestEntry:weightsEntry,groupOffset:groupOffset,sizeBytes:weightsBytes})};if(weightNames!=null){weightNames.forEach(((weightName,weightIndex)=>{if(weightName===weightsEntry.name){enqueueWeightsForFetchingFn();weightsFound[weightIndex]=true}}))}else{enqueueWeightsForFetchingFn()}allManifestWeightNames.push(weightsEntry.name);groupOffset+=weightsBytes}))}));if(!weightsFound.every((found=>found))){const weightsNotFound=weightNames.filter(((_,i)=>!weightsFound[i]));throw new Error(`Could not find weights in manifest with names: `+`${weightsNotFound.join(", ")}. \n`+`Manifest JSON has weights with names: `+`${allManifestWeightNames.join(", ")}.`)}const groupIndicesToFetch=groupIndicesToFetchMap.reduce(((accumulator,shouldFetch,i)=>{if(shouldFetch){accumulator.push(i)}return accumulator}),[]);const fetchUrls=[];groupIndicesToFetch.forEach((i=>{manifest[i].paths.forEach((filepath=>{const fetchUrl=filePathPrefix+(!filePathPrefix.endsWith("/")?"/":"")+filepath;fetchUrls.push(fetchUrl)}))}));const buffers=await fetchWeightsFunction(fetchUrls);const weightsTensorMap={};let bufferIndexOffset=0;groupIndicesToFetch.forEach((i=>{const numBuffers=manifest[i].paths.length;let groupBytes=0;for(let i=0;i<numBuffers;i++){groupBytes+=buffers[bufferIndexOffset+i].byteLength}const groupBuffer=new ArrayBuffer(groupBytes);const groupByteBuffer=new Uint8Array(groupBuffer);let groupBufferOffset=0;for(let i=0;i<numBuffers;i++){const buffer=new Uint8Array(buffers[bufferIndexOffset+i]);groupByteBuffer.set(buffer,groupBufferOffset);groupBufferOffset+=buffer.byteLength}const weightsEntries=groupWeightsToFetch[i];weightsEntries.forEach((weightsEntry=>{const byteBuffer=groupBuffer.slice(weightsEntry.groupOffset,weightsEntry.groupOffset+weightsEntry.sizeBytes);const nameToTensorMap=decodeWeights(byteBuffer,[weightsEntry.manifestEntry]);for(const name in nameToTensorMap){weightsTensorMap[name]=nameToTensorMap[name]}}));bufferIndexOffset+=numBuffers}));return weightsTensorMap}}const OCTET_STREAM_MIME_TYPE="application/octet-stream";const JSON_TYPE="application/json";class HTTPRequest{constructor(path,loadOptions){this.DEFAULT_METHOD="POST";if(loadOptions==null){loadOptions={}}this.weightPathPrefix=loadOptions.weightPathPrefix;this.onProgress=loadOptions.onProgress;this.weightUrlConverter=loadOptions.weightUrlConverter;if(loadOptions.fetchFunc!=null){assert(typeof loadOptions.fetchFunc==="function",(()=>"Must pass a function that matches the signature of "+"`fetch` (see "+"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"));this.fetch=loadOptions.fetchFunc}else{this.fetch=env().platform.fetch}assert(path!=null&&path.length>0,(()=>"URL path for http must not be null, undefined or "+"empty."));if(Array.isArray(path)){assert(path.length===2,(()=>"URL paths for http must have a length of 2, "+`(actual length is ${path.length}).`))}this.path=path;if(loadOptions.requestInit!=null&&loadOptions.requestInit.body!=null){throw new Error("requestInit is expected to have no pre-existing body, but has one.")}this.requestInit=loadOptions.requestInit||{}}async save(modelArtifacts){if(modelArtifacts.modelTopology instanceof ArrayBuffer){throw new Error("BrowserHTTPRequest.save() does not support saving model topology "+"in binary formats yet.")}const init=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);init.body=new FormData;const weightsManifest=[{paths:["./model.weights.bin"],weights:modelArtifacts.weightSpecs}];const modelTopologyAndWeightManifest={modelTopology:modelArtifacts.modelTopology,format:modelArtifacts.format,generatedBy:modelArtifacts.generatedBy,convertedBy:modelArtifacts.convertedBy,weightsManifest:weightsManifest};if(modelArtifacts.signature!=null){modelTopologyAndWeightManifest.signature=modelArtifacts.signature}if(modelArtifacts.userDefinedMetadata!=null){modelTopologyAndWeightManifest.userDefinedMetadata=modelArtifacts.userDefinedMetadata}if(modelArtifacts.modelInitializer!=null){modelTopologyAndWeightManifest.modelInitializer=modelArtifacts.modelInitializer}init.body.append("model.json",new Blob([JSON.stringify(modelTopologyAndWeightManifest)],{type:JSON_TYPE}),"model.json");if(modelArtifacts.weightData!=null){init.body.append("model.weights.bin",new Blob([modelArtifacts.weightData],{type:OCTET_STREAM_MIME_TYPE}),"model.weights.bin")}const response=await this.fetch(this.path,init);if(response.ok){return{modelArtifactsInfo:getModelArtifactsInfoForJSON(modelArtifacts),responses:[response]}}else{throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status `+`${response.status}.`)}}async load(){const modelConfigRequest=await this.fetch(this.path,this.requestInit);if(!modelConfigRequest.ok){throw new Error(`Request to ${this.path} failed with status code `+`${modelConfigRequest.status}. Please verify this URL points to `+`the model JSON of the model to load.`)}let modelConfig;try{modelConfig=await modelConfigRequest.json()}catch(e){let message=`Failed to parse model JSON of response from ${this.path}.`;if(this.path.endsWith(".pb")){message+=" Your path contains a .pb file extension. "+"Support for .pb models have been removed in TensorFlow.js 1.0 "+"in favor of .json models. You can re-convert your Python "+"TensorFlow model using the TensorFlow.js 1.0 conversion scripts "+"or you can convert your.pb models with the 'pb2json'"+"NPM script in the tensorflow/tfjs-converter repository."}else{message+=" Please make sure the server is serving valid "+"JSON for this request."}throw new Error(message)}const modelTopology=modelConfig.modelTopology;const weightsManifest=modelConfig.weightsManifest;const generatedBy=modelConfig.generatedBy;const convertedBy=modelConfig.convertedBy;const format=modelConfig.format;const signature=modelConfig.signature;const userDefinedMetadata=modelConfig.userDefinedMetadata;if(modelTopology==null&&weightsManifest==null){throw new Error(`The JSON from HTTP path ${this.path} contains neither model `+`topology or manifest for weights.`)}let weightSpecs;let weightData;if(weightsManifest!=null){const results=await this.loadWeights(weightsManifest);[weightSpecs,weightData]=results}const artifacts={modelTopology:modelTopology,weightSpecs:weightSpecs,weightData:weightData,generatedBy:generatedBy,convertedBy:convertedBy,format:format};if(signature!=null){artifacts.signature=signature}if(userDefinedMetadata!=null){artifacts.userDefinedMetadata=userDefinedMetadata}const initializer=modelConfig.modelInitializer;if(initializer){artifacts.modelInitializer=initializer}return artifacts}async loadWeights(weightsManifest){const weightPath=Array.isArray(this.path)?this.path[1]:this.path;const[prefix,suffix]=parseUrl(weightPath);const pathPrefix=this.weightPathPrefix||prefix;const weightSpecs=[];for(const entry of weightsManifest){weightSpecs.push(...entry.weights)}const fetchURLs=[];const urlPromises=[];for(const weightsGroup of weightsManifest){for(const path of weightsGroup.paths){if(this.weightUrlConverter!=null){urlPromises.push(this.weightUrlConverter(path))}else{fetchURLs.push(pathPrefix+path+suffix)}}}if(this.weightUrlConverter){fetchURLs.push(...await Promise.all(urlPromises))}const buffers=await loadWeightsAsArrayBuffer(fetchURLs,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress});return[weightSpecs,concatenateArrayBuffers(buffers)]}}HTTPRequest.URL_SCHEME_REGEX=/^https?:\/\//;function parseUrl(url){const lastSlash=url.lastIndexOf("/");const lastSearchParam=url.lastIndexOf("?");const prefix=url.substring(0,lastSlash);const suffix=lastSearchParam>lastSlash?url.substring(lastSearchParam):"";return[prefix+"/",suffix]}function isHTTPScheme(url){return url.match(HTTPRequest.URL_SCHEME_REGEX)!=null}const httpRouter=(url,loadOptions)=>{if(typeof fetch==="undefined"&&(loadOptions==null||loadOptions.fetchFunc==null)){return null}else{let isHTTP=true;if(Array.isArray(url)){isHTTP=url.every((urlItem=>isHTTPScheme(urlItem)))}else{isHTTP=isHTTPScheme(url)}if(isHTTP){return http(url,loadOptions)}}return null};IORouterRegistry.registerSaveRouter(httpRouter);IORouterRegistry.registerLoadRouter(httpRouter);function http(path,loadOptions){return new HTTPRequest(path,loadOptions)}function browserHTTPRequest(path,loadOptions){return http(path,loadOptions)}class PassthroughLoader{constructor(modelArtifacts){this.modelArtifacts=modelArtifacts}async load(){return this.modelArtifacts}}class PassthroughSaver{constructor(saveHandler){this.saveHandler=saveHandler}async save(modelArtifacts){return this.saveHandler(modelArtifacts)}}function fromMemory(modelArtifacts,weightSpecs,weightData,trainingConfig){if(arguments.length===1){const isModelArtifacts=modelArtifacts.modelTopology!=null||modelArtifacts.weightSpecs!=null;if(isModelArtifacts){return new PassthroughLoader(modelArtifacts)}else{console.warn("Please call tf.io.fromMemory() with only one argument. "+"The argument should be of type ModelArtifacts. "+"The multi-argument signature of tf.io.fromMemory() has been "+"deprecated and will be removed in a future release.");return new PassthroughLoader({modelTopology:modelArtifacts})}}else{console.warn("Please call tf.io.fromMemory() with only one argument. "+"The argument should be of type ModelArtifacts. "+"The multi-argument signature of tf.io.fromMemory() has been "+"deprecated and will be removed in a future release.");return new PassthroughLoader({modelTopology:modelArtifacts,weightSpecs:weightSpecs,weightData:weightData,trainingConfig:trainingConfig})}}function withSaveHandler(saveHandler){return new PassthroughSaver(saveHandler)}var io=Object.freeze({__proto__:null,browserFiles:browserFiles,browserHTTPRequest:browserHTTPRequest,concatenateArrayBuffers:concatenateArrayBuffers,decodeWeights:decodeWeights,encodeWeights:encodeWeights,fromMemory:fromMemory,getLoadHandlers:getLoadHandlers,getModelArtifactsInfoForJSON:getModelArtifactsInfoForJSON,getSaveHandlers:getSaveHandlers,http:http,isHTTPScheme:isHTTPScheme,loadWeights:loadWeights,registerLoadRouter:registerLoadRouter,registerSaveRouter:registerSaveRouter,weightsLoaderFactory:weightsLoaderFactory,withSaveHandler:withSaveHandler,copyModel:copyModel,listModels:listModels,moveModel:moveModel,removeModel:removeModel});function matMul_(a,b,transposeA=false,transposeB=false){let $a=convertToTensor(a,"a","matMul");let $b=convertToTensor(b,"b","matMul");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};const attrs={transposeA:transposeA,transposeB:transposeB};return ENGINE.runKernel(BatchMatMul,inputs,attrs)}const matMul$1=op({matMul_:matMul_});function oneHot_(indices,depth,onValue=1,offValue=0){if(depth<2){throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`)}const $indices=convertToTensor(indices,"indices","oneHot","int32");const inputs={indices:$indices};const attrs={depth:depth,onValue:onValue,offValue:offValue};return ENGINE.runKernel(OneHot,inputs,attrs)}const oneHot$1=op({oneHot_:oneHot_});function transpose_(x,perm){const $x=convertToTensor(x,"x","transpose");if(perm==null){perm=$x.shape.map(((s,i)=>i)).reverse()}assert($x.rank===perm.length,(()=>`Error in transpose: rank of input ${$x.rank} `+`must match length of perm ${perm}.`));perm.forEach((axis=>{assert(axis>=0&&axis<$x.rank,(()=>`All entries in 'perm' must be between 0 and ${$x.rank-1}`+` but got ${perm}`))}));if($x.rank<=1){return $x.clone()}const inputs={x:$x};const attrs={perm:perm};return ENGINE.runKernel(Transpose,inputs,attrs)}const transpose$1=op({transpose_:transpose_});function confusionMatrix_(labels,predictions,numClasses){const $labels=convertToTensor(labels,"labels","confusionMatrix");const $predictions=convertToTensor(predictions,"predictions","confusionMatrix");assert(numClasses==null||numClasses>0&&Number.isInteger(numClasses),(()=>`If provided, numClasses must be a positive integer, `+`but got ${numClasses}`));assert($labels.rank===1,(()=>`Expected the rank of labels to be 1, but got ${$labels.rank}`));assert($predictions.rank===1,(()=>`Expected the rank of predictions to be 1, `+`but got ${$predictions.rank}`));assert($labels.shape[0]===$predictions.shape[0],(()=>`Mismatch in the number of examples: `+`${$labels.shape[0]} vs. ${$predictions.shape[0]}. `+`Labels and predictions should have the same number of elements.`));assert(numClasses>0&&Number.isInteger(numClasses),(()=>`numClasses is required to be a positive integer, but got `+`${numClasses}`));const oneHotLabels=oneHot$1(cast$1($labels,"int32"),numClasses);const oneHotPredictions=oneHot$1(cast$1($predictions,"int32"),numClasses);const oneHotLabelsT=transpose$1(oneHotLabels);const product=matMul$1(oneHotLabelsT,oneHotPredictions);return cast$1(product,"int32")}const confusionMatrix=op({confusionMatrix_:confusionMatrix_});var math=Object.freeze({__proto__:null,confusionMatrix:confusionMatrix});function tensor3d(values,shape,dtype){assertNonNull(values);if(shape!=null&&shape.length!==3){throw new Error("tensor3d() requires shape to have three numbers")}const inferredShape=inferShape(values,dtype);if(inferredShape.length!==3&&inferredShape.length!==1){throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray")}if(inferredShape.length===1&&shape==null){throw new Error("tensor3d() requires shape to be provided when `values` "+"are a flat array")}return makeTensor(values,shape,inferredShape,dtype)}let fromPixels2DContext$1;function fromPixels_(pixels,numChannels=3){if(numChannels>4){throw new Error("Cannot construct Tensor with more than 4 channels from pixels.")}if(pixels==null){throw new Error("pixels passed to tf.browser.fromPixels() can not be null")}let isPixelData=false;let isImageData=false;let isVideo=false;let isImage=false;let isCanvasLike=false;let isImageBitmap=false;if(pixels.data instanceof Uint8Array){isPixelData=true}else if(typeof ImageData!=="undefined"&&pixels instanceof ImageData){isImageData=true}else if(typeof HTMLVideoElement!=="undefined"&&pixels instanceof HTMLVideoElement){isVideo=true}else if(typeof HTMLImageElement!=="undefined"&&pixels instanceof HTMLImageElement){isImage=true}else if(pixels.getContext!=null){isCanvasLike=true}else if(typeof ImageBitmap!=="undefined"&&pixels instanceof ImageBitmap){isImageBitmap=true}else{throw new Error("pixels passed to tf.browser.fromPixels() must be either an "+`HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData `+`in browser, or OffscreenCanvas, ImageData in webworker`+` or {data: Uint32Array, width: number, height: number}, `+`but was ${pixels.constructor.name}`)}if(isVideo){const HAVE_CURRENT_DATA_READY_STATE=2;if(isVideo&&pixels.readyState<HAVE_CURRENT_DATA_READY_STATE){throw new Error("The video element has not loaded data yet. Please wait for "+"`loadeddata` event on the <video> element.")}}const kernel=getKernel(FromPixels,ENGINE.backendName);if(kernel!=null){const inputs={pixels:pixels};const attrs={numChannels:numChannels};return ENGINE.runKernel(FromPixels,inputs,attrs)}const[width,height]=isVideo?[pixels.videoWidth,pixels.videoHeight]:[pixels.width,pixels.height];let vals;if(isCanvasLike){vals=pixels.getContext("2d").getImageData(0,0,width,height).data}else if(isImageData||isPixelData){vals=pixels.data}else if(isImage||isVideo||isImageBitmap){if(fromPixels2DContext$1==null){fromPixels2DContext$1=document.createElement("canvas").getContext("2d")}fromPixels2DContext$1.canvas.width=width;fromPixels2DContext$1.canvas.height=height;fromPixels2DContext$1.drawImage(pixels,0,0,width,height);vals=fromPixels2DContext$1.getImageData(0,0,width,height).data}let values;if(numChannels===4){values=new Int32Array(vals)}else{const numPixels=width*height;values=new Int32Array(numPixels*numChannels);for(let i=0;i<numPixels;i++){for(let channel=0;channel<numChannels;++channel){values[i*numChannels+channel]=vals[i*4+channel]}}}const outShape=[height,width,numChannels];return tensor3d(values,outShape,"int32")}function isPixelData(pixels){return pixels!=null&&pixels.data instanceof Uint8Array}function isImageBitmapFullySupported(){return typeof window!=="undefined"&&typeof ImageBitmap!=="undefined"&&window.hasOwnProperty("createImageBitmap")}function isNonEmptyPixels(pixels){return pixels!=null&&pixels.width!==0&&pixels.height!==0}function canWrapPixelsToImageBitmap(pixels){return isImageBitmapFullySupported()&&!(pixels instanceof ImageBitmap)&&isNonEmptyPixels(pixels)&&!isPixelData(pixels)}async function fromPixelsAsync(pixels,numChannels=3){let inputs=null;if(env().getBool("WRAP_TO_IMAGEBITMAP")&&canWrapPixelsToImageBitmap(pixels)){let imageBitmap;try{imageBitmap=await createImageBitmap(pixels,{premultiplyAlpha:"none"})}catch(e){imageBitmap=null}if(imageBitmap!=null&&imageBitmap.width===pixels.width&&imageBitmap.height===pixels.height){inputs=imageBitmap}else{inputs=pixels}}else{inputs=pixels}return fromPixels_(inputs,numChannels)}async function toPixels(img,canvas){let $img=convertToTensor(img,"img","toPixels");if(!(img instanceof Tensor)){const originalImgTensor=$img;$img=cast$1(originalImgTensor,"int32");originalImgTensor.dispose()}if($img.rank!==2&&$img.rank!==3){throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`)}const[height,width]=$img.shape.slice(0,2);const depth=$img.rank===2?1:$img.shape[2];if(depth>4||depth===2){throw new Error(`toPixels only supports depth of size `+`1, 3 or 4 but got ${depth}`)}if($img.dtype!=="float32"&&$img.dtype!=="int32"){throw new Error(`Unsupported type for toPixels: ${$img.dtype}.`+` Please use float32 or int32 tensors.`)}const data=await $img.data();const multiplier=$img.dtype==="float32"?255:1;const bytes=new Uint8ClampedArray(width*height*4);for(let i=0;i<height*width;++i){const rgba=[0,0,0,255];for(let d=0;d<depth;d++){const value=data[i*depth+d];if($img.dtype==="float32"){if(value<0||value>1){throw new Error(`Tensor values for a float32 Tensor must be in the `+`range [0 - 1] but encountered ${value}.`)}}else if($img.dtype==="int32"){if(value<0||value>255){throw new Error(`Tensor values for a int32 Tensor must be in the `+`range [0 - 255] but encountered ${value}.`)}}if(depth===1){rgba[0]=value*multiplier;rgba[1]=value*multiplier;rgba[2]=value*multiplier}else{rgba[d]=value*multiplier}}const j=i*4;bytes[j+0]=Math.round(rgba[0]);bytes[j+1]=Math.round(rgba[1]);bytes[j+2]=Math.round(rgba[2]);bytes[j+3]=Math.round(rgba[3])}if(canvas!=null){canvas.width=width;canvas.height=height;const ctx=canvas.getContext("2d");const imageData=new ImageData(bytes,width,height);ctx.putImageData(imageData,0,0)}if($img!==img){$img.dispose()}return bytes}const fromPixels$1=op({fromPixels_:fromPixels_});var browser=Object.freeze({__proto__:null,fromPixelsAsync:fromPixelsAsync,toPixels:toPixels,fromPixels:fromPixels$1});function prepareAndValidate(tensor,indices){const tensorRank=tensor.shape.length;const indicesRank=indices.shape.length;if(tensorRank<1){throw new Error("tf.gatherND() expects the input to be rank 1 or higher,"+` but the rank was ${tensorRank}.`)}if(indicesRank<1){throw new Error("tf.gatherND() expects the indices to be rank 1 or higher,"+` but the rank was ${indicesRank}.`)}if(indices.dtype!=="int32"){throw new Error("tf.gatherND() expects the indices to be int32 type,"+` but the dtype was ${indices.dtype}.`)}if(indices.shape[indicesRank-1]>tensorRank){throw new Error("index innermost dimension length must be <= tensor rank; saw: "+`${indices.shape[indicesRank-1]} vs. ${tensorRank}`)}if(sizeFromShape(tensor.shape)===0){throw new Error("Requested more than 0 entries, but input is empty."+` Input shape: ${tensor.shape}.`)}const indicesShape=indices.shape;const sliceRank=indicesShape[indicesShape.length-1];let nResult=1;for(let i=0;i<indicesShape.length-1;++i){nResult*=indicesShape[i]}const inputShape=tensor.shape;const resultShape=indicesShape.slice();resultShape.pop();let sliceSize=1;for(let i=sliceRank;i<tensorRank;++i){sliceSize*=inputShape[i];resultShape.push(inputShape[i])}const strides=[...computeStrides(tensor.shape).map((stride=>stride/sliceSize)),1].slice(0,sliceRank);return[resultShape,nResult,sliceSize,strides]}var gather_nd_util=Object.freeze({__proto__:null,prepareAndValidate:prepareAndValidate});function validateUpdateShape(shape,indices,updates){const sliceDim=indices.rank>1?indices.shape[indices.rank-1]:1;const batchDim=indices.rank>1?indices.rank-1:1;const shapeError="Must have updates.shape = indices.shape[:batchDim] + "+`shape[sliceDim:], got updates.shape: ${updates.shape}`+`, indices.shape: ${indices.shape}, shape: ${shape}`+`, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;if(updates.rank<batchDim){throw new Error(shapeError+` update.rank < ${batchDim}. `)}if(shape.length<sliceDim+(updates.rank-batchDim)){throw new Error(shapeError+` Output shape length < ${sliceDim+(updates.rank-batchDim)}`)}if(updates.rank!==batchDim+shape.length-sliceDim){throw new Error(shapeError+` update.rank != ${batchDim+shape.length-sliceDim}`)}for(let d=0;d<batchDim;++d){if(updates.shape[d]!==indices.shape[d]){throw new Error(shapeError+` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`)}}for(let d=0;d<updates.rank-batchDim;++d){if(updates.shape[d+batchDim]!==shape[d+sliceDim]){throw new Error(shapeError+` updates.shape[${d+batchDim}] (${updates.shape[d+batchDim]}) != shape[${d+batchDim}] (${shape[d+batchDim]})`)}}}function validateInput$1(updates,indices,shape){if(indices.rank<1){throw new Error("tf.scatterND() expects the indices to be rank 1 or higher,"+` but the rank was ${indices.rank}.`)}if(updates.rank<1){throw new Error("tf.scatterND() expects the updates to be rank 1 or higher,"+` but the rank was ${updates.rank}.`)}if(indices.dtype!=="int32"){throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`)}if(shape.length<1){throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`)}if(shape.length===0){if(indices.size===0){throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`)}if(updates.size===0){throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`)}}validateUpdateShape(shape,indices,updates)}function calculateShapes(updates,indices,shape){const indicesRank=indices.shape.length;const sliceRank=indicesRank>1?indices.shape[indicesRank-1]:1;const totalNd=shape.length;let sliceSize=1;for(let i=sliceRank;i<totalNd;++i){sliceSize*=shape[i]}const safeSliceDim=sliceRank<1?1:sliceRank;const numUpdates=sizeFromShape(indices.shape)/safeSliceDim;const strides=[...computeStrides(shape.slice(0,sliceRank)),1];const outputSize=sizeFromShape(shape);return{sliceRank:sliceRank,numUpdates:numUpdates,sliceSize:sliceSize,strides:strides,outputSize:outputSize}}var scatter_nd_util=Object.freeze({__proto__:null,validateUpdateShape:validateUpdateShape,validateInput:validateInput$1,calculateShapes:calculateShapes});function assertParamsValid(input,begin,size){const inputRank=input.shape.length;assert(inputRank===begin.length,(()=>`Error in slice${inputRank}D: Length of begin ${begin} must `+`match the rank of the array (${inputRank}).`));assert(inputRank===size.length,(()=>`Error in slice${inputRank}D: Length of size ${size} must `+`match the rank of the array (${inputRank}).`));for(let i=0;i<inputRank;++i){assert(begin[i]+size[i]<=input.shape[i],(()=>`Error in slice${inputRank}D: begin[${i}] + size[${i}] `+`(${begin[i]+size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`))}}function maskToAxes(mask){const axes=[];let axis=0;while(mask>0){if(mask&1){axes.push(axis)}mask/=2;axis++}return axes}function computeOutShape$2(begin,end,strides){const size=[];for(let axis=0;axis<begin.length;axis++){size[axis]=Math.ceil((end[axis]-begin[axis])/strides[axis])}return size}function stridesWithElidedDims(strides,ellipsisInsertionIndex,numElidedAxes,inputShape){const newStrides=[...strides];for(let i=newStrides.length;i<inputShape.length;i++){newStrides.push(1)}for(let i=0;i<numElidedAxes;i++){if(i===0){newStrides[ellipsisInsertionIndex]=1}else{newStrides.splice(ellipsisInsertionIndex,0,1);newStrides.pop()}}return newStrides}function unnormalizeAxis(ellipsisInsertionIndex,numElidedAxes,normalizedAxis){if(normalizedAxis<=ellipsisInsertionIndex){return normalizedAxis}return normalizedAxis-(numElidedAxes-1)}function getElidedAxes(numElidedAxes,ellipsisInsertionIndex){const elidedAxes=[];for(let i=0;i<numElidedAxes;i++){elidedAxes.push(ellipsisInsertionIndex+i)}return elidedAxes}function getNormalizedAxes(inputShape,ellipsisAxes,numInterpolatedAxes,begin,end,strides,beginMask,endMask,ellipsisMask){const inputRank=inputShape.length;let normalizedBegin=new Array(inputRank),normalizedEnd=new Array(inputRank),normalizedStrides=new Array(inputRank);if(ellipsisAxes.length&&numInterpolatedAxes>0){const fullIndex=ellipsisAxes[0];const numElidedAxes=numInterpolatedAxes+1;normalizedBegin=startIndicesWithElidedDims(beginMask,fullIndex,numElidedAxes,begin,inputShape);normalizedEnd=stopIndicesWithElidedDims(endMask,fullIndex,numElidedAxes,end,inputShape);normalizedStrides=stridesWithElidedDims(strides,fullIndex,numElidedAxes,inputShape)}else{for(let axis=0;axis<inputRank;axis++){normalizedBegin[axis]=startForAxis(beginMask,begin,strides,inputShape,axis,ellipsisMask);normalizedEnd[axis]=stopForAxis(endMask,end,strides,inputShape,axis,ellipsisMask);normalizedStrides[axis]=stridesForAxis(strides,axis,ellipsisMask)}}return{begin:normalizedBegin,end:normalizedEnd,strides:normalizedStrides}}function startIndicesWithElidedDims(beginMask,ellipsisInsertionIndex,numElidedAxes,originalBegin,inputShape){const newIndices=[...inputShape];const elidedAxes=getElidedAxes(numElidedAxes,ellipsisInsertionIndex);for(let axis=0;axis<newIndices.length;axis++){if(elidedAxes.indexOf(axis)>-1){newIndices[axis]=0}else{const originalAxis=unnormalizeAxis(ellipsisInsertionIndex,numElidedAxes,axis);let originalValue=originalBegin[originalAxis];if(beginMask&1<<originalAxis){originalValue=0}newIndices[axis]=originalValue}}return newIndices}function stopIndicesWithElidedDims(endMask,ellipsisInsertionIndex,numElidedAxes,originalEnd,inputShape){const newIndices=[...inputShape];const elidedAxes=getElidedAxes(numElidedAxes,ellipsisInsertionIndex);for(let axis=0;axis<newIndices.length;axis++){if(elidedAxes.indexOf(axis)>-1){newIndices[axis]=Number.MAX_SAFE_INTEGER}else{const originalAxis=unnormalizeAxis(ellipsisInsertionIndex,numElidedAxes,axis);let originalValue=originalEnd[originalAxis];if(endMask&1<<originalAxis){originalValue=Number.MAX_SAFE_INTEGER}newIndices[axis]=originalValue}}for(let i=0;i<newIndices.length;i++){const axisSize=inputShape[i];if(newIndices[i]<0){newIndices[i]+=axisSize}newIndices[i]=clamp(0,newIndices[i],inputShape[i])}return newIndices}function stridesForAxis(strides,axis,ellipsisMask){let stride=strides[axis];if(ellipsisMask&1<<axis||stride==null){stride=1}return stride}function startForAxis(beginMask,startIndices,strides,inputShape,axis,ellipsisMask){let start=startIndices[axis];const stride=strides[axis]||1;if(beginMask&1<<axis||ellipsisMask&1<<axis||start==null){if(stride>0){start=Number.MIN_SAFE_INTEGER}else{start=Number.MAX_SAFE_INTEGER}}const axisSize=inputShape[axis];if(start<0){start+=axisSize}start=clamp(0,start,axisSize-1);return start}function stopForAxis(endMask,stopIndices,strides,inputShape,axis,ellipsisMask){let stop=stopIndices[axis];const stride=strides[axis]||1;if(endMask&1<<axis||ellipsisMask&1<<axis||stop==null){if(stride>0){stop=Number.MAX_SAFE_INTEGER}else{stop=Number.MIN_SAFE_INTEGER}}const axisSize=inputShape[axis];if(stop<0){stop+=axisSize}if(stride>0){stop=clamp(0,stop,axisSize)}else{stop=clamp(-1,stop,axisSize-1)}return stop}function isSliceContinous(shape,begin,size){let firstNonOneAxis=size.length;for(let i=0;i<size.length;i++){if(size[i]>1){firstNonOneAxis=i;break}}for(let i=firstNonOneAxis+1;i<size.length;i++){if(begin[i]>0||size[i]!==shape[i]){return false}}return true}function computeFlatOffset(begin,strides){let flatOffset=begin.length>0?begin[begin.length-1]:1;for(let i=0;i<begin.length-1;i++){flatOffset+=begin[i]*strides[i]}return flatOffset}function parseSliceParams(x,begin,size){let begin_;const xRank=x.shape.length;if(typeof begin==="number"){begin_=[begin,...new Array(xRank-1).fill(0)]}else if(begin.length<xRank){begin_=begin.concat(new Array(xRank-begin.length).fill(0))}else{begin_=begin.slice()}begin_.forEach((d=>{assert(d!==-1,(()=>"slice() does not support negative begin indexing."))}));let size_;if(size==null){size_=new Array(xRank).fill(-1)}else if(typeof size==="number"){size_=[size,...new Array(xRank-1).fill(-1)]}else if(size.length<xRank){size_=size.concat(new Array(xRank-size.length).fill(-1))}else{size_=size}size_=size_.map(((d,i)=>{if(d>=0){return d}else{assert(d===-1,(()=>`Negative size values should be exactly -1 but got `+`${d} for the slice() size at index ${i}.`));return x.shape[i]-begin_[i]}}));return[begin_,size_]}function sliceInfo(xShape,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask){let $begin=begin.slice();let $end=end.slice();let $strides=strides;if(strides==null){$strides=new Array($begin.length)}const ellipsisAxes=maskToAxes(ellipsisMask);if(ellipsisAxes.length>1){throw new Error("Multiple ellipses in slice is not allowed.")}if(ellipsisMask!==0&&newAxisMask!==0){throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.")}if(ellipsisMask!==0&&shrinkAxisMask!==0){throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.")}const numInterpolatedAxes=xShape.length-$begin.length;const expandAxes=maskToAxes(newAxisMask);const newShape=xShape.slice();expandAxes.forEach((axis=>{$begin[axis]=0;$end[axis]=1;newShape.splice(axis,0,1)}));const{begin:normalizedBegin,end:normalizedEnd,strides:normalizedStrides}=getNormalizedAxes(newShape,ellipsisAxes,numInterpolatedAxes,$begin,$end,$strides,beginMask,endMask,ellipsisMask);$begin=normalizedBegin;$end=normalizedEnd;$strides=normalizedStrides;const shrinkAxes=maskToAxes(shrinkAxisMask);shrinkAxes.forEach((axis=>{$end[axis]=$begin[axis]+1;$strides[axis]=1}));const size=computeOutShape$2($begin,$end,$strides);const outShape=size.filter(((_,axis)=>shrinkAxes.indexOf(axis)===-1));const nonStrided=$strides.every((v=>v===1));return{nonStrided:nonStrided,$begin:$begin,$end:$end,$strides:$strides,size:size,newShape:newShape,outShape:outShape}}var slice_util=Object.freeze({__proto__:null,assertParamsValid:assertParamsValid,maskToAxes:maskToAxes,computeOutShape:computeOutShape$2,stridesWithElidedDims:stridesWithElidedDims,getNormalizedAxes:getNormalizedAxes,startIndicesWithElidedDims:startIndicesWithElidedDims,stopIndicesWithElidedDims:stopIndicesWithElidedDims,stridesForAxis:stridesForAxis,startForAxis:startForAxis,stopForAxis:stopForAxis,isSliceContinous:isSliceContinous,computeFlatOffset:computeFlatOffset,parseSliceParams:parseSliceParams,sliceInfo:sliceInfo});class Serializable{getClassName(){return this.constructor.className}static fromConfig(cls,config){return new cls(config)}}class SerializationMap{constructor(){this.classNameMap={}}static getMap(){if(SerializationMap.instance==null){SerializationMap.instance=new SerializationMap}return SerializationMap.instance}static register(cls){SerializationMap.getMap().classNameMap[cls.className]=[cls,cls.fromConfig]}}function registerClass(cls){assert(cls.className!=null,(()=>`Class being registered does not have the static className `+`property defined.`));assert(typeof cls.className==="string",(()=>`className is required to be a string, but got type `+typeof cls.className));assert(cls.className.length>0,(()=>`Class being registered has an empty-string as its className, `+`which is disallowed.`));SerializationMap.register(cls)}var serialization=Object.freeze({__proto__:null,Serializable:Serializable,SerializationMap:SerializationMap,registerClass:registerClass});const TEST_EPSILON_FLOAT32=.001;const TEST_EPSILON_FLOAT16=.1;function expectArraysClose(actual,expected,epsilon){if(epsilon==null){epsilon=testEpsilon()}return expectArraysPredicate(actual,expected,((a,b)=>areClose(a,b,epsilon)))}function testEpsilon(){return ENGINE.backend.floatPrecision()===32?TEST_EPSILON_FLOAT32:TEST_EPSILON_FLOAT16}function expectArraysPredicate(actual,expected,predicate){let checkClassType=true;if(isTypedArray(actual)||isTypedArray(expected)){checkClassType=false}if(isTypedArray(actual)&&isTypedArray(expected)){checkClassType=true}if(checkClassType){const aType=actual.constructor.name;const bType=expected.constructor.name;if(aType!==bType){throw new Error(`Arrays are of different type. Actual: ${aType}. `+`Expected: ${bType}`)}}if(Array.isArray(actual)&&Array.isArray(expected)){const actualShape=inferShape(actual);const expectedShape=inferShape(expected);if(!arraysEqual(actualShape,expectedShape)){throw new Error(`Arrays have different shapes. `+`Actual: [${actualShape}]. Expected: [${expectedShape}]`)}}const actualFlat=isTypedArray(actual)?actual:flatten(actual);const expectedFlat=isTypedArray(expected)?expected:flatten(expected);if(actualFlat.length!==expectedFlat.length){throw new Error(`Arrays have different lengths actual: ${actualFlat.length} vs `+`expected: ${expectedFlat.length}.\n`+`Actual:   ${actualFlat}.\n`+`Expected: ${expectedFlat}.`)}for(let i=0;i<expectedFlat.length;++i){const a=actualFlat[i];const e=expectedFlat[i];if(!predicate(a,e)){throw new Error(`Arrays differ: actual[${i}] = ${a}, expected[${i}] = ${e}.\n`+`Actual:   ${actualFlat}.\n`+`Expected: ${expectedFlat}.`)}}}function expectPromiseToFail(fn,done){fn().then((()=>done.fail()),(()=>done()))}function expectArraysEqual(actual,expected){const exp=typeof expected==="string"||typeof expected==="number"||typeof expected==="boolean"?[expected]:expected;if(isString(actual)||isString(actual[0])||isString(expected)||isString(expected[0])){return expectArraysPredicate(actual,exp,((a,b)=>a==b))}return expectArraysPredicate(actual,expected,((a,b)=>areClose(a,b,0)))}function expectNumbersClose(a,e,epsilon){if(epsilon==null){epsilon=testEpsilon()}if(!areClose(a,e,epsilon)){throw new Error(`Numbers differ: actual === ${a}, expected === ${e}`)}}function areClose(a,e,epsilon){if(!isFinite(a)&&!isFinite(e)){return true}if(isNaN(a)||isNaN(e)||Math.abs(a-e)>epsilon){return false}return true}function expectValuesInRange(actual,low,high){for(let i=0;i<actual.length;i++){if(actual[i]<low||actual[i]>high){throw new Error(`Value out of range:${actual[i]} low: ${low}, high: ${high}`)}}}function expectArrayBuffersEqual(actual,expected){expect(new Float32Array(actual)).toEqual(new Float32Array(expected))}function encodeStrings(a){for(let i=0;i<a.length;i++){const val=a[i];if(Array.isArray(val)){encodeStrings(val)}else{a[i]=encodeString(val)}}return a}var test_util=Object.freeze({__proto__:null,TEST_EPSILON_FLOAT16:TEST_EPSILON_FLOAT16,expectArraysClose:expectArraysClose,testEpsilon:testEpsilon,expectPromiseToFail:expectPromiseToFail,expectArraysEqual:expectArraysEqual,expectNumbersClose:expectNumbersClose,expectValuesInRange:expectValuesInRange,expectArrayBuffersEqual:expectArrayBuffersEqual,encodeStrings:encodeStrings});const version$1="3.6.0";function enableProdMode(){env().set("PROD",true)}function enableDebugMode(){env().set("DEBUG",true)}function disableDeprecationWarnings(){env().set("DEPRECATION_WARNINGS_ENABLED",false);console.warn(`TensorFlow.js deprecation warnings have been disabled.`)}function deprecationWarn(msg){if(env().getBool("DEPRECATION_WARNINGS_ENABLED")){console.warn(msg+" You can disable deprecation warnings with "+"tf.disableDeprecationWarnings().")}}function disposeVariables(){ENGINE.disposeVariables()}function engine(){return ENGINE}function memory(){return ENGINE.memory()}function profile(f){return ENGINE.profile(f)}function tidy(nameOrFn,fn){return ENGINE.tidy(nameOrFn,fn)}function dispose(container){const tensors=getTensorsInContainer(container);tensors.forEach((tensor=>tensor.dispose()))}function keep(result){return ENGINE.keep(result)}function time(f){return ENGINE.time(f)}function setBackend(backendName){return ENGINE.setBackend(backendName)}function ready(){return ENGINE.ready()}function getBackend(){return ENGINE.backendName}function removeBackend(name){ENGINE.removeBackend(name)}function findBackend(name){return ENGINE.findBackend(name)}function findBackendFactory(name){return ENGINE.findBackendFactory(name)}function registerBackend(name,factory,priority=1){return ENGINE.registerBackend(name,factory,priority)}function backend(){return ENGINE.backend}function setPlatform(platformName,platform){env().setPlatform(platformName,platform)}function add_(a,b){let $a=convertToTensor(a,"a","add");let $b=convertToTensor(b,"b","add");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(Add,inputs)}const add=op({add_:add_});function floorDiv_(a,b){let $a=convertToTensor(a,"a","floorDiv");let $b=convertToTensor(b,"b","floorDiv");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(FloorDiv,inputs)}const floorDiv$1=op({floorDiv_:floorDiv_});function div_(a,b){let $a=convertToTensor(a,"a","div");let $b=convertToTensor(b,"b","div");[$a,$b]=makeTypesMatch($a,$b);if($a.dtype==="int32"&&$b.dtype==="int32"){return floorDiv$1($a,$b)}const inputs={a:$a,b:$b};const attrs={};return ENGINE.runKernel(RealDiv,inputs,attrs)}const div=op({div_:div_});function mul_(a,b){let $a=convertToTensor(a,"a","mul");let $b=convertToTensor(b,"b","mul");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(Multiply,inputs)}const mul=op({mul_:mul_});function abs_(x){const $x=convertToTensor(x,"x","abs");if($x.dtype==="complex64"){const inputs={x:$x};return ENGINE.runKernel(ComplexAbs,inputs)}else{const inputs={x:$x};return ENGINE.runKernel(Abs,inputs)}}const abs$1=op({abs_:abs_});function acos_(x){const $x=convertToTensor(x,"x","acos");const inputs={x:$x};return ENGINE.runKernel(Acos,inputs)}const acos$1=op({acos_:acos_});function acosh_(x){const $x=convertToTensor(x,"x","acosh");const inputs={x:$x};return ENGINE.runKernel(Acosh,inputs)}const acosh$1=op({acosh_:acosh_});function addN_(tensors){assert(Array.isArray(tensors),(()=>"The argument passed to tf.addN() must be a list of tensors"));assert(tensors.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got `+`${tensors.length}`));const $tensors=tensors.map(((t,i)=>convertToTensor(t,`tensors${i}`,"addN")));const firstTensor=$tensors[0];$tensors.forEach((t=>{if(t.dtype!==firstTensor.dtype){throw new Error("All tensors passed to tf.addN() must have the same dtype")}}));$tensors.forEach((t=>{if(!arraysEqual(t.shape,firstTensor.shape)){throw new Error("All tensors passed to tf.addN() must have the same shape")}}));const inputs=$tensors;return ENGINE.runKernel(AddN,inputs)}const addN$1=op({addN_:addN_});function all_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","all","bool");const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(All,inputs,attrs)}const all$1=op({all_:all_});function any_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","any","bool");const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(Any,inputs,attrs)}const any$1=op({any_:any_});function argMax_(x,axis=0){const $x=convertToTensor(x,"x","argMax");const inputs={x:$x};const attrs={axis:axis};return ENGINE.runKernel(ArgMax,inputs,attrs)}const argMax$1=op({argMax_:argMax_});function argMin_(x,axis=0){const $x=convertToTensor(x,"x","argMin");const inputs={x:$x};const attrs={axis:axis};return ENGINE.runKernel(ArgMin,inputs,attrs)}const argMin$1=op({argMin_:argMin_});function asin_(x){const $x=convertToTensor(x,"x","asin");const inputs={x:$x};return ENGINE.runKernel(Asin,inputs)}const asin$1=op({asin_:asin_});function asinh_(x){const $x=convertToTensor(x,"x","asinh");const inputs={x:$x};return ENGINE.runKernel(Asinh,inputs)}const asinh$1=op({asinh_:asinh_});function atan_(x){const $x=convertToTensor(x,"x","atan");const inputs={x:$x};return ENGINE.runKernel(Atan,inputs)}const atan$1=op({atan_:atan_});function atan2_(a,b){let $a=convertToTensor(a,"a","atan2");let $b=convertToTensor(b,"b","atan2");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(Atan2,inputs)}const atan2$1=op({atan2_:atan2_});function atanh_(x){const $x=convertToTensor(x,"x","atanh");const inputs={x:$x};return ENGINE.runKernel(Atanh,inputs)}const atanh$1=op({atanh_:atanh_});function computeDilation2DInfo(inputShape,filterShape,strides,pad,dataFormat="NHWC",dilations){const inputChannels=inputShape[3];const $filterShape=[...filterShape,inputChannels];const $dataFormat=convertConv2DDataFormat(dataFormat);return computeConv2DInfo(inputShape,$filterShape,strides,dilations,pad,null,null,$dataFormat)}function computePool2DInfo(inShape,filterSize,strides,dilations,pad,roundingMode,dataFormat="channelsLast"){const[filterHeight,filterWidth]=parseTupleParam(filterSize);let filterShape;if(dataFormat==="channelsLast"){filterShape=[filterHeight,filterWidth,inShape[3],inShape[3]]}else if(dataFormat==="channelsFirst"){filterShape=[filterHeight,filterWidth,inShape[1],inShape[1]]}else{throw new Error(`Unknown dataFormat ${dataFormat}`)}return computeConv2DInfo(inShape,filterShape,strides,dilations,pad,roundingMode,false,dataFormat)}function computePool3DInfo(inShape,filterSize,strides,dilations,pad,roundingMode,dataFormat="NDHWC"){const[filterDepth,filterHeight,filterWidth]=parse3TupleParam(filterSize);let filterShape;let $dataFormat;if(dataFormat==="NDHWC"){$dataFormat="channelsLast";filterShape=[filterDepth,filterHeight,filterWidth,inShape[4],inShape[4]]}else if(dataFormat==="NCDHW"){$dataFormat="channelsFirst";filterShape=[filterDepth,filterHeight,filterWidth,inShape[1],inShape[1]]}else{throw new Error(`Unknown dataFormat ${dataFormat}`)}return computeConv3DInfo(inShape,filterShape,strides,dilations,pad,false,$dataFormat,roundingMode)}function computeConv2DInfo(inShape,filterShape,strides,dilations,pad,roundingMode,depthwise=false,dataFormat="channelsLast"){let[batchSize,inHeight,inWidth,inChannels]=[-1,-1,-1,-1];if(dataFormat==="channelsLast"){[batchSize,inHeight,inWidth,inChannels]=inShape}else if(dataFormat==="channelsFirst"){[batchSize,inChannels,inHeight,inWidth]=inShape}else{throw new Error(`Unknown dataFormat ${dataFormat}`)}const[filterHeight,filterWidth,,filterChannels]=filterShape;const[strideHeight,strideWidth]=parseTupleParam(strides);const[dilationHeight,dilationWidth]=parseTupleParam(dilations);const effectiveFilterHeight=getEffectiveFilterSize(filterHeight,dilationHeight);const effectiveFilterWidth=getEffectiveFilterSize(filterWidth,dilationWidth);const{padInfo:padInfo,outHeight:outHeight,outWidth:outWidth}=getPadAndOutInfo(pad,inHeight,inWidth,strideHeight,strideWidth,effectiveFilterHeight,effectiveFilterWidth,roundingMode,dataFormat);const outChannels=depthwise?filterChannels*inChannels:filterChannels;let outShape;if(dataFormat==="channelsFirst"){outShape=[batchSize,outChannels,outHeight,outWidth]}else if(dataFormat==="channelsLast"){outShape=[batchSize,outHeight,outWidth,outChannels]}return{batchSize:batchSize,dataFormat:dataFormat,inHeight:inHeight,inWidth:inWidth,inChannels:inChannels,outHeight:outHeight,outWidth:outWidth,outChannels:outChannels,padInfo:padInfo,strideHeight:strideHeight,strideWidth:strideWidth,filterHeight:filterHeight,filterWidth:filterWidth,effectiveFilterHeight:effectiveFilterHeight,effectiveFilterWidth:effectiveFilterWidth,dilationHeight:dilationHeight,dilationWidth:dilationWidth,inShape:inShape,outShape:outShape,filterShape:filterShape}}function computeConv3DInfo(inShape,filterShape,strides,dilations,pad,depthwise=false,dataFormat="channelsLast",roundingMode){let[batchSize,inDepth,inHeight,inWidth,inChannels]=[-1,-1,-1,-1,-1];if(dataFormat==="channelsLast"){[batchSize,inDepth,inHeight,inWidth,inChannels]=inShape}else if(dataFormat==="channelsFirst"){[batchSize,inChannels,inDepth,inHeight,inWidth]=inShape}else{throw new Error(`Unknown dataFormat ${dataFormat}`)}const[filterDepth,filterHeight,filterWidth,,filterChannels]=filterShape;const[strideDepth,strideHeight,strideWidth]=parse3TupleParam(strides);const[dilationDepth,dilationHeight,dilationWidth]=parse3TupleParam(dilations);const effectiveFilterDepth=getEffectiveFilterSize(filterDepth,dilationDepth);const effectiveFilterHeight=getEffectiveFilterSize(filterHeight,dilationHeight);const effectiveFilterWidth=getEffectiveFilterSize(filterWidth,dilationWidth);const{padInfo:padInfo,outDepth:outDepth,outHeight:outHeight,outWidth:outWidth}=get3DPadAndOutInfo(pad,inDepth,inHeight,inWidth,strideDepth,strideHeight,strideWidth,effectiveFilterDepth,effectiveFilterHeight,effectiveFilterWidth,roundingMode);const outChannels=depthwise?filterChannels*inChannels:filterChannels;let outShape;if(dataFormat==="channelsFirst"){outShape=[batchSize,outChannels,outDepth,outHeight,outWidth]}else if(dataFormat==="channelsLast"){outShape=[batchSize,outDepth,outHeight,outWidth,outChannels]}return{batchSize:batchSize,dataFormat:dataFormat,inDepth:inDepth,inHeight:inHeight,inWidth:inWidth,inChannels:inChannels,outDepth:outDepth,outHeight:outHeight,outWidth:outWidth,outChannels:outChannels,padInfo:padInfo,strideDepth:strideDepth,strideHeight:strideHeight,strideWidth:strideWidth,filterDepth:filterDepth,filterHeight:filterHeight,filterWidth:filterWidth,effectiveFilterDepth:effectiveFilterDepth,effectiveFilterHeight:effectiveFilterHeight,effectiveFilterWidth:effectiveFilterWidth,dilationDepth:dilationDepth,dilationHeight:dilationHeight,dilationWidth:dilationWidth,inShape:inShape,outShape:outShape,filterShape:filterShape}}function computeOutputShape2D(inShape,fieldSize,stride,zeroPad,roundingMode){if(zeroPad==null){zeroPad=computeDefaultPad(inShape,fieldSize,stride)}const inputRows=inShape[0];const inputCols=inShape[1];const outputRows=round$2((inputRows-fieldSize+2*zeroPad)/stride+1,roundingMode);const outputCols=round$2((inputCols-fieldSize+2*zeroPad)/stride+1,roundingMode);return[outputRows,outputCols]}function computeOutputShape4D(inShape,fieldSize,outChannels,stride,zeroPad,roundingMode){if(zeroPad==null){zeroPad=computeDefaultPad(inShape,fieldSize,stride)}const inputDepth=inShape[0];const inputRows=inShape[1];const inputCols=inShape[2];const outputDepths=round$2((inputDepth-fieldSize+2*zeroPad)/stride+1,roundingMode);const outputRows=round$2((inputRows-fieldSize+2*zeroPad)/stride+1,roundingMode);const outputCols=round$2((inputCols-fieldSize+2*zeroPad)/stride+1,roundingMode);return[outputDepths,outputRows,outputCols,outChannels]}function computeDefaultPad(inputShape,fieldSize,stride,dilation=1){const effectiveFieldSize=getEffectiveFilterSize(fieldSize,dilation);return Math.floor((inputShape[0]*(stride-1)-stride+effectiveFieldSize)/2)}function parseTupleParam(param){if(typeof param==="number"){return[param,param,param]}if(param.length===2){return[param[0],param[1],1]}return param}function parse3TupleParam(param){return typeof param==="number"?[param,param,param]:param}function getEffectiveFilterSize(filterSize,dilation){if(dilation<=1){return filterSize}return filterSize+(filterSize-1)*(dilation-1)}function getPadAndOutInfo(pad,inHeight,inWidth,strideHeight,strideWidth,filterHeight,filterWidth,roundingMode,dataFormat){let padInfo;let outHeight;let outWidth;if(typeof pad==="number"){const padType=pad===0?"VALID":"NUMBER";padInfo={top:pad,bottom:pad,left:pad,right:pad,type:padType};const outShape=computeOutputShape2D([inHeight,inWidth],filterHeight,strideHeight,pad,roundingMode);outHeight=outShape[0];outWidth=outShape[1]}else if(pad==="same"){outHeight=Math.ceil(inHeight/strideHeight);outWidth=Math.ceil(inWidth/strideWidth);const padAlongHeight=Math.max(0,(outHeight-1)*strideHeight+filterHeight-inHeight);const padAlongWidth=Math.max(0,(outWidth-1)*strideWidth+filterWidth-inWidth);const top=Math.floor(padAlongHeight/2);const bottom=padAlongHeight-top;const left=Math.floor(padAlongWidth/2);const right=padAlongWidth-left;padInfo={top:top,bottom:bottom,left:left,right:right,type:"SAME"}}else if(pad==="valid"){padInfo={top:0,bottom:0,left:0,right:0,type:"VALID"};outHeight=Math.ceil((inHeight-filterHeight+1)/strideHeight);outWidth=Math.ceil((inWidth-filterWidth+1)/strideWidth)}else if(typeof pad==="object"){const top=dataFormat==="channelsLast"?pad[1][0]:pad[2][0];const bottom=dataFormat==="channelsLast"?pad[1][1]:pad[2][1];const left=dataFormat==="channelsLast"?pad[2][0]:pad[3][0];const right=dataFormat==="channelsLast"?pad[2][1]:pad[3][1];const padType=top===0&&bottom===0&&left===0&&right===0?"VALID":"EXPLICIT";padInfo={top:top,bottom:bottom,left:left,right:right,type:padType};outHeight=round$2((inHeight-filterHeight+top+bottom)/strideHeight+1,roundingMode);outWidth=round$2((inWidth-filterWidth+left+right)/strideWidth+1,roundingMode)}else{throw Error(`Unknown padding parameter: ${pad}`)}return{padInfo:padInfo,outHeight:outHeight,outWidth:outWidth}}function get3DPadAndOutInfo(pad,inDepth,inHeight,inWidth,strideDepth,strideHeight,strideWidth,filterDepth,filterHeight,filterWidth,roundingMode){let padInfo;let outDepth;let outHeight;let outWidth;if(typeof pad==="number"){const padType=pad===0?"VALID":"NUMBER";padInfo={top:pad,bottom:pad,left:pad,right:pad,front:pad,back:pad,type:padType};const outShape=computeOutputShape4D([inDepth,inHeight,inWidth,1],filterDepth,1,strideDepth,pad,roundingMode);outDepth=outShape[0];outHeight=outShape[1];outWidth=outShape[2]}else if(pad==="same"){outDepth=Math.ceil(inDepth/strideDepth);outHeight=Math.ceil(inHeight/strideHeight);outWidth=Math.ceil(inWidth/strideWidth);const padAlongDepth=(outDepth-1)*strideDepth+filterDepth-inDepth;const padAlongHeight=(outHeight-1)*strideHeight+filterHeight-inHeight;const padAlongWidth=(outWidth-1)*strideWidth+filterWidth-inWidth;const front=Math.floor(padAlongDepth/2);const back=padAlongDepth-front;const top=Math.floor(padAlongHeight/2);const bottom=padAlongHeight-top;const left=Math.floor(padAlongWidth/2);const right=padAlongWidth-left;padInfo={top:top,bottom:bottom,left:left,right:right,front:front,back:back,type:"SAME"}}else if(pad==="valid"){padInfo={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"};outDepth=Math.ceil((inDepth-filterDepth+1)/strideDepth);outHeight=Math.ceil((inHeight-filterHeight+1)/strideHeight);outWidth=Math.ceil((inWidth-filterWidth+1)/strideWidth)}else{throw Error(`Unknown padding parameter: ${pad}`)}return{padInfo:padInfo,outDepth:outDepth,outHeight:outHeight,outWidth:outWidth}}function round$2(value,roundingMode){if(!roundingMode){return Math.trunc(value)}switch(roundingMode){case"round":return Math.round(value);case"ceil":return Math.ceil(value);case"floor":return Math.floor(value);default:throw new Error(`Unknown roundingMode ${roundingMode}`)}}function tupleValuesAreOne(param){const[dimA,dimB,dimC]=parseTupleParam(param);return dimA===1&&dimB===1&&dimC===1}function eitherStridesOrDilationsAreOne(strides,dilations){return tupleValuesAreOne(strides)||tupleValuesAreOne(dilations)}function convertConv2DDataFormat(dataFormat){if(dataFormat==="NHWC"){return"channelsLast"}else if(dataFormat==="NCHW"){return"channelsFirst"}else{throw new Error(`Unknown dataFormat ${dataFormat}`)}}function reshape_(x,shape){const $x=convertToTensor(x,"x","reshape","string_or_numeric");const inputs={x:$x};const attrs={shape:shape};return ENGINE.runKernel(Reshape,inputs,attrs)}const reshape$1=op({reshape_:reshape_});function avgPool_(x,filterSize,strides,pad,dimRoundingMode){const $x=convertToTensor(x,"x","avgPool","float32");const dilations=1;assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in avgPool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in avgPool: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x4D};const attrs={filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode};let res=ENGINE.runKernel(AvgPool,inputs,attrs);res=cast$1(res,$x.dtype);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const avgPool$1=op({avgPool_:avgPool_});function avgPool3d_(x,filterSize,strides,pad,dimRoundingMode,dataFormat="NDHWC"){const $x=convertToTensor(x,"x","avgPool3d","float32");let x5D=$x;let reshapedTo5D=false;if($x.rank===4){reshapedTo5D=true;x5D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2],$x.shape[3]])}assert(x5D.rank===5,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`));assert(dataFormat==="NDHWC",(()=>`Error in avgPool3d: Only NDHWC is currently supported, `+`but got dataFormat of ${dataFormat}`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in avgPool3d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x5D};const attrs={filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode,dataFormat:dataFormat};let res=ENGINE.runKernel(AvgPool3D,inputs,attrs);res=cast$1(res,x5D.dtype);if(reshapedTo5D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]])}return res}const avgPool3d=op({avgPool3d_:avgPool3d_});function concat_(tensors,axis=0){assert(tensors.length>=1,(()=>"Pass at least one tensor to concat"));const $tensors=convertToTensorArray(tensors,"tensors","concat","string_or_numeric");if($tensors[0].dtype==="complex64"){$tensors.forEach((tensor=>{if(tensor.dtype!=="complex64"){throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `)}}))}if($tensors.length===1){return clone($tensors[0])}const inputs=$tensors;const attr={axis:axis};return ENGINE.runKernel(Concat,inputs,attr)}const concat$1=op({concat_:concat_});function sigmoid_(x){const $x=convertToTensor(x,"x","sigmoid");const inputs={x:$x};return ENGINE.runKernel(Sigmoid,inputs)}const sigmoid$1=op({sigmoid_:sigmoid_});function slice_(x,begin,size){const $x=convertToTensor(x,"x","slice","string_or_numeric");if($x.rank===0){throw new Error("Slicing scalar is not possible")}const inputs={x:$x};const attrs={begin:begin,size:size};return ENGINE.runKernel(Slice,inputs,attrs)}const slice$1=op({slice_:slice_});function tanh_(x){const $x=convertToTensor(x,"x","tanh");const inputs={x:$x};return ENGINE.runKernel(Tanh,inputs)}const tanh$1=op({tanh_:tanh_});function basicLSTMCell_(forgetBias,lstmKernel,lstmBias,data,c,h){const $forgetBias=convertToTensor(forgetBias,"forgetBias","basicLSTMCell");const $lstmKernel=convertToTensor(lstmKernel,"lstmKernel","basicLSTMCell");const $lstmBias=convertToTensor(lstmBias,"lstmBias","basicLSTMCell");const $data=convertToTensor(data,"data","basicLSTMCell");const $c=convertToTensor(c,"c","basicLSTMCell");const $h=convertToTensor(h,"h","basicLSTMCell");const combined=concat$1([$data,$h],1);const weighted=matMul$1(combined,$lstmKernel);const res=add(weighted,$lstmBias);const batchSize=res.shape[0];const sliceCols=res.shape[1]/4;const sliceSize=[batchSize,sliceCols];const i=slice$1(res,[0,0],sliceSize);const j=slice$1(res,[0,sliceCols],sliceSize);const f=slice$1(res,[0,sliceCols*2],sliceSize);const o=slice$1(res,[0,sliceCols*3],sliceSize);const newC=add(mul(sigmoid$1(i),tanh$1(j)),mul($c,sigmoid$1(add($forgetBias,f))));const newH=mul(tanh$1(newC),sigmoid$1(o));return[newC,newH]}const basicLSTMCell=op({basicLSTMCell_:basicLSTMCell_});function batchToSpaceND_(x,blockShape,crops){const $x=convertToTensor(x,"x","batchToSpaceND");const prod=blockShape.reduce(((a,b)=>a*b));assert($x.rank>=1+blockShape.length,(()=>`input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`));assert(crops.length===blockShape.length,(()=>`crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`));assert($x.shape[0]%prod===0,(()=>`input tensor batch is ${$x.shape[0]} but is not divisible by the product of `+`the elements of blockShape ${blockShape.join(" * ")} === ${prod}`));const inputs={x:$x};const attrs={blockShape:blockShape,crops:crops};return ENGINE.runKernel(BatchToSpaceND,inputs,attrs)}const batchToSpaceND$1=op({batchToSpaceND_:batchToSpaceND_});function xAs4D(x){let x4D;if(x.rank===0||x.rank===1){x4D=reshape$1(x,[1,1,1,x.size])}else if(x.rank===2){x4D=reshape$1(x,[1,1,x.shape[0],x.shape[1]])}else if(x.rank===3){x4D=reshape$1(x,[1,x.shape[0],x.shape[1],x.shape[2]])}else{x4D=x}return x4D}function batchNorm_(x,mean,variance,offset,scale,varianceEpsilon){if(varianceEpsilon==null){varianceEpsilon=.001}const $x=convertToTensor(x,"x","batchNorm");const $mean=convertToTensor(mean,"mean","batchNorm");const $variance=convertToTensor(variance,"variance","batchNorm");let $scale;if(scale!=null){$scale=convertToTensor(scale,"scale","batchNorm")}let $offset;if(offset!=null){$offset=convertToTensor(offset,"offset","batchNorm")}assert($mean.rank===$variance.rank,(()=>"Batch normalization gradient requires mean and variance to have "+"equal ranks."));assert($offset==null||$mean.rank===$offset.rank,(()=>"Batch normalization gradient requires mean and offset to have "+"equal ranks."));assert($scale==null||$mean.rank===$scale.rank,(()=>"Batch normalization gradient requires mean and scale to have "+"equal ranks."));const x4D=xAs4D($x);const inputs={x:x4D,scale:$scale,offset:$offset,mean:$mean,variance:$variance};const attrs={varianceEpsilon:varianceEpsilon};const res=ENGINE.runKernel(FusedBatchNorm,inputs,attrs);return reshape$1(res,$x.shape)}const batchNorm$1=op({batchNorm_:batchNorm_});function batchNorm2d_(x,mean,variance,offset,scale,varianceEpsilon){const $x=convertToTensor(x,"x","batchNorm");const $mean=convertToTensor(mean,"mean","batchNorm");const $variance=convertToTensor(variance,"variance","batchNorm");let $scale;if(scale!=null){$scale=convertToTensor(scale,"scale","batchNorm")}let $offset;if(offset!=null){$offset=convertToTensor(offset,"offset","batchNorm")}assert($x.rank===2,(()=>`Error in batchNorm2D: x must be rank 2 but got rank `+`${$x.rank}.`));assert($mean.rank===2||$mean.rank===1,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but `+`got rank ${$mean.rank}.`));assert($variance.rank===2||$variance.rank===1,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 `+`but got rank ${$variance.rank}.`));if($scale!=null){assert($scale.rank===2||$scale.rank===1,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 `+`but got rank ${$scale.rank}.`))}if($offset!=null){assert($offset.rank===2||$offset.rank===1,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 `+`but got rank ${$offset.rank}.`))}return batchNorm$1($x,$mean,$variance,$offset,$scale,varianceEpsilon)}const batchNorm2d=op({batchNorm2d_:batchNorm2d_});function batchNorm3d_(x,mean,variance,offset,scale,varianceEpsilon){const $x=convertToTensor(x,"x","batchNorm");const $mean=convertToTensor(mean,"mean","batchNorm");const $variance=convertToTensor(variance,"variance","batchNorm");let $scale;if(scale!=null){$scale=convertToTensor(scale,"scale","batchNorm")}let $offset;if(offset!=null){$offset=convertToTensor(offset,"offset","batchNorm")}assert($x.rank===3,(()=>`Error in batchNorm3D: x must be rank 3 but got rank `+`${$x.rank}.`));assert($mean.rank===3||$mean.rank===1,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but `+`got rank ${$mean.rank}.`));assert($variance.rank===3||$variance.rank===1,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 `+`but got rank ${$variance.rank}.`));if($scale!=null){assert($scale.rank===3||$scale.rank===1,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 `+`but got rank ${$scale.rank}.`))}if($offset!=null){assert($offset.rank===3||$offset.rank===1,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 `+`but got rank ${$offset.rank}.`))}return batchNorm$1($x,$mean,$variance,$offset,$scale,varianceEpsilon)}const batchNorm3d=op({batchNorm3d_:batchNorm3d_});function batchNorm4d_(x,mean,variance,offset,scale,varianceEpsilon){const $x=convertToTensor(x,"x","batchNorm");const $mean=convertToTensor(mean,"mean","batchNorm");const $variance=convertToTensor(variance,"variance","batchNorm");let $scale;if(scale!=null){$scale=convertToTensor(scale,"scale","batchNorm")}let $offset;if(offset!=null){$offset=convertToTensor(offset,"offset","batchNorm")}assert($x.rank===4,(()=>`Error in batchNorm4D: x must be rank 4 but got rank `+`${$x.rank}.`));assert($mean.rank===4||$mean.rank===1,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but `+`got rank ${$mean.rank}.`));assert($variance.rank===4||$variance.rank===1,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 `+`but got rank ${$variance.rank}.`));if($scale!=null){assert($scale.rank===4||$scale.rank===1,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 `+`but got rank ${$scale.rank}.`))}if($offset!=null){assert($offset.rank===4||$offset.rank===1,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 `+`but got rank ${$offset.rank}.`))}return batchNorm$1($x,$mean,$variance,$offset,$scale,varianceEpsilon)}const batchNorm4d=op({batchNorm4d_:batchNorm4d_});function bincount_(x,weights,size){const $x=convertToTensor(x,"x","bincount");const $weights=convertToTensor(weights,"weights","bincount");assert($x.dtype==="int32",(()=>`Error in bincount: input `+`dtype must be int32, but got ${$x.dtype}`));assert(size>=0,(()=>`size must be non-negative, but got ${size}.`));assert($weights.size===$x.size||$weights.size===0,(()=>`Error in bincount: weights must have the same size as input or`+`0-length, but got input shape: ${$x.shape}, weights shape: `+`${$weights.shape}.`));const inputs={x:$x,weights:$weights};const attrs={size:size};return ENGINE.runKernel(Bincount,inputs,attrs)}const bincount$1=op({bincount_:bincount_});function broadcastTo_(x,shape){let input=convertToTensor(x,"broadcastTo","x");const xShape=input.shape;if(shape.some((d=>!(d>0)||d%1!==0))){throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`)}if(shape.length<input.rank){throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`)}if(shape.length>input.rank){const newShape=input.shape.slice();while(newShape.length<shape.length){newShape.unshift(1)}input=reshape$1(input,newShape)}const inputShape=input.shape;const reps=Array.from(shape);for(let i=shape.length-1;i>=0;i--){if(inputShape[i]===shape[i]){reps[i]=1}else if(input.shape[i]!==1){throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`)}}const axes=reps.map(((n,i)=>n>1?i:-1)).filter((i=>i>=0));if(axes.length===0){return clone(input)}const inputs={x:input};const attrs={reps:reps};return ENGINE.runKernel(Tile,inputs,attrs)}const broadcastTo=op({broadcastTo_:broadcastTo_});function ceil_(x){const $x=convertToTensor(x,"x","ceil");const inputs={x:$x};return ENGINE.runKernel(Ceil,inputs)}const ceil$1=op({ceil_:ceil_});function clipByValue_(x,clipValueMin,clipValueMax){const $x=convertToTensor(x,"x","clipByValue");assert(clipValueMin<=clipValueMax,(()=>`Error in clip: min (${clipValueMin}) must be `+`less than or equal to max (${clipValueMax}).`));const inputs={x:$x};const attrs={clipValueMin:clipValueMin,clipValueMax:clipValueMax};return ENGINE.runKernel(ClipByValue,inputs,attrs)}const clipByValue$1=op({clipByValue_:clipByValue_});function concat1d_(tensors){return concat$1(tensors,0)}const concat1d=op({concat1d_:concat1d_});function concat2d_(tensors,axis){return concat$1(tensors,axis)}const concat2d=op({concat2d_:concat2d_});function concat3d_(tensors,axis){return concat$1(tensors,axis)}const concat3d=op({concat3d_:concat3d_});function concat4d_(tensors,axis){return concat$1(tensors,axis)}const concat4d=op({concat4d_:concat4d_});function conv2d_(x,filter,strides,pad,dataFormat="NHWC",dilations=[1,1],dimRoundingMode){const $x=convertToTensor(x,"x","conv2d");const $filter=convertToTensor(filter,"filter","conv2d");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`));assert($filter.rank===4,(()=>`Error in conv2d: filter must be rank 4, but got rank `+`${$filter.rank}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in conv2d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inDepth=dataFormat==="NHWC"?x4D.shape[3]:x4D.shape[1];assert(inDepth===$filter.shape[2],(()=>`Error in conv2d: depth of input (${inDepth}) must match `+`input depth for filter ${$filter.shape[2]}.`));assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in conv2D: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));const inputs={x:x4D,filter:$filter};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode};const res=ENGINE.runKernel(Conv2D,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const conv2d$2=op({conv2d_:conv2d_});function conv1d_(x,filter,stride,pad,dataFormat="NWC",dilation=1,dimRoundingMode){const $x=convertToTensor(x,"x","conv1d");const $filter=convertToTensor(filter,"filter","conv1d");let x3D=$x;let reshapedTo3D=false;if($x.rank===2){reshapedTo3D=true;x3D=reshape$1($x,[1,$x.shape[0],$x.shape[1]])}assert(x3D.rank===3,(()=>`Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`));assert($filter.rank===3,(()=>`Error in conv1d: filter must be rank 3, but got rank `+`${$filter.rank}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in conv1d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}assert(x3D.shape[2]===$filter.shape[1],(()=>`Error in conv1d: depth of input (${x3D.shape[2]}) must match `+`input depth for filter ${$filter.shape[1]}.`));assert(eitherStridesOrDilationsAreOne(stride,dilation),(()=>"Error in conv1D: Either stride or dilation must be 1. "+`Got stride ${stride} and dilation '${dilation}'`));assert(dataFormat==="NWC",(()=>`Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`));const filter4D=reshape$1($filter,[1,$filter.shape[0],$filter.shape[1],$filter.shape[2]]);const input4D=reshape$1(x3D,[x3D.shape[0],1,x3D.shape[1],x3D.shape[2]]);const strides=[1,stride];const dilations=[1,dilation];const conv2dDataFormat="NHWC";const res=conv2d$2(input4D,filter4D,strides,pad,conv2dDataFormat,dilations,dimRoundingMode);if(reshapedTo3D){return reshape$1(res,[res.shape[2],res.shape[3]])}return reshape$1(res,[res.shape[0],res.shape[2],res.shape[3]])}const conv1d=op({conv1d_:conv1d_});function conv2DBackpropInput_(xShape,dy,filter,strides,pad,dataFormat="NHWC",dimRoundingMode){assert(xShape.length===dy.rank,(()=>`Length of inShape `+`(${xShape.length}) and rank of dy (${dy.rank}) must match`));let xShape4D=xShape;let dy4D=dy;let reshapedTo4D=false;if(dy.rank===3){reshapedTo4D=true;dy4D=reshape$1(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2]]);xShape4D=[1,xShape[0],xShape[1],xShape[2]]}assert(xShape4D.length===4,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length `+`${xShape4D.length}.`));assert(dy4D.rank===4,(()=>`Error in conv2dDerInput: dy must be rank 4, but got `+`rank ${dy4D.rank}`));assert(filter.rank===4,(()=>`Error in conv2dDerInput: filter must be rank 4, but got `+`rank ${filter.rank}`));const inDepth=dataFormat==="NHWC"?xShape4D[3]:xShape4D[1];const outDepth=dataFormat==="NHWC"?dy4D.shape[3]:dy4D.shape[1];assert(inDepth===filter.shape[2],(()=>`Error in conv2dDerInput: depth of input (${inDepth}) must `+`match input depth for filter ${filter.shape[2]}.`));assert(outDepth===filter.shape[3],(()=>`Error in conv2dDerInput: depth of output (${outDepth}) must `+`match output depth for filter ${filter.shape[3]}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in conv2dDerInput: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={dy:dy4D,filter:filter};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dimRoundingMode:dimRoundingMode,inputShape:xShape4D};const res=ENGINE.runKernel(Conv2DBackpropInput,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const conv2DBackpropInput$1=op({conv2DBackpropInput_:conv2DBackpropInput_});function conv2dTranspose_(x,filter,outputShape,strides,pad,dimRoundingMode){const $x=convertToTensor(x,"x","conv2dTranspose");const $filter=convertToTensor(filter,"filter","conv2dTranspose");return conv2DBackpropInput$1(outputShape,$x,$filter,strides,pad,"NHWC",dimRoundingMode)}const conv2dTranspose=op({conv2dTranspose_:conv2dTranspose_});function conv3d_(x,filter,strides,pad,dataFormat="NDHWC",dilations=[1,1,1]){const $x=convertToTensor(x,"x","conv3d");const $filter=convertToTensor(filter,"filter","conv3d");let x5D=$x;let reshapedTo5D=false;if($x.rank===4){reshapedTo5D=true;x5D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2],$x.shape[3]])}assert(x5D.rank===5,(()=>`Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`));assert($filter.rank===5,(()=>`Error in conv3d: filter must be rank 5, but got rank `+`${$filter.rank}.`));assert(x5D.shape[4]===$filter.shape[3],(()=>`Error in conv3d: depth of input (${x5D.shape[4]}) must match `+`input depth for filter ${$filter.shape[3]}.`));assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in conv3D: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));assert(dataFormat==="NDHWC",(()=>`Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`));const inputs={x:x5D,filter:$filter};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations};const res=ENGINE.runKernel(Conv3D,inputs,attrs);if(reshapedTo5D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]])}return res}const conv3d=op({conv3d_:conv3d_});function conv3DBackpropInput_(xShape,dy,filter,strides,pad){assert(xShape.length===dy.rank,(()=>`Length of inShape `+`(${xShape.length}) and rank of dy (${dy.rank}) must match`));let xShape5D=xShape;let dy5D=dy;let reshapedTo5D=false;if(dy.rank===4){reshapedTo5D=true;dy5D=reshape$1(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2],dy.shape[3]]);xShape5D=[1,xShape[0],xShape[1],xShape[2],xShape[3]]}const inDepth=xShape5D[4];const outDepth=dy5D.shape[4];assert(xShape5D.length===5,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length `+`${xShape5D.length}.`));assert(dy5D.rank===5,(()=>`Error in conv3dDerInput: dy must be rank 5, but got `+`rank ${dy5D.rank}`));assert(filter.rank===5,(()=>`Error in conv3dDerInput: filter must be rank 5, but got `+`rank ${filter.rank}`));assert(inDepth===filter.shape[3],(()=>`Error in conv3dDerInput: depth of input (${inDepth}) must `+`match input depth for filter ${filter.shape[3]}.`));assert(outDepth===filter.shape[4],(()=>`Error in conv3dDerInput: depth of output (${outDepth}) must `+`match output depth for filter ${filter.shape[4]}.`));const inputs={dy:dy5D,filter:filter};const attrs={pad:pad,strides:strides,inputShape:xShape5D};const res=ENGINE.runKernel(Conv3DBackpropInputV2,inputs,attrs);if(reshapedTo5D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]])}return res}const conv3DBackpropInput$1=op({conv3DBackpropInput_:conv3DBackpropInput_});function conv3dTranspose_(x,filter,outputShape,strides,pad){const $x=convertToTensor(x,"x","conv3dTranspose");const $filter=convertToTensor(filter,"filter","conv3dTranspose");return conv3DBackpropInput$1(outputShape,$x,$filter,strides,pad)}const conv3dTranspose=op({conv3dTranspose_:conv3dTranspose_});function cos_(x){const $x=convertToTensor(x,"x","cos");const inputs={x:$x};return ENGINE.runKernel(Cos,inputs)}const cos$1=op({cos_:cos_});function cosh_(x){const $x=convertToTensor(x,"x","cosh");const inputs={x:$x};return ENGINE.runKernel(Cosh,inputs)}const cosh$1=op({cosh_:cosh_});function cumsum_(x,axis=0,exclusive=false,reverse=false){const $x=convertToTensor(x,"x","cumsum");const inputs={x:$x};const attrs={axis:axis,exclusive:exclusive,reverse:reverse};return ENGINE.runKernel(Cumsum,inputs,attrs)}const cumsum$1=op({cumsum_:cumsum_});function denseBincount_(x,weights,size,binaryOutput=false){const $x=convertToTensor(x,"x","denseBincount");const $weights=convertToTensor(weights,"weights","denseBincount");assert($x.dtype==="int32",(()=>`Error in denseBincount: input `+`dtype must be int32, but got ${$x.dtype}`));assert($x.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got `+`rank ${$x.rank}.`));assert(size>=0,(()=>`size must be non-negative, but got ${size}.`));assert($weights.size===$x.size||$weights.size===0,(()=>`Error in denseBincount: weights must have the same shape as x or `+`0-length, but got x shape: ${$x.shape}, weights shape: `+`${$weights.shape}.`));const inputs={x:$x,weights:$weights};const attrs={size:size,binaryOutput:binaryOutput};return ENGINE.runKernel(DenseBincount,inputs,attrs)}const denseBincount$1=op({denseBincount_:denseBincount_});function depthToSpace_(x,blockSize,dataFormat="NHWC"){const $x=convertToTensor(x,"x","depthToSpace");const inputHeight=dataFormat==="NHWC"?$x.shape[1]:$x.shape[2];const inputWidth=dataFormat==="NHWC"?$x.shape[2]:$x.shape[3];const inputDepth=dataFormat==="NHWC"?$x.shape[3]:$x.shape[1];assert(inputHeight*blockSize>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${inputHeight} and ${blockSize}  for depthToSpace with input shape\n    ${$x.shape}`));assert(inputWidth*blockSize>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${inputWidth} and ${blockSize} for depthToSpace with input shape\n        ${$x.shape}`));assert(inputDepth%(blockSize*blockSize)===0,(()=>`Dimension size must be evenly divisible by ${blockSize*blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`));const inputs={x:$x};const attrs={blockSize:blockSize,dataFormat:dataFormat};return ENGINE.runKernel(DepthToSpace,inputs,attrs)}const depthToSpace$1=op({depthToSpace_:depthToSpace_});function depthwiseConv2d_(x,filter,strides,pad,dataFormat="NHWC",dilations=[1,1],dimRoundingMode){const $x=convertToTensor(x,"x","depthwiseConv2d");const $filter=convertToTensor(filter,"filter","depthwiseConv2d");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in depthwiseConv2d: input must be rank 4, but got `+`rank ${x4D.rank}.`));assert($filter.rank===4,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank `+`${$filter.rank}.`));assert(x4D.shape[3]===$filter.shape[2],(()=>`Error in depthwiseConv2d: number of input channels `+`(${x4D.shape[3]}) must match the inChannels dimension in `+`filter ${$filter.shape[2]}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in depthwiseConv2d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x4D,filter:$filter};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode};const res=ENGINE.runKernel(DepthwiseConv2dNative,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const depthwiseConv2d$1=op({depthwiseConv2d_:depthwiseConv2d_});function diag_(x){const $x=convertToTensor(x,"x","diag");const inputs={x:$x};return ENGINE.runKernel(Diag,inputs)}const diag$1=op({diag_:diag_});function dilation2d_(x,filter,strides,pad,dilations=[1,1],dataFormat="NHWC"){const $x=convertToTensor(x,"x","dilation2d");const $filter=convertToTensor(filter,"filter","dilation2d");assert($x.rank===3||$x.rank===4,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank `+`${$x.rank}.`));assert($filter.rank===3,(()=>`Error in dilation2d: filter must be rank 3, but got rank `+`${$filter.rank}.`));assert(dataFormat==="NHWC",(()=>`Error in dilation2d: Only NHWC is currently supported, `+`but got dataFormat of ${dataFormat}`));let x4D=$x;let reshapedTo4D=false;if($x.rank===3){x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]]);reshapedTo4D=true}const inputs={x:x4D,filter:$filter};const attrs={strides:strides,pad:pad,dilations:dilations};const res=ENGINE.runKernel(Dilation2D,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const dilation2d=op({dilation2d_:dilation2d_});function getBroadcastDims$1(inShape,outShape){const inRank=inShape.length;const dims=[];for(let i=0;i<inRank;i++){const dim=inRank-1-i;const a=inShape[dim]||1;const b=outShape[outShape.length-1-i]||1;if(b>1&&a===1){dims.unshift(dim)}}return dims}function getReductionAxes(inShape,outShape){const result=[];for(let i=0;i<outShape.length;i++){const inDim=inShape[inShape.length-i-1];const outAxis=outShape.length-i-1;const outDim=outShape[outAxis];if(inDim==null||inDim===1&&outDim>1){result.unshift(outAxis)}}return result}function assertAndGetBroadcastShape(shapeA,shapeB){const result=[];const l=Math.max(shapeA.length,shapeB.length);for(let i=0;i<l;i++){let a=shapeA[shapeA.length-i-1];if(a==null){a=1}let b=shapeB[shapeB.length-i-1];if(b==null){b=1}if(a===1){result.unshift(b)}else if(b===1){result.unshift(a)}else if(a!==b){const errMsg=`Operands could not be broadcast together with shapes `+`${shapeA} and ${shapeB}.`;throw Error(errMsg)}else{result.unshift(a)}}return result}function equal_(a,b){let $a=convertToTensor(a,"a","equal");let $b=convertToTensor(b,"b","equal");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(Equal,inputs)}const equal$1=op({equal_:equal_});function where_(condition,a,b){const $a=convertToTensor(a,"a","where");const $b=convertToTensor(b,"b","where");const $condition=convertToTensor(condition,"condition","where","bool");const broadcastShape=assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape,$a.shape),$b.shape);const $broadcastedCondition=broadcastTo($condition,broadcastShape);const $broadcastedA=broadcastTo($a,broadcastShape);const $broadcastedB=broadcastTo($b,broadcastShape);const inputs={condition:$broadcastedCondition,t:$broadcastedA,e:$broadcastedB};return ENGINE.runKernel(Select,inputs)}const where=op({where_:where_});function zerosLike_(x){const $x=convertToTensor(x,"x","zerosLike");const inputs={x:$x};return ENGINE.runKernel(ZerosLike,inputs)}const zerosLike$1=op({zerosLike_:zerosLike_});function divNoNan_(a,b){let $a=convertToTensor(a,"a","div");let $b=convertToTensor(b,"b","div");[$a,$b]=makeTypesMatch($a,$b);const divResult=div($a,$b);const zeros=zerosLike$1(divResult);const bEqualsZero=equal$1($b,zeros);return where(bEqualsZero,zeros,divResult)}const divNoNan=op({divNoNan_:divNoNan_});function dot_(t1,t2){const $t1=convertToTensor(t1,"t1","dot");const $t2=convertToTensor(t2,"t2","dot");assert(($t1.rank===1||$t1.rank===2)&&($t2.rank===1||$t2.rank===2),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks `+`${$t1.rank} and ${$t2.rank}.`));const t1Inner=$t1.rank===1?$t1.size:$t1.shape[1];const t2Inner=$t2.rank===1?$t2.size:$t2.shape[0];assert(t1Inner===t2Inner,(()=>`Error in dot: inner dimensions of inputs must match, but got `+`${t1Inner} and ${t2Inner}.`));if($t1.rank===1&&$t2.rank===1){const t12D=reshape$1($t1,[1,-1]);const t22D=reshape$1($t2,[-1,1]);const t1t2=matMul$1(t12D,t22D);return reshape$1(t1t2,[])}else if($t1.rank===1&&$t2.rank===2){const t12D=reshape$1($t1,[1,-1]);const t22D=reshape$1($t2,[$t2.shape[0],$t2.shape[1]]);const t1t2=matMul$1(t12D,t22D);return reshape$1(t1t2,[t1t2.size])}else if($t1.rank===2&&$t2.rank===1){const t22D=reshape$1($t2,[-1,1]);const t1t2=matMul$1($t1,t22D);return reshape$1(t1t2,[t1t2.size])}else{const t22D=reshape$1($t2,[$t2.shape[0],$t2.shape[1]]);const t1t2=matMul$1($t1,t22D);return t1t2}}const dot=op({dot_:dot_});function einsum_(equation,...tensors){const $tensors=tensors.map(((t,i)=>convertToTensor(t,`tensors${i}`,"einsum")));const attrs={equation:equation};return ENGINE.runKernel(Einsum,$tensors,attrs)}const einsum$1=op({einsum_:einsum_});function elu_(x){const $x=convertToTensor(x,"x","elu");const inputs={x:$x};return ENGINE.runKernel(Elu,inputs)}const elu$1=op({elu_:elu_});function erf_(x){let $x=convertToTensor(x,"x","erf");assert($x.dtype==="int32"||$x.dtype==="float32",(()=>"Input dtype must be `int32` or `float32`."));if($x.dtype==="int32"){$x=cast$1($x,"float32")}const inputs={x:$x};return ENGINE.runKernel(Erf,inputs)}const erf$1=op({erf_:erf_});function exp_(x){const $x=convertToTensor(x,"x","exp");const inputs={x:$x};return ENGINE.runKernel(Exp,inputs)}const exp$1=op({exp_:exp_});function expandDims_(x,axis=0){const $x=convertToTensor(x,"x","expandDims","string_or_numeric");assert(axis<=$x.rank,(()=>"Axis must be <= rank of the tensor"));const inputs={input:$x};const attrs={dim:axis};return ENGINE.runKernel(ExpandDims,inputs,attrs)}const expandDims$1=op({expandDims_:expandDims_});function expm1_(x){const $x=convertToTensor(x,"x","expm1");const inputs={x:$x};return ENGINE.runKernel(Expm1,inputs)}const expm1$1=op({expm1_:expm1_});function tile_(x,reps){const $x=convertToTensor(x,"x","tile","string_or_numeric");assert($x.rank===reps.length,(()=>`Error in transpose: rank of input ${$x.rank} `+`must match length of reps ${reps}.`));const inputs={x:$x};const attrs={reps:reps};return ENGINE.runKernel(Tile,inputs,attrs)}const tile$1=op({tile_:tile_});function eye_(numRows,numColumns,batchShape,dtype="float32"){if(numColumns==null){numColumns=numRows}const buff=buffer([numRows,numColumns],dtype);const n=numRows<=numColumns?numRows:numColumns;for(let i=0;i<n;++i){buff.set(1,i,i)}const out=reshape$1(buff.toTensor(),[numRows,numColumns]);if(batchShape==null){return out}else{if(batchShape.length===1){return tile$1(expandDims$1(out,0),[batchShape[0],1,1])}else if(batchShape.length===2){return tile$1(expandDims$1(expandDims$1(out,0),0),[batchShape[0],batchShape[1],1,1])}else if(batchShape.length===3){return tile$1(expandDims$1(expandDims$1(expandDims$1(out,0),0),0),[batchShape[0],batchShape[1],batchShape[2],1,1])}else{throw new Error(`eye() currently supports only 1D and 2D `+`batchShapes, but received ${batchShape.length}D.`)}}}const eye=op({eye_:eye_});function fill$1(shape,value,dtype){const attrs={shape:shape,value:value,dtype:dtype};return ENGINE.runKernel(Fill,{},attrs)}function floor_(x){const $x=convertToTensor(x,"x","floor");const inputs={x:$x};return ENGINE.runKernel(Floor,inputs)}const floor$1=op({floor_:floor_});function gather_(x,indices,axis=0,batchDims=0){const $x=convertToTensor(x,"x","gather");const $indices=convertToTensor(indices,"indices","gather","int32");const inputs={x:$x,indices:$indices};const attrs={axis:axis,batchDims:batchDims};return ENGINE.runKernel(GatherV2,inputs,attrs)}const gather=op({gather_:gather_});function greater_(a,b){let $a=convertToTensor(a,"a","greater");let $b=convertToTensor(b,"b","greater");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(Greater,inputs)}const greater$1=op({greater_:greater_});function greaterEqual_(a,b){let $a=convertToTensor(a,"a","greaterEqual");let $b=convertToTensor(b,"b","greaterEqual");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(GreaterEqual,inputs)}const greaterEqual$1=op({greaterEqual_:greaterEqual_});function imag_(input){const $input=convertToTensor(input,"input","imag");const inputs={input:$input};return ENGINE.runKernel(Imag,inputs)}const imag$1=op({imag_:imag_});function isFinite_(x){const $x=convertToTensor(x,"x","isFinite");const inputs={x:$x};return ENGINE.runKernel(IsFinite,inputs)}const isFinite$2=op({isFinite_:isFinite_});function isInf_(x){const $x=convertToTensor(x,"x","isInf");const inputs={x:$x};return ENGINE.runKernel(IsInf,inputs)}const isInf$1=op({isInf_:isInf_});function isNaN_(x){const $x=convertToTensor(x,"x","isNaN");const inputs={x:$x};return ENGINE.runKernel(IsNan,inputs)}const isNaN$2=op({isNaN_:isNaN_});function leakyRelu_(x,alpha=.2){const $x=convertToTensor(x,"x","leakyRelu");const inputs={x:$x};const attrs={alpha:alpha};return ENGINE.runKernel(LeakyRelu,inputs,attrs)}const leakyRelu$1=op({leakyRelu_:leakyRelu_});function less_(a,b){let $a=convertToTensor(a,"a","less");let $b=convertToTensor(b,"b","less");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(Less,inputs)}const less$1=op({less_:less_});function lessEqual_(a,b){let $a=convertToTensor(a,"a","lessEqual");let $b=convertToTensor(b,"b","lessEqual");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(LessEqual,inputs)}const lessEqual$1=op({lessEqual_:lessEqual_});function linspace(start,stop,num){if(num<=0){throw new Error("The number of values should be positive.")}const attrs={start:start,stop:stop,num:num};return ENGINE.runKernel(LinSpace,{},attrs)}function localResponseNormalization_(x,depthRadius=5,bias=1,alpha=1,beta=.5){const $x=convertToTensor(x,"x","localResponseNormalization");assert($x.rank===4||$x.rank===3,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${$x.rank}.`));assert(isInt(depthRadius),(()=>`Error in localResponseNormalization: depthRadius must be an `+`integer but got depthRadius ${depthRadius}.`));let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}const inputs={x:x4D};const attrs={depthRadius:depthRadius,bias:bias,alpha:alpha,beta:beta};const res=ENGINE.runKernel(LRN,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}else{return res}}const localResponseNormalization=op({localResponseNormalization_:localResponseNormalization_});function log_(x){const $x=convertToTensor(x,"x","log");const inputs={x:$x};return ENGINE.runKernel(Log,inputs)}const log$2=op({log_:log_});function log1p_(x){const $x=convertToTensor(x,"x","log1p");const inputs={x:$x};return ENGINE.runKernel(Log1p,inputs)}const log1p$1=op({log1p_:log1p_});function grad(f){assert(isFunction(f),(()=>"The f passed in grad(f) must be a function"));return(x,dy)=>{const $x=convertToTensor(x,"x","tf.grad","string_or_numeric");const $dy=dy!=null?convertToTensor(dy,"dy","tf.grad"):null;return ENGINE.tidy((()=>{const{value:value,grads:grads}=ENGINE.gradients((()=>f($x)),[$x],$dy);if($dy!=null){assertShapesMatch(value.shape,$dy.shape,"The shape of dy passed in grad(f)(x, dy) must match the shape "+"returned by f(x)")}checkGrads(grads);return grads[0]}))}}function grads(f){assert(isFunction(f),(()=>"The f passed in grads(f) must be a function"));return(args,dy)=>{assert(Array.isArray(args),(()=>"The args passed in grads(f)(args) must be an array "+"of `Tensor`s or `TensorLike`s"));const $args=convertToTensorArray(args,"args","tf.grads","string_or_numeric");const $dy=dy!=null?convertToTensor(dy,"dy","tf.grads"):null;return ENGINE.tidy((()=>{const{value:value,grads:grads}=ENGINE.gradients((()=>f(...$args)),$args,$dy);if($dy!=null){assertShapesMatch(value.shape,$dy.shape,"The shape of dy passed in grads(f)([x1,...], dy) must "+"match the shape returned by f([x1,...])")}checkGrads(grads);return grads}))}}function valueAndGrad(f){assert(isFunction(f),(()=>"The f passed in valueAndGrad(f) must be a function"));return(x,dy)=>{assert(x instanceof Tensor,(()=>"The x passed in valueAndGrad(f)(x) must be a tensor"));assert(dy==null||dy instanceof Tensor,(()=>"The dy passed in valueAndGrad(f)(x, dy) must be a tensor"));const{grads:grads,value:value}=ENGINE.gradients((()=>f(x)),[x],dy);checkGrads(grads);return{grad:grads[0],value:value}}}function valueAndGrads(f){assert(isFunction(f),(()=>"The f passed in valueAndGrads(f) must be a function"));return(args,dy)=>{assert(Array.isArray(args)&&args.every((arg=>arg instanceof Tensor)),(()=>"The args passed in valueAndGrads(f)(args) must be array of "+"tensors"));assert(dy==null||dy instanceof Tensor,(()=>"The dy passed in valueAndGrads(f)(args, dy) must be a tensor"));const res=ENGINE.gradients((()=>f(...args)),args,dy);if(dy!=null){assertShapesMatch(res.value.shape,dy.shape,"The shape of dy passed in valueAndGrads(f)([x1,...], dy) must "+"match the shape returned by f([x1,...])")}checkGrads(res.grads);return res}}function variableGrads(f,varList){assert(isFunction(f),(()=>"The f passed in variableGrads(f) must be a function"));assert(varList==null||Array.isArray(varList)&&varList.every((v=>v instanceof Variable)),(()=>"The varList passed in variableGrads(f, varList) must be an array "+"of variables"));const specifiedVarList=varList!=null;if(!specifiedVarList){varList=[];for(const varName in ENGINE.registeredVariables){varList.push(ENGINE.registeredVariables[varName])}}const specifiedNonTrainable=specifiedVarList?varList.filter((variable=>!variable.trainable)):null;const originalVarCount=varList.length;varList=varList.filter((variable=>variable.trainable));assert(varList.length>0,(()=>`variableGrads() expects at least one of the input variables to `+`be trainable, but none of the ${originalVarCount} variables is `+`trainable.`));const allowNoGradients=true;const{value:value,grads:grads}=ENGINE.gradients(f,varList,null,allowNoGradients);assert(grads.some((g=>g!=null)),(()=>"Cannot find a connection between any variable and the result of "+"the loss function y=f(x). Please make sure the operations that "+"use variables are inside the function f passed to minimize()."));assert(value.rank===0,(()=>`The f passed in variableGrads(f) must return a scalar, but it `+`returned a rank-${value.rank} tensor`));const namedGrads={};varList.forEach(((v,i)=>{if(grads[i]!=null){namedGrads[v.name]=grads[i]}}));if(specifiedNonTrainable!=null){specifiedNonTrainable.forEach((v=>namedGrads[v.name]=null))}return{value:value,grads:namedGrads}}function customGrad(f){return ENGINE.customGrad(f)}function checkGrads(grads){const numNullGradients=grads.filter((g=>g==null)).length;if(numNullGradients>0){throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.`)}}function neg_(x){const $x=convertToTensor(x,"x","neg");const inputs={x:$x};return ENGINE.runKernel(Neg,inputs)}const neg$1=op({neg_:neg_});function softplus_(x){const $x=convertToTensor(x,"x","softplus");const inputs={x:$x};return ENGINE.runKernel(Softplus,inputs)}const softplus$1=op({softplus_:softplus_});function logSigmoid_(x){const $x=convertToTensor(x,"x","logSigmoid");const customOp=customGrad((x=>{const value=neg$1(softplus$1(neg$1(x)));const gradFunc=dy=>{const derX=mul(dy,sigmoid$1(neg$1(x)));return derX};return{value:value,gradFunc:gradFunc}}));return customOp($x)}const logSigmoid=op({logSigmoid_:logSigmoid_});function max_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","max");const inputs={x:$x};const attrs={reductionIndices:axis,keepDims:keepDims};return ENGINE.runKernel(Max,inputs,attrs)}const max$1=op({max_:max_});function sub_(a,b){let $a=convertToTensor(a,"a","sub");let $b=convertToTensor(b,"b","sub");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(Sub,inputs)}const sub$1=op({sub_:sub_});function sum_(x,axis=null,keepDims=false){let $x=convertToTensor(x,"x","sum");if($x.dtype==="bool"){$x=cast$1($x,"int32")}const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(Sum,inputs,attrs)}const sum$1=op({sum_:sum_});function logSoftmax_(logits,axis=-1){const $logits=convertToTensor(logits,"logits","logSoftmax");if(axis===-1){axis=$logits.rank-1}if(axis!==$logits.rank-1){throw Error("Log Softmax along a non-last dimension is not yet supported. "+`Logits was rank ${$logits.rank} and axis was ${axis}`)}const customOp=customGrad(((logits,save)=>{const keepDims=true;const xMax=max$1(logits,axis,true);const shifted=sub$1(logits,xMax);const value=sub$1(cast$1(shifted,"float32"),log$2(sum$1(exp$1(shifted),axis,keepDims)));save([value]);const gradFunc=(dy,saved)=>{const[value]=saved;const keepDims=true;const softmax=exp$1(value);return sub$1(dy,mul(sum$1(dy,axis,keepDims),softmax))};return{value:value,gradFunc:gradFunc}}));return customOp($logits)}const logSoftmax=op({logSoftmax_:logSoftmax_});function axesAreInnerMostDims(axes,rank){for(let i=0;i<axes.length;++i){if(axes[axes.length-i-1]!==rank-1-i){return false}}return true}function combineLocations(outputLoc,reduceLoc,axes){const rank=outputLoc.length+reduceLoc.length;const loc=[];let outIdx=0;let reduceIdx=0;for(let dim=0;dim<rank;dim++){if(axes.indexOf(dim)===-1){loc.push(outputLoc[outIdx++])}else{loc.push(reduceLoc[reduceIdx++])}}return loc}function computeOutAndReduceShapes(aShape,axes){const outShape=[];const rank=aShape.length;for(let dim=0;dim<rank;dim++){if(axes.indexOf(dim)===-1){outShape.push(aShape[dim])}}const reduceShape=axes.map((dim=>aShape[dim]));return[outShape,reduceShape]}function expandShapeToKeepDim(shape,axes){const reduceSubShape=axes.map((x=>1));return combineLocations(shape,reduceSubShape,axes)}function assertAxesAreInnerMostDims(msg,axes,rank){assert(axesAreInnerMostDims(axes,rank),(()=>`${msg} supports only inner-most axes for now. `+`Got axes ${axes} and rank-${rank} input.`))}function getAxesPermutation(axes,rank){if(axesAreInnerMostDims(axes,rank)){return null}const result=[];for(let i=0;i<rank;++i){if(axes.indexOf(i)===-1){result.push(i)}}axes.forEach((axis=>result.push(axis)));return result}function getUndoAxesPermutation(axes){return axes.map(((axis,i)=>[i,axis])).sort(((a,b)=>a[1]-b[1])).map((x=>x[0]))}function getInnerMostAxes(numAxes,rank){const res=[];for(let i=rank-numAxes;i<rank;++i){res.push(i)}return res}function logSumExp_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","logSumExp");const axes=parseAxisParam(axis,$x.shape);const xMax=max$1($x,axes,true);const a=sub$1($x,xMax);const b=exp$1(a);const c=sum$1(b,axes);const d=log$2(c);const res=add(reshape$1(xMax,d.shape),d);if(keepDims){const newShape=expandShapeToKeepDim(res.shape,axes);return reshape$1(res,newShape)}return res}const logSumExp=op({logSumExp_:logSumExp_});function logicalAnd_(a,b){const $a=convertToTensor(a,"a","logicalAnd","bool");const $b=convertToTensor(b,"b","logicalAnd","bool");assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(LogicalAnd,inputs)}const logicalAnd$1=op({logicalAnd_:logicalAnd_});function logicalNot_(x){const $x=convertToTensor(x,"x","logicalNot","bool");const inputs={x:$x};return ENGINE.runKernel(LogicalNot,inputs)}const logicalNot$1=op({logicalNot_:logicalNot_});function logicalOr_(a,b){const $a=convertToTensor(a,"a","logicalOr","bool");const $b=convertToTensor(b,"b","logicalOr","bool");assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(LogicalOr,inputs)}const logicalOr$1=op({logicalOr_:logicalOr_});function logicalXor_(a,b){const $a=convertToTensor(a,"a","logicalXor","bool");const $b=convertToTensor(b,"b","logicalXor","bool");assertAndGetBroadcastShape($a.shape,$b.shape);return logicalAnd$1(logicalOr$1(a,b),logicalNot$1(logicalAnd$1(a,b)))}const logicalXor=op({logicalXor_:logicalXor_});function maxPool_(x,filterSize,strides,pad,dimRoundingMode){const $x=convertToTensor(x,"x","maxPool");const dilations=1;let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`));assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in maxPool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in maxPool: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x4D};const attrs={filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode};const res=ENGINE.runKernel(MaxPool,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const maxPool$1=op({maxPool_:maxPool_});function maxPool3d_(x,filterSize=[1,1,1],strides,pad,dimRoundingMode,dataFormat="NDHWC"){const $x=convertToTensor(x,"x","maxPool3d");let x5D=$x;let reshapedTo5D=false;if($x.rank===4){reshapedTo5D=true;x5D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2],$x.shape[3]])}assert(x5D.rank===5,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`));assert(dataFormat==="NDHWC",(()=>`Error in maxPool3d: Only NDHWC is currently supported, `+`but got dataFormat of ${dataFormat}`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in maxPool3d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x5D};const attrs={filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode,dataFormat:dataFormat};const res=ENGINE.runKernel(MaxPool3D,inputs,attrs);if(reshapedTo5D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3],res.shape[4]])}return res}const maxPool3d$1=op({maxPool3d_:maxPool3d_});function maxPoolWithArgmax_(x,filterSize,strides,pad,includeBatchInIndex=false){const $x=convertToTensor(x,"x","maxPoolWithArgmax");const inputs={x:$x};const attrs={filterSize:filterSize,strides:strides,pad:pad,includeBatchInIndex:includeBatchInIndex};const result=ENGINE.runKernel(MaxPoolWithArgmax,inputs,attrs);return{result:result[0],indexes:result[1]}}const maxPoolWithArgmax=op({maxPoolWithArgmax_:maxPoolWithArgmax_});function maximum_(a,b){let $a=convertToTensor(a,"a","maximum");let $b=convertToTensor(b,"b","maximum");[$a,$b]=makeTypesMatch($a,$b);if($a.dtype==="bool"){$a=cast$1($a,"int32");$b=cast$1($b,"int32")}assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(Maximum,inputs)}const maximum$1=op({maximum_:maximum_});function mean_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","mean");const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(Mean,inputs,attrs)}const mean=op({mean_:mean_});function zeros(shape,dtype="float32"){if(dtype==="complex64"){const real=zeros(shape,"float32");const imag=zeros(shape,"float32");return complex$1(real,imag)}const values=makeZerosTypedArray(sizeFromShape(shape),dtype);return ENGINE.makeTensor(values,shape,dtype)}function ones(shape,dtype="float32"){if(dtype==="complex64"){const real=ones(shape,"float32");const imag=zeros(shape,"float32");return complex$1(real,imag)}const values=makeOnesTypedArray(sizeFromShape(shape),dtype);return ENGINE.makeTensor(values,shape,dtype)}function meshgrid(x,y,{indexing:indexing="xy"}={}){if(indexing!=="xy"&&indexing!=="ij"){throw new TypeError(`${indexing} is not a valid third argument to meshgrid`)}if(x===undefined){return[]}let $x=convertToTensor(x,"x","meshgrid",x instanceof Tensor?x.dtype:"float32");if(y===undefined){return[$x]}let $y=convertToTensor(y,"y","meshgrid",y instanceof Tensor?y.dtype:"float32");const w=sizeFromShape($x.shape);const h=sizeFromShape($y.shape);if(indexing==="xy"){$x=reshape$1($x,[1,-1]);$y=reshape$1($y,[-1,1]);return[matMul$1(ones([h,1],$x.dtype),$x),matMul$1($y,ones([1,w],$y.dtype))]}$x=reshape$1($x,[-1,1]);$y=reshape$1($y,[1,-1]);return[matMul$1($x,ones([1,h],$x.dtype)),matMul$1(ones([w,1],$y.dtype),$y)]}function min_(x,axis=null,keepDims=false){const $x=convertToTensor(x,"x","min");const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(Min,inputs,attrs)}const min$1=op({min_:min_});function minimum_(a,b){let $a=convertToTensor(a,"a","minimum");let $b=convertToTensor(b,"b","minimum");[$a,$b]=makeTypesMatch($a,$b);if($a.dtype==="bool"){$a=cast$1($a,"int32");$b=cast$1($b,"int32")}assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(Minimum,inputs)}const minimum$1=op({minimum_:minimum_});function mirrorPad_(x,paddings,mode){assert(mode==="reflect"||mode==="symmetric",(()=>`Invalid mode. Mode must be either reflect or symmetric. `+`Got ${mode}.`));const $x=convertToTensor(x,"x","mirrorPad");if($x.rank===0){throw new Error("mirrorPad(scalar) is not defined. "+"Pass non-scalar to mirrorPad")}assert(paddings.length===$x.rank,(()=>`Padding doesn't match input. Must be ${$x.rank}. `+`Got ${paddings.length}.`));const shapeOffset=mode==="reflect"?1:0;for(let i=0;i<$x.rank;i++){assert(paddings[i].length===2,(()=>`Invalid number of paddings. Must be length of 2 each.`));assert(paddings[i][0]>=0&&paddings[i][0]<=$x.shape[i]-shapeOffset&&paddings[i][1]>=0&&paddings[i][1]<=$x.shape[i]-shapeOffset,(()=>`Padding in dimension ${i} cannot be greater than or equal `+`to ${$x.shape[i]-shapeOffset} or less than 0 for input of `+`shape ${$x.shape}`))}const attrs={paddings:paddings,mode:mode};const inputs={x:$x};return ENGINE.runKernel(MirrorPad,inputs,attrs)}const mirrorPad=op({mirrorPad_:mirrorPad_});function mod_(a,b){let $a=convertToTensor(a,"a","mod");let $b=convertToTensor(b,"b","mod");[$a,$b]=makeTypesMatch($a,$b);const inputs={a:$a,b:$b};return ENGINE.runKernel(Mod,inputs)}const mod$1=op({mod_:mod_});function square_(x){const $x=convertToTensor(x,"x","square");const attrs={};return ENGINE.runKernel("Square",{x:$x},attrs)}const square$1=op({square_:square_});function moments_(x,axis=null,keepDims=false){x=convertToTensor(x,"x","moments");const axes=parseAxisParam(axis,x.shape);const xMean=mean(x,axes,keepDims);let keepDimsShape=xMean.shape;if(!keepDims){keepDimsShape=expandShapeToKeepDim(xMean.shape,axes)}const devSquared=square$1(sub$1(cast$1(x,"float32"),reshape$1(xMean,keepDimsShape)));const variance=mean(devSquared,axes,keepDims);return{mean:xMean,variance:variance}}const moments=op({moments_:moments_});function multiRNNCell_(lstmCells,data,c,h){const $data=convertToTensor(data,"data","multiRNNCell");const $c=convertToTensorArray(c,"c","multiRNNCell");const $h=convertToTensorArray(h,"h","multiRNNCell");let input=$data;const newStates=[];for(let i=0;i<lstmCells.length;i++){const output=lstmCells[i](input,$c[i],$h[i]);newStates.push(output[0]);newStates.push(output[1]);input=output[1]}const newC=[];const newH=[];for(let i=0;i<newStates.length;i+=2){newC.push(newStates[i]);newH.push(newStates[i+1])}return[newC,newH]}const multiRNNCell=op({multiRNNCell_:multiRNNCell_});function multinomial_(logits,numSamples,seed,normalized=false){const $logits=convertToTensor(logits,"logits","multinomial");const numOutcomes=$logits.size;const origRank=$logits.rank;if(numOutcomes<2){throw new Error(`Error in multinomial: you need at least 2 outcomes, but got `+`${numOutcomes}.`)}if(origRank>2){throw new Error(`Rank of probabilities must be 1 or 2, but is ${origRank}`)}seed=seed||Math.random();const logits2D=origRank===1?reshape$1($logits,[1,-1]):$logits;const inputs={logits:logits2D};const attrs={numSamples:numSamples,seed:seed,normalized:normalized};const res=ENGINE.runKernel(Multinomial,inputs,attrs);return origRank===1?reshape$1(res,[res.size]):res}const multinomial$1=op({multinomial_:multinomial_});function notEqual_(a,b){let $a=convertToTensor(a,"a","notEqual");let $b=convertToTensor(b,"b","notEqual");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};return ENGINE.runKernel(NotEqual,inputs)}const notEqual$1=op({notEqual_:notEqual_});function onesLike_(x){const $x=convertToTensor(x,"x","onesLike");const inputs={x:$x};return ENGINE.runKernel(OnesLike,inputs)}const onesLike$1=op({onesLike_:onesLike_});function outerProduct_(v1,v2){const $v1=convertToTensor(v1,"v1","outerProduct");const $v2=convertToTensor(v2,"v2","outerProduct");assert($v1.rank===1&&$v2.rank===1,(()=>`Error in outerProduct: inputs must be rank 1, but got ranks `+`${$v1.rank} and ${$v2.rank}.`));const v12D=reshape$1($v1,[-1,1]);const v22D=reshape$1($v2,[1,-1]);return matMul$1(v12D,v22D)}const outerProduct=op({outerProduct_:outerProduct_});function pad_(x,paddings,constantValue=0){const $x=convertToTensor(x,"x","pad");if($x.rank===0){throw new Error("pad(scalar) is not defined. Pass non-scalar to pad")}const attrs={paddings:paddings,constantValue:constantValue};const inputs={x:$x};return ENGINE.runKernel(PadV2,inputs,attrs)}const pad=op({pad_:pad_});function pad1d_(x,paddings,constantValue=0){assert(paddings.length===2,(()=>"Invalid number of paddings. Must be length of 2."));return pad(x,[paddings],constantValue)}const pad1d=op({pad1d_:pad1d_});function pad2d_(x,paddings,constantValue=0){assert(paddings.length===2&&paddings[0].length===2&&paddings[1].length===2,(()=>"Invalid number of paddings. Must be length of 2 each."));return pad(x,paddings,constantValue)}const pad2d=op({pad2d_:pad2d_});function pad3d_(x,paddings,constantValue=0){assert(paddings.length===3&&paddings[0].length===2&&paddings[1].length===2&&paddings[2].length===2,(()=>"Invalid number of paddings. Must be length of 2 each."));return pad(x,paddings,constantValue)}const pad3d=op({pad3d_:pad3d_});function pad4d_(x,paddings,constantValue=0){assert(paddings.length===4&&paddings[0].length===2&&paddings[1].length===2&&paddings[2].length===2&&paddings[3].length===2,(()=>"Invalid number of paddings. Must be length of 2 each."));return pad(x,paddings,constantValue)}const pad4d=op({pad4d_:pad4d_});function spaceToBatchND_(x,blockShape,paddings){const $x=convertToTensor(x,"x","spaceToBatchND");assert($x.rank>=1+blockShape.length,(()=>`input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`));assert(paddings.length===blockShape.length,(()=>`paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`));assert($x.shape.reduce(((a,b,i)=>{if(i>0&&i<=blockShape.length){return a&&(b+paddings[i-1][0]+paddings[i-1][1])%blockShape[i-1]===0}return a}),true),(()=>`input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`));const inputs={x:$x};const attrs={blockShape:blockShape,paddings:paddings};return ENGINE.runKernel(SpaceToBatchND,inputs,attrs)}const spaceToBatchND$1=op({spaceToBatchND_:spaceToBatchND_});function pool_(input,windowShape,poolingType,pad,dilations,strides){if(dilations==null){dilations=[1,1]}if(strides==null){strides=1}if(pad===0){pad="valid"}const $x=convertToTensor(input,"x","maxPool");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in pool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));const convInfo=computePool2DInfo(x4D.shape,windowShape,strides,dilations,pad);const dilation=[convInfo.dilationHeight,convInfo.dilationWidth];let basePadding;if(pad==="same"){basePadding=withSpaceToBatchBasePaddings([convInfo.filterHeight,convInfo.filterWidth],dilation)}else{basePadding=[[0,0],[0,0]]}const isDilationOne=dilation[0]===1&&dilation[1]===1;const[adjustedPadding,adjustedCrops]=requiredSpaceToBatchPaddings([convInfo.inHeight,convInfo.inWidth],dilation,basePadding);const convertedPad=isDilationOne?pad:"valid";const convertedX=isDilationOne?x4D:spaceToBatchND$1(x4D,dilation,adjustedPadding);const forwardOp=poolingType==="avg"?()=>avgPool$1(convertedX,windowShape,strides,convertedPad):()=>maxPool$1(convertedX,windowShape,strides,convertedPad);const y=forwardOp();const res=isDilationOne?y:batchToSpaceND$1(y,dilation,adjustedCrops);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}function requiredSpaceToBatchPaddings(inputShape,blockShape,basePadding){const padStart=basePadding.map((b=>b[0]));const origPadEnd=basePadding.map((b=>b[1]));const fullInputShape=inputShape.concat(padStart,origPadEnd);const padEndExtra=blockShape.map(((b,i)=>(b-fullInputShape[i]%b)%b));const padEnd=origPadEnd.map(((s,i)=>s+padEndExtra[i]));const paddings=blockShape.map(((_,i)=>[padStart[i],padEnd[i]]));const crops=blockShape.map(((_,i)=>[0,padEndExtra[i]]));return[paddings,crops]}function withSpaceToBatchBasePaddings(filterShape,dilation){const dilatedFilterShape=filterShape.map(((s,i)=>s+(s-1)*(dilation[i]-1)));const padExtraShape=dilatedFilterShape.map((s=>s-1));const padExtraStart=padExtraShape.map((s=>Math.floor(s/2)));const padExtraEnd=padExtraShape.map(((s,i)=>s-padExtraStart[i]));return padExtraShape.map(((_,i)=>[padExtraStart[i],padExtraEnd[i]]))}const pool=op({pool_:pool_});function pow_(base,exp){let $base=convertToTensor(base,"base","pow");let $exp=convertToTensor(exp,"exp","pow");[$base,$exp]=makeTypesMatch($base,$exp);const inputs={a:$base,b:$exp};return ENGINE.runKernel(Pow,inputs)}const pow$1=op({pow_:pow_});function prelu_(x,alpha){const $x=convertToTensor(x,"x","prelu");const $alpha=convertToTensor(alpha,"alpha","prelu");const inputs={x:$x,alpha:$alpha};return ENGINE.runKernel(Prelu,inputs)}const prelu$1=op({prelu_:prelu_});function prod_(x,axis=null,keepDims=false){let $x=convertToTensor(x,"x","prod");if($x.dtype==="bool"){$x=cast$1($x,"int32")}const inputs={x:$x};const attrs={axis:axis,keepDims:keepDims};return ENGINE.runKernel(Prod,inputs,attrs)}const prod$1=op({prod_:prod_});function rand_(shape,randFunction,dtype){const size=sizeFromShape(shape);let values=null;if(dtype==null||dtype==="float32"){values=new Float32Array(size)}else if(dtype==="int32"){values=new Int32Array(size)}else if(dtype==="bool"){values=new Uint8Array(size)}else{throw new Error(`Unknown data type ${dtype}`)}for(let i=0;i<size;i++){values[i]=randFunction()}return ENGINE.makeTensor(values,shape,dtype)}const rand=op({rand_:rand_});var commonjsGlobal=typeof globalThis!=="undefined"?globalThis:typeof window!=="undefined"?window:typeof global!=="undefined"?global:typeof self!=="undefined"?self:{};function getAugmentedNamespace(n){if(n.__esModule)return n;var a=Object.defineProperty({},"__esModule",{value:true});Object.keys(n).forEach((function(k){var d=Object.getOwnPropertyDescriptor(n,k);Object.defineProperty(a,k,d.get?d:{enumerable:true,get:function(){return n[k]}})}));return a}function createCommonjsModule(fn){var module={exports:{}};return fn(module,module.exports),module.exports}var alea=createCommonjsModule((function(module){(function(global,module,define){function Alea(seed){var me=this,mash=Mash();me.next=function(){var t=2091639*me.s0+me.c*2.3283064365386963e-10;me.s0=me.s1;me.s1=me.s2;return me.s2=t-(me.c=t|0)};me.c=1;me.s0=mash(" ");me.s1=mash(" ");me.s2=mash(" ");me.s0-=mash(seed);if(me.s0<0){me.s0+=1}me.s1-=mash(seed);if(me.s1<0){me.s1+=1}me.s2-=mash(seed);if(me.s2<0){me.s2+=1}mash=null}function copy(f,t){t.c=f.c;t.s0=f.s0;t.s1=f.s1;t.s2=f.s2;return t}function impl(seed,opts){var xg=new Alea(seed),state=opts&&opts.state,prng=xg.next;prng.int32=function(){return xg.next()*4294967296|0};prng.double=function(){return prng()+(prng()*2097152|0)*11102230246251565e-32};prng.quick=prng;if(state){if(typeof state=="object")copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}function Mash(){var n=4022871197;var mash=function(data){data=data.toString();for(var i=0;i<data.length;i++){n+=data.charCodeAt(i);var h=.02519603282416938*n;n=h>>>0;h-=n;h*=n;n=h>>>0;h-=n;n+=h*4294967296}return(n>>>0)*2.3283064365386963e-10};return mash}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.alea=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var xor128=createCommonjsModule((function(module){(function(global,module,define){function XorGen(seed){var me=this,strseed="";me.x=0;me.y=0;me.z=0;me.w=0;me.next=function(){var t=me.x^me.x<<11;me.x=me.y;me.y=me.z;me.z=me.w;return me.w^=me.w>>>19^t^t>>>8};if(seed===(seed|0)){me.x=seed}else{strseed+=seed}for(var k=0;k<strseed.length+64;k++){me.x^=strseed.charCodeAt(k)|0;me.next()}}function copy(f,t){t.x=f.x;t.y=f.y;t.z=f.z;t.w=f.w;return t}function impl(seed,opts){var xg=new XorGen(seed),state=opts&&opts.state,prng=function(){return(xg.next()>>>0)/4294967296};prng.double=function(){do{var top=xg.next()>>>11,bot=(xg.next()>>>0)/4294967296,result=(top+bot)/(1<<21)}while(result===0);return result};prng.int32=xg.next;prng.quick=prng;if(state){if(typeof state=="object")copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.xor128=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var xorwow=createCommonjsModule((function(module){(function(global,module,define){function XorGen(seed){var me=this,strseed="";me.next=function(){var t=me.x^me.x>>>2;me.x=me.y;me.y=me.z;me.z=me.w;me.w=me.v;return(me.d=me.d+362437|0)+(me.v=me.v^me.v<<4^(t^t<<1))|0};me.x=0;me.y=0;me.z=0;me.w=0;me.v=0;if(seed===(seed|0)){me.x=seed}else{strseed+=seed}for(var k=0;k<strseed.length+64;k++){me.x^=strseed.charCodeAt(k)|0;if(k==strseed.length){me.d=me.x<<10^me.x>>>4}me.next()}}function copy(f,t){t.x=f.x;t.y=f.y;t.z=f.z;t.w=f.w;t.v=f.v;t.d=f.d;return t}function impl(seed,opts){var xg=new XorGen(seed),state=opts&&opts.state,prng=function(){return(xg.next()>>>0)/4294967296};prng.double=function(){do{var top=xg.next()>>>11,bot=(xg.next()>>>0)/4294967296,result=(top+bot)/(1<<21)}while(result===0);return result};prng.int32=xg.next;prng.quick=prng;if(state){if(typeof state=="object")copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.xorwow=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var xorshift7=createCommonjsModule((function(module){(function(global,module,define){function XorGen(seed){var me=this;me.next=function(){var X=me.x,i=me.i,t,v;t=X[i];t^=t>>>7;v=t^t<<24;t=X[i+1&7];v^=t^t>>>10;t=X[i+3&7];v^=t^t>>>3;t=X[i+4&7];v^=t^t<<7;t=X[i+7&7];t=t^t<<13;v^=t^t<<9;X[i]=v;me.i=i+1&7;return v};function init(me,seed){var j,X=[];if(seed===(seed|0)){X[0]=seed}else{seed=""+seed;for(j=0;j<seed.length;++j){X[j&7]=X[j&7]<<15^seed.charCodeAt(j)+X[j+1&7]<<13}}while(X.length<8)X.push(0);for(j=0;j<8&&X[j]===0;++j);if(j==8)X[7]=-1;me.x=X;me.i=0;for(j=256;j>0;--j){me.next()}}init(me,seed)}function copy(f,t){t.x=f.x.slice();t.i=f.i;return t}function impl(seed,opts){if(seed==null)seed=+new Date;var xg=new XorGen(seed),state=opts&&opts.state,prng=function(){return(xg.next()>>>0)/4294967296};prng.double=function(){do{var top=xg.next()>>>11,bot=(xg.next()>>>0)/4294967296,result=(top+bot)/(1<<21)}while(result===0);return result};prng.int32=xg.next;prng.quick=prng;if(state){if(state.x)copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.xorshift7=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var xor4096=createCommonjsModule((function(module){(function(global,module,define){function XorGen(seed){var me=this;me.next=function(){var w=me.w,X=me.X,i=me.i,t,v;me.w=w=w+1640531527|0;v=X[i+34&127];t=X[i=i+1&127];v^=v<<13;t^=t<<17;v^=v>>>15;t^=t>>>12;v=X[i]=v^t;me.i=i;return v+(w^w>>>16)|0};function init(me,seed){var t,v,i,j,w,X=[],limit=128;if(seed===(seed|0)){v=seed;seed=null}else{seed=seed+"\0";v=0;limit=Math.max(limit,seed.length)}for(i=0,j=-32;j<limit;++j){if(seed)v^=seed.charCodeAt((j+32)%seed.length);if(j===0)w=v;v^=v<<10;v^=v>>>15;v^=v<<4;v^=v>>>13;if(j>=0){w=w+1640531527|0;t=X[j&127]^=v+w;i=0==t?i+1:0}}if(i>=128){X[(seed&&seed.length||0)&127]=-1}i=127;for(j=4*128;j>0;--j){v=X[i+34&127];t=X[i=i+1&127];v^=v<<13;t^=t<<17;v^=v>>>15;t^=t>>>12;X[i]=v^t}me.w=w;me.X=X;me.i=i}init(me,seed)}function copy(f,t){t.i=f.i;t.w=f.w;t.X=f.X.slice();return t}function impl(seed,opts){if(seed==null)seed=+new Date;var xg=new XorGen(seed),state=opts&&opts.state,prng=function(){return(xg.next()>>>0)/4294967296};prng.double=function(){do{var top=xg.next()>>>11,bot=(xg.next()>>>0)/4294967296,result=(top+bot)/(1<<21)}while(result===0);return result};prng.int32=xg.next;prng.quick=prng;if(state){if(state.X)copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.xor4096=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var tychei=createCommonjsModule((function(module){(function(global,module,define){function XorGen(seed){var me=this,strseed="";me.next=function(){var b=me.b,c=me.c,d=me.d,a=me.a;b=b<<25^b>>>7^c;c=c-d|0;d=d<<24^d>>>8^a;a=a-b|0;me.b=b=b<<20^b>>>12^c;me.c=c=c-d|0;me.d=d<<16^c>>>16^a;return me.a=a-b|0};me.a=0;me.b=0;me.c=2654435769|0;me.d=1367130551;if(seed===Math.floor(seed)){me.a=seed/4294967296|0;me.b=seed|0}else{strseed+=seed}for(var k=0;k<strseed.length+20;k++){me.b^=strseed.charCodeAt(k)|0;me.next()}}function copy(f,t){t.a=f.a;t.b=f.b;t.c=f.c;t.d=f.d;return t}function impl(seed,opts){var xg=new XorGen(seed),state=opts&&opts.state,prng=function(){return(xg.next()>>>0)/4294967296};prng.double=function(){do{var top=xg.next()>>>11,bot=(xg.next()>>>0)/4294967296,result=(top+bot)/(1<<21)}while(result===0);return result};prng.int32=xg.next;prng.quick=prng;if(state){if(typeof state=="object")copy(state,xg);prng.state=function(){return copy(xg,{})}}return prng}if(module&&module.exports){module.exports=impl}else if(define&&define.amd){define((function(){return impl}))}else{this.tychei=impl}})(commonjsGlobal,module,typeof undefined=="function")}));var empty={};var empty$1=Object.freeze({__proto__:null,default:empty});var require$$1=getAugmentedNamespace(empty$1);var seedrandom$1=createCommonjsModule((function(module){(function(pool,math){var global=this,width=256,chunks=6,digits=52,rngname="random",startdenom=math.pow(width,chunks),significance=math.pow(2,digits),overflow=significance*2,mask=width-1,nodecrypto;function seedrandom(seed,options,callback){var key=[];options=options==true?{entropy:true}:options||{};var shortseed=mixkey(flatten(options.entropy?[seed,tostring(pool)]:seed==null?autoseed():seed,3),key);var arc4=new ARC4(key);var prng=function(){var n=arc4.g(chunks),d=startdenom,x=0;while(n<significance){n=(n+x)*width;d*=width;x=arc4.g(1)}while(n>=overflow){n/=2;d/=2;x>>>=1}return(n+x)/d};prng.int32=function(){return arc4.g(4)|0};prng.quick=function(){return arc4.g(4)/4294967296};prng.double=prng;mixkey(tostring(arc4.S),pool);return(options.pass||callback||function(prng,seed,is_math_call,state){if(state){if(state.S){copy(state,arc4)}prng.state=function(){return copy(arc4,{})}}if(is_math_call){math[rngname]=prng;return seed}else return prng})(prng,shortseed,"global"in options?options.global:this==math,options.state)}math["seed"+rngname]=seedrandom;function ARC4(key){var t,keylen=key.length,me=this,i=0,j=me.i=me.j=0,s=me.S=[];if(!keylen){key=[keylen++]}while(i<width){s[i]=i++}for(i=0;i<width;i++){s[i]=s[j=mask&j+key[i%keylen]+(t=s[i])];s[j]=t}(me.g=function(count){var t,r=0,i=me.i,j=me.j,s=me.S;while(count--){t=s[i=mask&i+1];r=r*width+s[mask&(s[i]=s[j=mask&j+t])+(s[j]=t)]}me.i=i;me.j=j;return r})(width)}function copy(f,t){t.i=f.i;t.j=f.j;t.S=f.S.slice();return t}function flatten(obj,depth){var result=[],typ=typeof obj,prop;if(depth&&typ=="object"){for(prop in obj){try{result.push(flatten(obj[prop],depth-1))}catch(e){}}}return result.length?result:typ=="string"?obj:obj+"\0"}function mixkey(seed,key){var stringseed=seed+"",smear,j=0;while(j<stringseed.length){key[mask&j]=mask&(smear^=key[mask&j]*19)+stringseed.charCodeAt(j++)}return tostring(key)}function autoseed(){try{var out;if(nodecrypto&&(out=nodecrypto.randomBytes)){out=out(width)}else{out=new Uint8Array(width);(global.crypto||global.msCrypto).getRandomValues(out)}return tostring(out)}catch(e){var browser=global.navigator,plugins=browser&&browser.plugins;return[+new Date,global,plugins,global.screen,tostring(pool)]}}function tostring(a){return String.fromCharCode.apply(0,a)}mixkey(math.random(),pool);if(module.exports){module.exports=seedrandom;try{nodecrypto=require$$1}catch(ex){}}})([],Math)}));seedrandom$1.alea=alea;seedrandom$1.xor128=xor128;seedrandom$1.xorwow=xorwow;seedrandom$1.xorshift7=xorshift7;seedrandom$1.xor4096=xor4096;seedrandom$1.tychei=tychei;var seedrandom=seedrandom$1;class MPRandGauss{constructor(mean,stdDeviation,dtype,truncated,seed){this.mean=mean;this.stdDev=stdDeviation;this.dtype=dtype;this.nextVal=NaN;this.truncated=truncated;if(this.truncated){this.upper=this.mean+this.stdDev*2;this.lower=this.mean-this.stdDev*2}const seedValue=seed?seed:Math.random();this.random=seedrandom.alea(seedValue.toString())}nextValue(){if(!isNaN(this.nextVal)){const value=this.nextVal;this.nextVal=NaN;return value}let resultX,resultY;let isValid=false;while(!isValid){let v1,v2,s;do{v1=2*this.random()-1;v2=2*this.random()-1;s=v1*v1+v2*v2}while(s>=1||s===0);const mul=Math.sqrt(-2*Math.log(s)/s);resultX=this.mean+this.stdDev*v1*mul;resultY=this.mean+this.stdDev*v2*mul;if(!this.truncated||this.isValidTruncated(resultX)){isValid=true}}if(!this.truncated||this.isValidTruncated(resultY)){this.nextVal=this.convertValue(resultY)}return this.convertValue(resultX)}convertValue(value){if(this.dtype==null||this.dtype==="float32"){return value}return Math.round(value)}isValidTruncated(value){return value<=this.upper&&value>=this.lower}}class RandGamma{constructor(alpha,beta,dtype,seed){this.alpha=alpha;this.beta=1/beta;this.dtype=dtype;const seedValue=seed?seed:Math.random();this.randu=seedrandom.alea(seedValue.toString());this.randn=new MPRandGauss(0,1,dtype,false,this.randu());if(alpha<1){this.d=alpha+2/3}else{this.d=alpha-1/3}this.c=1/Math.sqrt(9*this.d)}nextValue(){let x2,v0,v1,x,u,v;while(true){do{x=this.randn.nextValue();v=1+this.c*x}while(v<=0);v*=v*v;x2=x*x;v0=1-.331*x2*x2;v1=.5*x2+this.d*(1-v+Math.log(v));u=this.randu();if(u<v0||Math.log(u)<v1){break}}v=1/this.beta*this.d*v;if(this.alpha<1){v*=Math.pow(this.randu(),1/this.alpha)}return this.convertValue(v)}convertValue(value){if(this.dtype==="float32"){return value}return Math.round(value)}}class UniformRandom{constructor(min=0,max=1,dtype,seed){this.canReturnFloat=()=>this.dtype==null||this.dtype==="float32";this.min=min;this.range=max-min;this.dtype=dtype;if(seed==null){seed=Math.random()}if(typeof seed==="number"){seed=seed.toString()}if(!this.canReturnFloat()&&this.range<=1){throw new Error(`The difference between ${min} - ${max} <= 1 and dtype is not float`)}this.random=seedrandom.alea(seed)}convertValue(value){if(this.canReturnFloat()){return value}return Math.round(value)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}function randomGamma_(shape,alpha,beta=1,dtype="float32",seed){if(beta==null){beta=1}if(dtype==null){dtype="float32"}if(dtype!=="float32"&&dtype!=="int32"){throw new Error(`Unsupported data type ${dtype}`)}const rgamma=new RandGamma(alpha,beta,dtype,seed);const res=buffer(shape,dtype);for(let i=0;i<res.values.length;i++){res.values[i]=rgamma.nextValue()}return res.toTensor()}const randomGamma=op({randomGamma_:randomGamma_});function randomNormal_(shape,mean=0,stdDev=1,dtype,seed){if(dtype!=null&&dtype==="bool"){throw new Error(`Unsupported data type ${dtype}`)}const randGauss=new MPRandGauss(mean,stdDev,dtype,false,seed);const res=buffer(shape,dtype);for(let i=0;i<res.values.length;i++){res.values[i]=randGauss.nextValue()}return res.toTensor()}const randomNormal=op({randomNormal_:randomNormal_});function randomUniform_(shape,minval=0,maxval=1,dtype="float32",seed){const res=buffer(shape,dtype);const random=new UniformRandom(minval,maxval,null,seed);for(let i=0;i<res.values.length;i++){res.values[i]=random.nextValue()}return res.toTensor()}const randomUniform=op({randomUniform_:randomUniform_});function range$1(start,stop,step=1,dtype="float32"){if(step===0){throw new Error("Cannot have a step of zero")}const attrs={start:start,stop:stop,step:step,dtype:dtype};return ENGINE.runKernel(Range,{},attrs)}function real_(input){const $input=convertToTensor(input,"input","real");const inputs={input:$input};return ENGINE.runKernel(Real,inputs)}const real$1=op({real_:real_});function reciprocal_(x){const $x=convertToTensor(x,"x","reciprocal");const inputs={x:$x};return ENGINE.runKernel(Reciprocal,inputs)}const reciprocal$1=op({reciprocal_:reciprocal_});function relu_(x){const $x=convertToTensor(x,"x","relu");const inputs={x:$x};return ENGINE.runKernel(Relu,inputs)}const relu$1=op({relu_:relu_});function relu6_(x){const $x=convertToTensor(x,"x","relu6");const inputs={x:$x};return ENGINE.runKernel(Relu6,inputs)}const relu6$1=op({relu6_:relu6_});function reverse_(x,axis){const $x=convertToTensor(x,"x","reverse");const inputs={x:$x};const attrs={dims:axis};return ENGINE.runKernel(Reverse,inputs,attrs)}const reverse$1=op({reverse_:reverse_});function reverse1d_(x){const $x=convertToTensor(x,"x","reverse");assert($x.rank===1,(()=>`Error in reverse1D: x must be rank 1 but got rank ${$x.rank}.`));return reverse$1($x,0)}const reverse1d=op({reverse1d_:reverse1d_});function reverse2d_(x,axis){const $x=convertToTensor(x,"x","reverse");assert($x.rank===2,(()=>`Error in reverse2D: x must be rank 2 but got rank ${$x.rank}.`));return reverse$1($x,axis)}const reverse2d=op({reverse2d_:reverse2d_});function reverse3d_(x,axis){const $x=convertToTensor(x,"x","reverse");assert($x.rank===3,(()=>`Error in reverse3D: x must be rank 3 but got rank ${$x.rank}.`));return reverse$1($x,axis)}const reverse3d=op({reverse3d_:reverse3d_});function reverse4d_(x,axis){const $x=convertToTensor(x,"x","reverse");assert($x.rank===4,(()=>`Error in reverse4D: x must be rank 4 but got rank ${$x.rank}.`));return reverse$1($x,axis)}const reverse4d=op({reverse4d_:reverse4d_});function round_(x){const $x=convertToTensor(x,"x","round");const inputs={x:$x};return ENGINE.runKernel(Round,inputs)}const round$1=op({round_:round_});function rsqrt_(x){const $x=convertToTensor(x,"x","rsqrt");const inputs={x:$x};return ENGINE.runKernel(Rsqrt,inputs)}const rsqrt$1=op({rsqrt_:rsqrt_});function scalar(value,dtype){if((isTypedArray(value)&&dtype!=="string"||Array.isArray(value))&&dtype!=="complex64"){throw new Error("Error creating a new Scalar: value must be a primitive "+"(number|boolean|string)")}if(dtype==="string"&&isTypedArray(value)&&!(value instanceof Uint8Array)){throw new Error("When making a scalar from encoded string, "+"the value must be `Uint8Array`.")}const shape=[];const inferredShape=[];return makeTensor(value,shape,inferredShape,dtype)}function selu_(x){const $x=convertToTensor(x,"x","selu");const inputs={x:$x};return ENGINE.runKernel(Selu,inputs)}const selu$1=op({selu_:selu_});function separableConv2d_(x,depthwiseFilter,pointwiseFilter,strides,pad,dilation=[1,1],dataFormat="NHWC"){const $x=convertToTensor(x,"x","separableConv2d");const $depthwiseFilter=convertToTensor(depthwiseFilter,"depthwiseFilter","separableConv2d");const $pointwiseFilter=convertToTensor(pointwiseFilter,"pointwiseFilter","separableConv2d");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}if(dataFormat==="NCHW"){throw new Error("separableConv2d currently does not support dataFormat NCHW; only "+"NHWC is supported")}assert(x4D.rank===4,(()=>`Error in separableConv2d: input must be rank 4, but got `+`rank ${x4D.rank}.`));assert($depthwiseFilter.rank===4,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but `+`got rank ${$depthwiseFilter.rank}.`));assert($pointwiseFilter.rank===4,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but `+`got rank ${$depthwiseFilter.rank}.`));assert($pointwiseFilter.shape[0]===1,(()=>`Error in separableConv2d: the first dimension of pointwise filter `+` must be 1, but got ${$pointwiseFilter.shape[0]}.`));assert($pointwiseFilter.shape[1]===1,(()=>`Error in separableConv2d: the second dimension of pointwise `+`filter must be 1, but got ${$pointwiseFilter.shape[1]}.`));const inChannels=$depthwiseFilter.shape[2];const channelMultiplier=$depthwiseFilter.shape[3];assert($pointwiseFilter.shape[2]===inChannels*channelMultiplier,(()=>`Error in separableConv2d: the third dimension of pointwise filter `+`must be ${inChannels*channelMultiplier}, `+`but got ${$pointwiseFilter.shape[2]}.`));const depthwise=depthwiseConv2d$1(x4D,$depthwiseFilter,strides,pad,dataFormat,dilation);const pointwiseStride=1;const res=conv2d$2(depthwise,$pointwiseFilter,pointwiseStride,"valid",dataFormat);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const separableConv2d=op({separableConv2d_:separableConv2d_});async function setdiff1dAsync_(x,y){const $x=convertToTensor(x,"x","setdiff1d");const $y=convertToTensor(y,"y","setdiff1d");assert($x.dtype===$y.dtype,(()=>`x and y should have the same dtype, but got x (${$x.dtype}) and y (${$y.dtype}).`));assert($x.rank===1,(()=>`x should be 1D tensor, but got x (${$x.shape}).`));assert($y.rank===1,(()=>`y should be 1D tensor, but got y (${$y.shape}).`));const xVals=await $x.data();const yVals=await $y.data();const ySet=new Set(yVals);let outputSize=0;for(let i=0;i<xVals.length;i++){if(!ySet.has(xVals[i])){outputSize++}}const buffer=new TensorBuffer([outputSize],$x.dtype);const indices=new TensorBuffer([outputSize],"int32");for(let i=0,p=0;i<xVals.length;i++){if(!ySet.has(xVals[i])){buffer.values[p]=xVals[i];indices.values[p]=i;p++}}return[buffer.toTensor(),indices.toTensor()]}const setdiff1dAsync=setdiff1dAsync_;function sign_(x){const $x=convertToTensor(x,"x","sign");const inputs={x:$x};return ENGINE.runKernel(Sign,inputs)}const sign$1=op({sign_:sign_});function sin_(x){const $x=convertToTensor(x,"x","sin");const inputs={x:$x};return ENGINE.runKernel(Sin,inputs)}const sin$1=op({sin_:sin_});function sinh_(x){const $x=convertToTensor(x,"x","sinh");const inputs={x:$x};return ENGINE.runKernel(Sinh,inputs)}const sinh$1=op({sinh_:sinh_});function slice1d_(x,begin,size){const $x=convertToTensor(x,"x","slice1d");assert($x.rank===1,(()=>`slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`));return slice$1($x,[begin],[size])}const slice1d=op({slice1d_:slice1d_});function slice2d_(x,begin,size){const $x=convertToTensor(x,"x","slice2d");assert($x.rank===2,(()=>`slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`));return slice$1($x,begin,size)}const slice2d=op({slice2d_:slice2d_});function slice3d_(x,begin,size){const $x=convertToTensor(x,"x","slice3d");assert($x.rank===3,(()=>`slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`));return slice$1($x,begin,size)}const slice3d=op({slice3d_:slice3d_});function slice4d_(x,begin,size){const $x=convertToTensor(x,"x","slice4d");assert($x.rank===4,(()=>`slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`));return slice$1($x,begin,size)}const slice4d=op({slice4d_:slice4d_});function softmax_(logits,dim=-1){const $logits=convertToTensor(logits,"logits","softmax","float32");if(dim===-1){dim=$logits.rank-1}if(dim!==$logits.rank-1){throw Error("Softmax along a non-last dimension is not yet supported. "+`Logits was rank ${$logits.rank} and dim was ${dim}`)}const inputs={logits:$logits};const attrs={dim:dim};return ENGINE.runKernel(Softmax,inputs,attrs)}const softmax$1=op({softmax_:softmax_});function fft_(input){assert(input.dtype==="complex64",(()=>`The dtype for tf.spectral.fft() must be complex64 `+`but got ${input.dtype}.`));const inputs={input:input};return ENGINE.runKernel(FFT,inputs)}const fft$1=op({fft_:fft_});function ifft_(input){assert(input.dtype==="complex64",(()=>`The dtype for tf.spectral.ifft() must be complex64 `+`but got ${input.dtype}.`));const inputs={input:input};return ENGINE.runKernel(IFFT,inputs)}const ifft$1=op({ifft_:ifft_});function irfft_(input){const innerDimensionSize=input.shape[input.shape.length-1];const batch=input.size/innerDimensionSize;let ret;if(innerDimensionSize<=2){const complexInput=reshape$1(input,[batch,innerDimensionSize]);ret=ifft$1(complexInput)}else{const outputShape=[batch,2*(innerDimensionSize-1)];const realInput=reshape$1(real$1(input),[batch,innerDimensionSize]);const imagInput=reshape$1(imag$1(input),[batch,innerDimensionSize]);const realConjugate=reverse$1(slice$1(realInput,[0,1],[batch,innerDimensionSize-2]),1);const imagConjugate=mul(reverse$1(slice$1(imagInput,[0,1],[batch,innerDimensionSize-2]),1),scalar(-1));const r=concat$1([realInput,realConjugate],1);const i=concat$1([imagInput,imagConjugate],1);const complexInput=reshape$1(complex$1(r,i),[outputShape[0],outputShape[1]]);ret=ifft$1(complexInput)}ret=real$1(ret);if(input.rank===3&&input.shape[0]!==0){const temp=ret;const batch=input.shape[0];ret=reshape$1(ret,[batch,ret.shape[0]/batch,ret.shape[1]]);temp.dispose()}return ret}const irfft=op({irfft_:irfft_});function split_(x,numOrSizeSplits,axis=0){const $x=convertToTensor(x,"x","split");const inputs={x:$x};const attr={numOrSizeSplits:numOrSizeSplits,axis:axis};return ENGINE.runKernel(SplitV,inputs,attr)}const split$1=op({split_:split_});function rfft_(input,fftLength){assert(input.dtype==="float32",(()=>`The dtype for rfft() must be real value but got ${input.dtype}`));let innerDimensionSize=input.shape[input.shape.length-1];const batch=input.size/innerDimensionSize;let adjustedInput;if(fftLength!=null&&fftLength<innerDimensionSize){const begin=input.shape.map((v=>0));const size=input.shape.map((v=>v));size[input.shape.length-1]=fftLength;adjustedInput=slice$1(input,begin,size);innerDimensionSize=fftLength}else if(fftLength!=null&&fftLength>innerDimensionSize){const zerosShape=input.shape.map((v=>v));zerosShape[input.shape.length-1]=fftLength-innerDimensionSize;adjustedInput=concat$1([input,zeros(zerosShape)],input.shape.length-1);innerDimensionSize=fftLength}else{adjustedInput=input}const zerosInput=zerosLike$1(adjustedInput);const complexInput=reshape$1(complex$1(adjustedInput,zerosInput),[batch,innerDimensionSize]);const ret=fft$1(complexInput);const half=Math.floor(innerDimensionSize/2)+1;const realValues=real$1(ret);const imagValues=imag$1(ret);const realComplexConjugate=split$1(realValues,[half,innerDimensionSize-half],realValues.shape.length-1);const imagComplexConjugate=split$1(imagValues,[half,innerDimensionSize-half],imagValues.shape.length-1);const outputShape=adjustedInput.shape.slice();outputShape[adjustedInput.shape.length-1]=half;return reshape$1(complex$1(realComplexConjugate[0],imagComplexConjugate[0]),outputShape)}const rfft=op({rfft_:rfft_});function sqrt_(x){const $x=convertToTensor(x,"x","sqrt");const inputs={x:$x};return ENGINE.runKernel(Sqrt,inputs)}const sqrt$1=op({sqrt_:sqrt_});function squaredDifference_(a,b){let $a=convertToTensor(a,"a","squaredDifference");let $b=convertToTensor(b,"b","squaredDifference");[$a,$b]=makeTypesMatch($a,$b);assertAndGetBroadcastShape($a.shape,$b.shape);const inputs={a:$a,b:$b};const attrs={};return ENGINE.runKernel(SquaredDifference,inputs,attrs)}const squaredDifference$1=op({squaredDifference_:squaredDifference_});function squeeze_(x,axis){const $x=convertToTensor(x,"x","squeeze");return reshape$1($x,squeezeShape($x.shape,axis).newShape)}const squeeze=op({squeeze_:squeeze_});function stack_(tensors,axis=0){const $tensors=convertToTensorArray(tensors,"tensors","stack","string_or_numeric");assert($tensors.length>=1,(()=>"Pass at least one tensor to tf.stack"));if($tensors.length>0){assert(axis<=$tensors[0].rank,(()=>"Axis must be <= rank of the tensor"))}const inputs=$tensors;const attrs={axis:axis};return ENGINE.runKernel(Pack,inputs,attrs)}const stack=op({stack_:stack_});function step_(x,alpha=0){const $x=convertToTensor(x,"x","step");const inputs={x:$x};const attrs={alpha:alpha};return ENGINE.runKernel(Step,inputs,attrs)}const step$1=op({step_:step_});function stridedSlice_(x,begin,end,strides,beginMask=0,endMask=0,ellipsisMask=0,newAxisMask=0,shrinkAxisMask=0){const $x=convertToTensor(x,"x","stridedSlice");const inputs={x:$x};const attrs={begin:begin,end:end,strides:strides,beginMask:beginMask,endMask:endMask,ellipsisMask:ellipsisMask,newAxisMask:newAxisMask,shrinkAxisMask:shrinkAxisMask};return ENGINE.runKernel(StridedSlice,inputs,attrs)}const stridedSlice$1=op({stridedSlice_:stridedSlice_});function tan_(x){const $x=convertToTensor(x,"x","tan");const inputs={x:$x};return ENGINE.runKernel(Tan,inputs)}const tan$1=op({tan_:tan_});function tensor1d(values,dtype){assertNonNull(values);const inferredShape=inferShape(values,dtype);if(inferredShape.length!==1){throw new Error("tensor1d() requires values to be a flat/TypedArray")}const shape=null;return makeTensor(values,shape,inferredShape,dtype)}function tensor2d(values,shape,dtype){assertNonNull(values);if(shape!=null&&shape.length!==2){throw new Error("tensor2d() requires shape to have two numbers")}const inferredShape=inferShape(values,dtype);if(inferredShape.length!==2&&inferredShape.length!==1){throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray")}if(inferredShape.length===1&&shape==null){throw new Error("tensor2d() requires shape to be provided when `values` "+"are a flat/TypedArray")}return makeTensor(values,shape,inferredShape,dtype)}function tensor4d(values,shape,dtype){assertNonNull(values);if(shape!=null&&shape.length!==4){throw new Error("tensor4d() requires shape to have four numbers")}const inferredShape=inferShape(values,dtype);if(inferredShape.length!==4&&inferredShape.length!==1){throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray")}if(inferredShape.length===1&&shape==null){throw new Error("tensor4d() requires shape to be provided when `values` "+"are a flat array")}return makeTensor(values,shape,inferredShape,dtype)}function tensor5d(values,shape,dtype){assertNonNull(values);if(shape!=null&&shape.length!==5){throw new Error("tensor5d() requires shape to have five numbers")}const inferredShape=inferShape(values,dtype);if(inferredShape.length!==5&&inferredShape.length!==1){throw new Error("tensor5d() requires values to be "+"number[][][][][] or flat/TypedArray")}if(inferredShape.length===1&&shape==null){throw new Error("tensor5d() requires shape to be provided when `values` "+"are a flat array")}return makeTensor(values,shape,inferredShape,dtype)}function tensor6d(values,shape,dtype){assertNonNull(values);if(shape!=null&&shape.length!==6){throw new Error("tensor6d() requires shape to have six numbers")}const inferredShape=inferShape(values,dtype);if(inferredShape.length!==6&&inferredShape.length!==1){throw new Error("tensor6d() requires values to be number[][][][][][] or "+"flat/TypedArray")}if(inferredShape.length===1&&shape==null){throw new Error("tensor6d() requires shape to be provided when `values` "+"are a flat array")}shape=shape||inferredShape;return makeTensor(values,shape,inferredShape,dtype)}function topk_(x,k=1,sorted=true){const $x=convertToTensor(x,"x","topk");if($x.rank===0){throw new Error("topk() expects the input to be of rank 1 or higher")}const lastDim=$x.shape[$x.shape.length-1];if(k>lastDim){throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) `+`but got ${k}`)}const inputs={x:$x};const attrs={k:k,sorted:sorted};const[values,indices]=ENGINE.runKernel(TopK,inputs,attrs);return{values:values,indices:indices}}const topk=op({topk_:topk_});function truncatedNormal_(shape,mean=0,stdDev=1,dtype,seed){if(dtype!=null&&dtype==="bool"){throw new Error(`Unsupported data type $ { dtype }`)}const randGauss=new MPRandGauss(mean,stdDev,dtype,true,seed);const res=buffer(shape,dtype);for(let i=0;i<res.values.length;i++){res.values[i]=randGauss.nextValue()}return res.toTensor()}const truncatedNormal=op({truncatedNormal_:truncatedNormal_});function unique_(x,axis=0){const $x=convertToTensor(x,"x","unique","string_or_numeric");assert($x.rank>0,(()=>"The input tensor must be at least 1D"));const inputs={x:$x};const attrs={axis:axis};const[values,indices]=ENGINE.runKernel(Unique,inputs,attrs);return{values:values,indices:indices}}const unique$1=op({unique_:unique_});function unsortedSegmentSum_(x,segmentIds,numSegments){const $x=convertToTensor(x,"x","unsortedSegmentSum");const $segmentIds=convertToTensor(segmentIds,"segmentIds","unsortedSegmentSum","int32");assert(isInt(numSegments),(()=>"numSegments must be of dtype int"));const inputs={x:$x,segmentIds:$segmentIds};const attrs={numSegments:numSegments};return ENGINE.runKernel(UnsortedSegmentSum,inputs,attrs)}const unsortedSegmentSum$1=op({unsortedSegmentSum_:unsortedSegmentSum_});function unstack_(x,axis=0){const $x=convertToTensor(x,"x","unstack","string_or_numeric");assert(axis>=-$x.shape.length&&axis<$x.shape.length,(()=>`Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`));const inputs={value:$x};const attrs={axis:axis};return ENGINE.runKernel(Unpack,inputs,attrs)}const unstack=op({unstack_:unstack_});function variable(initialValue,trainable=true,name,dtype){return ENGINE.makeVariable(initialValue,trainable,name,dtype)}function whereImpl$1(condShape,condVals){const indices=[];for(let i=0;i<condVals.length;i++){if(condVals[i]){indices.push(i)}}const inBuffer=buffer(condShape,"int32");const out=buffer([indices.length,condShape.length],"int32");for(let i=0;i<indices.length;i++){const loc=inBuffer.indexToLoc(indices[i]);const offset=i*condShape.length;out.values.set(loc,offset)}return out.toTensor()}async function whereAsync_(condition){const $condition=convertToTensor(condition,"condition","whereAsync","bool");const vals=await $condition.data();const res=whereImpl$1($condition.shape,vals);if(condition!==$condition){$condition.dispose()}return res}const whereAsync=whereAsync_;async function booleanMaskAsync_(tensor,mask,axis){const $tensor=convertToTensor(tensor,"tensor","boolMask");const $mask=convertToTensor(mask,"mask","boolMask","bool");const axisFrom=axis==null?0:axis;const maskDim=$mask.rank;const tensorShape=$tensor.shape;assert(maskDim>0,(()=>"mask cannot be scalar"));assertShapesMatch(tensorShape.slice(axisFrom,axisFrom+maskDim),$mask.shape,`mask's shape must match the first K dimensions of tensor's shape,`);let leadingSize=1;for(let i=axisFrom;i<axisFrom+maskDim;i++){leadingSize*=tensorShape[i]}const targetTensorShape=tensorShape.slice(0,axisFrom).concat([leadingSize],tensorShape.slice(axisFrom+maskDim));const reshapedTensor=reshape$1($tensor,targetTensorShape);const reshapedMask=reshape$1($mask,[-1]);const positivePositions=await whereAsync(reshapedMask);const indices=squeeze(positivePositions,[1]);const res=gather(reshapedTensor,indices,axisFrom);if(tensor!==$tensor){$tensor.dispose()}if(mask!==$mask){$mask.dispose()}indices.dispose();reshapedTensor.dispose();reshapedMask.dispose();positivePositions.dispose();return res}const booleanMaskAsync=booleanMaskAsync_;function norm_(x,ord="euclidean",axis=null,keepDims=false){x=convertToTensor(x,"x","norm");const norm=normImpl(x,ord,axis);let keepDimsShape=norm.shape;if(keepDims){const axes=parseAxisParam(axis,x.shape);keepDimsShape=expandShapeToKeepDim(norm.shape,axes)}return reshape$1(norm,keepDimsShape)}function normImpl(x,p,axis=null){if(x.rank===0){return abs$1(x)}if(x.rank!==1&&axis===null){return normImpl(reshape$1(x,[-1]),p,axis)}if(x.rank===1||typeof axis==="number"||Array.isArray(axis)&&axis.length===1){if(p===1){return sum$1(abs$1(x),axis)}if(p===Infinity){return max$1(abs$1(x),axis)}if(p===-Infinity){return min$1(abs$1(x),axis)}if(p==="euclidean"||p===2){return sqrt$1(sum$1(pow$1(abs$1(x),scalar(2,"int32")),axis))}throw new Error(`Error in norm: invalid ord value: ${p}`)}if(Array.isArray(axis)&&axis.length===2){if(p===1){return max$1(sum$1(abs$1(x),axis[0]),axis[1]-1)}if(p===Infinity){return max$1(sum$1(abs$1(x),axis[1]),axis[0])}if(p===-Infinity){return min$1(sum$1(abs$1(x),axis[1]),axis[0])}if(p==="fro"||p==="euclidean"){return sqrt$1(sum$1(square$1(x),axis))}throw new Error(`Error in norm: invalid ord value: ${p}`)}throw new Error(`Error in norm: invalid axis: ${axis}`)}const norm=op({norm_:norm_});function movingAverage_(v,x,decay,step,zeroDebias=true){const $v=convertToTensor(v,"v","movingAverage");const $x=convertToTensor(x,"x","movingAverage");const $decay=convertToTensor(decay,"decay","movingAverage");assertTypesMatch($v,$x);assert(arraysEqual($v.shape,$x.shape),(()=>"Shape mismatch in v and x"));const one=scalar(1);const oneMinusDecay=sub$1(one,$decay);let update=mul(sub$1($x,$v),oneMinusDecay);if(zeroDebias){assert(step!=null,(()=>"When using zeroDebias: true, step is required."));const $step=convertToTensor(step,"step","movingAverage");update=div(update,sub$1(one,pow$1($decay,$step)))}return add($v,update)}const movingAverage=op({movingAverage_:movingAverage_});function scatterND_(indices,updates,shape){const $indices=convertToTensor(indices,"indices","scatterND","int32");const $updates=convertToTensor(updates,"updates","scatterND");validateInput$1($updates,$indices,shape);const inputs={indices:$indices,updates:$updates};const attrs={shape:shape};return ENGINE.runKernel(ScatterNd,inputs,attrs)}const scatterND=op({scatterND_:scatterND_});function validateInput(sparseIndices,sparseValues,outputShape,defaultValues){if(sparseIndices.dtype!=="int32"){throw new Error("tf.sparseToDense() expects the indices to be int32 type,"+` but the dtype was ${sparseIndices.dtype}.`)}if(sparseIndices.rank>2){throw new Error("sparseIndices should be a scalar, vector, or matrix,"+` but got shape ${sparseIndices.shape}.`)}const numElems=sparseIndices.rank>0?sparseIndices.shape[0]:1;const numDims=sparseIndices.rank>1?sparseIndices.shape[1]:1;if(outputShape.length!==numDims){throw new Error("outputShape has incorrect number of elements:,"+` ${outputShape.length}, should be: ${numDims}.`)}const numValues=sparseValues.size;if(!(sparseValues.rank===0||sparseValues.rank===1&&numValues===numElems)){throw new Error("sparseValues has incorrect shape "+`${sparseValues.shape}, should be [] or [${numElems}]`)}if(sparseValues.dtype!==defaultValues.dtype){throw new Error("sparseValues.dtype must match defaultValues.dtype")}}function sparseToDense_(sparseIndices,sparseValues,outputShape,defaultValue=0){const $sparseIndices=convertToTensor(sparseIndices,"sparseIndices","sparseToDense","int32");const $sparseValues=convertToTensor(sparseValues,"sparseValues","sparseToDense");const $defaultValue=convertToTensor(defaultValue,"defaultValue","sparseToDense",$sparseValues.dtype);validateInput($sparseIndices,$sparseValues,outputShape,$defaultValue);const inputs={sparseIndices:$sparseIndices,sparseValues:$sparseValues,defaultValue:$defaultValue};const attrs={outputShape:outputShape};return ENGINE.runKernel(SparseToDense,inputs,attrs)}const sparseToDense$1=op({sparseToDense_:sparseToDense_});function gatherND_(x,indices){const $indices=convertToTensor(indices,"indices","gatherND","int32");const $x=convertToTensor(x,"x","gatherND");const inputs={params:$x,indices:$indices};return ENGINE.runKernel(GatherNd,inputs)}const gatherND=op({gatherND_:gatherND_});function getNoiseShape(x,noiseShape){if(noiseShape==null){return x.shape.slice()}if(arraysEqual(x.shape,noiseShape)){return noiseShape}if(x.shape.length===noiseShape.length){const newDimension=[];for(let i=0;i<x.shape.length;i++){if(noiseShape[i]==null&&x.shape[i]!=null){newDimension.push(x.shape[i])}else{newDimension.push(noiseShape[i])}}return newDimension}return noiseShape}function dropout_(x,rate,noiseShape,seed){const $x=convertToTensor(x,"x","dropout");assert($x.dtype==="float32",(()=>`x has to be a floating point tensor since it's going to be `+`scaled, but got a ${$x.dtype} tensor instead.`));assert(rate>=0&&rate<1,(()=>`rate must be a float in the range [0, 1), but got ${rate}.`));if(rate===0){return x instanceof Tensor?$x.clone():$x}const $noiseShape=getNoiseShape($x,noiseShape);const keepProb=1-rate;const multiplier=div(floor$1(add(randomUniform($noiseShape,0,1,"float32",seed),keepProb)),keepProb);return mul($x,multiplier)}const dropout=op({dropout_:dropout_});function enclosingPowerOfTwo(value){return Math.floor(Math.pow(2,Math.ceil(Math.log(value)/Math.log(2))))}function cosineWindow(windowLength,a,b){const even=1-windowLength%2;const newValues=new Float32Array(windowLength);for(let i=0;i<windowLength;++i){const cosArg=2*Math.PI*i/(windowLength+even-1);newValues[i]=a-b*Math.cos(cosArg)}return tensor1d(newValues,"float32")}async function inTopKAsync_(predictions,targets,k=1){const $predictions=convertToTensor(predictions,"predictions","inTopK");const $targets=convertToTensor(targets,"targets","inTopK");assert($predictions.rank>1,(()=>"inTopK() expects the predictions to be of rank 2 or higher, "+`but got ${$predictions.rank}`));assert($predictions.rank-1===$targets.rank,(()=>`predictions rank should be 1 larger than `+`targets rank, but got predictions rank `+`${$predictions.rank} and targets rank ${$targets.rank}`));assertShapesMatch($predictions.shape.slice(0,$predictions.shape.length-1),$targets.shape,`predictions's shape should be align with the targets' shape, `+"except the last dimension.");const lastDim=$predictions.shape[$predictions.shape.length-1];assert(k>0&&k<=lastDim,(()=>`'k' passed to inTopK() must be > 0 && <= the predictions last `+`dimension (${lastDim}), but got ${k}`));const predictionsVals=await $predictions.data();const targetsVals=await $targets.data();const[batch,size]=[predictionsVals.length/lastDim,lastDim];const precision=getTypedArrayFromDType("bool",batch);for(let b=0;b<batch;b++){const offset=b*size;const vals=predictionsVals.subarray(offset,offset+size);const valAndInd=[];for(let i=0;i<vals.length;i++){valAndInd.push({value:vals[i],index:i})}valAndInd.sort(((a,b)=>b.value-a.value));precision[b]=0;for(let i=0;i<k;i++){if(valAndInd[i].index===targetsVals[b]){precision[b]=1;break}}}if(predictions!==$predictions){$predictions.dispose()}if(targets!==$targets){$targets.dispose()}return tensor(precision,$targets.shape,"bool")}const inTopKAsync=inTopKAsync_;function conv2DBackpropFilter_(x,dy,filterShape,strides,pad,dataFormat="NHWC",dimRoundingMode){let x4D=x;if(x.rank===3){x4D=reshape$1(x,[1,x.shape[0],x.shape[1],x.shape[2]])}let dy4D=dy;if(dy4D.rank===3){dy4D=reshape$1(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2]])}assert(x4D.rank===4,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape `+`${x4D.shape}.`));assert(dy4D.rank===4,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape `+`${dy4D.shape}.`));assert(filterShape.length===4,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got `+`${filterShape}.`));const inDepth=dataFormat==="NHWC"?x4D.shape[3]:x4D.shape[1];const outDepth=dataFormat==="NHWC"?dy4D.shape[3]:dy4D.shape[1];assert(inDepth===filterShape[2],(()=>`Error in conv2dDerFilter: depth of input ${inDepth}) must `+`match input depth in filter (${filterShape[2]}.`));assert(outDepth===filterShape[3],(()=>`Error in conv2dDerFilter: depth of dy (${outDepth}) must `+`match output depth for filter (${filterShape[3]}).`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in conv2dDerFilter: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const inputs={x:x4D,dy:dy4D};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dimRoundingMode:dimRoundingMode,filterShape:filterShape};return ENGINE.runKernel(Conv2DBackpropFilter,inputs,attrs)}const conv2DBackpropFilter$1=op({conv2DBackpropFilter_:conv2DBackpropFilter_});function getFusedDyActivation(dy,y,activation){if(activation==null||activation==="linear"){return dy}if(activation==="relu"){return mul(dy,step$1(y))}throw new Error(`Cannot compute gradient for fused activation ${activation}.`)}function getFusedBiasGradient(bias,dyActivation){let res=dyActivation;const reduceAxes=getReductionAxes(bias.shape,dyActivation.shape);if(reduceAxes.length>0){res=sum$1(res,reduceAxes)}return reshape$1(res,bias.shape)}function applyActivation(x,activation,preluActivationWeights,leakyreluAlpha){if(activation==="linear"){return x}else if(activation==="relu"){return relu$1(x)}else if(activation==="elu"){return elu$1(x)}else if(activation==="relu6"){return relu6$1(x)}else if(activation==="prelu"){return prelu$1(x,preluActivationWeights)}else if(activation==="leakyrelu"){return leakyRelu$1(x,leakyreluAlpha)}else if(activation==="sigmoid"){return sigmoid$1(x)}throw new Error(`Unknown fused activation ${activation}.`)}const shouldFuse=(gradientDepth,activation)=>{const gradientMode=gradientDepth>0;return!gradientMode||activation==="linear"};function fusedConv2d_({x:x,filter:filter,strides:strides,pad:pad,dataFormat:dataFormat="NHWC",dilations:dilations=[1,1],dimRoundingMode:dimRoundingMode,bias:bias,activation:activation="linear",preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha}){activation=activation||"linear";if(shouldFuse(ENGINE.state.gradientDepth,activation)===false){let result=conv2d$2(x,filter,strides,pad,dataFormat,dilations,dimRoundingMode);if(bias!=null){result=add(result,bias)}return applyActivation(result,activation,preluActivationWeights,leakyreluAlpha)}const $x=convertToTensor(x,"x","conv2d");const $filter=convertToTensor(filter,"filter","conv2d");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in fused conv2d: input must be rank 4, but got rank `+`${x4D.rank}.`));assert($filter.rank===4,(()=>`Error in fused conv2d: filter must be rank 4, but got rank `+`${$filter.rank}.`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in fused conv2d: pad must be an integer when using, `+`dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}assert(x4D.shape[3]===$filter.shape[2],(()=>`Error in conv2d: depth of input (${x4D.shape[3]}) must match `+`input depth for filter ${$filter.shape[2]}.`));assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in conv2D: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));assert(dataFormat==="NHWC",(()=>`Error in conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported.`));const convInfo=computeConv2DInfo(x4D.shape,$filter.shape,strides,dilations,pad,dimRoundingMode);let $bias;if(bias!=null){$bias=convertToTensor(bias,"bias","fused conv2d");[$bias]=makeTypesMatch($bias,$x);assertAndGetBroadcastShape(convInfo.outShape,$bias.shape)}let $preluActivationWeights;if(preluActivationWeights!=null){$preluActivationWeights=convertToTensor(preluActivationWeights,"prelu weights","fused conv2d")}const grad=(dy,saved)=>{const[$filter,x4D,y,$bias]=saved;const dyActivation=getFusedDyActivation(dy,y,activation);assert(tupleValuesAreOne(dilations),(()=>"Error in gradient of fused conv2D: "+`dilation rates greater than 1 `+`are not yet supported in gradients. Got dilations '${dilations}'`));const xDer=conv2DBackpropInput$1(x4D.shape,dyActivation,$filter,strides,pad);const filterDer=conv2DBackpropFilter$1(x4D,dyActivation,$filter.shape,strides,pad);const der=[xDer,filterDer];if($bias!=null){const biasDer=getFusedBiasGradient($bias,dyActivation);der.push(biasDer)}return der};const inputs={x:x4D,filter:$filter,bias:$bias,preluActivationWeights:$preluActivationWeights};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode,activation:activation,leakyreluAlpha:leakyreluAlpha};if(bias==null){const customOp=customGrad(((x4D,filter,save)=>{let res=ENGINE.runKernel(FusedConv2D,inputs,attrs);save([filter,x4D,res]);if(reshapedTo4D){res=reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return{value:res,gradFunc:grad}}));return customOp(x4D,$filter)}else{const customOpWithBias=customGrad(((x4D,filter,bias,save)=>{let res=ENGINE.runKernel(FusedConv2D,inputs,attrs);save([filter,x4D,res,bias]);if(reshapedTo4D){res=reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return{value:res,gradFunc:grad}}));return customOpWithBias(x4D,$filter,$bias)}}const conv2d$1=op({fusedConv2d_:fusedConv2d_});function depthwiseConv2dNativeBackpropFilter_(x,dy,filterShape,strides,pad,dilations=[1,1],dimRoundingMode){let x4D=x;if(x.rank===3){x4D=reshape$1(x,[1,x.shape[0],x.shape[1],x.shape[2]])}let dy4D=dy;if(dy4D.rank===3){dy4D=reshape$1(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2]])}const inputs={x:x4D,dy:dy4D};const attrs={strides:strides,pad:pad,dimRoundingMode:dimRoundingMode,dilations:dilations,filterShape:filterShape};return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter,inputs,attrs)}const depthwiseConv2dNativeBackpropFilter$1=op({depthwiseConv2dNativeBackpropFilter_:depthwiseConv2dNativeBackpropFilter_});function depthwiseConv2dNativeBackpropInput_(xShape,dy,filter,strides,pad,dilations=[1,1],dimRoundingMode){let dy4D=dy;let reshapedTo4D=false;if(dy.rank===3){reshapedTo4D=true;dy4D=reshape$1(dy,[1,dy.shape[0],dy.shape[1],dy.shape[2]])}const inputs={dy:dy4D,filter:filter};const attrs={strides:strides,pad:pad,dimRoundingMode:dimRoundingMode,dilations:dilations,inputShape:xShape};const res=ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const depthwiseConv2dNativeBackpropInput$1=op({depthwiseConv2dNativeBackpropInput_:depthwiseConv2dNativeBackpropInput_});function fusedDepthwiseConv2d_({x:x,filter:filter,strides:strides,pad:pad,dataFormat:dataFormat="NHWC",dilations:dilations=[1,1],dimRoundingMode:dimRoundingMode,bias:bias,activation:activation="linear",preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha}){if(shouldFuse(ENGINE.state.gradientDepth,activation)===false){let result=depthwiseConv2d$1(x,filter,strides,pad,dataFormat,dilations,dimRoundingMode);if(bias!=null){result=add(result,bias)}return applyActivation(result,activation,preluActivationWeights,leakyreluAlpha)}const $x=convertToTensor(x,"x","depthwiseConv2d");const $filter=convertToTensor(filter,"filter","depthwiseConv2d");let x4D=$x;let reshapedTo4D=false;if($x.rank===3){reshapedTo4D=true;x4D=reshape$1($x,[1,$x.shape[0],$x.shape[1],$x.shape[2]])}assert(x4D.rank===4,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got `+`rank ${x4D.rank}.`));assert($filter.rank===4,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, `+`but got rank ${$filter.rank}.`));assert(x4D.shape[3]===$filter.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels `+`(${x4D.shape[3]}) must match the inChannels dimension in `+`filter ${$filter.shape[2]}.`));if(dilations==null){dilations=[1,1]}assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in fused depthwiseConv2d: Either strides or dilations must "+`be 1. Got strides ${strides} and dilations '${dilations}'`));if(dimRoundingMode!=null){assert(isInt(pad),(()=>`Error in fused depthwiseConv2d: pad must be an integer when `+`using dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`))}const convInfo=computeConv2DInfo(x4D.shape,$filter.shape,strides,dilations,pad,dimRoundingMode,true);let $bias;if(bias!=null){$bias=convertToTensor(bias,"bias","fused conv2d");[$bias]=makeTypesMatch($bias,$x);assertAndGetBroadcastShape(convInfo.outShape,$bias.shape)}let $preluActivationWeights;if(preluActivationWeights!=null){$preluActivationWeights=convertToTensor(preluActivationWeights,"prelu weights","fused depthwiseConv2d")}const grad=(dy,saved)=>{assert(tupleValuesAreOne(dilations),(()=>"Error in gradient of fused depthwiseConv2d: dilation rates "+`greater than 1 are not yet supported. Got dilations `+`'${dilations}'`));const[$filter,x4D,y,bias]=saved;const dyActivation=getFusedDyActivation(dy,y,activation);const xDer=depthwiseConv2dNativeBackpropInput$1(x4D.shape,dyActivation,$filter,strides,pad,dilations,dimRoundingMode);const filterDer=depthwiseConv2dNativeBackpropFilter$1(x4D,dyActivation,$filter.shape,strides,pad,dilations,dimRoundingMode);if(bias!=null){const biasDer=getFusedBiasGradient($bias,dyActivation);return[xDer,filterDer,biasDer]}return[xDer,filterDer]};const inputs={x:x4D,filter:$filter,bias:$bias,preluActivationWeights:$preluActivationWeights};const attrs={strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode,activation:activation,leakyreluAlpha:leakyreluAlpha};if(bias==null){const customOp=customGrad(((x4D,filter,save)=>{let res=ENGINE.runKernel(FusedDepthwiseConv2D,inputs,attrs);save([filter,x4D,res]);if(reshapedTo4D){res=reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return{value:res,gradFunc:grad}}));return customOp(x4D,$filter)}else{const customOpWithBias=customGrad(((x4D,filter,bias,save)=>{let res=ENGINE.runKernel(FusedDepthwiseConv2D,inputs,attrs);save([filter,x4D,res,bias]);if(reshapedTo4D){res=reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return{value:res,gradFunc:grad}}));return customOpWithBias(x4D,$filter,$bias)}}const depthwiseConv2d=op({fusedDepthwiseConv2d_:fusedDepthwiseConv2d_});function fusedMatMul_({a:a,b:b,transposeA:transposeA=false,transposeB:transposeB=false,bias:bias,activation:activation="linear",preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha}){if(shouldFuse(ENGINE.state.gradientDepth,activation)===false){let result=matMul$1(a,b,transposeA,transposeB);if(bias!=null){result=add(result,bias)}return applyActivation(result,activation,preluActivationWeights,leakyreluAlpha)}let $a=convertToTensor(a,"a","fused matMul");let $b=convertToTensor(b,"b","fused matMul");[$a,$b]=makeTypesMatch($a,$b);const innerShapeA=transposeA?$a.shape[$a.rank-2]:$a.shape[$a.rank-1];const innerShapeB=transposeB?$b.shape[$b.rank-1]:$b.shape[$b.rank-2];const outerShapeA=transposeA?$a.shape[$a.rank-1]:$a.shape[$a.rank-2];const outerShapeB=transposeB?$b.shape[$b.rank-2]:$b.shape[$b.rank-1];const outerDimsA=$a.shape.slice(0,-2);const outerDimsB=$b.shape.slice(0,-2);const batchDimA=sizeFromShape(outerDimsA);const batchDimB=sizeFromShape(outerDimsB);assert($a.rank>=2&&$b.rank>=2&&$a.rank===$b.rank,(()=>`Error in fused matMul: inputs must have the same rank of at `+`least 2, got ranks ${$a.rank} and ${$b.rank}.`));assert(arraysEqual(outerDimsA,outerDimsB),(()=>`Error in fused matMul: outer dimensions (${outerDimsA}) and (`+`${outerDimsB}) of Tensors with shapes ${$a.shape} and `+`${$b.shape} must match.`));assert(innerShapeA===innerShapeB,(()=>`Error in fused matMul: inner shapes (${innerShapeA}) and (`+`${innerShapeB}) of Tensors with shapes ${$a.shape} and `+`${$b.shape} and transposeA=${transposeA}`+` and transposeB=${transposeB} must match.`));const outShape=$a.shape.slice(0,-2).concat([outerShapeA,outerShapeB]);const a3D=transposeA?reshape$1($a,[batchDimA,innerShapeA,outerShapeA]):reshape$1($a,[batchDimA,outerShapeA,innerShapeA]);const b3D=transposeB?reshape$1($b,[batchDimB,outerShapeB,innerShapeB]):reshape$1($b,[batchDimB,innerShapeB,outerShapeB]);let $bias;if(bias!=null){$bias=convertToTensor(bias,"bias","fused matMul");[$bias]=makeTypesMatch($bias,$a);assertAndGetBroadcastShape(outShape,$bias.shape)}let $preluActivationWeights;if(preluActivationWeights!=null){$preluActivationWeights=convertToTensor(preluActivationWeights,"prelu weights","fused matMul")}const grad=(dy,saved)=>{const[a3D,b3D,y,$bias]=saved;const dyActivation=getFusedDyActivation(reshape$1(dy,y.shape),y,activation);let aDer;let bDer;if(!transposeA&&!transposeB){aDer=matMul$1(dyActivation,b3D,false,true);bDer=matMul$1(a3D,dyActivation,true,false)}else if(!transposeA&&transposeB){aDer=matMul$1(dyActivation,b3D,false,false);bDer=matMul$1(dyActivation,a3D,true,false)}else if(transposeA&&!transposeB){aDer=matMul$1(b3D,dyActivation,false,true);bDer=matMul$1(a3D,dyActivation,false,false)}else{aDer=matMul$1(b3D,dyActivation,true,true);bDer=matMul$1(dyActivation,a3D,true,true)}if(bias!=null){const biasDer=getFusedBiasGradient($bias,dyActivation);return[aDer,bDer,biasDer]}else{return[aDer,bDer]}};const inputs={a:a3D,b:b3D,bias:$bias,preluActivationWeights:$preluActivationWeights};const attrs={transposeA:transposeA,transposeB:transposeB,activation:activation,leakyreluAlpha:leakyreluAlpha};if(bias==null){const customOp=customGrad(((a3D,b3D,save)=>{const res=ENGINE.runKernel(_FusedMatMul,inputs,attrs);save([a3D,b3D,res]);return{value:reshape$1(res,outShape),gradFunc:grad}}));return customOp(a3D,b3D)}else{const customOpWithBias=customGrad(((a3D,b3D,$bias,save)=>{const res=ENGINE.runKernel(_FusedMatMul,inputs,attrs);save([a3D,b3D,res,$bias]);return{value:reshape$1(res,outShape),gradFunc:grad}}));return customOpWithBias(a3D,b3D,$bias)}}const matMul=op({fusedMatMul_:fusedMatMul_});var fused_ops=Object.freeze({__proto__:null,conv2d:conv2d$1,depthwiseConv2d:depthwiseConv2d,matMul:matMul});function hammingWindow_(windowLength){return cosineWindow(windowLength,.54,.46)}const hammingWindow=op({hammingWindow_:hammingWindow_});function hannWindow_(windowLength){return cosineWindow(windowLength,.5,.5)}const hannWindow=op({hannWindow_:hannWindow_});function frame_(signal,frameLength,frameStep,padEnd=false,padValue=0){let start=0;const output=[];while(start+frameLength<=signal.size){output.push(slice$1(signal,start,frameLength));start+=frameStep}if(padEnd){while(start<signal.size){const padLen=start+frameLength-signal.size;const pad=concat$1([slice$1(signal,start,frameLength-padLen),fill$1([padLen],padValue)]);output.push(pad);start+=frameStep}}if(output.length===0){return tensor2d([],[0,frameLength])}return reshape$1(concat$1(output),[output.length,frameLength])}const frame=op({frame_:frame_});function stft_(signal,frameLength,frameStep,fftLength,windowFn=hannWindow){if(fftLength==null){fftLength=enclosingPowerOfTwo(frameLength)}const framedSignal=frame(signal,frameLength,frameStep);const windowedSignal=mul(framedSignal,windowFn(frameLength));return rfft(windowedSignal,fftLength)}const stft=op({stft_:stft_});function cropAndResize_(image,boxes,boxInd,cropSize,method="bilinear",extrapolationValue=0){const $image=convertToTensor(image,"image","cropAndResize");const $boxes=convertToTensor(boxes,"boxes","cropAndResize","float32");const $boxInd=convertToTensor(boxInd,"boxInd","cropAndResize","int32");const numBoxes=$boxes.shape[0];assert($image.rank===4,(()=>"Error in cropAndResize: image must be rank 4,"+`but got rank ${$image.rank}.`));assert($boxes.rank===2&&$boxes.shape[1]===4,(()=>`Error in cropAndResize: boxes must be have size [${numBoxes},4] `+`but had shape ${$boxes.shape}.`));assert($boxInd.rank===1&&$boxInd.shape[0]===numBoxes,(()=>`Error in cropAndResize: boxInd must be have size [${numBoxes}] `+`but had shape ${$boxes.shape}.`));assert(cropSize.length===2,(()=>`Error in cropAndResize: cropSize must be of length 2, but got `+`length ${cropSize.length}.`));assert(cropSize[0]>=1&&cropSize[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${cropSize}`));assert(method==="bilinear"||method==="nearest",(()=>`method must be bilinear or nearest, but was ${method}`));const inputs={image:$image,boxes:$boxes,boxInd:$boxInd};const attrs={method:method,extrapolationValue:extrapolationValue,cropSize:cropSize};const res=ENGINE.runKernel(CropAndResize,inputs,attrs);return res}const cropAndResize$1=op({cropAndResize_:cropAndResize_});function flipLeftRight_(image){const $image=convertToTensor(image,"image","flipLeftRight","float32");assert($image.rank===4,(()=>"Error in flipLeftRight: image must be rank 4,"+`but got rank ${$image.rank}.`));const inputs={image:$image};const res=ENGINE.runKernel(FlipLeftRight,inputs,{});return res}const flipLeftRight=op({flipLeftRight_:flipLeftRight_});function rotateWithOffset_(image,radians,fillValue=0,center=.5){const $image=convertToTensor(image,"image","rotateWithOffset","float32");assert($image.rank===4,(()=>"Error in rotateWithOffset: image must be rank 4,"+`but got rank ${$image.rank}.`));const inputs={image:$image};const attrs={radians:radians,fillValue:fillValue,center:center};const res=ENGINE.runKernel(RotateWithOffset,inputs,attrs);return res}const rotateWithOffset=op({rotateWithOffset_:rotateWithOffset_});function nonMaxSuppSanityCheck(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma){if(iouThreshold==null){iouThreshold=.5}if(scoreThreshold==null){scoreThreshold=Number.NEGATIVE_INFINITY}if(softNmsSigma==null){softNmsSigma=0}const numBoxes=boxes.shape[0];maxOutputSize=Math.min(maxOutputSize,numBoxes);assert(0<=iouThreshold&&iouThreshold<=1,(()=>`iouThreshold must be in [0, 1], but was '${iouThreshold}'`));assert(boxes.rank===2,(()=>`boxes must be a 2D tensor, but was of rank '${boxes.rank}'`));assert(boxes.shape[1]===4,(()=>`boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`));assert(scores.rank===1,(()=>"scores must be a 1D tensor"));assert(scores.shape[0]===numBoxes,(()=>`scores has incompatible shape with boxes. Expected ${numBoxes}, `+`but was ${scores.shape[0]}`));assert(0<=softNmsSigma&&softNmsSigma<=1,(()=>`softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`));return{maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,softNmsSigma:softNmsSigma}}function nonMaxSuppression_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppression");const $scores=convertToTensor(scores,"scores","nonMaxSuppression");const inputs=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold);maxOutputSize=inputs.maxOutputSize;iouThreshold=inputs.iouThreshold;scoreThreshold=inputs.scoreThreshold;const attrs={maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold};return ENGINE.runKernel(NonMaxSuppressionV3,{boxes:$boxes,scores:$scores},attrs)}const nonMaxSuppression=op({nonMaxSuppression_:nonMaxSuppression_});function binaryInsert(arr,element,comparator){const index=binarySearch(arr,element,comparator);const insertionPoint=index<0?-(index+1):index;arr.splice(insertionPoint,0,element)}function binarySearch(arr,target,comparator){return binarySearch_(arr,target,comparator||defaultComparator)}function defaultComparator(a,b){return a>b?1:a<b?-1:0}function binarySearch_(arr,target,comparator){let left=0;let right=arr.length;let middle=0;let found=false;while(left<right){middle=left+(right-left>>>1);const compareResult=comparator(target,arr[middle]);if(compareResult>0){left=middle+1}else{right=middle;found=!compareResult}}return found?left:-left-1}function nonMaxSuppressionV3Impl$1(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold){return nonMaxSuppressionImpl_(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,0)}function nonMaxSuppressionV4Impl$1(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize){return nonMaxSuppressionImpl_(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,0,false,padToMaxOutputSize,true)}function nonMaxSuppressionV5Impl$1(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma){return nonMaxSuppressionImpl_(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma,true)}function nonMaxSuppressionImpl_(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma,returnScoresTensor=false,padToMaxOutputSize=false,returnValidOutputs=false){const candidates=[];for(let i=0;i<scores.length;i++){if(scores[i]>scoreThreshold){candidates.push({score:scores[i],boxIndex:i,suppressBeginIndex:0})}}candidates.sort(ascendingComparator);const scale=softNmsSigma>0?-.5/softNmsSigma:0;const selectedIndices=[];const selectedScores=[];while(selectedIndices.length<maxOutputSize&&candidates.length>0){const candidate=candidates.pop();const{score:originalScore,boxIndex:boxIndex,suppressBeginIndex:suppressBeginIndex}=candidate;if(originalScore<scoreThreshold){break}let ignoreCandidate=false;for(let j=selectedIndices.length-1;j>=suppressBeginIndex;--j){const iou=intersectionOverUnion(boxes,boxIndex,selectedIndices[j]);if(iou>=iouThreshold){ignoreCandidate=true;break}candidate.score=candidate.score*suppressWeight(iouThreshold,scale,iou);if(candidate.score<=scoreThreshold){break}}candidate.suppressBeginIndex=selectedIndices.length;if(!ignoreCandidate){if(candidate.score===originalScore){selectedIndices.push(boxIndex);selectedScores.push(candidate.score)}else if(candidate.score>scoreThreshold){binaryInsert(candidates,candidate,ascendingComparator)}}}const validOutputs=selectedIndices.length;const elemsToPad=maxOutputSize-validOutputs;if(padToMaxOutputSize&&elemsToPad>0){selectedIndices.push(...new Array(elemsToPad).fill(0));selectedScores.push(...new Array(elemsToPad).fill(0))}const result={selectedIndices:selectedIndices};if(returnScoresTensor){result["selectedScores"]=selectedScores}if(returnValidOutputs){result["validOutputs"]=validOutputs}return result}function intersectionOverUnion(boxes,i,j){const iCoord=boxes.subarray(i*4,i*4+4);const jCoord=boxes.subarray(j*4,j*4+4);const yminI=Math.min(iCoord[0],iCoord[2]);const xminI=Math.min(iCoord[1],iCoord[3]);const ymaxI=Math.max(iCoord[0],iCoord[2]);const xmaxI=Math.max(iCoord[1],iCoord[3]);const yminJ=Math.min(jCoord[0],jCoord[2]);const xminJ=Math.min(jCoord[1],jCoord[3]);const ymaxJ=Math.max(jCoord[0],jCoord[2]);const xmaxJ=Math.max(jCoord[1],jCoord[3]);const areaI=(ymaxI-yminI)*(xmaxI-xminI);const areaJ=(ymaxJ-yminJ)*(xmaxJ-xminJ);if(areaI<=0||areaJ<=0){return 0}const intersectionYmin=Math.max(yminI,yminJ);const intersectionXmin=Math.max(xminI,xminJ);const intersectionYmax=Math.min(ymaxI,ymaxJ);const intersectionXmax=Math.min(xmaxI,xmaxJ);const intersectionArea=Math.max(intersectionYmax-intersectionYmin,0)*Math.max(intersectionXmax-intersectionXmin,0);return intersectionArea/(areaI+areaJ-intersectionArea)}function suppressWeight(iouThreshold,scale,iou){const weight=Math.exp(scale*iou*iou);return iou<=iouThreshold?weight:0}function ascendingComparator(c1,c2){return c1.score-c2.score||c1.score===c2.score&&c2.boxIndex-c1.boxIndex}async function nonMaxSuppressionAsync_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppressionAsync");const $scores=convertToTensor(scores,"scores","nonMaxSuppressionAsync");const inputs=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold);maxOutputSize=inputs.maxOutputSize;iouThreshold=inputs.iouThreshold;scoreThreshold=inputs.scoreThreshold;const boxesAndScores=await Promise.all([$boxes.data(),$scores.data()]);const boxesVals=boxesAndScores[0];const scoresVals=boxesAndScores[1];const{selectedIndices:selectedIndices}=nonMaxSuppressionV3Impl$1(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold);if($boxes!==boxes){$boxes.dispose()}if($scores!==scores){$scores.dispose()}return tensor1d(selectedIndices,"int32")}const nonMaxSuppressionAsync=nonMaxSuppressionAsync_;function nonMaxSuppressionWithScore_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY,softNmsSigma=0){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppression");const $scores=convertToTensor(scores,"scores","nonMaxSuppression");const params=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma);maxOutputSize=params.maxOutputSize;iouThreshold=params.iouThreshold;scoreThreshold=params.scoreThreshold;softNmsSigma=params.softNmsSigma;const inputs={boxes:$boxes,scores:$scores};const attrs={maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,softNmsSigma:softNmsSigma};const result=ENGINE.runKernel(NonMaxSuppressionV5,inputs,attrs);return{selectedIndices:result[0],selectedScores:result[1]}}const nonMaxSuppressionWithScore=op({nonMaxSuppressionWithScore_:nonMaxSuppressionWithScore_});async function nonMaxSuppressionWithScoreAsync_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY,softNmsSigma=0){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppressionAsync");const $scores=convertToTensor(scores,"scores","nonMaxSuppressionAsync");const params=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma);maxOutputSize=params.maxOutputSize;iouThreshold=params.iouThreshold;scoreThreshold=params.scoreThreshold;softNmsSigma=params.softNmsSigma;const boxesAndScores=await Promise.all([$boxes.data(),$scores.data()]);const boxesVals=boxesAndScores[0];const scoresVals=boxesAndScores[1];const{selectedIndices:selectedIndices,selectedScores:selectedScores}=nonMaxSuppressionV5Impl$1(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma);if($boxes!==boxes){$boxes.dispose()}if($scores!==scores){$scores.dispose()}return{selectedIndices:tensor1d(selectedIndices,"int32"),selectedScores:tensor1d(selectedScores)}}const nonMaxSuppressionWithScoreAsync=nonMaxSuppressionWithScoreAsync_;function nonMaxSuppressionPadded_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY,padToMaxOutputSize=false){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppression");const $scores=convertToTensor(scores,"scores","nonMaxSuppression");const params=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold,null);const $maxOutputSize=params.maxOutputSize;const $iouThreshold=params.iouThreshold;const $scoreThreshold=params.scoreThreshold;const inputs={boxes:$boxes,scores:$scores};const attrs={maxOutputSize:$maxOutputSize,iouThreshold:$iouThreshold,scoreThreshold:$scoreThreshold,padToMaxOutputSize:padToMaxOutputSize};const result=ENGINE.runKernel(NonMaxSuppressionV4,inputs,attrs);return{selectedIndices:result[0],validOutputs:result[1]}}const nonMaxSuppressionPadded=op({nonMaxSuppressionPadded_:nonMaxSuppressionPadded_});async function nonMaxSuppressionPaddedAsync_(boxes,scores,maxOutputSize,iouThreshold=.5,scoreThreshold=Number.NEGATIVE_INFINITY,padToMaxOutputSize=false){const $boxes=convertToTensor(boxes,"boxes","nonMaxSuppressionAsync");const $scores=convertToTensor(scores,"scores","nonMaxSuppressionAsync");const params=nonMaxSuppSanityCheck($boxes,$scores,maxOutputSize,iouThreshold,scoreThreshold,null);const $maxOutputSize=params.maxOutputSize;const $iouThreshold=params.iouThreshold;const $scoreThreshold=params.scoreThreshold;const[boxesVals,scoresVals]=await Promise.all([$boxes.data(),$scores.data()]);const{selectedIndices:selectedIndices,validOutputs:validOutputs}=nonMaxSuppressionV4Impl$1(boxesVals,scoresVals,$maxOutputSize,$iouThreshold,$scoreThreshold,padToMaxOutputSize);if($boxes!==boxes){$boxes.dispose()}if($scores!==scores){$scores.dispose()}return{selectedIndices:tensor1d(selectedIndices,"int32"),validOutputs:scalar(validOutputs,"int32")}}const nonMaxSuppressionPaddedAsync=nonMaxSuppressionPaddedAsync_;function resizeBilinear_(images,size,alignCorners=false,halfPixelCenters=false){const $images=convertToTensor(images,"images","resizeBilinear");assert($images.rank===3||$images.rank===4,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got `+`rank ${$images.rank}.`));assert(size.length===2,(()=>`Error in resizeBilinear: new shape must 2D, but got shape `+`${size}.`));assert(halfPixelCenters===false||alignCorners===false,(()=>`Error in resizeBilinear: If halfPixelCenters is true, `+`alignCorners must be false.`));let batchImages=$images;let reshapedTo4D=false;if($images.rank===3){reshapedTo4D=true;batchImages=reshape$1($images,[1,$images.shape[0],$images.shape[1],$images.shape[2]])}const inputs={images:batchImages};const attrs={alignCorners:alignCorners,halfPixelCenters:halfPixelCenters,size:size};const res=ENGINE.runKernel(ResizeBilinear,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const resizeBilinear$1=op({resizeBilinear_:resizeBilinear_});function resizeNearestNeighbor_(images,size,alignCorners=false,halfPixelCenters=false){const $images=convertToTensor(images,"images","resizeNearestNeighbor");assert($images.rank===3||$images.rank===4,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got `+`rank ${$images.rank}.`));assert(size.length===2,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape `+`${size}.`));assert($images.dtype==="float32"||$images.dtype==="int32",(()=>"`images` must have `int32` or `float32` as dtype"));assert(halfPixelCenters===false||alignCorners===false,(()=>`Error in resizeNearestNeighbor: If halfPixelCenters is true, `+`alignCorners must be false.`));let batchImages=$images;let reshapedTo4D=false;if($images.rank===3){reshapedTo4D=true;batchImages=reshape$1($images,[1,$images.shape[0],$images.shape[1],$images.shape[2]])}const inputs={images:batchImages};const attrs={alignCorners:alignCorners,halfPixelCenters:halfPixelCenters,size:size};const res=ENGINE.runKernel(ResizeNearestNeighbor,inputs,attrs);if(reshapedTo4D){return reshape$1(res,[res.shape[1],res.shape[2],res.shape[3]])}return res}const resizeNearestNeighbor$1=op({resizeNearestNeighbor_:resizeNearestNeighbor_});function threshold_(image,method="binary",inverted=false,threshValue=.5){const $image=convertToTensor(image,"image","threshold");const RED_INTENCITY_COEF=.2989;const GREEN_INTENCITY_COEF=.587;const BLUE_INTENCITY_COEF=.114;const totalPixelsInImage=$image.shape[0]*$image.shape[1];let $threshold=mul(tensor1d([threshValue]),255);let r,g,b,grayscale;assert($image.rank===3,(()=>"Error in threshold: image must be rank 3,"+`but got rank ${$image.rank}.`));assert($image.shape[2]===3||$image.shape[2]===1,(()=>"Error in threshold: "+"image color channel must be equal to 3 or 1"+`but got ${$image.shape[2]}.`));assert($image.dtype==="int32"||$image.dtype==="float32",(()=>"Error in dtype: image dtype must be int32 or float32,"+`but got dtype ${$image.dtype}.`));assert(method==="otsu"||method==="binary",(()=>`Method must be binary or otsu, but was ${method}`));if($image.shape[2]===3){[r,g,b]=split$1($image,[1,1,1],-1);const $r=mul(r,RED_INTENCITY_COEF);const $g=mul(g,GREEN_INTENCITY_COEF);const $b=mul(b,BLUE_INTENCITY_COEF);grayscale=add(add($r,$g),$b)}else{grayscale=image}if(method==="otsu"){const $histogram=bincount$1(cast$1(round$1(grayscale),"int32"),tensor([]),256);$threshold=otsu($histogram,totalPixelsInImage)}const invCondition=inverted?lessEqual$1(grayscale,$threshold):greater$1(grayscale,$threshold);const result=cast$1(mul(invCondition,255),"int32");return result}function otsu(histogram,total){let bestThresh=tensor1d([-1]);let bestInBetVar=tensor1d([0]);let cInBetVar=tensor1d([0]);let classFirst,classSecond,meanFirst,meanSec,weightForeground,weightBack;for(let index=0;index<histogram.size-1;index++){classFirst=slice$1(histogram,0,index+1);classSecond=slice$1(histogram,index+1);weightForeground=div(sum$1(classFirst),total);weightBack=div(sum$1(classSecond),total);const meanFirstDivA=sum$1(mul(classFirst,range$1(0,classFirst.size)));meanFirst=div(meanFirstDivA,sum$1(classFirst));const meanSecFill=fill$1(classSecond.shape,classFirst.size);const meanSecAdd=add(range$1(0,classSecond.size),meanSecFill);const meanSecMul=mul(classSecond,meanSecAdd);meanSec=div(sum$1(meanSecMul),sum$1(classSecond));const cInBetVarSubA=sub$1(meanFirst,meanSec);const cInBetVarSubB=sub$1(meanFirst,meanSec);const cInBetVarMul=mul(weightForeground,weightBack);cInBetVar=mul(mul(cInBetVarMul,cInBetVarSubA),cInBetVarSubB);const condition=greater$1(cInBetVar,bestInBetVar);bestInBetVar=where(condition,cInBetVar,bestInBetVar);bestThresh=where(condition,tensor1d([index]),bestThresh)}return bestThresh}const threshold=op({threshold_:threshold_});function transform_(image,transforms,interpolation="nearest",fillMode="constant",fillValue=0,outputShape){const $image=convertToTensor(image,"image","transform","float32");const $transforms=convertToTensor(transforms,"transforms","transform","float32");assert($image.rank===4,(()=>"Error in transform: image must be rank 4,"+`but got rank ${$image.rank}.`));assert($transforms.rank===2&&($transforms.shape[0]===$image.shape[0]||$transforms.shape[0]===1)&&$transforms.shape[1]===8,(()=>`Error in transform: Input transform should be batch x 8 or 1 x 8`));assert(outputShape==null||outputShape.length===2,(()=>"Error in transform: outputShape must be [height, width] or null, "+`but got ${outputShape}.`));const inputs={image:$image,transforms:$transforms};const attrs={interpolation:interpolation,fillMode:fillMode,fillValue:fillValue,outputShape:outputShape};return ENGINE.runKernel(Transform,inputs,attrs)}const transform$1=op({transform_:transform_});function bandPart_(a,numLower,numUpper){assert(numLower%1===0,(()=>`bandPart(): numLower must be an integer, got ${numLower}.`));assert(numUpper%1===0,(()=>`bandPart(): numUpper must be an integer, got ${numUpper}.`));const $a=convertToTensor(a,"a","bandPart");assert($a.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${$a.rank}.`));const shape=$a.shape;const[M,N]=$a.shape.slice(-2);if(!(numLower<=M)){throw new Error(`bandPart(): numLower (${numLower})`+` must not be greater than the number of rows (${M}).`)}if(!(numUpper<=N)){throw new Error(`bandPart(): numUpper (${numUpper})`+` must not be greater than the number of columns (${N}).`)}if(numLower<0){numLower=M}if(numUpper<0){numUpper=N}const i=reshape$1(range$1(0,M,1,"int32"),[-1,1]);const j=range$1(0,N,1,"int32");const ij=sub$1(i,j);const inBand=logicalAnd$1(lessEqual$1(ij,scalar(+numLower,"int32")),greaterEqual$1(ij,scalar(-numUpper,"int32")));const zero=zeros([M,N],$a.dtype);return reshape$1(stack(unstack(reshape$1($a,[-1,M,N])).map((mat=>where(inBand,mat,zero)))),shape)}const bandPart=op({bandPart_:bandPart_});function gramSchmidt_(xs){let inputIsTensor2D;if(Array.isArray(xs)){inputIsTensor2D=false;assert(xs!=null&&xs.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or "+"empty"));const dim=xs[0].shape[0];for(let i=1;i<xs.length;++i){assert(xs[i].shape[0]===dim,(()=>"Gram-Schmidt: Non-unique lengths found in the input vectors: "+`(${xs[i].shape[0]} vs. ${dim})`))}}else{inputIsTensor2D=true;xs=split$1(xs,xs.shape[0],0).map((x=>squeeze(x,[0])))}assert(xs.length<=xs[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${xs.length}) exceeds `+`number of dimensions (${xs[0].shape[0]}).`));const ys=[];const xs1d=xs;for(let i=0;i<xs.length;++i){ys.push(ENGINE.tidy((()=>{let x=xs1d[i];if(i>0){for(let j=0;j<i;++j){const proj=mul(sum$1(mul(ys[j],x)),ys[j]);x=sub$1(x,proj)}}return div(x,norm(x,"euclidean"))})))}if(inputIsTensor2D){return stack(ys,0)}else{return ys}}const gramSchmidt=op({gramSchmidt_:gramSchmidt_});function qr_(x,fullMatrices=false){assert(x.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`));if(x.rank===2){return qr2d(x,fullMatrices)}else{const outerDimsProd=x.shape.slice(0,x.shape.length-2).reduce(((value,prev)=>value*prev));const x2ds=unstack(reshape$1(x,[outerDimsProd,x.shape[x.shape.length-2],x.shape[x.shape.length-1]]),0);const q2ds=[];const r2ds=[];x2ds.forEach((x2d=>{const[q2d,r2d]=qr2d(x2d,fullMatrices);q2ds.push(q2d);r2ds.push(r2d)}));const q=reshape$1(stack(q2ds,0),x.shape);const r=reshape$1(stack(r2ds,0),x.shape);return[q,r]}}function qr2d(x,fullMatrices=false){return ENGINE.tidy((()=>{assert(x.shape.length===2,(()=>`qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`));const m=x.shape[0];const n=x.shape[1];let q=eye(m);let r=clone(x);const one2D=tensor2d([[1]],[1,1]);let w=clone(one2D);const iters=m>=n?n:m;for(let j=0;j<iters;++j){const rTemp=r;const wTemp=w;const qTemp=q;[w,r,q]=ENGINE.tidy((()=>{const rjEnd1=slice$1(r,[j,j],[m-j,1]);const normX=norm(rjEnd1);const rjj=slice$1(r,[j,j],[1,1]);const s=where(greater$1(rjj,0),tensor2d([[-1]]),tensor2d([[1]]));const u1=sub$1(rjj,mul(s,normX));const wPre=div(rjEnd1,u1);if(wPre.shape[0]===1){w=clone(one2D)}else{w=concat$1([one2D,slice$1(wPre,[1,0],[wPre.shape[0]-1,wPre.shape[1]])],0)}const tau=neg$1(div(matMul$1(s,u1),normX));const rjEndAll=slice$1(r,[j,0],[m-j,n]);const tauTimesW=mul(tau,w);const wT=transpose$1(w);if(j===0){r=sub$1(rjEndAll,matMul$1(tauTimesW,matMul$1(wT,rjEndAll)))}else{const rTimesTau=sub$1(rjEndAll,matMul$1(tauTimesW,matMul$1(wT,rjEndAll)));r=concat$1([slice$1(r,[0,0],[j,n]),rTimesTau],0)}const tawTimesWT=transpose$1(tauTimesW);const qAllJEnd=slice$1(q,[0,j],[m,q.shape[1]-j]);if(j===0){q=sub$1(qAllJEnd,matMul$1(matMul$1(qAllJEnd,w),tawTimesWT))}else{const qTimesTau=sub$1(qAllJEnd,matMul$1(matMul$1(qAllJEnd,w),tawTimesWT));q=concat$1([slice$1(q,[0,0],[m,j]),qTimesTau],1)}return[w,r,q]}));dispose([rTemp,wTemp,qTemp])}if(!fullMatrices&&m>n){q=slice$1(q,[0,0],[m,n]);r=slice$1(r,[0,0],[n,n])}return[q,r]}))}const qr=op({qr_:qr_});var Reduction;(function(Reduction){Reduction[Reduction["NONE"]=0]="NONE";Reduction[Reduction["MEAN"]=1]="MEAN";Reduction[Reduction["SUM"]=2]="SUM";Reduction[Reduction["SUM_BY_NONZERO_WEIGHTS"]=3]="SUM_BY_NONZERO_WEIGHTS"})(Reduction||(Reduction={}));function computeWeightedLoss_(losses,weights,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $losses=convertToTensor(losses,"losses","computeWeightedLoss");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","computeWeightedLoss")}const weightedLoss=$weights==null?$losses:mul($losses,$weights);if(reduction===Reduction.NONE){return weightedLoss}if(reduction===Reduction.SUM){return sum$1(weightedLoss)}if(reduction===Reduction.MEAN){if($weights==null){return mean(weightedLoss)}else{const broadcastFactor=$losses.size/$weights.size;const result=div(sum$1(weightedLoss),sum$1($weights));return broadcastFactor>1?div(result,scalar(broadcastFactor)):result}}if(reduction===Reduction.SUM_BY_NONZERO_WEIGHTS){if($weights==null){return div(sum$1(weightedLoss),scalar($losses.size))}else{const broadcastedWeights=mul($weights,ones($losses.shape));const numNonZeros=cast$1(sum$1(notEqual$1(broadcastedWeights,scalar(0))),"float32");return div(sum$1(weightedLoss),numNonZeros)}}throw Error(`Unknown reduction: ${reduction}`)}const computeWeightedLoss=op({computeWeightedLoss_:computeWeightedLoss_});function absoluteDifference_(labels,predictions,weights,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $labels=convertToTensor(labels,"labels","absoluteDifference");const $predictions=convertToTensor(predictions,"predictions","absoluteDifference");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","absoluteDifference")}assertShapesMatch($labels.shape,$predictions.shape,"Error in absoluteDifference: ");const losses=abs$1(sub$1($labels,$predictions));return computeWeightedLoss(losses,$weights,reduction)}const absoluteDifference=op({absoluteDifference_:absoluteDifference_});function cosineDistance_(labels,predictions,axis,weights,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $labels=convertToTensor(labels,"labels","cosineDistance");const $predictions=convertToTensor(predictions,"predictions","cosineDistance");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","cosineDistance")}assertShapesMatch($labels.shape,$predictions.shape,"Error in cosineDistance: ");const one=scalar(1);const losses=sub$1(one,sum$1(mul($labels,$predictions),axis,true));return computeWeightedLoss(losses,$weights,reduction)}const cosineDistance=op({cosineDistance_:cosineDistance_});function hingeLoss_(labels,predictions,weights,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){let $labels=convertToTensor(labels,"labels","hingeLoss");const $predictions=convertToTensor(predictions,"predictions","hingeLoss");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","hingeLoss")}assertShapesMatch($labels.shape,$predictions.shape,"Error in hingeLoss: ");const one=scalar(1);$labels=sub$1(mul(scalar(2),$labels),one);const losses=relu$1(sub$1(one,mul($labels,$predictions)));return computeWeightedLoss(losses,$weights,reduction)}const hingeLoss=op({hingeLoss_:hingeLoss_});function huberLoss_(labels,predictions,weights,delta=1,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $labels=convertToTensor(labels,"labels","huberLoss");const $predictions=convertToTensor(predictions,"predictions","huberLoss");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","huberLoss")}assertShapesMatch($labels.shape,$predictions.shape,"Error in huberLoss: ");const deltaScalar=scalar(delta);const error=abs$1(sub$1($predictions,$labels));const quadratic=minimum$1(error,deltaScalar);const linear=sub$1(error,quadratic);const losses=add(mul(scalar(.5),square$1(quadratic)),mul(deltaScalar,linear));return computeWeightedLoss(losses,$weights,reduction)}const huberLoss=op({huberLoss_:huberLoss_});function logLoss_(labels,predictions,weights,epsilon=1e-7,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $labels=convertToTensor(labels,"labels","logLoss");const $predictions=convertToTensor(predictions,"predictions","logLoss");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","logLoss")}assertShapesMatch($labels.shape,$predictions.shape,"Error in logLoss: ");const one=scalar(1);const epsilonScalar=scalar(epsilon);const l1=neg$1(mul($labels,log$2(add($predictions,epsilonScalar))));const l2=mul(sub$1(one,$labels),log$2(add(sub$1(one,$predictions),epsilonScalar)));const losses=sub$1(l1,l2);return computeWeightedLoss(losses,$weights,reduction)}const logLoss=op({logLoss_:logLoss_});function meanSquaredError_(labels,predictions,weights,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){const $labels=convertToTensor(labels,"labels","meanSquaredError");const $predictions=convertToTensor(predictions,"predictions","meanSquaredError");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","meanSquaredError")}assertShapesMatch($labels.shape,$predictions.shape,"Error in meanSquaredError: ");const losses=squaredDifference$1($labels,$predictions);return computeWeightedLoss(losses,$weights,reduction)}const meanSquaredError=op({meanSquaredError_:meanSquaredError_});function sigmoidCrossEntropyWithLogits_(labels,logits){const $labels=convertToTensor(labels,"labels","sigmoidCrossEntropyWithLogits");const $logits=convertToTensor(logits,"logits","sigmoidCrossEntropyWithLogits");assertShapesMatch($labels.shape,$logits.shape,"Error in sigmoidCrossEntropyWithLogits: ");const maxOutput=relu$1($logits);const outputXTarget=mul($logits,$labels);const sigmoidOutput=log1p$1(exp$1(neg$1(abs$1($logits))));return add(sub$1(maxOutput,outputXTarget),sigmoidOutput)}function sigmoidCrossEntropy_(multiClassLabels,logits,weights,labelSmoothing=0,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){let $multiClassLabels=convertToTensor(multiClassLabels,"multiClassLabels","sigmoidCrossEntropy");const $logits=convertToTensor(logits,"logits","sigmoidCrossEntropy");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","sigmoidCrossEntropy")}assertShapesMatch($multiClassLabels.shape,$logits.shape,"Error in sigmoidCrossEntropy: ");if(labelSmoothing>0){const labelSmoothingScalar=scalar(labelSmoothing);const one=scalar(1);const half=scalar(.5);$multiClassLabels=add(mul($multiClassLabels,sub$1(one,labelSmoothingScalar)),mul(half,labelSmoothingScalar))}const losses=sigmoidCrossEntropyWithLogits_($multiClassLabels,$logits);return computeWeightedLoss(losses,$weights,reduction)}const sigmoidCrossEntropy=op({sigmoidCrossEntropy_:sigmoidCrossEntropy_});function softmaxCrossEntropyWithLogits_(labels,logits,dim=-1){if(dim===-1){dim=logits.rank-1}if(dim!==logits.rank-1){throw Error(`Softmax cross entropy along a non-last dimension is not yet `+`supported. Labels / logits was rank ${logits.rank} `+`and dim was ${dim}`)}const customOp=customGrad(((labels,logits,save)=>{const keepDims=true;const lse=logSumExp(logits,[dim],keepDims);const logResult=sub$1(cast$1(logits,"float32"),lse);save([labels,logResult]);const costVector=neg$1(mul(logResult,labels));const value=sum$1(costVector,[dim]);const gradFunc=(dy,saved)=>{const[labels,logResult]=saved;const dyShape=expandShapeToKeepDim(dy.shape,[dim]);return[mul(reshape$1(dy,dyShape),sub$1(cast$1(labels,"float32"),exp$1(logResult))),mul(reshape$1(dy,dyShape),sub$1(exp$1(logResult),cast$1(labels,"float32")))]};return{value:value,gradFunc:gradFunc}}));return customOp(labels,logits)}function softmaxCrossEntropy_(onehotLabels,logits,weights,labelSmoothing=0,reduction=Reduction.SUM_BY_NONZERO_WEIGHTS){let $onehotLabels=convertToTensor(onehotLabels,"onehotLabels","softmaxCrossEntropy");const $logits=convertToTensor(logits,"logits","softmaxCrossEntropy");let $weights=null;if(weights!=null){$weights=convertToTensor(weights,"weights","softmaxCrossEntropy")}assertShapesMatch($onehotLabels.shape,$logits.shape,"Error in softmaxCrossEntropy: ");if(labelSmoothing>0){const labelSmoothingScalar=scalar(labelSmoothing);const one=scalar(1);const numClasses=scalar($onehotLabels.shape[1]);$onehotLabels=add(mul($onehotLabels,sub$1(one,labelSmoothingScalar)),div(labelSmoothingScalar,numClasses))}const losses=softmaxCrossEntropyWithLogits_($onehotLabels,$logits);return computeWeightedLoss(losses,$weights,reduction)}const softmaxCrossEntropy=op({softmaxCrossEntropy_:softmaxCrossEntropy_});function sparseFillEmptyRows_(indices,values,denseShape,defaultValue){const $indices=convertToTensor(indices,"indices","sparseFillEmptyRows");const $values=convertToTensor(values,"values","sparseFillEmptyRows");const $denseShape=convertToTensor(denseShape,"denseShape","sparseFillEmptyRows");const $defaultValue=convertToTensor(defaultValue,"defaultValue","sparseFillEmptyRows",$values.dtype);if($indices.rank!==2){throw new Error(`Indices should be Tensor2D but received shape\n        ${$indices.shape}`)}if($values.rank!==1){throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`)}if($denseShape.rank!==1){throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`)}if($defaultValue.rank!==0){throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`)}const inputs={indices:$indices,values:$values,denseShape:$denseShape,defaultValue:$defaultValue};const result=ENGINE.runKernel(SparseFillEmptyRows,inputs);return{outputIndices:result[0],outputValues:result[1],emptyRowIndicator:result[2],reverseIndexMap:result[3]}}const sparseFillEmptyRows$1=op({sparseFillEmptyRows_:sparseFillEmptyRows_});function sparseReshape_(inputIndices,inputShape,newShape){const $inputIndices=convertToTensor(inputIndices,"inputIndices","sparseReshape");const $inputShape=convertToTensor(inputShape,"inputShape","sparseReshape");const $newShape=convertToTensor(newShape,"newShape","sparseReshape");if($inputIndices.rank!==2){throw new Error(`Input indices should be Tensor2D but received shape\n        ${$inputIndices.shape}`)}if($inputShape.rank!==1){throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`)}if($newShape.rank!==1){throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`)}const inputs={inputIndices:$inputIndices,inputShape:$inputShape,newShape:$newShape};const result=ENGINE.runKernel(SparseReshape,inputs);return{outputIndices:result[0],outputShape:result[1]}}const sparseReshape$1=op({sparseReshape_:sparseReshape_});const spectral$1={fft:fft$1,ifft:ifft$1,rfft:rfft,irfft:irfft};const signal={hammingWindow:hammingWindow,hannWindow:hannWindow,frame:frame,stft:stft};const image$1={flipLeftRight:flipLeftRight,resizeNearestNeighbor:resizeNearestNeighbor$1,resizeBilinear:resizeBilinear$1,rotateWithOffset:rotateWithOffset,cropAndResize:cropAndResize$1,nonMaxSuppression:nonMaxSuppression,nonMaxSuppressionAsync:nonMaxSuppressionAsync,nonMaxSuppressionWithScore:nonMaxSuppressionWithScore,nonMaxSuppressionWithScoreAsync:nonMaxSuppressionWithScoreAsync,nonMaxSuppressionPadded:nonMaxSuppressionPadded,nonMaxSuppressionPaddedAsync:nonMaxSuppressionPaddedAsync,threshold:threshold,transform:transform$1};const linalg={bandPart:bandPart,gramSchmidt:gramSchmidt,qr:qr};const losses={absoluteDifference:absoluteDifference,computeWeightedLoss:computeWeightedLoss,cosineDistance:cosineDistance,hingeLoss:hingeLoss,huberLoss:huberLoss,logLoss:logLoss,meanSquaredError:meanSquaredError,sigmoidCrossEntropy:sigmoidCrossEntropy,softmaxCrossEntropy:softmaxCrossEntropy};const sparse={sparseFillEmptyRows:sparseFillEmptyRows$1,sparseReshape:sparseReshape$1};class Optimizer extends Serializable{minimize(f,returnCost=false,varList){const{value:value,grads:grads}=this.computeGradients(f,varList);if(varList!=null){const gradArray=varList.map((v=>({name:v.name,tensor:grads[v.name]})));this.applyGradients(gradArray)}else{this.applyGradients(grads)}dispose(grads);if(returnCost){return value}else{value.dispose();return null}}get iterations(){if(this.iterations_==null){this.iterations_=0}return this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(f,varList){return variableGrads(f,varList)}dispose(){if(this.iterations_!=null){dispose(this.iterations_)}}async saveIterations(){if(this.iterations_==null){this.iterations_=0}return{name:"iter",tensor:scalar(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(weightValues){throw new Error(`setWeights() is not implemented for this optimizer class `+`${this.getClassName()}`)}async extractIterations(weightValues){this.iterations_=(await weightValues[0].tensor.data())[0];return weightValues.slice(1)}}Object.defineProperty(Optimizer,Symbol.hasInstance,{value:instance=>instance.minimize!=null&&instance.computeGradients!=null&&instance.applyGradients!=null});class AdadeltaOptimizer extends Optimizer{constructor(learningRate,rho,epsilon=null){super();this.learningRate=learningRate;this.rho=rho;this.epsilon=epsilon;this.accumulatedGrads=[];this.accumulatedUpdates=[];if(epsilon==null){this.epsilon=ENGINE.backend.epsilon()}}applyGradients(variableGradients){const variableNames=Array.isArray(variableGradients)?variableGradients.map((item=>item.name)):Object.keys(variableGradients);variableNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];const trainable=false;if(this.accumulatedGrads[i]==null){this.accumulatedGrads[i]={originalName:`${name}/accum_grad`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}if(this.accumulatedUpdates[i]==null){this.accumulatedUpdates[i]={originalName:`${name}/accum_var`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const accumulatedGrad=this.accumulatedGrads[i].variable;const accumulatedUpdate=this.accumulatedUpdates[i].variable;tidy((()=>{const newAccumulatedGrad=add(mul(accumulatedGrad,this.rho),mul(square$1(gradient),1-this.rho));const updates=mul(div(sqrt$1(add(accumulatedUpdate,this.epsilon)),sqrt$1(add(accumulatedGrad,this.epsilon))),gradient);const newAccumulatedUpdate=add(mul(accumulatedUpdate,this.rho),mul(square$1(updates),1-this.rho));accumulatedGrad.assign(newAccumulatedGrad);accumulatedUpdate.assign(newAccumulatedUpdate);const newValue=add(mul(updates,-this.learningRate),value);value.assign(newValue)}))}));this.incrementIterations()}dispose(){if(this.accumulatedUpdates!=null){dispose(this.accumulatedGrads.map((v=>v.variable)));dispose(this.accumulatedUpdates.map((v=>v.variable)))}}async getWeights(){const variables=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(variables.map((v=>({name:v.originalName,tensor:v.variable}))))}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);const variableCount=weightValues.length/2;const trainable=false;this.accumulatedGrads=weightValues.slice(0,variableCount).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})));this.accumulatedUpdates=weightValues.slice(variableCount,variableCount*2).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(cls,config){return new cls(config["learningRate"],config["rho"],config["epsilon"])}}AdadeltaOptimizer.className="Adadelta";registerClass(AdadeltaOptimizer);class AdagradOptimizer extends Optimizer{constructor(learningRate,initialAccumulatorValue=.1){super();this.learningRate=learningRate;this.initialAccumulatorValue=initialAccumulatorValue;this.accumulatedGrads=[]}applyGradients(variableGradients){const variableNames=Array.isArray(variableGradients)?variableGradients.map((item=>item.name)):Object.keys(variableGradients);variableNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];if(this.accumulatedGrads[i]==null){const trainable=false;this.accumulatedGrads[i]={originalName:`${name}/accumulator`,variable:tidy((()=>fill$1(value.shape,this.initialAccumulatorValue).variable(trainable)))}}const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const accumulatedGrad=this.accumulatedGrads[i].variable;tidy((()=>{const newAccumulatedGrad=add(accumulatedGrad,square$1(gradient));accumulatedGrad.assign(newAccumulatedGrad);const newValue=add(mul(div(gradient,sqrt$1(add(newAccumulatedGrad,ENGINE.backend.epsilon()))),-this.learningRate),value);value.assign(newValue)}))}));this.incrementIterations()}dispose(){if(this.accumulatedGrads!=null){dispose(this.accumulatedGrads.map((v=>v.variable)))}}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((v=>({name:v.originalName,tensor:v.variable}))))}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);const trainable=false;this.accumulatedGrads=weightValues.map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(cls,config){return new cls(config["learningRate"],config["initialAccumulatorValue"])}}AdagradOptimizer.className="Adagrad";registerClass(AdagradOptimizer);class AdamOptimizer extends Optimizer{constructor(learningRate,beta1,beta2,epsilon=null){super();this.learningRate=learningRate;this.beta1=beta1;this.beta2=beta2;this.epsilon=epsilon;this.accumulatedFirstMoment=[];this.accumulatedSecondMoment=[];tidy((()=>{this.accBeta1=scalar(beta1).variable();this.accBeta2=scalar(beta2).variable()}));if(epsilon==null){this.epsilon=ENGINE.backend.epsilon()}}applyGradients(variableGradients){const varNames=Array.isArray(variableGradients)?variableGradients.map((v=>v.name)):Object.keys(variableGradients);tidy((()=>{const oneMinusAccBeta1=sub$1(1,this.accBeta1);const oneMinusAccBeta2=sub$1(1,this.accBeta2);varNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];const trainable=false;if(this.accumulatedFirstMoment[i]==null){this.accumulatedFirstMoment[i]={originalName:`${name}/m`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}if(this.accumulatedSecondMoment[i]==null){this.accumulatedSecondMoment[i]={originalName:`${name}/v`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const firstMoment=this.accumulatedFirstMoment[i].variable;const secondMoment=this.accumulatedSecondMoment[i].variable;const newFirstMoment=add(mul(firstMoment,this.beta1),mul(gradient,1-this.beta1));const newSecondMoment=add(mul(secondMoment,this.beta2),mul(square$1(gradient),1-this.beta2));const biasCorrectedFirstMoment=div(newFirstMoment,oneMinusAccBeta1);const biasCorrectedSecondMoment=div(newSecondMoment,oneMinusAccBeta2);firstMoment.assign(newFirstMoment);secondMoment.assign(newSecondMoment);const newValue=add(mul(div(biasCorrectedFirstMoment,add(sqrt$1(biasCorrectedSecondMoment),this.epsilon)),-this.learningRate),value);value.assign(newValue)}));this.accBeta1.assign(mul(this.accBeta1,this.beta1));this.accBeta2.assign(mul(this.accBeta2,this.beta2))}));this.incrementIterations()}dispose(){this.accBeta1.dispose();this.accBeta2.dispose();if(this.accumulatedFirstMoment!=null){dispose(this.accumulatedFirstMoment.map((v=>v.variable)))}if(this.accumulatedSecondMoment!=null){dispose(this.accumulatedSecondMoment.map((v=>v.variable)))}}async getWeights(){const variables=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(variables.map((v=>({name:v.originalName,tensor:v.variable}))))}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);tidy((()=>{this.accBeta1.assign(pow$1(this.beta1,this.iterations_+1));this.accBeta2.assign(pow$1(this.beta2,this.iterations_+1))}));const variableCount=weightValues.length/2;const trainable=false;this.accumulatedFirstMoment=weightValues.slice(0,variableCount).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})));this.accumulatedSecondMoment=weightValues.slice(variableCount,variableCount*2).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(cls,config){return new cls(config["learningRate"],config["beta1"],config["beta2"],config["epsilon"])}}AdamOptimizer.className="Adam";registerClass(AdamOptimizer);class AdamaxOptimizer extends Optimizer{constructor(learningRate,beta1,beta2,epsilon=null,decay=0){super();this.learningRate=learningRate;this.beta1=beta1;this.beta2=beta2;this.epsilon=epsilon;this.decay=decay;this.accumulatedFirstMoment=[];this.accumulatedWeightedInfNorm=[];tidy((()=>{this.iteration=scalar(0).variable();this.accBeta1=scalar(beta1).variable()}));if(epsilon==null){this.epsilon=ENGINE.backend.epsilon()}}applyGradients(variableGradients){const variableNames=Array.isArray(variableGradients)?variableGradients.map((item=>item.name)):Object.keys(variableGradients);tidy((()=>{const oneMinusAccBeta1=sub$1(1,this.accBeta1);const lr=div(-this.learningRate,add(mul(this.iteration,this.decay),1));variableNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];const trainable=false;if(this.accumulatedFirstMoment[i]==null){this.accumulatedFirstMoment[i]={originalName:`${name}/m`,variable:zerosLike$1(value).variable(trainable)}}if(this.accumulatedWeightedInfNorm[i]==null){this.accumulatedWeightedInfNorm[i]={originalName:`${name}/v`,variable:zerosLike$1(value).variable(trainable)}}const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const firstMoment=this.accumulatedFirstMoment[i].variable;const weightedInfNorm=this.accumulatedWeightedInfNorm[i].variable;const newFirstMoment=add(mul(firstMoment,this.beta1),mul(gradient,1-this.beta1));const ut0=mul(weightedInfNorm,this.beta2);const ut1=abs$1(gradient);const newWeightedInfNorm=maximum$1(ut0,ut1);firstMoment.assign(newFirstMoment);weightedInfNorm.assign(newWeightedInfNorm);const newValue=add(mul(div(lr,oneMinusAccBeta1),div(newFirstMoment,add(newWeightedInfNorm,this.epsilon))),value);value.assign(newValue)}));this.iteration.assign(add(this.iteration,1));this.accBeta1.assign(mul(this.accBeta1,this.beta1))}));this.incrementIterations()}dispose(){this.accBeta1.dispose();this.iteration.dispose();if(this.accumulatedFirstMoment!=null){dispose(this.accumulatedFirstMoment.map((v=>v.variable)))}if(this.accumulatedWeightedInfNorm!=null){dispose(this.accumulatedWeightedInfNorm.map((v=>v.variable)))}}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(weightValues){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(cls,config){return new cls(config["learningRate"],config["beta1"],config["beta2"],config["epsilon"],config["decay"])}}AdamaxOptimizer.className="Adamax";registerClass(AdamaxOptimizer);class SGDOptimizer extends Optimizer{constructor(learningRate){super();this.learningRate=learningRate;this.setLearningRate(learningRate)}applyGradients(variableGradients){const varNames=Array.isArray(variableGradients)?variableGradients.map((v=>v.name)):Object.keys(variableGradients);varNames.forEach(((name,i)=>{const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const value=ENGINE.registeredVariables[name];tidy((()=>{const newValue=add(mul(this.c,gradient),value);value.assign(newValue)}))}));this.incrementIterations()}setLearningRate(learningRate){this.learningRate=learningRate;if(this.c!=null){this.c.dispose()}this.c=keep(scalar(-learningRate))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);if(weightValues.length!==0){throw new Error("SGD optimizer does not have settable weights.")}}getConfig(){return{learningRate:this.learningRate}}static fromConfig(cls,config){return new cls(config["learningRate"])}}SGDOptimizer.className="SGD";registerClass(SGDOptimizer);class MomentumOptimizer extends SGDOptimizer{constructor(learningRate,momentum,useNesterov=false){super(learningRate);this.learningRate=learningRate;this.momentum=momentum;this.useNesterov=useNesterov;this.accumulations=[];this.m=scalar(this.momentum)}applyGradients(variableGradients){const variableNames=Array.isArray(variableGradients)?variableGradients.map((item=>item.name)):Object.keys(variableGradients);variableNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];if(this.accumulations[i]==null){const trainable=false;this.accumulations[i]={originalName:`${name}/momentum`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}const accumulation=this.accumulations[i].variable;const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}tidy((()=>{let newValue;const newAccumulation=add(mul(this.m,accumulation),gradient);if(this.useNesterov){newValue=add(mul(this.c,add(gradient,mul(newAccumulation,this.m))),value)}else{newValue=add(mul(this.c,newAccumulation),value)}accumulation.assign(newAccumulation);value.assign(newValue)}))}));this.incrementIterations()}dispose(){this.m.dispose();if(this.accumulations!=null){dispose(this.accumulations.map((v=>v.variable)))}}setMomentum(momentum){this.momentum=momentum}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((v=>({name:v.originalName,tensor:v.variable}))))}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);const trainable=false;this.accumulations=weightValues.map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(cls,config){return new cls(config["learningRate"],config["momentum"],config["useNesterov"])}}MomentumOptimizer.className="Momentum";registerClass(MomentumOptimizer);class RMSPropOptimizer extends Optimizer{constructor(learningRate,decay=.9,momentum=0,epsilon=null,centered=false){super();this.learningRate=learningRate;this.decay=decay;this.momentum=momentum;this.epsilon=epsilon;this.accumulatedMeanSquares=[];this.accumulatedMoments=[];this.accumulatedMeanGrads=[];this.centered=centered;if(epsilon==null){this.epsilon=ENGINE.backend.epsilon()}if(learningRate==null){throw new Error(`learningRate for RMSPropOptimizer must be defined.`)}}applyGradients(variableGradients){const variableNames=Array.isArray(variableGradients)?variableGradients.map((item=>item.name)):Object.keys(variableGradients);variableNames.forEach(((name,i)=>{const value=ENGINE.registeredVariables[name];const trainable=false;if(this.accumulatedMeanSquares[i]==null){this.accumulatedMeanSquares[i]={originalName:`${name}/rms`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}if(this.accumulatedMoments[i]==null){this.accumulatedMoments[i]={originalName:`${name}/momentum`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}if(this.accumulatedMeanGrads[i]==null&&this.centered){this.accumulatedMeanGrads[i]={originalName:`${name}/mg`,variable:tidy((()=>zerosLike$1(value).variable(trainable)))}}const gradient=Array.isArray(variableGradients)?variableGradients[i].tensor:variableGradients[name];if(gradient==null){return}const accumulatedMeanSquare=this.accumulatedMeanSquares[i].variable;const accumulatedMoments=this.accumulatedMoments[i].variable;tidy((()=>{const newAccumulatedMeanSquare=add(mul(accumulatedMeanSquare,this.decay),mul(square$1(gradient),1-this.decay));if(this.centered){const accumulatedMeanGrad=this.accumulatedMeanGrads[i].variable;const newAccumulatedMeanGrad=add(mul(accumulatedMeanGrad,this.decay),mul(gradient,1-this.decay));const gradContribution=div(mul(gradient,this.learningRate),sqrt$1(sub$1(newAccumulatedMeanSquare,add(square$1(newAccumulatedMeanGrad),this.epsilon))));const newAccumulatedMoments=add(mul(accumulatedMoments,this.momentum),gradContribution);accumulatedMeanSquare.assign(newAccumulatedMeanSquare);accumulatedMeanGrad.assign(newAccumulatedMeanGrad);accumulatedMoments.assign(newAccumulatedMoments);const newValue=sub$1(value,newAccumulatedMoments);value.assign(newValue)}else{const newAccumulatedMeanSquare=add(mul(accumulatedMeanSquare,this.decay),mul(square$1(gradient),1-this.decay));const newAccumulatedMoments=add(mul(accumulatedMoments,this.momentum),div(mul(gradient,this.learningRate),sqrt$1(add(newAccumulatedMeanSquare,this.epsilon))));accumulatedMeanSquare.assign(newAccumulatedMeanSquare);accumulatedMoments.assign(newAccumulatedMoments);const newValue=sub$1(value,newAccumulatedMoments);value.assign(newValue)}}))}));this.incrementIterations()}dispose(){if(this.accumulatedMeanSquares!=null){dispose(this.accumulatedMeanSquares.map((v=>v.variable)))}if(this.accumulatedMeanGrads!=null&&this.centered){dispose(this.accumulatedMeanGrads.map((v=>v.variable)))}if(this.accumulatedMoments!=null){dispose(this.accumulatedMoments.map((v=>v.variable)))}}async getWeights(){const variables=[...this.accumulatedMeanSquares,...this.accumulatedMoments];if(this.centered){variables.push(...this.accumulatedMeanGrads)}return[await this.saveIterations()].concat(variables.map((v=>({name:v.originalName,tensor:v.variable}))))}async setWeights(weightValues){weightValues=await this.extractIterations(weightValues);const variableCount=this.centered?weightValues.length/3:weightValues.length/2;const trainable=false;this.accumulatedMeanSquares=weightValues.slice(0,variableCount).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})));this.accumulatedMoments=weightValues.slice(variableCount,variableCount*2).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})));if(this.centered){this.accumulatedMeanGrads=weightValues.slice(variableCount*2,variableCount*3).map((v=>({originalName:v.name,variable:v.tensor.variable(trainable)})))}}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(cls,config){return new cls(config["learningRate"],config["decay"],config["momentum"],config["epsilon"],config["centered"])}}RMSPropOptimizer.className="RMSProp";registerClass(RMSPropOptimizer);class OptimizerConstructors{static sgd(learningRate){return new SGDOptimizer(learningRate)}static momentum(learningRate,momentum,useNesterov=false){return new MomentumOptimizer(learningRate,momentum,useNesterov)}static rmsprop(learningRate,decay=.9,momentum=0,epsilon=null,centered=false){return new RMSPropOptimizer(learningRate,decay,momentum,epsilon,centered)}static adam(learningRate=.001,beta1=.9,beta2=.999,epsilon=null){return new AdamOptimizer(learningRate,beta1,beta2,epsilon)}static adadelta(learningRate=.001,rho=.95,epsilon=null){return new AdadeltaOptimizer(learningRate,rho,epsilon)}static adamax(learningRate=.002,beta1=.9,beta2=.999,epsilon=null,decay=0){return new AdamaxOptimizer(learningRate,beta1,beta2,epsilon,decay)}static adagrad(learningRate,initialAccumulatorValue=.1){return new AdagradOptimizer(learningRate,initialAccumulatorValue)}}const train={sgd:OptimizerConstructors.sgd,momentum:OptimizerConstructors.momentum,adadelta:OptimizerConstructors.adadelta,adagrad:OptimizerConstructors.adagrad,rmsprop:OptimizerConstructors.rmsprop,adamax:OptimizerConstructors.adamax,adam:OptimizerConstructors.adam};const delayCallback=(()=>{if(typeof requestAnimationFrame!=="undefined"){return requestAnimationFrame}else if(typeof setImmediate!=="undefined"){return setImmediate}return f=>f()})();function nextFrame(){return new Promise((resolve=>delayCallback((()=>resolve()))))}function assertParamsConsistent(shapes,axis){const rank=shapes[0].length;shapes.forEach(((shape,i)=>{assert(shape.length===rank,(()=>`Error in concat${rank}D: rank of tensors[${i}] must be the same `+`as the rank of the rest (${rank})`))}));assert(axis>=0&&axis<rank,(()=>`Error in concat${rank}D: axis must be between 0 and ${rank-1}.`));const firstShape=shapes[0];shapes.forEach(((shape,i)=>{for(let r=0;r<rank;r++){assert(r===axis||shape[r]===firstShape[r],(()=>`Error in concat${rank}D: Shape of tensors[${i}] (${shape}) `+`does not match the shape of the rest (${firstShape}) `+`along the non-concatenated axis ${i}.`))}}))}function computeOutShape$1(shapes,axis){const outputShape=shapes[0].slice();for(let i=1;i<shapes.length;i++){outputShape[axis]+=shapes[i][axis]}return outputShape}const PARALLELIZE_THRESHOLD=30;function computeOptimalWindowSize(inSize){if(inSize<=PARALLELIZE_THRESHOLD){return inSize}return nearestDivisor(inSize,Math.floor(Math.sqrt(inSize)))}function getImageCenter(center,imageHeight,imageWidth){const centerX=imageWidth*(typeof center==="number"?center:center[0]);const centerY=imageHeight*(typeof center==="number"?center:center[1]);return[centerX,centerY]}function getReshaped(inputShape,blockShape,prod,batchToSpace=true){let reshaped=[];if(batchToSpace){reshaped=reshaped.concat(blockShape.slice(0));reshaped.push(inputShape[0]/prod);reshaped=reshaped.concat(inputShape.slice(1))}else{reshaped=reshaped.concat(inputShape[0]);const spatialLength=blockShape.length;for(let i=0;i<spatialLength;++i){reshaped=reshaped.concat([inputShape[i+1]/blockShape[i],blockShape[i]])}reshaped=reshaped.concat(inputShape.slice(spatialLength+1))}return reshaped}function getPermuted(reshapedRank,blockShapeRank,batchToSpace=true){const permuted=[];if(batchToSpace){permuted.push(blockShapeRank);for(let i=blockShapeRank+1;i<reshapedRank;++i){if(i<=2*blockShapeRank){permuted.push(i);permuted.push(i-(blockShapeRank+1))}else{permuted.push(i)}}}else{const permutedBeforeBatch=[];const permutedAfterBatch=[];for(let i=1;i<reshapedRank;++i){if(i>=blockShapeRank*2+1||i%2===1){permutedAfterBatch.push(i)}else{permutedBeforeBatch.push(i)}}permuted.push(...permutedBeforeBatch);permuted.push(0);permuted.push(...permutedAfterBatch)}return permuted}function getReshapedPermuted(inputShape,blockShape,prod,batchToSpace=true){const reshapedPermuted=[];if(batchToSpace){reshapedPermuted.push(inputShape[0]/prod)}else{reshapedPermuted.push(inputShape[0]*prod)}for(let i=1;i<inputShape.length;++i){if(i<=blockShape.length){if(batchToSpace){reshapedPermuted.push(blockShape[i-1]*inputShape[i])}else{reshapedPermuted.push(inputShape[i]/blockShape[i-1])}}else{reshapedPermuted.push(inputShape[i])}}return reshapedPermuted}function getSliceBeginCoords(crops,blockShape){const sliceBeginCoords=[0];for(let i=0;i<blockShape;++i){sliceBeginCoords.push(crops[i][0])}return sliceBeginCoords}function getSliceSize(uncroppedShape,crops,blockShape){const sliceSize=uncroppedShape.slice(0,1);for(let i=0;i<blockShape;++i){sliceSize.push(uncroppedShape[i+1]-crops[i][0]-crops[i][1])}return sliceSize}const SELU_SCALEALPHA=1.7580993408473768;const SELU_SCALE=1.0507009873554805;const ERF_P=.3275911;const ERF_A1=.254829592;const ERF_A2=-.284496736;const ERF_A3=1.421413741;const ERF_A4=-1.453152027;const ERF_A5=1.061405429;function warn(...msg){if(!env().getBool("IS_TEST")){console.warn(...msg)}}function log$1(...msg){if(!env().getBool("IS_TEST")){console.log(...msg)}}function mergeRealAndImagArrays(real,imag){if(real.length!==imag.length){throw new Error(`Cannot merge real and imag arrays of different lengths. real:`+`${real.length}, imag: ${imag.length}.`)}const result=new Float32Array(real.length*2);for(let i=0;i<result.length;i+=2){result[i]=real[i/2];result[i+1]=imag[i/2]}return result}function splitRealAndImagArrays(complex){const real=new Float32Array(complex.length/2);const imag=new Float32Array(complex.length/2);for(let i=0;i<complex.length;i+=2){real[i/2]=complex[i];imag[i/2]=complex[i+1]}return{real:real,imag:imag}}function complexWithEvenIndex(complex){const len=Math.ceil(complex.length/4);const real=new Float32Array(len);const imag=new Float32Array(len);for(let i=0;i<complex.length;i+=4){real[Math.floor(i/4)]=complex[i];imag[Math.floor(i/4)]=complex[i+1]}return{real:real,imag:imag}}function complexWithOddIndex(complex){const len=Math.floor(complex.length/4);const real=new Float32Array(len);const imag=new Float32Array(len);for(let i=2;i<complex.length;i+=4){real[Math.floor(i/4)]=complex[i];imag[Math.floor(i/4)]=complex[i+1]}return{real:real,imag:imag}}function getComplexWithIndex(complex,index){const real=complex[index*2];const imag=complex[index*2+1];return{real:real,imag:imag}}function assignToTypedArray(data,real,imag,index){data[index*2]=real;data[index*2+1]=imag}function exponents(n,inverse){const real=new Float32Array(n/2);const imag=new Float32Array(n/2);for(let i=0;i<Math.ceil(n/2);i++){const x=(inverse?2:-2)*Math.PI*(i/n);real[i]=Math.cos(x);imag[i]=Math.sin(x)}return{real:real,imag:imag}}function exponent(k,n,inverse){const x=(inverse?2:-2)*Math.PI*(k/n);const real=Math.cos(x);const imag=Math.sin(x);return{real:real,imag:imag}}const ARROW="->";const ARROW_REGEX=/->/g;const COMMA=",";const ELLIPSIS="...";function decodeEinsumEquation(equation,numTensors){equation=equation.replace(/\s/g,"");const numArrows=(equation.length-equation.replace(ARROW_REGEX,"").length)/ARROW.length;if(numArrows<1){throw new Error("Equations without an arrow are not supported.")}else if(numArrows>1){throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`)}const[inputString,outputString]=equation.split(ARROW);assert(inputString.indexOf(ELLIPSIS)===-1,(()=>`The ellipsis notation ("${ELLIPSIS}") is not supported yet.`));const inputTerms=inputString.split(COMMA);const numInputs=inputTerms.length;if(numTensors!==numInputs){throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`)}if(numInputs>2){throw new Error("Support for more than 2 input tensors is not implemented yet.")}const allDims=[];for(let i=0;i<outputString.length;++i){const dimName=outputString[i];if(!inputTerms.some((inputTerm=>inputTerm.indexOf(dimName)!==-1))){throw new Error(`Output subscripts contain the label ${dimName} `+`not present in the input subscripts.`)}if(allDims.indexOf(dimName)===-1){allDims.push(dimName)}}for(let i=0;i<inputString.length;++i){const dimName=inputString[i];if(allDims.indexOf(dimName)===-1&&dimName!==COMMA){allDims.push(dimName)}}const idDims=new Array(inputTerms.length);for(let i=0;i<numInputs;++i){if(new Set(inputTerms[i].split("")).size!==inputTerms[i].length){throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. `+`Support for duplicate axes in input is not implemented yet.`)}idDims[i]=[];for(let j=0;j<inputTerms[i].length;++j){idDims[i].push(allDims.indexOf(inputTerms[i][j]))}}const numDims=allDims.length;const numOutDims=outputString.length;const summedDims=[];for(let i=numOutDims;i<numDims;++i){summedDims.push(i)}return{allDims:allDims,summedDims:summedDims,idDims:idDims}}function getEinsumPermutation(nDims,idDims){let permutationIndices=new Array(nDims);permutationIndices.fill(-1);for(let i=0;i<idDims.length;++i){permutationIndices[idDims[i]]=i}const expandDims=[];for(let i=0;i<nDims;++i){if(permutationIndices[i]===-1){expandDims.push(i)}}permutationIndices=permutationIndices.filter((d=>d!==-1));return{permutationIndices:permutationIndices,expandDims:expandDims}}function checkEinsumDimSizes(nDims,idDims,tensors){const dimSizes=new Array(nDims);for(let i=0;i<tensors.length;++i){const shape=tensors[i].shape;for(let j=0;j<idDims[i].length;++j){if(dimSizes[idDims[i][j]]===undefined){dimSizes[idDims[i][j]]=shape[j]}else{assert(dimSizes[idDims[i][j]]===shape[j],(()=>`Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} `+`of input shaped ${JSON.stringify(shape)}, `+`but got dimension ${shape[j]}`))}}}}function getEinsumComputePath(summedDims,idDims){const path=summedDims;const steps=[];let nSteps=0;if(summedDims.length===0){path.push(-1)}nSteps=summedDims.length+1;for(let i=0;i<nSteps;++i){steps.push([])}const computedTermIndices=[];for(let i=0;i<path.length;++i){const summedDim=path[i];const termIndices=findTermsWithDim(idDims,summedDim);for(const termIndex of termIndices){if(computedTermIndices.indexOf(termIndex)===-1){steps[i].push(termIndex);computedTermIndices.push(termIndex)}}}return{path:path,steps:steps}}function isIdentityPermutation(perm){return perm.every(((dim,index)=>dim===index))}function findTermsWithDim(idDims,dim){const termIndices=[];for(let i=0;i<idDims.length;++i){if(idDims[i].length===0||idDims[i].indexOf(dim)!==-1||dim===-1){termIndices.push(i)}}return termIndices}function prepareSplitSize(x,numOrSizeSplits,axis=0){let splitSizes=[];if(typeof numOrSizeSplits==="number"){assert(x.shape[axis]%numOrSizeSplits===0,(()=>"Number of splits must evenly divide the axis."));splitSizes=new Array(numOrSizeSplits).fill(x.shape[axis]/numOrSizeSplits)}else{const numOfNegs=numOrSizeSplits.reduce(((count,value)=>{if(value===-1){count+=1}return count}),0);assert(numOfNegs<=1,(()=>"There should be only one negative value in split array."));const negIndex=numOrSizeSplits.indexOf(-1);if(negIndex!==-1){const total=numOrSizeSplits.reduce(((a,b)=>b>0?a+b:a));numOrSizeSplits[negIndex]=x.shape[axis]-total}assert(x.shape[axis]===numOrSizeSplits.reduce(((a,b)=>a+b)),(()=>"The sum of sizes must match the size of the axis dimension."));splitSizes=numOrSizeSplits}return splitSizes}function segOpComputeOptimalWindowSize(inSize,numSegments){let done=false;let res;if(inSize<=PARALLELIZE_THRESHOLD){res=inSize;done=true}else{res=nearestDivisor(inSize,Math.floor(Math.sqrt(inSize)))}while(!done){if(res>numSegments||res===inSize){done=true}else{res=nearestDivisor(inSize,res+1)}}return res}function computeOutShape(aShape,axis,numSegments){const outShape=[];const rank=aShape.length;for(let dim=0;dim<rank;dim++){if(dim!==axis){outShape.push(aShape[dim])}else{outShape.push(numSegments)}}return outShape}function collectGatherOpShapeInfo(x,indices,axis,batchDims){const indicesRank=indices.shape.length;const xRank=x.shape.length;if(batchDims!==0){if(batchDims<-indicesRank||batchDims>indicesRank){throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`)}}if(batchDims<0){batchDims+=indicesRank}if(batchDims>xRank){throw new Error(`batchDims (${batchDims}) must be less than rank(x) (\n    ${xRank}).`)}if(axis<batchDims){throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`)}for(let i=0;i<batchDims;++i){if(x.shape[i]!==indices.shape[i]){throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`)}}const dimSize=x.shape[axis];const outputShape=[];let batchSize=1;let outerSize=1;let sliceSize=1;for(let i=0;i<batchDims;++i){outputShape.push(x.shape[i]);batchSize*=x.shape[i]}for(let i=batchDims;i<axis;i++){outputShape.push(x.shape[i]);outerSize*=x.shape[i]}for(let i=batchDims;i<indicesRank;i++){outputShape.push(indices.shape[i])}for(let i=axis+1;i<xRank;i++){outputShape.push(x.shape[i]);sliceSize*=x.shape[i]}return{batchSize:batchSize,sliceSize:sliceSize,outerSize:outerSize,dimSize:dimSize,outputShape:outputShape}}var segment_util=Object.freeze({__proto__:null,segOpComputeOptimalWindowSize:segOpComputeOptimalWindowSize,computeOutShape:computeOutShape,collectGatherOpShapeInfo:collectGatherOpShapeInfo});function fromUint8ToStringArray(vals){try{return vals.map((val=>decodeString(val)))}catch(err){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`)}}function fromStringArrayToUint8(strings){return strings.map((s=>encodeString(s)))}var backend_util=Object.freeze({__proto__:null,slice_util:slice_util,segment_util:segment_util,fromUint8ToStringArray:fromUint8ToStringArray,fromStringArrayToUint8:fromStringArrayToUint8,upcastType:upcastType,axesAreInnerMostDims:axesAreInnerMostDims,combineLocations:combineLocations,computeOutAndReduceShapes:computeOutAndReduceShapes,expandShapeToKeepDim:expandShapeToKeepDim,assertAxesAreInnerMostDims:assertAxesAreInnerMostDims,getAxesPermutation:getAxesPermutation,getUndoAxesPermutation:getUndoAxesPermutation,getInnerMostAxes:getInnerMostAxes,getBroadcastDims:getBroadcastDims$1,getReductionAxes:getReductionAxes,assertAndGetBroadcastShape:assertAndGetBroadcastShape,assertParamsConsistent:assertParamsConsistent,computeOutShape:computeOutShape$1,computeDilation2DInfo:computeDilation2DInfo,computePool2DInfo:computePool2DInfo,computePool3DInfo:computePool3DInfo,computeConv2DInfo:computeConv2DInfo,computeConv3DInfo:computeConv3DInfo,computeDefaultPad:computeDefaultPad,tupleValuesAreOne:tupleValuesAreOne,eitherStridesOrDilationsAreOne:eitherStridesOrDilationsAreOne,convertConv2DDataFormat:convertConv2DDataFormat,getFusedDyActivation:getFusedDyActivation,getFusedBiasGradient:getFusedBiasGradient,applyActivation:applyActivation,shouldFuse:shouldFuse,PARALLELIZE_THRESHOLD:PARALLELIZE_THRESHOLD,computeOptimalWindowSize:computeOptimalWindowSize,getImageCenter:getImageCenter,getReshaped:getReshaped,getPermuted:getPermuted,getReshapedPermuted:getReshapedPermuted,getSliceBeginCoords:getSliceBeginCoords,getSliceSize:getSliceSize,prepareAndValidate:prepareAndValidate,validateUpdateShape:validateUpdateShape,validateInput:validateInput$1,calculateShapes:calculateShapes,SELU_SCALEALPHA:SELU_SCALEALPHA,SELU_SCALE:SELU_SCALE,ERF_P:ERF_P,ERF_A1:ERF_A1,ERF_A2:ERF_A2,ERF_A3:ERF_A3,ERF_A4:ERF_A4,ERF_A5:ERF_A5,warn:warn,log:log$1,mergeRealAndImagArrays:mergeRealAndImagArrays,splitRealAndImagArrays:splitRealAndImagArrays,complexWithEvenIndex:complexWithEvenIndex,complexWithOddIndex:complexWithOddIndex,getComplexWithIndex:getComplexWithIndex,assignToTypedArray:assignToTypedArray,exponents:exponents,exponent:exponent,decodeEinsumEquation:decodeEinsumEquation,getEinsumPermutation:getEinsumPermutation,checkEinsumDimSizes:checkEinsumDimSizes,getEinsumComputePath:getEinsumComputePath,isIdentityPermutation:isIdentityPermutation,prepareSplitSize:prepareSplitSize});var kernel_impls=Object.freeze({__proto__:null,nonMaxSuppressionV3Impl:nonMaxSuppressionV3Impl$1,nonMaxSuppressionV4Impl:nonMaxSuppressionV4Impl$1,nonMaxSuppressionV5Impl:nonMaxSuppressionV5Impl$1,whereImpl:whereImpl$1});var tf=Object.freeze({__proto__:null,AdadeltaOptimizer:AdadeltaOptimizer,AdagradOptimizer:AdagradOptimizer,AdamOptimizer:AdamOptimizer,AdamaxOptimizer:AdamaxOptimizer,MomentumOptimizer:MomentumOptimizer,Optimizer:Optimizer,RMSPropOptimizer:RMSPropOptimizer,SGDOptimizer:SGDOptimizer,Tensor:Tensor,TensorBuffer:TensorBuffer,Variable:Variable,get Rank(){return Rank},sumOutType:sumOutType,upcastType:upcastType,get Reduction(){return Reduction},customGrad:customGrad,grad:grad,grads:grads,valueAndGrad:valueAndGrad,valueAndGrads:valueAndGrads,variableGrads:variableGrads,Environment:Environment,env:env,get ENV(){return ENV$2},nextFrame:nextFrame,KernelBackend:KernelBackend,DataStorage:DataStorage,abs:abs$1,acos:acos$1,acosh:acosh$1,add:add,addN:addN$1,all:all$1,any:any$1,argMax:argMax$1,argMin:argMin$1,asin:asin$1,asinh:asinh$1,atan:atan$1,atan2:atan2$1,atanh:atanh$1,avgPool:avgPool$1,avgPool3d:avgPool3d,basicLSTMCell:basicLSTMCell,batchToSpaceND:batchToSpaceND$1,batchNorm:batchNorm$1,batchNorm2d:batchNorm2d,batchNorm3d:batchNorm3d,batchNorm4d:batchNorm4d,bincount:bincount$1,broadcastTo:broadcastTo,buffer:buffer,cast:cast$1,ceil:ceil$1,clipByValue:clipByValue$1,clone:clone,complex:complex$1,concat:concat$1,concat1d:concat1d,concat2d:concat2d,concat3d:concat3d,concat4d:concat4d,conv1d:conv1d,conv2d:conv2d$2,conv2dTranspose:conv2dTranspose,conv3d:conv3d,conv3dTranspose:conv3dTranspose,cos:cos$1,cosh:cosh$1,cumsum:cumsum$1,denseBincount:denseBincount$1,depthToSpace:depthToSpace$1,depthwiseConv2d:depthwiseConv2d$1,diag:diag$1,dilation2d:dilation2d,div:div,divNoNan:divNoNan,dot:dot,einsum:einsum$1,elu:elu$1,equal:equal$1,erf:erf$1,exp:exp$1,expandDims:expandDims$1,expm1:expm1$1,eye:eye,fill:fill$1,floor:floor$1,floorDiv:floorDiv$1,gather:gather,greater:greater$1,greaterEqual:greaterEqual$1,imag:imag$1,isFinite:isFinite$2,isInf:isInf$1,isNaN:isNaN$2,leakyRelu:leakyRelu$1,less:less$1,lessEqual:lessEqual$1,linspace:linspace,localResponseNormalization:localResponseNormalization,log:log$2,log1p:log1p$1,logSigmoid:logSigmoid,logSoftmax:logSoftmax,logSumExp:logSumExp,logicalAnd:logicalAnd$1,logicalNot:logicalNot$1,logicalOr:logicalOr$1,logicalXor:logicalXor,matMul:matMul$1,max:max$1,maxPool:maxPool$1,maxPool3d:maxPool3d$1,maxPoolWithArgmax:maxPoolWithArgmax,maximum:maximum$1,mean:mean,meshgrid:meshgrid,min:min$1,minimum:minimum$1,mirrorPad:mirrorPad,mod:mod$1,moments:moments,mul:mul,multiRNNCell:multiRNNCell,multinomial:multinomial$1,neg:neg$1,notEqual:notEqual$1,oneHot:oneHot$1,ones:ones,onesLike:onesLike$1,outerProduct:outerProduct,pad:pad,pad1d:pad1d,pad2d:pad2d,pad3d:pad3d,pad4d:pad4d,pool:pool,pow:pow$1,prelu:prelu$1,print:print,prod:prod$1,rand:rand,randomGamma:randomGamma,randomNormal:randomNormal,randomUniform:randomUniform,range:range$1,real:real$1,reciprocal:reciprocal$1,relu:relu$1,relu6:relu6$1,reshape:reshape$1,reverse:reverse$1,reverse1d:reverse1d,reverse2d:reverse2d,reverse3d:reverse3d,reverse4d:reverse4d,round:round$1,rsqrt:rsqrt$1,scalar:scalar,selu:selu$1,separableConv2d:separableConv2d,setdiff1dAsync:setdiff1dAsync,sigmoid:sigmoid$1,sign:sign$1,sin:sin$1,sinh:sinh$1,slice:slice$1,slice1d:slice1d,slice2d:slice2d,slice3d:slice3d,slice4d:slice4d,softmax:softmax$1,softplus:softplus$1,spaceToBatchND:spaceToBatchND$1,fft:fft$1,ifft:ifft$1,irfft:irfft,rfft:rfft,split:split$1,sqrt:sqrt$1,square:square$1,squaredDifference:squaredDifference$1,squeeze:squeeze,stack:stack,step:step$1,stridedSlice:stridedSlice$1,sub:sub$1,sum:sum$1,tan:tan$1,tanh:tanh$1,tensor:tensor,tensor1d:tensor1d,tensor2d:tensor2d,tensor3d:tensor3d,tensor4d:tensor4d,tensor5d:tensor5d,tensor6d:tensor6d,tile:tile$1,topk:topk,truncatedNormal:truncatedNormal,unique:unique$1,unsortedSegmentSum:unsortedSegmentSum$1,unstack:unstack,variable:variable,where:where,whereAsync:whereAsync,zeros:zeros,zerosLike:zerosLike$1,op:op,OP_SCOPE_SUFFIX:OP_SCOPE_SUFFIX,booleanMaskAsync:booleanMaskAsync,transpose:transpose$1,norm:norm,movingAverage:movingAverage,scatterND:scatterND,sparseToDense:sparseToDense$1,gatherND:gatherND,dropout:dropout,enclosingPowerOfTwo:enclosingPowerOfTwo,cosineWindow:cosineWindow,inTopKAsync:inTopKAsync,image:image$1,linalg:linalg,losses:losses,spectral:spectral$1,fused:fused_ops,signal:signal,sparse:sparse,train:train,enableProdMode:enableProdMode,enableDebugMode:enableDebugMode,disableDeprecationWarnings:disableDeprecationWarnings,deprecationWarn:deprecationWarn,disposeVariables:disposeVariables,engine:engine,memory:memory,profile:profile,tidy:tidy,dispose:dispose,keep:keep,time:time,setBackend:setBackend,ready:ready,getBackend:getBackend,removeBackend:removeBackend,findBackend:findBackend,findBackendFactory:findBackendFactory,registerBackend:registerBackend,backend:backend,setPlatform:setPlatform,getKernel:getKernel,getGradient:getGradient,getKernelsForBackend:getKernelsForBackend,registerKernel:registerKernel,registerGradient:registerGradient,unregisterKernel:unregisterKernel,unregisterGradient:unregisterGradient,copyRegisteredKernels:copyRegisteredKernels,Abs:Abs,Acos:Acos,Acosh:Acosh,Add:Add,AddN:AddN,All:All,Any:Any,ArgMax:ArgMax,ArgMin:ArgMin,Asin:Asin,Asinh:Asinh,Atan:Atan,Atanh:Atanh,Atan2:Atan2,AvgPool:AvgPool,AvgPoolGrad:AvgPoolGrad,AvgPool3D:AvgPool3D,AvgPool3DGrad:AvgPool3DGrad,BatchMatMul:BatchMatMul,BatchToSpaceND:BatchToSpaceND,Bincount:Bincount,BroadcastTo:BroadcastTo,Cast:Cast,Ceil:Ceil,ClipByValue:ClipByValue,Complex:Complex,ComplexAbs:ComplexAbs,Concat:Concat,Conv2D:Conv2D,Conv2DBackpropFilter:Conv2DBackpropFilter,Conv2DBackpropInput:Conv2DBackpropInput,Conv3D:Conv3D,Conv3DBackpropFilterV2:Conv3DBackpropFilterV2,Conv3DBackpropInputV2:Conv3DBackpropInputV2,Cos:Cos,Cosh:Cosh,Cumsum:Cumsum,CropAndResize:CropAndResize,DenseBincount:DenseBincount,DepthToSpace:DepthToSpace,DepthwiseConv2dNative:DepthwiseConv2dNative,DepthwiseConv2dNativeBackpropFilter:DepthwiseConv2dNativeBackpropFilter,DepthwiseConv2dNativeBackpropInput:DepthwiseConv2dNativeBackpropInput,Diag:Diag,Dilation2D:Dilation2D,Dilation2DBackpropInput:Dilation2DBackpropInput,Dilation2DBackpropFilter:Dilation2DBackpropFilter,RealDiv:RealDiv,Einsum:Einsum,Elu:Elu,EluGrad:EluGrad,Erf:Erf,Equal:Equal,Exp:Exp,ExpandDims:ExpandDims,Expm1:Expm1,FFT:FFT,Fill:Fill,FlipLeftRight:FlipLeftRight,Floor:Floor,FloorDiv:FloorDiv,FusedBatchNorm:FusedBatchNorm,GatherV2:GatherV2,GatherNd:GatherNd,Greater:Greater,GreaterEqual:GreaterEqual,Identity:Identity,IFFT:IFFT,Imag:Imag,IsFinite:IsFinite,IsInf:IsInf,IsNan:IsNan,LeakyRelu:LeakyRelu,Less:Less,LessEqual:LessEqual,LinSpace:LinSpace,Log:Log,Log1p:Log1p,LogicalAnd:LogicalAnd,LogicalNot:LogicalNot,LogicalOr:LogicalOr,LogSoftmax:LogSoftmax,LRN:LRN,LRNGrad:LRNGrad,Max:Max,Maximum:Maximum,MaxPool:MaxPool,MaxPoolGrad:MaxPoolGrad,MaxPool3D:MaxPool3D,MaxPool3DGrad:MaxPool3DGrad,MaxPoolWithArgmax:MaxPoolWithArgmax,Mean:Mean,Min:Min,Minimum:Minimum,MirrorPad:MirrorPad,Mod:Mod,Multinomial:Multinomial,Multiply:Multiply,Neg:Neg,NotEqual:NotEqual,NonMaxSuppressionV3:NonMaxSuppressionV3,NonMaxSuppressionV4:NonMaxSuppressionV4,NonMaxSuppressionV5:NonMaxSuppressionV5,OnesLike:OnesLike,OneHot:OneHot,Pack:Pack,PadV2:PadV2,Pool:Pool,Pow:Pow,Prelu:Prelu,Prod:Prod,Range:Range,Real:Real,Reciprocal:Reciprocal,Relu:Relu,Reshape:Reshape,ResizeNearestNeighbor:ResizeNearestNeighbor,ResizeNearestNeighborGrad:ResizeNearestNeighborGrad,ResizeBilinear:ResizeBilinear,ResizeBilinearGrad:ResizeBilinearGrad,Relu6:Relu6,Reverse:Reverse,Round:Round,Rsqrt:Rsqrt,ScatterNd:ScatterNd,Select:Select,Selu:Selu,Slice:Slice,Sin:Sin,Sinh:Sinh,Sign:Sign,Sigmoid:Sigmoid,Softplus:Softplus,Sqrt:Sqrt,Sum:Sum,SpaceToBatchND:SpaceToBatchND,SplitV:SplitV,Softmax:Softmax,SparseFillEmptyRows:SparseFillEmptyRows,SparseReshape:SparseReshape,SparseToDense:SparseToDense,SquaredDifference:SquaredDifference,Square:Square,StridedSlice:StridedSlice,Sub:Sub,Tan:Tan,Tanh:Tanh,Tile:Tile,TopK:TopK,Transform:Transform,Transpose:Transpose,Unique:Unique,Unpack:Unpack,UnsortedSegmentSum:UnsortedSegmentSum,ZerosLike:ZerosLike,Step:Step,FromPixels:FromPixels,RotateWithOffset:RotateWithOffset,_FusedMatMul:_FusedMatMul,FusedConv2D:FusedConv2D,FusedDepthwiseConv2D:FusedDepthwiseConv2D,version_core:version$1,browser:browser,io:io,math:math,serialization:serialization,test_util:test_util,util:util,backend_util:backend_util,tensor_util:tensor_util,slice_util:slice_util,gather_util:gather_nd_util,scatter_util:scatter_nd_util,device_util:device_util,kernel_impls:kernel_impls});var DataType;(function(DataType){DataType[DataType["DT_INVALID"]=0]="DT_INVALID";DataType[DataType["DT_FLOAT"]=1]="DT_FLOAT";DataType[DataType["DT_DOUBLE"]=2]="DT_DOUBLE";DataType[DataType["DT_INT32"]=3]="DT_INT32";DataType[DataType["DT_UINT8"]=4]="DT_UINT8";DataType[DataType["DT_INT16"]=5]="DT_INT16";DataType[DataType["DT_INT8"]=6]="DT_INT8";DataType[DataType["DT_STRING"]=7]="DT_STRING";DataType[DataType["DT_COMPLEX64"]=8]="DT_COMPLEX64";DataType[DataType["DT_INT64"]=9]="DT_INT64";DataType[DataType["DT_BOOL"]=10]="DT_BOOL";DataType[DataType["DT_QINT8"]=11]="DT_QINT8";DataType[DataType["DT_QUINT8"]=12]="DT_QUINT8";DataType[DataType["DT_QINT32"]=13]="DT_QINT32";DataType[DataType["DT_BFLOAT16"]=14]="DT_BFLOAT16";DataType[DataType["DT_FLOAT_REF"]=101]="DT_FLOAT_REF";DataType[DataType["DT_DOUBLE_REF"]=102]="DT_DOUBLE_REF";DataType[DataType["DT_INT32_REF"]=103]="DT_INT32_REF";DataType[DataType["DT_UINT8_REF"]=104]="DT_UINT8_REF";DataType[DataType["DT_INT16_REF"]=105]="DT_INT16_REF";DataType[DataType["DT_INT8_REF"]=106]="DT_INT8_REF";DataType[DataType["DT_STRING_REF"]=107]="DT_STRING_REF";DataType[DataType["DT_COMPLEX64_REF"]=108]="DT_COMPLEX64_REF";DataType[DataType["DT_INT64_REF"]=109]="DT_INT64_REF";DataType[DataType["DT_BOOL_REF"]=110]="DT_BOOL_REF";DataType[DataType["DT_QINT8_REF"]=111]="DT_QINT8_REF";DataType[DataType["DT_QUINT8_REF"]=112]="DT_QUINT8_REF";DataType[DataType["DT_QINT32_REF"]=113]="DT_QINT32_REF";DataType[DataType["DT_BFLOAT16_REF"]=114]="DT_BFLOAT16_REF"})(DataType||(DataType={}));var SaverDef;(function(SaverDef){(function(CheckpointFormatVersion){CheckpointFormatVersion[CheckpointFormatVersion["LEGACY"]=0]="LEGACY";CheckpointFormatVersion[CheckpointFormatVersion["V1"]=1]="V1";CheckpointFormatVersion[CheckpointFormatVersion["V2"]=2]="V2"})(SaverDef.CheckpointFormatVersion||(SaverDef.CheckpointFormatVersion={}))})(SaverDef||(SaverDef={}));const CUSTOM_OPS={};function getRegisteredOp(name){return CUSTOM_OPS[name]}function getParamValue(paramName,node,tensorMap,context,resourceManager){const inputParam=node.inputParams[paramName];if(inputParam&&inputParam.inputIndexStart!==undefined){const start=inputParam.inputIndexStart;const end=inputParam.inputIndexEnd===0?undefined:inputParam.inputIndexEnd===undefined?start+1:inputParam.inputIndexEnd;if(inputParam.type==="tensor"){return getTensor(node.inputNames[inputParam.inputIndexStart],tensorMap,context,resourceManager)}if(inputParam.type==="tensors"){const inputs=node.inputNames.slice(start,end);return inputs.map((name=>getTensor(name,tensorMap,context,resourceManager)))}const tensor=getTensor(node.inputNames.slice(start)[0],tensorMap,context,resourceManager);const data=tensor.dataSync();return inputParam.type==="number"?data[0]:toNestedArray(tensor.shape,data)}const attrParam=node.attrParams[paramName];return attrParam&&attrParam.value}function getTensor(name,tensorsMap,context,resourceManager){const[nodeName,index]=parseNodeName(name);if(resourceManager!=null){const tensor=resourceManager.getHashTableHandleByName(nodeName);if(tensor!=null){return tensor}}const contextId=context.currentContextIds.find((contextId=>!!tensorsMap[getNodeNameWithContextId(nodeName,contextId)]));return contextId!==undefined?tensorsMap[getNodeNameWithContextId(nodeName,contextId)][index]:undefined}function getTensorsForCurrentContenxt(name,tensorsMap,context){return tensorsMap[getNodeNameWithContextId(name,context.currentContextId)]}function getNodeNameAndIndex(inputName,context){const[nodeName,index]=parseNodeName(inputName);return[getNodeNameWithContextId(nodeName,context&&context.currentContextId),index]}function getNodeNameWithContextId(name,contextId){return!!contextId?`${name}-${contextId}`:name}function parseNodeName(name){const parts=name.split(":");if(parts.length===1){return[name,0]}const nodeName=parts[0];return[nodeName,Number(parts[parts.length-1])]}function getPadding(node,tensorMap,context){let pad=getParamValue("pad",node,tensorMap,context);if(pad==="explicit"){pad=getParamValue("explicitPaddings",node,tensorMap,context);const explicitPadding=[[0,0],[0,0],[0,0],[0,0]];for(let i=0;i<4;i++){explicitPadding[i][0]=pad[i*2];explicitPadding[i][1]=pad[i*2+1]}return explicitPadding}return pad}function cloneTensor(tensor){return tensor.kept?tensor:clone(tensor)}const json$g=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]}];var arithmetic=Object.freeze({__proto__:null,json:json$g});const json$f=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"clipValueMin",type:"number"},{start:2,name:"clipValueMax",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:true}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:true}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:true},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"IsNan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]}];var basicMath=Object.freeze({__proto__:null,json:json$f});const json$e=[{tfOpName:"EmptyTensorList",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"maxNumElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:true}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]}];var control=Object.freeze({__proto__:null,json:json$e});const json$d=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[],notSupported:true},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:true},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number"}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]",notSupported:true}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}];var convolution=Object.freeze({__proto__:null,json:json$d});const json$c=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:true},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:true},{tfName:"T",name:"T",type:"number",notSupported:true}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:true},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:true}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}];var creation=Object.freeze({__proto__:null,json:json$c});const json$b=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:true},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]}];var dynamic=Object.freeze({__proto__:null,json:json$b});const json$a=[{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}];var evaluation=Object.freeze({__proto__:null,json:json$a});const json$9=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:true},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}];var graph=Object.freeze({__proto__:null,json:json$9});const json$8=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:true},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:true}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:true},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:true}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:true},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:true}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:true},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:true}]},{tfOpName:"LookupTableSize",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]},{tfOpName:"LookupTableSizeV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]}];var hashTable=Object.freeze({__proto__:null,json:json$8});const json$7=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]}];var image=Object.freeze({__proto__:null,json:json$7});const json$6=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]}];var logical=Object.freeze({__proto__:null,json:json$6});const json$5=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:false},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:false},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:false},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:false},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:false},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:false},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:false},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:false},{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:true}]},{tfOpName:"Einsum",category:"matrices",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"equation",name:"equation",type:"string"},{tfName:"N",name:"n",type:"number",defaultValue:2},{tfName:"T",name:"dtype",type:"dtype"}]}];var matrices=Object.freeze({__proto__:null,json:json$5});const json$4=[{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:true}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:true,notSupported:true}]}];var normalization=Object.freeze({__proto__:null,json:json$4});const json$3=[{tfOpName:"Bincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}]},{tfOpName:"DenseBincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}],attrs:[{tfName:"binary_output",name:"binaryOutput",type:"bool"}]},{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}];var reduction=Object.freeze({__proto__:null,json:json$3});const json$2=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}],attrs:[{tfName:"batch_dims",name:"batchDims",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:true}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool[]"}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:true}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:false,notSupported:true}]}];var sliceJoin=Object.freeze({__proto__:null,json:json$2});const json$1=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:true}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:true}]}];var spectral=Object.freeze({__proto__:null,json:json$1});const json=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:true},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]}];var transformation=Object.freeze({__proto__:null,json:json});class OperationMapper{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const ops=[arithmetic,basicMath,control,convolution,creation,dynamic,evaluation,logical,image,graph,matrices,normalization,reduction,sliceJoin,spectral,transformation,hashTable];const mappersJson=[].concat(...ops.map((op=>op.json)));this.opMappers=mappersJson.reduce(((map,mapper)=>{map[mapper.tfOpName]=mapper;return map}),{})}transformGraph(graph,signature={}){const tfNodes=graph.node;const placeholders=[];const weights=[];const initNodes=[];const nodes=tfNodes.reduce(((map,node)=>{map[node.name]=this.mapNode(node);if(node.op.startsWith("Placeholder")){placeholders.push(map[node.name])}else if(node.op==="Const"){weights.push(map[node.name])}else if(node.input==null||node.input.length===0){initNodes.push(map[node.name])}return map}),{});let inputs=[];const outputs=[];let inputNodeNameToKey={};let outputNodeNameToKey={};if(signature!=null){inputNodeNameToKey=this.mapSignatureEntries(signature.inputs);outputNodeNameToKey=this.mapSignatureEntries(signature.outputs)}const allNodes=Object.keys(nodes);allNodes.forEach((key=>{const node=nodes[key];node.inputNames.forEach((name=>{const[nodeName]=getNodeNameAndIndex(name);node.inputs.push(nodes[nodeName]);nodes[nodeName].children.push(node)}))}));if(Object.keys(outputNodeNameToKey).length===0){allNodes.forEach((key=>{const node=nodes[key];if(node.children.length===0){outputs.push(node)}}))}else{Object.keys(outputNodeNameToKey).forEach((name=>{const[nodeName]=getNodeNameAndIndex(name);const node=nodes[nodeName];if(node!=null){node.signatureKey=outputNodeNameToKey[name];outputs.push(node)}}))}if(Object.keys(inputNodeNameToKey).length>0){Object.keys(inputNodeNameToKey).forEach((name=>{const[nodeName]=getNodeNameAndIndex(name);const node=nodes[nodeName];if(node){node.signatureKey=inputNodeNameToKey[name];inputs.push(node)}}))}else{inputs=placeholders}let functions={};if(graph.library!=null&&graph.library.function!=null){functions=graph.library.function.reduce(((functions,func)=>{functions[func.signature.name]=this.mapFunction(func);return functions}),{})}const result={nodes:nodes,inputs:inputs,outputs:outputs,weights:weights,placeholders:placeholders,signature:signature,functions:functions};if(initNodes.length>0){result.initNodes=initNodes}return result}mapSignatureEntries(entries){return Object.keys(entries||{}).reduce(((prev,curr)=>{prev[entries[curr].name]=curr;return prev}),{})}mapNode(node){const mapper=getRegisteredOp(node.op)||this.opMappers[node.op]||{};if(node.attr==null){node.attr={}}const newNode={name:node.name,op:node.op,category:mapper.category,inputNames:(node.input||[]).map((input=>input.startsWith("^")?input.substr(1):input)),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:node.attr};if(mapper.inputs!=null){newNode.inputParams=mapper.inputs.reduce(((map,param)=>{map[param.name]={type:param.type,inputIndexStart:param.start,inputIndexEnd:param.end};return map}),{})}if(mapper.attrs!=null){newNode.attrParams=mapper.attrs.reduce(((map,param)=>{const type=param.type;let value=undefined;switch(param.type){case"string":value=getStringParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getStringParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"string[]":value=getStringArrayParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getStringArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"number":value=getNumberParam(node.attr,param.tfName,param.defaultValue||0);if(value===undefined&&!!param.tfDeprecatedName){value=getNumberParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"number[]":value=getNumericArrayParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getNumericArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"bool":value=getBoolParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getBoolParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"bool[]":value=getBoolArrayParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getBoolArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"shape":value=getTensorShapeParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getTensorShapeParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"shape[]":value=getTensorShapeArrayParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getTensorShapeArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"dtype":value=getDtypeParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getDtypeParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"dtype[]":value=getDtypeArrayParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getDtypeArrayParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"func":value=getFuncParam(node.attr,param.tfName,param.defaultValue);if(value===undefined&&!!param.tfDeprecatedName){value=getFuncParam(node.attr,param.tfDeprecatedName,param.defaultValue)}break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${param.type} for op: ${node.op}`)}map[param.name]={value:value,type:type};return map}),{})}return newNode}mapFunction(functionDef){const tfNodes=functionDef.nodeDef;const placeholders=[];const weights=[];let nodes={};if(tfNodes!=null){nodes=tfNodes.reduce(((map,node)=>{map[node.name]=this.mapNode(node);if(node.op==="Const"){weights.push(map[node.name])}return map}),{})}const inputs=[];const outputs=[];functionDef.signature.inputArg.forEach((arg=>{const[nodeName]=getNodeNameAndIndex(arg.name);const node={name:nodeName,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:parseDtypeParam(arg.type),type:"dtype"}},children:[]};node.signatureKey=arg.name;inputs.push(node);nodes[nodeName]=node}));const allNodes=Object.keys(nodes);allNodes.forEach((key=>{const node=nodes[key];node.inputNames.forEach((name=>{const[nodeName]=getNodeNameAndIndex(name);node.inputs.push(nodes[nodeName]);nodes[nodeName].children.push(node)}))}));const returnNodeMap=functionDef.ret;functionDef.signature.outputArg.forEach((output=>{const[nodeName,index]=getNodeNameAndIndex(returnNodeMap[output.name]);const node=nodes[nodeName];if(node!=null){node.defaultOutput=index;outputs.push(node)}}));const signature=this.mapArgsToSignature(functionDef);return{nodes:nodes,inputs:inputs,outputs:outputs,weights:weights,placeholders:placeholders,signature:signature}}mapArgsToSignature(functionDef){return{methodName:functionDef.signature.name,inputs:functionDef.signature.inputArg.reduce(((map,arg)=>{map[arg.name]=this.mapArgToTensorInfo(arg);return map}),{}),outputs:functionDef.signature.outputArg.reduce(((map,arg)=>{map[arg.name]=this.mapArgToTensorInfo(arg,functionDef.ret);return map}),{})}}mapArgToTensorInfo(arg,nameMap){let name=arg.name;if(nameMap!=null){name=nameMap[name]}return{name:name,dtype:arg.type}}}function decodeBase64(text){const global=env().global;if(typeof global.atob!=="undefined"){return global.atob(text)}else if(typeof Buffer!=="undefined"){return new Buffer(text,"base64").toString()}else{throw new Error("Unable to decode base64 in this environment. "+"Missing built-in atob() or Buffer()")}}function parseStringParam(s,keepCase){const value=Array.isArray(s)?String.fromCharCode.apply(null,s):decodeBase64(s);return keepCase?value:value.toLowerCase()}function getStringParam(attrs,name,def,keepCase=false){const param=attrs[name];if(param!=null){return parseStringParam(param.s,keepCase)}return def}function getBoolParam(attrs,name,def){const param=attrs[name];return param?param.b:def}function getNumberParam(attrs,name,def){const param=attrs[name]||{};const value=param["i"]!=null?param["i"]:param["f"]!=null?param["f"]:def;return typeof value==="number"?value:parseInt(value,10)}function parseDtypeParam(value){if(typeof value==="string"){value=DataType[value]}switch(value){case DataType.DT_FLOAT:return"float32";case DataType.DT_INT32:case DataType.DT_INT64:case DataType.DT_INT8:case DataType.DT_UINT8:return"int32";case DataType.DT_BOOL:return"bool";case DataType.DT_DOUBLE:return"float32";case DataType.DT_STRING:return"string";default:return null}}function getFuncParam(attrs,name,def){const param=attrs[name];if(param&&param.func){return param.func.name}return def}function getDtypeParam(attrs,name,def){const param=attrs[name];if(param&&param.type){return parseDtypeParam(param.type)}return def}function getDtypeArrayParam(attrs,name,def){const param=attrs[name];if(param&&param.list&&param.list.type){return param.list.type.map((v=>parseDtypeParam(v)))}return def}function parseTensorShapeParam(shape){if(shape.unknownRank){return undefined}if(shape.dim!=null){return shape.dim.map((dim=>typeof dim.size==="number"?dim.size:parseInt(dim.size,10)))}return[]}function getTensorShapeParam(attrs,name,def){const param=attrs[name];if(param&&param.shape){return parseTensorShapeParam(param.shape)}return def}function getNumericArrayParam(attrs,name,def){const param=attrs[name];if(param){return((param.list.f&&param.list.f.length?param.list.f:param.list.i)||[]).map((v=>typeof v==="number"?v:parseInt(v,10)))}return def}function getStringArrayParam(attrs,name,def,keepCase=false){const param=attrs[name];if(param&&param.list&&param.list.s){return param.list.s.map((v=>parseStringParam(v,keepCase)))}return def}function getTensorShapeArrayParam(attrs,name,def){const param=attrs[name];if(param&&param.list&&param.list.shape){return param.list.shape.map((v=>parseTensorShapeParam(v)))}return def}function getBoolArrayParam(attrs,name,def){const param=attrs[name];if(param&&param.list&&param.list.b){return param.list.b}return def}class NodeValueImpl{constructor(node,tensorMap,context){this.node=node;this.tensorMap=tensorMap;this.context=context;this.inputs=[];this.attrs={};this.inputs=node.inputNames.map((name=>this.getInput(name)));if(node.rawAttrs!=null){this.attrs=Object.keys(node.rawAttrs).reduce(((attrs,key)=>{attrs[key]=this.getAttr(key);return attrs}),{})}}getInput(name){return getTensor(name,this.tensorMap,this.context)}getAttr(name,defaultValue){const value=this.node.rawAttrs[name];if(value.tensor!=null){return getTensor(name,this.tensorMap,this.context)}if(value.i!=null||value.f!=null){return getNumberParam(this.node.rawAttrs,name,defaultValue)}if(value.s!=null){return getStringParam(this.node.rawAttrs,name,defaultValue)}if(value.b!=null){return getBoolParam(this.node.rawAttrs,name,defaultValue)}if(value.shape!=null){return getTensorShapeParam(this.node.rawAttrs,name,defaultValue)}if(value.type!=null){return getDtypeParam(this.node.rawAttrs,name,defaultValue)}if(value.list!=null){if(value.list.i!=null||value.list.f!=null){return getNumericArrayParam(this.node.rawAttrs,name,defaultValue)}if(value.list.s!=null){return getStringArrayParam(this.node.rawAttrs,name,defaultValue)}if(value.list.shape!=null){return getTensorShapeArrayParam(this.node.rawAttrs,name,defaultValue)}if(value.list.b!=null){return getBoolArrayParam(this.node.rawAttrs,name,defaultValue)}if(value.list.type!=null){return getDtypeArrayParam(this.node.rawAttrs,name,defaultValue)}}return defaultValue}}const executeOp$i=(node,tensorMap,context)=>{switch(node.op){case"BiasAdd":case"AddV2":case"Add":{return[add(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"AddN":{return[addN$1(getParamValue("tensors",node,tensorMap,context))]}case"FloorMod":case"Mod":return[mod$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"Mul":return[mul(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))];case"RealDiv":case"Div":{return[div(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"DivNoNan":{return[divNoNan(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"FloorDiv":{return[floorDiv$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Sub":{return[sub$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Minimum":{return[minimum$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Maximum":{return[maximum$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Pow":{return[pow$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"SquaredDifference":{return[squaredDifference$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$h=(node,tensorMap,context)=>{switch(node.op){case"Abs":case"ComplexAbs":return[abs$1(getParamValue("x",node,tensorMap,context))];case"Acos":return[acos$1(getParamValue("x",node,tensorMap,context))];case"Acosh":return[acosh$1(getParamValue("x",node,tensorMap,context))];case"Asin":return[asin$1(getParamValue("x",node,tensorMap,context))];case"Asinh":return[asinh$1(getParamValue("x",node,tensorMap,context))];case"Atan":return[atan$1(getParamValue("x",node,tensorMap,context))];case"Atan2":return[atan2$1(getParamValue("x",node,tensorMap,context),getParamValue("y",node,tensorMap,context))];case"Atanh":return[atanh$1(getParamValue("x",node,tensorMap,context))];case"Ceil":return[ceil$1(getParamValue("x",node,tensorMap,context))];case"Complex":return[complex$1(getParamValue("real",node,tensorMap,context),getParamValue("imag",node,tensorMap,context))];case"Cos":return[cos$1(getParamValue("x",node,tensorMap,context))];case"Cosh":return[cosh$1(getParamValue("x",node,tensorMap,context))];case"Elu":return[elu$1(getParamValue("x",node,tensorMap,context))];case"Erf":return[erf$1(getParamValue("x",node,tensorMap,context))];case"Exp":return[exp$1(getParamValue("x",node,tensorMap,context))];case"Expm1":{return[expm1$1(getParamValue("x",node,tensorMap,context))]}case"Floor":return[floor$1(getParamValue("x",node,tensorMap,context))];case"Log":return[log$2(getParamValue("x",node,tensorMap,context))];case"Log1p":{return[log1p$1(getParamValue("x",node,tensorMap,context))]}case"Imag":return[imag$1(getParamValue("x",node,tensorMap,context))];case"Neg":return[neg$1(getParamValue("x",node,tensorMap,context))];case"Reciprocal":{return[reciprocal$1(getParamValue("x",node,tensorMap,context))]}case"Real":return[real$1(getParamValue("x",node,tensorMap,context))];case"Relu":return[relu$1(getParamValue("x",node,tensorMap,context))];case"Round":{return[round$1(getParamValue("x",node,tensorMap,context))]}case"Selu":return[selu$1(getParamValue("x",node,tensorMap,context))];case"Sigmoid":return[sigmoid$1(getParamValue("x",node,tensorMap,context))];case"Sin":return[sin$1(getParamValue("x",node,tensorMap,context))];case"Sign":{return[sign$1(getParamValue("x",node,tensorMap,context))]}case"Sinh":{return[sinh$1(getParamValue("x",node,tensorMap,context))]}case"Softplus":{return[softplus$1(getParamValue("x",node,tensorMap,context))]}case"Sqrt":{return[sqrt$1(getParamValue("x",node,tensorMap,context))]}case"Square":{return[square$1(getParamValue("x",node,tensorMap,context))]}case"Tanh":{return[tanh$1(getParamValue("x",node,tensorMap,context))]}case"Tan":return[tan$1(getParamValue("x",node,tensorMap,context))];case"ClipByValue":return[clipByValue$1(getParamValue("x",node,tensorMap,context),getParamValue("clipValueMin",node,tensorMap,context),getParamValue("clipValueMax",node,tensorMap,context))];case"Relu6":return[relu6$1(getParamValue("x",node,tensorMap,context))];case"Rsqrt":return[rsqrt$1(getTensor(node.inputNames[0],tensorMap,context))];case"Prod":return[prod$1(getParamValue("x",node,tensorMap,context),getParamValue("axes",node,tensorMap,context))];case"LeakyRelu":return[leakyRelu$1(getParamValue("x",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context))];case"Prelu":return[prelu$1(getParamValue("x",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context))];case"IsNan":return[isNaN$2(getTensor(node.inputNames[0],tensorMap,context))];default:throw TypeError(`Node type ${node.op} is not implemented`)}};function assertShapesMatchAllowUndefinedSize(shapeA,shapeB,errorMessagePrefix=""){if(typeof shapeA==="number"||typeof shapeB==="number"){return}assert(shapeA.length===shapeB.length,(()=>errorMessagePrefix+` Shapes ${shapeA} and ${shapeB} must match`));for(let i=0;i<shapeA.length;i++){const dim0=shapeA[i];const dim1=shapeB[i];assert(dim0<0||dim1<0||dim0===dim1,(()=>errorMessagePrefix+` Shapes ${shapeA} and ${shapeB} must match`))}}function fullDefinedShape(elementShape){if(typeof elementShape==="number"||elementShape.some((dim=>dim<0))){return false}return true}function inferElementShape(listElementShape,tensors,elementShape){let partialShape=mergeElementShape(listElementShape,elementShape);const notfullDefinedShape=!fullDefinedShape(partialShape);if(notfullDefinedShape&&tensors.length===0){throw new Error(`Tried to calculate elements of an empty list`+` with non-fully-defined elementShape: ${partialShape}`)}if(notfullDefinedShape){tensors.forEach((tensor=>{partialShape=mergeElementShape(tensor.shape,partialShape)}))}if(!fullDefinedShape(partialShape)){throw new Error(`Non-fully-defined elementShape: ${partialShape}`)}return partialShape}function mergeElementShape(elementShapeA,elementShapeB){if(typeof elementShapeA==="number"){return elementShapeB}if(typeof elementShapeB==="number"){return elementShapeA}if(elementShapeA.length!==elementShapeB.length){throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${elementShapeB}`)}const result=[];for(let i=0;i<elementShapeA.length;++i){const dim0=elementShapeA[i];const dim1=elementShapeB[i];if(dim0>=0&&dim1>=0&&dim0!==dim1){throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${elementShapeB}`)}result[i]=dim0>=0?dim0:dim1}return result}class TensorArray{constructor(name,dtype,maxSize,elementShape,identicalElementShapes,dynamicSize,clearAfterRead){this.name=name;this.dtype=dtype;this.maxSize=maxSize;this.elementShape=elementShape;this.identicalElementShapes=identicalElementShapes;this.dynamicSize=dynamicSize;this.clearAfterRead=clearAfterRead;this.tensors=[];this.closed_=false;this.idTensor=scalar(0);keep(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(keepIds){this.tensors.forEach((tensor=>{if(keepIds==null||!keepIds.has(tensor.tensor.id)){tensor.tensor.dispose()}}));this.tensors=[];this.closed_=true;this.idTensor.dispose()}size(){return this.tensors.length}read(index){if(this.closed_){throw new Error(`TensorArray ${this.name} has already been closed.`)}if(index<0||index>=this.size()){throw new Error(`Tried to read from index ${index}, but array size is: ${this.size()}`)}const tensorWithState=this.tensors[index];if(tensorWithState.cleared){throw new Error(`TensorArray ${this.name}: Could not read index ${index} twice because it was cleared after a previous read `+`(perhaps try setting clear_after_read = false?).`)}if(this.clearAfterRead){tensorWithState.cleared=true}tensorWithState.read=true;return tensorWithState.tensor}readMany(indices){return indices.map((index=>this.read(index)))}write(index,tensor){if(this.closed_){throw new Error(`TensorArray ${this.name} has already been closed.`)}if(index<0||!this.dynamicSize&&index>=this.maxSize){throw new Error(`Tried to write to index ${index}, but array is not resizeable and size is: ${this.maxSize}`)}const t=this.tensors[index]||{};if(tensor.dtype!==this.dtype){throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${tensor.dtype}, but TensorArray dtype is ${this.dtype}.`)}if(this.size()===0&&(this.elementShape==null||this.elementShape.length===0)){this.elementShape=tensor.shape}assertShapesMatchAllowUndefinedSize(this.elementShape,tensor.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${index}.`);if(t.read){throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been read.`)}if(t.written){throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${index}, because it has already been written.`)}t.tensor=tensor;keep(tensor);t.written=true;this.tensors[index]=t}writeMany(indices,tensors){if(indices.length!==tensors.length){throw new Error(`TensorArray ${this.name}: could not write multiple tensors,`+`because the index size: ${indices.length} is not the same as tensors size: ${tensors.length}.`)}indices.forEach(((i,index)=>this.write(i,tensors[index])))}gather(indices,dtype){if(!!dtype&&dtype!==this.dtype){throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${dtype}`)}if(!indices){indices=[];for(let i=0;i<this.size();i++){indices.push(i)}}else{indices=indices.slice(0,this.size())}if(indices.length===0){return tensor([],[0].concat(this.elementShape))}const tensors=this.readMany(indices);assertShapesMatchAllowUndefinedSize(this.elementShape,tensors[0].shape,"TensorArray shape mismatch: ");return stack(tensors,0)}concat(dtype){if(!!dtype&&dtype!==this.dtype){throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${dtype}`)}if(this.size()===0){return tensor([],[0].concat(this.elementShape))}const indices=[];for(let i=0;i<this.size();i++){indices.push(i)}const tensors=this.readMany(indices);assertShapesMatchAllowUndefinedSize(this.elementShape,tensors[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${tensors[0].shape})`);return concat$1(tensors,0)}scatter(indices,tensor){if(tensor.dtype!==this.dtype){throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor.dtype}`)}if(indices.length!==tensor.shape[0]){throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor.shape[0]}`)}const maxIndex=Math.max(...indices);if(!this.dynamicSize&&maxIndex>=this.maxSize){throw new Error(`Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`)}this.writeMany(indices,unstack(tensor,0))}split(length,tensor){if(tensor.dtype!==this.dtype){throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${tensor.dtype}`)}let totalLength=0;const cumulativeLengths=length.map((len=>{totalLength+=len;return totalLength}));if(totalLength!==tensor.shape[0]){throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`)}if(!this.dynamicSize&&length.length!==this.maxSize){throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${length.length}), `+"and the TensorArray is not marked as dynamically resizeable")}const elementPerRow=totalLength===0?0:tensor.size/totalLength;const tensors=[];tidy((()=>{tensor=reshape$1(tensor,[1,totalLength,elementPerRow]);for(let i=0;i<length.length;++i){const previousLength=i===0?0:cumulativeLengths[i-1];const indices=[0,previousLength,0];const sizes=[1,length[i],elementPerRow];tensors[i]=reshape$1(slice$1(tensor,indices,sizes),this.elementShape)}return tensors}));const indices=[];for(let i=0;i<length.length;i++){indices[i]=i}this.writeMany(indices,tensors)}}class TensorList{constructor(tensors,elementShape,elementDtype,maxNumElements=-1){this.tensors=tensors;this.elementShape=elementShape;this.elementDtype=elementDtype;if(tensors!=null){tensors.forEach((tensor=>{if(elementDtype!==tensor.dtype){throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${tensor.dtype}`)}assertShapesMatchAllowUndefinedSize(elementShape,tensor.shape,"TensorList shape mismatch: ");keep(tensor)}))}this.idTensor=scalar(0);this.maxNumElements=maxNumElements;keep(this.idTensor)}get id(){return this.idTensor.id}copy(){return new TensorList([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(keepIds){this.tensors.forEach((tensor=>{if(keepIds==null||!keepIds.has(tensor.id)){tensor.dispose()}}));this.tensors.length=0;this.idTensor.dispose()}size(){return this.tensors.length}stack(elementShape,elementDtype,numElements=-1){if(elementDtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`)}if(numElements!==-1&&this.tensors.length!==numElements){throw new Error(`Operation expected a list with ${numElements} elements but got a list with ${this.tensors.length} elements.`)}assertShapesMatchAllowUndefinedSize(elementShape,this.elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return tidy((()=>{const reshapedTensors=this.tensors.map((tensor=>reshape$1(tensor,outputElementShape)));return stack(reshapedTensors,0)}))}popBack(elementShape,elementDtype){if(elementDtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`)}if(this.size()===0){throw new Error("Trying to pop from an empty list.")}const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);const tensor=this.tensors.pop();assertShapesMatchAllowUndefinedSize(tensor.shape,elementShape,"TensorList shape mismatch: ");return reshape$1(tensor,outputElementShape)}pushBack(tensor){if(tensor.dtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${this.elementDtype}`)}assertShapesMatchAllowUndefinedSize(tensor.shape,this.elementShape,"TensorList shape mismatch: ");if(this.maxNumElements===this.size()){throw new Error(`Trying to push element into a full list.`)}keep(tensor);this.tensors.push(tensor)}resize(size){if(size<0){throw new Error(`TensorListResize expects size to be non-negative. Got: ${size}`)}if(this.maxNumElements!==-1&&size>this.maxNumElements){throw new Error(`TensorListResize input size ${size} is greater maxNumElement ${this.maxNumElements}.`)}this.tensors.length=size}getItem(elementIndex,elementShape,elementDtype){if(elementDtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`)}if(elementIndex<0||elementIndex>this.tensors.length){throw new Error(`Trying to access element ${elementIndex} in a list with ${this.tensors.length} elements.`)}if(this.tensors[elementIndex]==null){throw new Error(`element at index ${elementIndex} is null.`)}assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape,elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);return reshape$1(this.tensors[elementIndex],outputElementShape)}setItem(elementIndex,tensor){if(tensor.dtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${this.elementDtype}`)}if(elementIndex<0||this.maxNumElements!==-1&&elementIndex>=this.maxNumElements){throw new Error(`Trying to set element ${elementIndex} in a list with max ${this.maxNumElements} elements.`)}assertShapesMatchAllowUndefinedSize(this.elementShape,tensor.shape,"TensorList shape mismatch: ");keep(tensor);this.tensors[elementIndex]=tensor}gather(indices,elementDtype,elementShape){if(elementDtype!==this.elementDtype){throw new Error(`Invalid data types; op elements ${elementDtype}, but list elements ${this.elementDtype}`)}assertShapesMatchAllowUndefinedSize(this.elementShape,elementShape,"TensorList shape mismatch: ");indices=indices.slice(0,this.size());const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);if(indices.length===0){return tensor([],[0].concat(outputElementShape))}return tidy((()=>{const tensors=indices.map((i=>reshape$1(this.tensors[i],outputElementShape)));return stack(tensors,0)}))}concat(elementDtype,elementShape){if(!!elementDtype&&elementDtype!==this.elementDtype){throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${elementDtype}`)}assertShapesMatchAllowUndefinedSize(this.elementShape,elementShape,"TensorList shape mismatch: ");const outputElementShape=inferElementShape(this.elementShape,this.tensors,elementShape);if(this.size()===0){return tensor([],[0].concat(outputElementShape))}return tidy((()=>{const tensors=this.tensors.map((t=>reshape$1(t,outputElementShape)));return concat$1(tensors,0)}))}}function fromTensor(tensor,elementShape,elementDtype){const dtype=tensor.dtype;if(tensor.shape.length<1){throw new Error(`Tensor must be at least a vector, but saw shape: ${tensor.shape}`)}if(tensor.dtype!==elementDtype){throw new Error(`Invalid data types; op elements ${tensor.dtype}, but list elements ${elementDtype}`)}const tensorElementShape=tensor.shape.slice(1);assertShapesMatchAllowUndefinedSize(tensorElementShape,elementShape,"TensorList shape mismatch: ");const tensorList=unstack(tensor);return new TensorList(tensorList,elementShape,dtype)}function reserve(elementShape,elementDtype,numElements){return new TensorList([],elementShape,elementDtype,numElements)}function scatter(tensor,indices,elementShape,numElements){if(indices.length!==tensor.shape[0]){throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${indices.length} vs. ${tensor.shape[0]}`)}const maxIndex=Math.max(...indices);if(numElements!=null&&numElements!==-1&&maxIndex>=numElements){throw new Error(`Max index must be < array size (${maxIndex}  vs. ${numElements})`)}const list=new TensorList([],elementShape,tensor.dtype,numElements);const tensors=unstack(tensor,0);indices.forEach(((value,index)=>{list.setItem(value,tensors[index])}));return list}function split(tensor,length,elementShape){let totalLength=0;const cumulativeLengths=length.map((len=>{totalLength+=len;return totalLength}));if(totalLength!==tensor.shape[0]){throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`)}const shapeWithoutFirstDim=tensor.shape.slice(1);const outputElementShape=mergeElementShape(shapeWithoutFirstDim,elementShape);const elementPerRow=totalLength===0?0:tensor.size/totalLength;const tensors=tidy((()=>{const tensors=[];tensor=reshape$1(tensor,[1,totalLength,elementPerRow]);for(let i=0;i<length.length;++i){const previousLength=i===0?0:cumulativeLengths[i-1];const indices=[0,previousLength,0];const sizes=[1,length[i],elementPerRow];tensors[i]=reshape$1(slice$1(tensor,indices,sizes),outputElementShape)}tensor.dispose();return tensors}));const list=new TensorList([],elementShape,tensor.dtype,length.length);for(let i=0;i<tensors.length;i++){list.setItem(i,tensors[i])}return list}const executeOp$g=async(node,tensorMap,context)=>{switch(node.op){case"If":case"StatelessIf":{const thenFunc=getParamValue("thenBranch",node,tensorMap,context);const elseFunc=getParamValue("elseBranch",node,tensorMap,context);const cond=getParamValue("cond",node,tensorMap,context);const args=getParamValue("args",node,tensorMap,context);const condValue=await cond.data();if(condValue[0]){return context.functionMap[thenFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap)}else{return context.functionMap[elseFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap)}}case"While":case"StatelessWhile":{const bodyFunc=getParamValue("body",node,tensorMap,context);const condFunc=getParamValue("cond",node,tensorMap,context);const args=getParamValue("args",node,tensorMap,context);const condResult=await context.functionMap[condFunc].executeFunctionAsync(args,context.tensorArrayMap,context.tensorListMap);const argIds=args.map((tensor=>tensor.id));let condValue=await condResult[0].data();condResult.forEach((tensor=>{if(!tensor.kept&&argIds.indexOf(tensor.id)===-1){tensor.dispose()}}));let result=args;while(condValue[0]){const origResult=result;result=await context.functionMap[bodyFunc].executeFunctionAsync(result,context.tensorArrayMap,context.tensorListMap);const resultIds=result.map((tensor=>tensor.id));origResult.forEach((tensor=>{if(!tensor.kept&&argIds.indexOf(tensor.id)===-1&&resultIds.indexOf(tensor.id)===-1){tensor.dispose()}}));const condResult=await context.functionMap[condFunc].executeFunctionAsync(result,context.tensorArrayMap,context.tensorListMap);condValue=await condResult[0].data();condResult.forEach((tensor=>{if(!tensor.kept&&argIds.indexOf(tensor.id)===-1&&resultIds.indexOf(tensor.id)===-1){tensor.dispose()}}))}return result}case"LoopCond":{const pred=getParamValue("pred",node,tensorMap,context);return[cloneTensor(pred)]}case"Switch":{const pred=getParamValue("pred",node,tensorMap,context);let data=getParamValue("data",node,tensorMap,context);if(!data.kept){data=cloneTensor(data)}return(await pred.data())[0]?[undefined,data]:[data,undefined]}case"Merge":{const inputName=node.inputNames.find((name=>getTensor(name,tensorMap,context)!==undefined));if(inputName){const data=getTensor(inputName,tensorMap,context);return[cloneTensor(data)]}return undefined}case"Enter":{const frameId=getParamValue("frameName",node,tensorMap,context);const data=getParamValue("tensor",node,tensorMap,context);context.enterFrame(frameId);return[cloneTensor(data)]}case"Exit":{const data=getParamValue("tensor",node,tensorMap,context);context.exitFrame();return[cloneTensor(data)]}case"NextIteration":{const data=getParamValue("tensor",node,tensorMap,context);context.nextIteration();return[cloneTensor(data)]}case"TensorArrayV3":{const size=getParamValue("size",node,tensorMap,context);const dtype=getParamValue("dtype",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const dynamicSize=getParamValue("dynamicSize",node,tensorMap,context);const clearAfterRead=getParamValue("clearAfterRead",node,tensorMap,context);const identicalElementShapes=getParamValue("identicalElementShapes",node,tensorMap,context);const name=getParamValue("name",node,tensorMap,context);const tensorArray=new TensorArray(name,dtype,size,elementShape,identicalElementShapes,dynamicSize,clearAfterRead);context.addTensorArray(tensorArray);return[tensorArray.idTensor,scalar(1)]}case"TensorArrayWriteV3":{const id=getParamValue("tensorArrayId",node,tensorMap,context);const index=getParamValue("index",node,tensorMap,context);const writeTensor=getParamValue("tensor",node,tensorMap,context);const writeTensorArray=context.getTensorArray(id.id);writeTensorArray.write(index,writeTensor);return[writeTensorArray.idTensor]}case"TensorArrayReadV3":{const readId=getParamValue("tensorArrayId",node,tensorMap,context);const readIndex=getParamValue("index",node,tensorMap,context);const readTensorArray=context.getTensorArray(readId.id);return[readTensorArray.read(readIndex)]}case"TensorArrayGatherV3":{const gatherId=getParamValue("tensorArrayId",node,tensorMap,context);const gatherIndices=getParamValue("indices",node,tensorMap,context);const gatherDtype=getParamValue("dtype",node,tensorMap,context);const gatherTensorArray=context.getTensorArray(gatherId.id);return[gatherTensorArray.gather(gatherIndices,gatherDtype)]}case"TensorArrayScatterV3":{const scatterId=getParamValue("tensorArrayId",node,tensorMap,context);const scatterIndices=getParamValue("indices",node,tensorMap,context);const scatterTensor=getParamValue("tensor",node,tensorMap,context);const scatterTensorArray=context.getTensorArray(scatterId.id);scatterTensorArray.scatter(scatterIndices,scatterTensor);return[scatterTensorArray.idTensor]}case"TensorArrayConcatV3":{const concatId=getParamValue("tensorArrayId",node,tensorMap,context);const concatTensorArray=context.getTensorArray(concatId.id);const concatDtype=getParamValue("dtype",node,tensorMap,context);return[concatTensorArray.concat(concatDtype)]}case"TensorArraySplitV3":{const splitId=getParamValue("tensorArrayId",node,tensorMap,context);const splitTensor=getParamValue("tensor",node,tensorMap,context);const lengths=getParamValue("lengths",node,tensorMap,context);const splitTensorArray=context.getTensorArray(splitId.id);splitTensorArray.split(lengths,splitTensor);return[splitTensorArray.idTensor]}case"TensorArraySizeV3":{const sizeId=getParamValue("tensorArrayId",node,tensorMap,context);const sizeTensorArray=context.getTensorArray(sizeId.id);return[scalar(sizeTensorArray.size(),"int32")]}case"TensorArrayCloseV3":{const closeId=getParamValue("tensorArrayId",node,tensorMap,context);const closeTensorArray=context.getTensorArray(closeId.id);closeTensorArray.clearAndClose();return[closeTensorArray.idTensor]}case"TensorListSetItem":{const idTensor=getParamValue("tensorListId",node,tensorMap,context);const index=getParamValue("index",node,tensorMap,context);const writeTensor=getParamValue("tensor",node,tensorMap,context);const tensorList=context.getTensorList(idTensor.id);tensorList.setItem(index,writeTensor);return[tensorList.idTensor]}case"TensorListGetItem":{const idTensor=getParamValue("tensorListId",node,tensorMap,context);const readIndex=getParamValue("index",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDType=getParamValue("elementDType",node,tensorMap,context);const tensorList=context.getTensorList(idTensor.id);return[tensorList.getItem(readIndex,elementShape,elementDType)]}case"TensorListScatterV2":case"TensorListScatter":{const scatterIndices=getParamValue("indices",node,tensorMap,context);const scatterTensor=getParamValue("tensor",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const numElements=getParamValue("numElements",node,tensorMap,context);const tensorList=scatter(scatterTensor,scatterIndices,elementShape,numElements);context.addTensorList(tensorList);return[tensorList.idTensor]}case"TensorListReserve":case"EmptyTensorList":{const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDtype=getParamValue("elementDType",node,tensorMap,context);let numElementsParam;if(node.op==="TensorListReserve"){numElementsParam="numElements"}else{numElementsParam="maxNumElements"}const numElements=getParamValue(numElementsParam,node,tensorMap,context);const tensorList=reserve(elementShape,elementDtype,numElements);context.addTensorList(tensorList);return[tensorList.idTensor]}case"TensorListGather":{const gatherId=getParamValue("tensorListId",node,tensorMap,context);const gatherIndices=getParamValue("indices",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDtype=getParamValue("elementDType",node,tensorMap,context);const tensorList=context.getTensorList(gatherId.id);return[tensorList.gather(gatherIndices,elementDtype,elementShape)]}case"TensorListStack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDtype=getParamValue("elementDType",node,tensorMap,context);const numElements=getParamValue("numElements",node,tensorMap,context);const tensorList=context.getTensorList(idTensor.id);return[tensorList.stack(elementShape,elementDtype,numElements)]}case"TensorListFromTensor":{const tensor=getParamValue("tensor",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDtype=getParamValue("elementDType",node,tensorMap,context);const tensorList=fromTensor(tensor,elementShape,elementDtype);context.addTensorList(tensorList);return[tensorList.idTensor]}case"TensorListConcat":{const concatId=getParamValue("tensorListId",node,tensorMap,context);const tensorList=context.getTensorList(concatId.id);const concatDtype=getParamValue("dtype",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);return[tensorList.concat(concatDtype,elementShape)]}case"TensorListPushBack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context);const writeTensor=getParamValue("tensor",node,tensorMap,context);const tensorList=context.getTensorList(idTensor.id);tensorList.pushBack(writeTensor);return[tensorList.idTensor]}case"TensorListPopBack":{const idTensor=getParamValue("tensorListId",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const elementDType=getParamValue("elementDType",node,tensorMap,context);const tensorList=context.getTensorList(idTensor.id);return[tensorList.popBack(elementShape,elementDType)]}case"TensorListSplit":{const splitTensor=getParamValue("tensor",node,tensorMap,context);const elementShape=getParamValue("elementShape",node,tensorMap,context);const lengths=getParamValue("lengths",node,tensorMap,context);const tensorList=split(splitTensor,lengths,elementShape);context.addTensorList(tensorList);return[tensorList.idTensor]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};function fusedConvAndDepthWiseParams(node,tensorMap,context){const[extraOp,activationFunc]=getParamValue("fusedOps",node,tensorMap,context);const isBiasAdd=extraOp==="biasadd";const isPrelu=activationFunc==="prelu";const isBatchNorm=extraOp==="fusedbatchnorm";const numArgs=getParamValue("numArgs",node,tensorMap,context);if(isBiasAdd){if(isPrelu&&numArgs!==2){throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu "+"must have two extra arguments: bias and alpha.")}if(!isPrelu&&numArgs!==1){throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have "+"one extra argument: bias.")}}if(isBatchNorm){throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported")}const stride=getParamValue("strides",node,tensorMap,context);const pad=getPadding(node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();const dilations=getParamValue("dilations",node,tensorMap,context);const[biasArg,preluArg]=getParamValue("args",node,tensorMap,context);const leakyreluAlpha=getParamValue("leakyreluAlpha",node,tensorMap,context);return{stride:stride,pad:pad,dataFormat:dataFormat,dilations:dilations,biasArg:biasArg,preluArg:preluArg,activationFunc:activationFunc,leakyreluAlpha:leakyreluAlpha}}const executeOp$f=(node,tensorMap,context)=>{switch(node.op){case"Conv1D":{const stride=getParamValue("stride",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();const dilation=getParamValue("dilation",node,tensorMap,context);return[conv1d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),stride,pad,dataFormat,dilation)]}case"Conv2D":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getPadding(node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();const dilations=getParamValue("dilations",node,tensorMap,context);return[conv2d$2(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2]],pad,dataFormat,[dilations[1],dilations[2]])]}case"_FusedConv2D":{const{stride:stride,pad:pad,dataFormat:dataFormat,dilations:dilations,biasArg:biasArg,preluArg:preluArg,activationFunc:activationFunc,leakyreluAlpha:leakyreluAlpha}=fusedConvAndDepthWiseParams(node,tensorMap,context);return[conv2d$1({x:getParamValue("x",node,tensorMap,context),filter:getParamValue("filter",node,tensorMap,context),strides:[stride[1],stride[2]],pad:pad,dataFormat:dataFormat,dilations:[dilations[1],dilations[2]],bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha:leakyreluAlpha})]}case"FusedDepthwiseConv2dNative":{const{stride:stride,pad:pad,dataFormat:dataFormat,dilations:dilations,biasArg:biasArg,preluArg:preluArg,activationFunc:activationFunc,leakyreluAlpha:leakyreluAlpha}=fusedConvAndDepthWiseParams(node,tensorMap,context);return[depthwiseConv2d({x:getParamValue("x",node,tensorMap,context),filter:getParamValue("filter",node,tensorMap,context),strides:[stride[1],stride[2]],pad:pad,dataFormat:dataFormat,dilations:[dilations[1],dilations[2]],bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha:leakyreluAlpha})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const shape=getParamValue("outputShape",node,tensorMap,context);const stride=getParamValue("strides",node,tensorMap,context);const pad=getPadding(node,tensorMap,context);return[conv2dTranspose(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),shape,[stride[1],stride[2]],pad)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getPadding(node,tensorMap,context);const dilations=getParamValue("dilations",node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();return[depthwiseConv2d$1(getParamValue("input",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2]],pad,dataFormat,[dilations[1],dilations[2]])]}case"Conv3D":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();const dilations=getParamValue("dilations",node,tensorMap,context);return[conv3d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[stride[1],stride[2],stride[3]],pad,dataFormat,[dilations[1],dilations[2],dilations[3]])]}case"AvgPool":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[avgPool$1(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad)]}case"MaxPool":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[maxPool$1(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad)]}case"MaxPoolWithArgmax":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const kernelSize=getParamValue("kernelSize",node,tensorMap,context);const includeBatchInIndex=getParamValue("includeBatchInIndex",node,tensorMap,context);const{result:result,indexes:indexes}=maxPoolWithArgmax(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2]],[stride[1],stride[2]],pad,includeBatchInIndex);return[result,indexes]}case"AvgPool3D":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[avgPool3d(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2],kernelSize[3]],[stride[1],stride[2],stride[3]],pad)]}case"MaxPool3D":{const stride=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const kernelSize=getParamValue("kernelSize",node,tensorMap,context);return[maxPool3d$1(getParamValue("x",node,tensorMap,context),[kernelSize[1],kernelSize[2],kernelSize[3]],[stride[1],stride[2],stride[3]],pad)]}case"Dilation2D":{const strides=getParamValue("strides",node,tensorMap,context);const pad=getParamValue("pad",node,tensorMap,context);const dilations=getParamValue("dilations",node,tensorMap,context);const strideHeight=strides[1];const strideWidth=strides[2];const dilationHeight=dilations[1];const dilationWidth=dilations[2];return[dilation2d(getParamValue("x",node,tensorMap,context),getParamValue("filter",node,tensorMap,context),[strideHeight,strideWidth],pad,[dilationHeight,dilationWidth],"NHWC")]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$e=(node,tensorMap,context)=>{switch(node.op){case"Fill":{const shape=getParamValue("shape",node,tensorMap,context);const dtype=getParamValue("dtype",node,tensorMap,context);const value=getParamValue("value",node,tensorMap,context);return[fill$1(shape,value,dtype)]}case"LinSpace":{const start=getParamValue("start",node,tensorMap,context);const stop=getParamValue("stop",node,tensorMap,context);const num=getParamValue("num",node,tensorMap,context);return[linspace(start,stop,num)]}case"Multinomial":{const logits=getParamValue("logits",node,tensorMap,context);const numSamples=getParamValue("numSamples",node,tensorMap,context);const seed=getParamValue("seed",node,tensorMap,context);return[multinomial$1(logits,numSamples,seed)]}case"OneHot":{const indices=getParamValue("indices",node,tensorMap,context);const depth=getParamValue("depth",node,tensorMap,context);const onValue=getParamValue("onValue",node,tensorMap,context);const offValue=getParamValue("offValue",node,tensorMap,context);return[oneHot$1(indices,depth,onValue,offValue)]}case"Ones":{return[ones(getParamValue("shape",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))]}case"OnesLike":{return[onesLike$1(getParamValue("x",node,tensorMap,context))]}case"RandomUniform":{return[randomUniform(getParamValue("shape",node,tensorMap,context),getParamValue("minval",node,tensorMap,context),getParamValue("maxval",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))]}case"Range":{const start=getParamValue("start",node,tensorMap,context);const stop=getParamValue("stop",node,tensorMap,context);const step=getParamValue("step",node,tensorMap,context);return[range$1(start,stop,step,getParamValue("dtype",node,tensorMap,context))]}case"TruncatedNormal":{const shape=getParamValue("shape",node,tensorMap,context);const mean=getParamValue("mean",node,tensorMap,context);const stdDev=getParamValue("stdDev",node,tensorMap,context);const seed=getParamValue("seed",node,tensorMap,context);return[truncatedNormal(shape,mean,stdDev,getParamValue("dtype",node,tensorMap,context),seed)]}case"Zeros":{return[zeros(getParamValue("shape",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))]}case"ZerosLike":{return[zerosLike$1(getParamValue("x",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};function nmsParams(node,tensorMap,context){const boxes=getParamValue("boxes",node,tensorMap,context);const scores=getParamValue("scores",node,tensorMap,context);const maxOutputSize=getParamValue("maxOutputSize",node,tensorMap,context);const iouThreshold=getParamValue("iouThreshold",node,tensorMap,context);const scoreThreshold=getParamValue("scoreThreshold",node,tensorMap,context);const softNmsSigma=getParamValue("softNmsSigma",node,tensorMap,context);return{boxes:boxes,scores:scores,maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,softNmsSigma:softNmsSigma}}const executeOp$d=async(node,tensorMap,context)=>{switch(node.op){case"NonMaxSuppressionV5":{const{boxes:boxes,scores:scores,maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,softNmsSigma:softNmsSigma}=nmsParams(node,tensorMap,context);const result=await image$1.nonMaxSuppressionWithScoreAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,softNmsSigma);return[result.selectedIndices,result.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:boxes,scores:scores,maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold}=nmsParams(node,tensorMap,context);const padToMaxOutputSize=getParamValue("padToMaxOutputSize",node,tensorMap,context);const result=await image$1.nonMaxSuppressionPaddedAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize);return[result.selectedIndices,result.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:boxes,scores:scores,maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold}=nmsParams(node,tensorMap,context);return[await image$1.nonMaxSuppressionAsync(boxes,scores,maxOutputSize,iouThreshold,scoreThreshold)]}case"Where":{const condition=cast$1(getParamValue("condition",node,tensorMap,context),"bool");const result=[await whereAsync(condition)];condition.dispose();return result}case"ListDiff":{return setdiff1dAsync(getParamValue("x",node,tensorMap,context),getParamValue("y",node,tensorMap,context))}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$c=(node,tensorMap,context)=>{switch(node.op){case"TopKV2":{const x=getParamValue("x",node,tensorMap,context);const k=getParamValue("k",node,tensorMap,context);const sorted=getParamValue("sorted",node,tensorMap,context);const result=topk(x,k,sorted);return[result.values,result.indices]}case"Unique":{const x=getParamValue("x",node,tensorMap,context);const result=unique$1(x);return[result.values,result.indices]}case"UniqueV2":{const x=getParamValue("x",node,tensorMap,context);const axis=getParamValue("axis",node,tensorMap,context);const result=unique$1(x,axis);return[result.values,result.indices]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$b=(node,tensorMap,context)=>{switch(node.op){case"Const":{return tensorMap[node.name]}case"PlaceholderWithDefault":const def=getParamValue("default",node,tensorMap,context);return[getTensor(node.name,tensorMap,context)||def];case"Placeholder":return[getTensor(node.name,tensorMap,context)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":{const data=getParamValue("x",node,tensorMap,context);return[cloneTensor(data)]}case"IdentityN":return getParamValue("x",node,tensorMap,context).map((t=>cloneTensor(t)));case"Snapshot":const snapshot=getParamValue("x",node,tensorMap,context);return[cloneTensor(snapshot)];case"Shape":return[tensor1d(getParamValue("x",node,tensorMap,context).shape,"int32")];case"ShapeN":return getParamValue("x",node,tensorMap,context).map((t=>tensor1d(t.shape)));case"Size":return[scalar(getParamValue("x",node,tensorMap,context).size,"int32")];case"Rank":return[scalar(getParamValue("x",node,tensorMap,context).rank,"int32")];case"NoOp":return[scalar(1)];case"Print":const input=getParamValue("x",node,tensorMap,context);const data=getParamValue("data",node,tensorMap,context);const message=getParamValue("message",node,tensorMap,context);const summarize=getParamValue("summarize",node,tensorMap,context);console.warn("The graph has a tf.print() operation,"+"usually used for debugging, which slows down performance.");console.log(message);for(let i=0;i<data.length;i++){console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0,summarize))}return[input];default:throw TypeError(`Node type ${node.op} is not implemented`)}};class HashTable{constructor(keyDType,valueDType){this.keyDType=keyDType;this.valueDType=valueDType;this.handle=scalar(0);this.tensorMap=new Map;keep(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach((value=>value.dispose()));this.tensorMap.clear();this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return scalar(this.size(),"int32")}async import(keys,values){this.checkKeyAndValueTensor(keys,values);const $keys=await keys.data();this.tensorMap.forEach((value=>value.dispose()));this.tensorMap.clear();return tidy((()=>{const $values=unstack(values);const keysLength=$keys.length;const valuesLength=$values.length;assert(keysLength===valuesLength,(()=>`The number of elements doesn't match, keys has `+`${keysLength} elements, the values has ${valuesLength} `+`elements.`));for(let i=0;i<keysLength;i++){const key=$keys[i];const value=$values[i];keep(value);this.tensorMap.set(key,value)}return this.handle}))}async find(keys,defaultValue){this.checkKeyAndValueTensor(keys,defaultValue);const $keys=await keys.data();return tidy((()=>{const result=[];for(let i=0;i<$keys.length;i++){const key=$keys[i];const value=this.findWithDefault(key,defaultValue);result.push(value)}return stack(result)}))}findWithDefault(key,defaultValue){const result=this.tensorMap.get(key);return result!=null?result:defaultValue}checkKeyAndValueTensor(key,value){if(key.dtype!==this.keyDType){throw new Error(`Expect key dtype ${this.keyDType}, but got `+`${key.dtype}`)}if(value.dtype!==this.valueDType){throw new Error(`Expect value dtype ${this.valueDType}, but got `+`${value.dtype}`)}}}const executeOp$a=async(node,tensorMap,context,resourceManager)=>{switch(node.op){case"HashTable":case"HashTableV2":{const keyDType=getParamValue("keyDType",node,tensorMap,context);const valueDType=getParamValue("valueDType",node,tensorMap,context);const hashTable=new HashTable(keyDType,valueDType);resourceManager.addHashTable(node.name,hashTable);return[hashTable.handle]}case"LookupTableImport":case"LookupTableImportV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager);const keys=getParamValue("keys",node,tensorMap,context);const values=getParamValue("values",node,tensorMap,context);const hashTable=resourceManager.getHashTableById(handle.id);return[await hashTable.import(keys,values)]}case"LookupTableFind":case"LookupTableFindV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager);const keys=getParamValue("keys",node,tensorMap,context);const defaultValue=getParamValue("defaultValue",node,tensorMap,context);const hashTable=resourceManager.getHashTableById(handle.id);return[await hashTable.find(keys,defaultValue)]}case"LookupTableSize":case"LookupTableSizeV2":{const handle=getParamValue("tableHandle",node,tensorMap,context,resourceManager);const hashTable=resourceManager.getHashTableById(handle.id);return[hashTable.tensorSize()]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$9=(node,tensorMap,context)=>{switch(node.op){case"ResizeBilinear":{const images=getParamValue("images",node,tensorMap,context);const size=getParamValue("size",node,tensorMap,context);const alignCorners=getParamValue("alignCorners",node,tensorMap,context);const halfPixelCenters=getParamValue("halfPixelCenters",node,tensorMap,context);return[image$1.resizeBilinear(images,[size[0],size[1]],alignCorners,halfPixelCenters)]}case"ResizeNearestNeighbor":{const images=getParamValue("images",node,tensorMap,context);const size=getParamValue("size",node,tensorMap,context);const alignCorners=getParamValue("alignCorners",node,tensorMap,context);const halfPixelCenters=getParamValue("halfPixelCenters",node,tensorMap,context);return[image$1.resizeNearestNeighbor(images,[size[0],size[1]],alignCorners,halfPixelCenters)]}case"CropAndResize":{const image=getParamValue("image",node,tensorMap,context);const boxes=getParamValue("boxes",node,tensorMap,context);const boxInd=getParamValue("boxInd",node,tensorMap,context);const cropSize=getParamValue("cropSize",node,tensorMap,context);const method=getParamValue("method",node,tensorMap,context);const extrapolationValue=getParamValue("extrapolationValue",node,tensorMap,context);return[image$1.cropAndResize(image,boxes,boxInd,cropSize,method,extrapolationValue)]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$8=(node,tensorMap,context)=>{switch(node.op){case"Equal":{return[equal$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"NotEqual":{return[notEqual$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Greater":{return[greater$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"GreaterEqual":{return[greaterEqual$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Less":{return[less$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"LessEqual":{return[lessEqual$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"LogicalAnd":{return[logicalAnd$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"LogicalNot":{return[logicalNot$1(getParamValue("a",node,tensorMap,context))]}case"LogicalOr":{return[logicalOr$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}case"Select":case"SelectV2":{return[where(getParamValue("condition",node,tensorMap,context),getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$7=(node,tensorMap,context)=>{switch(node.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[matMul$1(getParamValue("a",node,tensorMap,context),getParamValue("b",node,tensorMap,context),getParamValue("transposeA",node,tensorMap,context),getParamValue("transposeB",node,tensorMap,context))];case"Einsum":return[einsum$1(getParamValue("equation",node,tensorMap,context),...getParamValue("tensors",node,tensorMap,context))];case"Transpose":return[transpose$1(getParamValue("x",node,tensorMap,context),getParamValue("perm",node,tensorMap,context))];case"_FusedMatMul":const[extraOp,activationFunc]=getParamValue("fusedOps",node,tensorMap,context);const isBiasAdd=extraOp==="biasadd";const isPrelu=activationFunc==="prelu";const numArgs=getParamValue("numArgs",node,tensorMap,context);const leakyreluAlpha=getParamValue("leakyreluAlpha",node,tensorMap,context);if(isBiasAdd){if(isPrelu&&numArgs!==2){throw new Error("Fused MatMul with BiasAdd and Prelu must have two "+"extra arguments: bias and alpha.")}if(!isPrelu&&numArgs!==1){throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}}const[biasArg,preluArg]=getParamValue("args",node,tensorMap,context);return[matMul({a:getParamValue("a",node,tensorMap,context),b:getParamValue("b",node,tensorMap,context),transposeA:getParamValue("transposeA",node,tensorMap,context),transposeB:getParamValue("transposeB",node,tensorMap,context),bias:biasArg,activation:activationFunc,preluActivationWeights:preluArg,leakyreluAlpha:leakyreluAlpha})];default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$6=(node,tensorMap,context)=>{switch(node.op){case"FusedBatchNorm":case"FusedBatchNormV2":{return[batchNorm$1(getParamValue("x",node,tensorMap,context),getParamValue("mean",node,tensorMap,context),getParamValue("variance",node,tensorMap,context),getParamValue("offset",node,tensorMap,context),getParamValue("scale",node,tensorMap,context),getParamValue("epsilon",node,tensorMap,context))]}case"FusedBatchNormV3":{return[batchNorm$1(getParamValue("x",node,tensorMap,context),getParamValue("mean",node,tensorMap,context),getParamValue("variance",node,tensorMap,context),getParamValue("offset",node,tensorMap,context),getParamValue("scale",node,tensorMap,context),getParamValue("epsilon",node,tensorMap,context))]}case"LRN":{return[localResponseNormalization(getParamValue("x",node,tensorMap,context),getParamValue("radius",node,tensorMap,context),getParamValue("bias",node,tensorMap,context),getParamValue("alpha",node,tensorMap,context),getParamValue("beta",node,tensorMap,context))]}case"Softmax":{return[softmax$1(getParamValue("x",node,tensorMap,context))]}case"LogSoftmax":{return[logSoftmax(getParamValue("x",node,tensorMap,context))]}case"SparseToDense":{return[sparseToDense$1(getParamValue("sparseIndices",node,tensorMap,context),getParamValue("outputShape",node,tensorMap,context),getParamValue("sparseValues",node,tensorMap,context),getParamValue("defaultValue",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$5=(node,tensorMap,context)=>{switch(node.op){case"Max":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[max$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Mean":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[mean(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Min":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[min$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Sum":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[sum$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"All":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[all$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Any":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[any$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"ArgMax":{const axis=getParamValue("axis",node,tensorMap,context);return[argMax$1(getParamValue("x",node,tensorMap,context),axis)]}case"ArgMin":{const axis=getParamValue("axis",node,tensorMap,context);return[argMin$1(getParamValue("x",node,tensorMap,context),axis)]}case"Prod":{const axis=getParamValue("axis",node,tensorMap,context);const keepDims=getParamValue("keepDims",node,tensorMap,context);return[prod$1(getParamValue("x",node,tensorMap,context),axis,keepDims)]}case"Cumsum":{const axis=getParamValue("axis",node,tensorMap,context);const exclusive=getParamValue("exclusive",node,tensorMap,context);const reverse=getParamValue("reverse",node,tensorMap,context);return[cumsum$1(getParamValue("x",node,tensorMap,context),axis,exclusive,reverse)]}case"Bincount":const x=getParamValue("x",node,tensorMap,context);const weights=getParamValue("weights",node,tensorMap,context);const size=getParamValue("size",node,tensorMap,context);return[bincount$1(x,weights,size)];case"DenseBincount":{const x=getParamValue("x",node,tensorMap,context);const weights=getParamValue("weights",node,tensorMap,context);const size=getParamValue("size",node,tensorMap,context);const binaryOutput=getParamValue("binaryOutput",node,tensorMap,context);return[denseBincount$1(x,weights,size,binaryOutput)]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$4=(node,tensorMap,context)=>{switch(node.op){case"ConcatV2":case"Concat":{const n=getParamValue("n",node,tensorMap,context);const axis=getParamValue("axis",node,tensorMap,context);let inputs=getParamValue("tensors",node,tensorMap,context);inputs=inputs.slice(0,n);return[concat$1(inputs,axis)]}case"Gather":{const input=getParamValue("x",node,tensorMap,context);const indices=getParamValue("indices",node,tensorMap,context);return[gather(input,cast$1(indices,"int32"),0)]}case"GatherV2":{const axis=getParamValue("axis",node,tensorMap,context);const batchDims=getParamValue("batchDims",node,tensorMap,context);const input=getParamValue("x",node,tensorMap,context);const indices=getParamValue("indices",node,tensorMap,context);return[gather(input,cast$1(indices,"int32"),axis,batchDims)]}case"Reverse":{const dims=getParamValue("dims",node,tensorMap,context);const axis=[];for(let i=0;i<dims.length;i++){if(dims[i]){axis.push(i)}}const input=getParamValue("x",node,tensorMap,context);return[reverse$1(input,axis)]}case"ReverseV2":{const axis=getParamValue("axis",node,tensorMap,context);const input=getParamValue("x",node,tensorMap,context);return[reverse$1(input,axis)]}case"Slice":{const begin=getParamValue("begin",node,tensorMap,context);const size=getParamValue("size",node,tensorMap,context);return[slice$1(getParamValue("x",node,tensorMap,context),begin,size)]}case"StridedSlice":{const begin=getParamValue("begin",node,tensorMap,context);const end=getParamValue("end",node,tensorMap,context);const strides=getParamValue("strides",node,tensorMap,context);const beginMask=getParamValue("beginMask",node,tensorMap,context);const endMask=getParamValue("endMask",node,tensorMap,context);const ellipsisMask=getParamValue("ellipsisMask",node,tensorMap,context);const newAxisMask=getParamValue("newAxisMask",node,tensorMap,context);const shrinkAxisMask=getParamValue("shrinkAxisMask",node,tensorMap,context);const tensor=getParamValue("x",node,tensorMap,context);return[stridedSlice$1(tensor,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask)]}case"Pack":{return tidy((()=>{const axis=getParamValue("axis",node,tensorMap,context);const tensors=getParamValue("tensors",node,tensorMap,context);const shape=tensors[0].shape;const squeezedShape=squeeze(tensors[0]).shape;const mapped=tensors.map((tensor=>{const sameShape=arraysEqual(tensor.shape,shape);if(!sameShape&&!arraysEqual(squeeze(tensor).shape,squeezedShape)){throw new Error("the input tensors shape does not match")}return sameShape?tensor:reshape$1(tensor,shape)}));return[stack(mapped,axis)]}))}case"Unpack":{const axis=getParamValue("axis",node,tensorMap,context);const tensor=getParamValue("tensor",node,tensorMap,context);return unstack(tensor,axis)}case"Tile":{const reps=getParamValue("reps",node,tensorMap,context);return[tile$1(getParamValue("x",node,tensorMap,context),reps)]}case"Split":case"SplitV":{const axis=getParamValue("axis",node,tensorMap,context);const numOrSizeSplits=getParamValue("numOrSizeSplits",node,tensorMap,context);const tensor=getParamValue("x",node,tensorMap,context);return split$1(tensor,numOrSizeSplits,axis)}case"ScatterNd":{const indices=getParamValue("indices",node,tensorMap,context);const values=getParamValue("values",node,tensorMap,context);const shape=getParamValue("shape",node,tensorMap,context);return[scatterND(indices,values,shape)]}case"GatherNd":{const x=getParamValue("x",node,tensorMap,context);const indices=getParamValue("indices",node,tensorMap,context);return[gatherND(x,indices)]}case"SparseToDense":{const indices=getParamValue("sparseIndices",node,tensorMap,context);const shape=getParamValue("outputShape",node,tensorMap,context);const sparseValues=getParamValue("sparseValues",node,tensorMap,context);const defaultValue=getParamValue("defaultValue",node,tensorMap,context);return[sparseToDense$1(indices,sparseValues,shape,sparseValues.dtype===defaultValue.dtype?defaultValue:cast$1(defaultValue,sparseValues.dtype))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$3=(node,tensorMap,context)=>{switch(node.op){case"SparseReshape":{const{outputIndices:outputIndices,outputShape:outputShape}=sparse.sparseReshape(getParamValue("inputIndices",node,tensorMap,context),getParamValue("inputShape",node,tensorMap,context),getParamValue("newShape",node,tensorMap,context));return[outputIndices,outputShape]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$2=(node,tensorMap,context)=>{switch(node.op){case"FFT":{return[fft$1(getParamValue("x",node,tensorMap,context))]}case"IFFT":{return[ifft$1(getParamValue("x",node,tensorMap,context))]}case"RFFT":{return[rfft(getParamValue("x",node,tensorMap,context))]}case"IRFFT":{return[irfft(getParamValue("x",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};const executeOp$1=(node,tensorMap,context)=>{switch(node.op){case"Cast":{return[cast$1(getParamValue("x",node,tensorMap,context),getParamValue("dtype",node,tensorMap,context))]}case"ExpandDims":{const axis=getParamValue("axis",node,tensorMap,context);return[expandDims$1(getParamValue("x",node,tensorMap,context),axis)]}case"Squeeze":{const axis=getParamValue("axis",node,tensorMap,context);return[squeeze(getParamValue("x",node,tensorMap,context),axis)]}case"Reshape":{return[reshape$1(getParamValue("x",node,tensorMap,context),getParamValue("shape",node,tensorMap,context))]}case"MirrorPad":{return[mirrorPad(getParamValue("x",node,tensorMap,context),getParamValue("padding",node,tensorMap,context),getParamValue("mode",node,tensorMap,context))]}case"PadV2":case"Pad":{return[pad(getParamValue("x",node,tensorMap,context),getParamValue("padding",node,tensorMap,context),getParamValue("constantValue",node,tensorMap,context))]}case"SpaceToBatchND":{const blockShape=getParamValue("blockShape",node,tensorMap,context);const paddings=getParamValue("paddings",node,tensorMap,context);return[spaceToBatchND$1(getParamValue("x",node,tensorMap,context),blockShape,paddings)]}case"BatchToSpaceND":{const blockShape=getParamValue("blockShape",node,tensorMap,context);const crops=getParamValue("crops",node,tensorMap,context);return[batchToSpaceND$1(getParamValue("x",node,tensorMap,context),blockShape,crops)]}case"DepthToSpace":{const blockSize=getParamValue("blockSize",node,tensorMap,context);const dataFormat=getParamValue("dataFormat",node,tensorMap,context).toUpperCase();return[depthToSpace$1(getParamValue("x",node,tensorMap,context),blockSize,dataFormat)]}case"BroadcastTo":{return[broadcastTo(getParamValue("x",node,tensorMap,context),getParamValue("shape",node,tensorMap,context))]}default:throw TypeError(`Node type ${node.op} is not implemented`)}};function executeOp(node,tensorMap,context,resourceManager){const value=((node,tensorMap,context)=>{switch(node.category){case"arithmetic":return tidy((()=>executeOp$i(node,tensorMap,context)));case"basic_math":return tidy((()=>executeOp$h(node,tensorMap,context)));case"control":return executeOp$g(node,tensorMap,context);case"convolution":return tidy((()=>executeOp$f(node,tensorMap,context)));case"creation":return tidy((()=>executeOp$e(node,tensorMap,context)));case"dynamic":return executeOp$d(node,tensorMap,context);case"evaluation":return tidy((()=>executeOp$c(node,tensorMap,context)));case"image":return tidy((()=>executeOp$9(node,tensorMap,context)));case"graph":return tidy((()=>executeOp$b(node,tensorMap,context)));case"logical":return tidy((()=>executeOp$8(node,tensorMap,context)));case"matrices":return tidy((()=>executeOp$7(node,tensorMap,context)));case"normalization":return tidy((()=>executeOp$6(node,tensorMap,context)));case"reduction":return tidy((()=>executeOp$5(node,tensorMap,context)));case"slice_join":return tidy((()=>executeOp$4(node,tensorMap,context)));case"sparse":return tidy((()=>executeOp$3(node,tensorMap,context)));case"spectral":return tidy((()=>executeOp$2(node,tensorMap,context)));case"transformation":return tidy((()=>executeOp$1(node,tensorMap,context)));case"hash_table":return executeOp$a(node,tensorMap,context,resourceManager);case"custom":const opMapper=getRegisteredOp(node.op);if(opMapper&&opMapper.customExecutor){return opMapper.customExecutor(new NodeValueImpl(node,tensorMap,context))}else{throw TypeError(`Custom op ${node.op} is not registered.`)}default:throw TypeError(`Unknown op '${node.op}'. File an issue at `+`https://github.com/tensorflow/tfjs/issues so we can add it`+`, or register a custom execution with tf.registerOp()`)}})(node,tensorMap,context);if(isPromise(value)){return value.then((data=>[].concat(data)))}return[].concat(value)}class ExecutionContext{constructor(weightMap={},tensorArrayMap={},tensorListMap={},functionMap={}){this.weightMap=weightMap;this.tensorArrayMap=tensorArrayMap;this.tensorListMap=tensorListMap;this.functionMap=functionMap;this.rootContext={id:0,frameName:"",iterationId:0};this.contexts=[this.rootContext];this.lastId=0;this.generateCurrentContextIds()}newFrame(id,frameName){return{id:id,frameName:frameName,iterationId:0}}set currentContext(contexts){if(this.contexts!==contexts){this.contexts=contexts;this.generateCurrentContextIds()}}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const names=[];for(let i=0;i<this.contexts.length-1;i++){const contexts=this.contexts.slice(0,this.contexts.length-i);names.push(this.contextIdforContexts(contexts))}names.push("");this._currentContextIds=names}contextIdforContexts(contexts){return contexts?contexts.map((context=>context.id===0&&context.iterationId===0?"":`${context.frameName}-${context.iterationId}`)).join("/"):""}enterFrame(frameId){if(this.contexts){this.lastId++;this.contexts=this.contexts.slice();this.contexts.push(this.newFrame(this.lastId,frameId));this._currentContextIds.unshift(this.contextIdforContexts(this.contexts))}}exitFrame(){if(this.contexts&&this.contexts.length>1){this.contexts=this.contexts.slice();this.contexts.splice(-1);this.currentContextIds.shift()}else{throw new Error("Cannot exit frame, the context is empty")}}nextIteration(){if(this.contexts&&this.contexts.length>0){this.contexts=this.contexts.slice();this.lastId++;const context=Object.assign({},this.contexts[this.contexts.length-1]);context.iterationId+=1;context.id=this.lastId;this.contexts.splice(-1,1,context);this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}else{throw new Error("Cannot increase frame iteration, the context is empty")}}getWeight(name){return this.weightMap[name]}addTensorArray(tensorArray){this.tensorArrayMap[tensorArray.id]=tensorArray}getTensorArray(id){return this.tensorArrayMap[id]}addTensorList(tensorList){this.tensorListMap[tensorList.id]=tensorList}getTensorList(id){return this.tensorListMap[id]}dispose(keepIds){for(const key in this.tensorArrayMap){this.tensorArrayMap[key].clearAndClose(keepIds)}for(const key in this.tensorListMap){this.tensorListMap[key].clearAndClose(keepIds)}}}function getExecutionSubgraph(inputs,outputs,weightMap,initNodes){const usedNodes=new Set;const missingInputs=[];let dynamicNode=null;let syncInputs=null;const seen=new Set;const inputNodeNames=Object.keys(inputs).map((name=>parseNodeName(name)[0]));let initNodeNames=[];if(initNodes!=null){initNodeNames=initNodes.map((node=>parseNodeName(node.name)[0]))}const frontier=[...outputs];while(frontier.length>0){const node=frontier.pop();if(isControlFlow(node)||isDynamicShape(node)||isHashTable(node)){if(dynamicNode==null){dynamicNode=node;syncInputs=dynamicNode.children.map((child=>child.name)).filter((name=>usedNodes.has(name)))}}usedNodes.add(node.name);if(weightMap[node.name]!=null){continue}if(inputNodeNames.indexOf(node.name)!==-1){continue}if(initNodeNames.indexOf(node.name)!==-1){continue}if(node.inputs.length===0){missingInputs.push(node.name);continue}node.inputs.forEach((input=>{if(seen.has(input.name)){return}seen.add(input.name);frontier.push(input)}))}return{inputs:inputs,outputs:outputs,usedNodes:usedNodes,missingInputs:missingInputs,dynamicNode:dynamicNode,syncInputs:syncInputs}}function getNodesInTopologicalOrder(graph,weightMap,executionInfo){const{usedNodes:usedNodes,inputs:inputs}=executionInfo;const frontier=[];const inputNodes=Object.keys(inputs).map((name=>parseNodeName(name)[0])).map((name=>graph.nodes[name]));const initNodes=graph.initNodes;inputNodes.forEach((input=>{if(usedNodes.has(input.name)){frontier.push(input)}}));graph.weights.forEach((weight=>{if(usedNodes.has(weight.name)){frontier.push(weight)}}));if(initNodes!=null){initNodes.forEach((node=>{if(usedNodes.has(node.name)){frontier.push(node)}}))}const seen=new Set;const orderedNodes=[];while(frontier.length>0){const node=frontier.pop();seen.add(node.name);if(!weightMap[node.name]){orderedNodes.push(node)}node.children.forEach((child=>{if(!seen.has(child.name)&&usedNodes.has(child.name)&&child.inputs.every((input=>seen.has(input.name)))){frontier.push(child)}}))}return orderedNodes}const CONTROL_FLOW_OPS=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"];const DYNAMIC_SHAPE_OPS=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"];const HASH_TABLE_OPS=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"];function isControlFlow(node){return CONTROL_FLOW_OPS.indexOf(node.op)>=0}function isDynamicShape(node){return DYNAMIC_SHAPE_OPS.indexOf(node.op)>=0}function isHashTable(node){return HASH_TABLE_OPS.indexOf(node.op)>=0}class GraphExecutor{constructor(graph,parent){this.graph=graph;this.parent=parent;this.compiledMap=new Map;this._weightMap={};this.SEPERATOR=",";this._functions={};this._functionExecutorMap={};this._outputs=graph.outputs;this._inputs=graph.inputs;this._initNodes=graph.initNodes;this._signature=graph.signature;this._functions=graph.functions;if(graph.functions!=null){Object.keys(graph.functions).forEach((name=>{this._functionExecutorMap[name]=new GraphExecutor(graph.functions[name],this)}))}}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(weightMap){const weightIds=Object.keys(weightMap).map((key=>weightMap[key].map((tensor=>tensor.id))));this._weightIds=[].concat(...weightIds);this._weightMap=weightMap}set resourceManager(resourceManager){this._resourceManager=resourceManager}get inputs(){return this._inputs.map((node=>({name:node.name,shape:node.attrParams["shape"]?node.attrParams["shape"].value:undefined,dtype:node.attrParams["dtype"]?node.attrParams["dtype"].value:undefined})))}get outputs(){return this._outputs.map((node=>({name:node.name,shape:node.attrParams["shape"]?node.attrParams["shape"].value:undefined,dtype:node.attrParams["dtype"]?node.attrParams["dtype"].value:undefined})))}get inputNodes(){return this._inputs.map((node=>node.signatureKey||node.name))}get outputNodes(){return this._outputs.map((node=>{const name=node.signatureKey||node.name;return node.defaultOutput?`${name}:${node.defaultOutput}`:name}))}get functions(){return Object.keys(this._functions).reduce(((map,key)=>{map[key]=this._functions[key].signature;return map}),{})}getCompilationKey(inputs,outputs){const sortedInputs=inputs.map((node=>node.name)).sort();const sortedOutputs=outputs.map((node=>node.name)).sort();return sortedInputs.join(this.SEPERATOR)+"--"+sortedOutputs.join(this.SEPERATOR)}compile(inputs,outputs){const executionInfo=getExecutionSubgraph(inputs,outputs,this.weightMap,this._initNodes);const{missingInputs:missingInputs,dynamicNode:dynamicNode,syncInputs:syncInputs}=executionInfo;if(dynamicNode!=null){throw new Error(`This execution contains the node '${dynamicNode.name}', which has `+`the dynamic op '${dynamicNode.op}'. Please use `+`model.executeAsync() instead. Alternatively, to avoid the `+`dynamic ops, specify the inputs [${syncInputs}]`)}if(missingInputs.length>0){const outNames=outputs.map((n=>n.name));const inNames=Object.keys(inputs);throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs `+`[${inNames}]. Missing the following inputs: [${missingInputs}]`)}return getNodesInTopologicalOrder(this.graph,this.weightMap,executionInfo)}execute(inputs,outputs){inputs=this.mapInputs(inputs);const names=Object.keys(inputs).sort();this.checkInputs(inputs);this.checkInputShapeAndType(inputs);outputs=this.mapOutputs(outputs);this.checkOutputs(outputs);const inputNodes=names.map((name=>this.graph.nodes[parseNodeName(name)[0]]));const outputNodeNames=outputs.map((name=>parseNodeName(name)[0]));let outputNodes=outputNodeNames.map((name=>this.graph.nodes[name]));if(outputNodes.length===0){outputNodes=this._outputs}const compilationKey=this.getCompilationKey(inputNodes,outputNodes);let orderedNodes=this.compiledMap.get(compilationKey);if(orderedNodes==null){orderedNodes=this.compile(inputs,outputNodes);this.compiledMap.set(compilationKey,orderedNodes)}const tensorArrayMap={};const tensorListMap={};return tidy((()=>{const context=new ExecutionContext(this.weightMap,tensorArrayMap,tensorListMap,this.functionExecutorMap);const tensorsMap=Object.assign({},this.weightMap);Object.keys(inputs).forEach((name=>{const[nodeName,index]=parseNodeName(name);const tensors=[];tensors[index]=inputs[name];tensorsMap[nodeName]=tensors}));const tensorsToKeep=this.getFrozenTensorIds(tensorsMap);const intermediateTensorConsumerCount={};for(let i=0;i<orderedNodes.length;i++){const node=orderedNodes[i];if(!tensorsMap[node.name]){const tensors=executeOp(node,tensorsMap,context,this._resourceManager);if(isPromise(tensors)){throw new Error(`The execution of the op '${node.op}' returned a promise. `+`Please use model.executeAsync() instead.`)}tensorsMap[node.name]=tensors;this.checkTensorForDisposal(node.name,node,tensorsMap,context,tensorsToKeep,outputNodeNames,intermediateTensorConsumerCount)}}if(this.parent==null){context.dispose(tensorsToKeep)}return outputs.map((name=>getTensor(name,tensorsMap,context)))}))}getFrozenTensorIds(tensorMap){const ids=[].concat.apply([],Object.keys(tensorMap).map((key=>tensorMap[key])).map((tensors=>tensors.map((tensor=>tensor.id)))));return new Set(ids)}checkTensorForDisposal(nodeName,node,tensorMap,context,tensorsToKeep,outputNames,intermediateTensorConsumerCount){if(node.category==="control"||outputNames.indexOf(nodeName)!==-1){return}tensorMap[nodeName].forEach((tensor=>{if(tensor!=null){intermediateTensorConsumerCount[tensor.id]=(intermediateTensorConsumerCount[tensor.id]||0)+node.children.length}}));node.inputs.forEach((input=>{if(input.category!=="control"){const tensors=getTensorsForCurrentContenxt(input.name,tensorMap,context);if(tensors!=null){tensors.forEach((tensor=>{if(tensor&&!tensor.kept&&!tensorsToKeep.has(tensor.id)){const count=intermediateTensorConsumerCount[tensor.id];if(count===1){tensor.dispose();delete intermediateTensorConsumerCount[tensor.id]}else if(count!=null){intermediateTensorConsumerCount[tensor.id]--}}}))}}}))}async executeAsync(inputs,outputs){return this._executeAsync(inputs,outputs)}async _executeAsync(inputs,outputs,isFunctionExecution=false,tensorArrayMap={},tensorListMap={}){if(!isFunctionExecution){inputs=this.mapInputs(inputs);this.checkInputs(inputs);this.checkInputShapeAndType(inputs);outputs=this.mapOutputs(outputs);this.checkOutputs(outputs)}const context=new ExecutionContext(this.weightMap,tensorArrayMap,tensorListMap,this.functionExecutorMap);const tensorMap=await this.executeWithControlFlow(inputs,context,outputs,isFunctionExecution);const results=outputs.map((name=>getTensor(name,tensorMap,context)));const outputIds=results.map((t=>t.id));const inputIds=Object.keys(inputs).map((name=>inputs[name].id));const keepIds=new Set([...outputIds,...inputIds,...this.weightIds]);Object.keys(tensorMap).forEach((key=>{const tensorArray=tensorMap[key];tensorArray.forEach((tensor=>{if(tensor&&!tensor.kept&&!tensor.isDisposed&&!keepIds.has(tensor.id)){tensor.dispose()}}))}));if(this.parent==null){context.dispose(keepIds)}return results}async executeFunctionAsync(inputs,tensorArrayMap,tensorListMap){const mappedInputs=inputs.reduce(((map,tensor,index)=>{map[this.inputs[index].name]=tensor;return map}),{});return this._executeAsync(mappedInputs,this.outputNodes,true,tensorArrayMap,tensorListMap)}async executeWithControlFlow(inputs,context,outputNames,isFunctionExecution){const names=Object.keys(inputs);const inputNodes=names.map((name=>this.graph.nodes[parseNodeName(name)[0]]));const outputNodeNames=outputNames.map((name=>parseNodeName(name)[0]));let outputNodes=outputNodeNames.map((name=>this.graph.nodes[name]));if(outputNodes.length===0){outputNodes=this._outputs}const{usedNodes:usedNodes,missingInputs:missingInputs,dynamicNode:dynamicNode,syncInputs:syncInputs}=getExecutionSubgraph(inputs,outputNodes,this.weightMap,this._initNodes);const stack=[...inputNodes,...this.graph.weights,...this._initNodes||[]].map((node=>({node:node,contexts:context.currentContext})));const tensorsMap=Object.assign({},this.weightMap);Object.keys(inputs).forEach((name=>{const[nodeName,index]=parseNodeName(name);const tensors=[];tensors[index]=inputs[name];tensorsMap[nodeName]=tensors}));const intermediateTensorConsumerCount={};const tensorsToKeep=this.getFrozenTensorIds(tensorsMap);const added={};while(stack.length>0){const promises=this.processStack(inputNodes,stack,context,tensorsMap,added,tensorsToKeep,outputNodeNames,intermediateTensorConsumerCount,usedNodes);await Promise.all(promises)}if(dynamicNode==null&&!isFunctionExecution){console.warn(`This model execution did not contain any nodes with control flow `+`or dynamic output shapes. You can use model.execute() instead.`)}const missingOutputs=outputNodes.filter((node=>!isControlFlow(node)&&!getTensor(node.name,tensorsMap,context))).map((node=>node.name));if(missingOutputs.length>0){let alternativeMsg="";if(dynamicNode!=null){alternativeMsg=`Alternatively, to avoid the dynamic ops, use model.execute() `+`and specify the inputs [${syncInputs}]`}throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided `+`inputs [${names}]. Consider providing the following inputs: `+`[${missingInputs}]. ${alternativeMsg}`)}return tensorsMap}processStack(inputNodes,stack,context,tensorMap,added,tensorsToKeep,outputNames,intermediateTensorConsumerCount,usedNodes){const promises=[];while(stack.length>0){const item=stack.pop();context.currentContext=item.contexts;let nodeName="";if(item.node.op==="Enter"&&getParamValue("isConstant",item.node,tensorMap,context)){[nodeName]=getNodeNameAndIndex(item.node.name,context)}if(tensorMap[item.node.name]==null){const tensors=executeOp(item.node,tensorMap,context,this._resourceManager);if(!nodeName){[nodeName]=getNodeNameAndIndex(item.node.name,context)}const currentContext=context.currentContext;if(isPromise(tensors)){promises.push(tensors.then((t=>{tensorMap[nodeName]=t;context.currentContext=currentContext;this.checkTensorForDisposal(nodeName,item.node,tensorMap,context,tensorsToKeep,outputNames,intermediateTensorConsumerCount);this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes);return t})))}else{tensorMap[nodeName]=tensors;this.checkTensorForDisposal(nodeName,item.node,tensorMap,context,tensorsToKeep,outputNames,intermediateTensorConsumerCount);this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes)}}else{this.processChildNodes(item.node,stack,context,tensorMap,added,usedNodes)}}return promises}processChildNodes(node,stack,context,tensorMap,added,usedNodes){node.children.forEach((childNode=>{const[nodeName]=getNodeNameAndIndex(childNode.name,context);if(added[nodeName]||!usedNodes.has(childNode.name)){return}if(childNode.op==="Merge"){if(childNode.inputNames.some((name=>!!getTensor(name,tensorMap,context)))){added[nodeName]=true;stack.push({contexts:context.currentContext,node:childNode})}}else if(childNode.inputNames.every((name=>!!getTensor(name,tensorMap,context)))){added[nodeName]=true;stack.push({contexts:context.currentContext,node:childNode})}}))}dispose(){Object.keys(this.weightMap).forEach((key=>this.weightMap[key].forEach((tensor=>tensor.dispose()))))}checkInputShapeAndType(inputs){Object.keys(inputs).forEach((name=>{const input=inputs[name];const[nodeName]=parseNodeName(name);const node=this.graph.nodes[nodeName];if(node.attrParams["shape"]&&node.attrParams["shape"].value){const shape=node.attrParams["shape"].value;const match=shape.length===input.shape.length&&input.shape.every(((dim,index)=>shape[index]===-1||shape[index]===dim));assert(match,(()=>`The shape of dict['${node.name}'] provided in `+`model.execute(dict) must be [${shape}], but was `+`[${input.shape}]`))}if(node.attrParams["dtype"]&&node.attrParams["dtype"].value){assert(input.dtype===node.attrParams["dtype"].value,(()=>`The dtype of dict['${node.name}'] provided in `+`model.execute(dict) must be `+`${node.attrParams["dtype"].value}, but was ${input.dtype}`))}}))}mapInputs(inputs){const result={};for(const inputName in inputs){if(this._signature!=null&&this._signature.inputs!=null&&this._signature.inputs[inputName]!=null){const tensor=this._signature.inputs[inputName];result[tensor.name]=inputs[inputName]}else{result[inputName]=inputs[inputName]}}return result}checkInputs(inputs){const notInGraph=Object.keys(inputs).filter((name=>{const[nodeName]=parseNodeName(name);return this.graph.nodes[nodeName]==null}));if(notInGraph.length>0){throw new Error(`The dict provided in model.execute(dict) has `+`keys: [${notInGraph}] that are not part of graph`)}}mapOutputs(outputs){return outputs.map((name=>{if(this._signature!=null&&this._signature.outputs!=null&&this._signature.outputs[name]!=null){const tensor=this._signature.outputs[name];return tensor.name}return name}),{})}checkOutputs(outputs){outputs.forEach((name=>{const[normalizedName]=parseNodeName(name);if(!this.graph.nodes[normalizedName]){throw new Error(`The output '${name}' is not found in the graph`)}}))}}class ResourceManager{constructor(hashTableNameToHandle={},hashTableMap={}){this.hashTableNameToHandle=hashTableNameToHandle;this.hashTableMap=hashTableMap}addHashTable(name,hashTable){this.hashTableNameToHandle[name]=hashTable.handle;this.hashTableMap[hashTable.id]=hashTable}getHashTableHandleByName(name){return this.hashTableNameToHandle[name]}getHashTableById(id){return this.hashTableMap[id]}dispose(){for(const key in this.hashTableMap){this.hashTableMap[key].clearAndClose();delete this.hashTableMap[key]}for(const name in this.hashTableNameToHandle){this.hashTableNameToHandle[name].dispose();delete this.hashTableNameToHandle[name]}}}const TFHUB_SEARCH_PARAM="?tfjs-format=file";const DEFAULT_MODEL_NAME="model.json";class GraphModel{constructor(modelUrl,loadOptions={}){this.modelUrl=modelUrl;this.loadOptions=loadOptions;this.version="n/a";if(loadOptions==null){this.loadOptions={}}this.resourceManager=new ResourceManager}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}findIOHandler(){const path=this.modelUrl;if(path.load!=null){this.handler=path}else if(this.loadOptions.requestInit!=null){this.handler=browserHTTPRequest(path,this.loadOptions)}else{const handlers=getLoadHandlers(path,this.loadOptions);if(handlers.length===0){handlers.push(browserHTTPRequest(path,this.loadOptions))}else if(handlers.length>1){throw new Error(`Found more than one (${handlers.length}) load handlers for `+`URL '${[path]}'`)}this.handler=handlers[0]}}async load(){this.findIOHandler();if(this.handler.load==null){throw new Error("Cannot proceed with model loading because the IOHandler provided "+"does not have the `load` method implemented.")}const artifacts=await this.handler.load();return this.loadSync(artifacts)}loadSync(artifacts){this.artifacts=artifacts;const graph=this.artifacts.modelTopology;let signature;if(this.artifacts.userDefinedMetadata!=null&&this.artifacts.userDefinedMetadata.signature!=null){signature=this.artifacts.userDefinedMetadata.signature}else{signature=this.artifacts.signature}this.signature=signature;this.version=`${graph.versions.producer}.${graph.versions.minConsumer}`;const weightMap=decodeWeights(this.artifacts.weightData,this.artifacts.weightSpecs);this.executor=new GraphExecutor(OperationMapper.Instance.transformGraph(graph,this.signature));this.executor.weightMap=this.convertTensorMapToTensorsMap(weightMap);this.executor.resourceManager=this.resourceManager;if(artifacts.modelInitializer!=null&&artifacts.modelInitializer.node!=null){const initializer=OperationMapper.Instance.transformGraph(artifacts.modelInitializer);this.initializer=new GraphExecutor(initializer);this.initializer.weightMap=this.executor.weightMap;this.initializer.resourceManager=this.resourceManager;this.initializer.executeAsync({},[])}return true}async save(handlerOrURL,config){if(typeof handlerOrURL==="string"){const handlers=getSaveHandlers(handlerOrURL);if(handlers.length===0){throw new Error(`Cannot find any save handlers for URL '${handlerOrURL}'`)}else if(handlers.length>1){throw new Error(`Found more than one (${handlers.length}) save handlers for `+`URL '${handlerOrURL}'`)}handlerOrURL=handlers[0]}if(handlerOrURL.save==null){throw new Error("GraphModel.save() cannot proceed because the IOHandler "+"provided does not have the `save` attribute defined.")}return handlerOrURL.save(this.artifacts)}predict(inputs,config){return this.execute(inputs,this.outputNodes)}normalizeInputs(inputs){if(!(inputs instanceof Tensor)&&!Array.isArray(inputs)){return inputs}inputs=Array.isArray(inputs)?inputs:[inputs];if(inputs.length!==this.inputNodes.length){throw new Error("Input tensor count mismatch,"+`the graph model has ${this.inputNodes.length} placeholders, `+`while there are ${inputs.length} input tensors.`)}return this.inputNodes.reduce(((map,inputName,i)=>{map[inputName]=inputs[i];return map}),{})}normalizeOutputs(outputs){outputs=outputs||this.outputNodes;return!Array.isArray(outputs)?[outputs]:outputs}execute(inputs,outputs){inputs=this.normalizeInputs(inputs);outputs=this.normalizeOutputs(outputs);const result=this.executor.execute(inputs,outputs);return result.length>1?result:result[0]}async executeAsync(inputs,outputs){inputs=this.normalizeInputs(inputs);outputs=this.normalizeOutputs(outputs);const result=await this.executor.executeAsync(inputs,outputs);return result.length>1?result:result[0]}convertTensorMapToTensorsMap(map){return Object.keys(map).reduce(((newMap,key)=>{newMap[key]=[map[key]];return newMap}),{})}dispose(){this.executor.dispose();if(this.initializer){this.initializer.dispose()}this.resourceManager.dispose()}}async function loadGraphModel(modelUrl,options={}){if(modelUrl==null){throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url "+"or an IOHandler that loads the model")}if(options==null){options={}}if(options.fromTFHub){if(modelUrl.load==null){if(!modelUrl.endsWith("/")){modelUrl=modelUrl+"/"}modelUrl=`${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`}}const model=new GraphModel(modelUrl,options);await model.load();return model}const contexts={};const WEBGL_ATTRIBUTES={alpha:false,antialias:false,premultipliedAlpha:false,preserveDrawingBuffer:false,depth:false,stencil:false,failIfMajorPerformanceCaveat:true};function setWebGLContext(webGLVersion,gl){contexts[webGLVersion]=gl}function getWebGLContext(webGLVersion){if(!(webGLVersion in contexts)){const newCtx=getWebGLRenderingContext(webGLVersion);if(newCtx!==null){contexts[webGLVersion]=newCtx}else{console.log("Could not get context for WebGL version",webGLVersion);return null}}const gl=contexts[webGLVersion];if(gl.isContextLost()){delete contexts[webGLVersion];return getWebGLContext(webGLVersion)}gl.disable(gl.DEPTH_TEST);gl.disable(gl.STENCIL_TEST);gl.disable(gl.BLEND);gl.disable(gl.DITHER);gl.disable(gl.POLYGON_OFFSET_FILL);gl.disable(gl.SAMPLE_COVERAGE);gl.enable(gl.SCISSOR_TEST);gl.enable(gl.CULL_FACE);gl.cullFace(gl.BACK);return contexts[webGLVersion]}function createCanvas(webGLVersion){if(typeof OffscreenCanvas!=="undefined"&&webGLVersion===2){return new OffscreenCanvas(300,150)}else if(typeof document!=="undefined"){return document.createElement("canvas")}else{throw new Error("Cannot create a canvas in this context")}}function getWebGLRenderingContext(webGLVersion){if(webGLVersion!==1&&webGLVersion!==2){throw new Error("Cannot get WebGL rendering context, WebGL is disabled.")}const canvas=createCanvas(webGLVersion);canvas.addEventListener("webglcontextlost",(ev=>{ev.preventDefault();delete contexts[webGLVersion]}),false);if(webGLVersion===1){return canvas.getContext("webgl",WEBGL_ATTRIBUTES)||canvas.getContext("experimental-webgl",WEBGL_ATTRIBUTES)}return canvas.getContext("webgl2",WEBGL_ATTRIBUTES)}var PackingScheme;(function(PackingScheme){PackingScheme[PackingScheme["DENSE"]=0]="DENSE";PackingScheme[PackingScheme["SHARED_BATCH"]=1]="SHARED_BATCH"})(PackingScheme||(PackingScheme={}));var TextureUsage;(function(TextureUsage){TextureUsage[TextureUsage["RENDER"]=0]="RENDER";TextureUsage[TextureUsage["UPLOAD"]=1]="UPLOAD";TextureUsage[TextureUsage["PIXELS"]=2]="PIXELS";TextureUsage[TextureUsage["DOWNLOAD"]=3]="DOWNLOAD"})(TextureUsage||(TextureUsage={}));var PhysicalTextureType;(function(PhysicalTextureType){PhysicalTextureType[PhysicalTextureType["UNPACKED_FLOAT16"]=0]="UNPACKED_FLOAT16";PhysicalTextureType[PhysicalTextureType["UNPACKED_FLOAT32"]=1]="UNPACKED_FLOAT32";PhysicalTextureType[PhysicalTextureType["PACKED_4X1_UNSIGNED_BYTE"]=2]="PACKED_4X1_UNSIGNED_BYTE";PhysicalTextureType[PhysicalTextureType["PACKED_2X2_FLOAT32"]=3]="PACKED_2X2_FLOAT32";PhysicalTextureType[PhysicalTextureType["PACKED_2X2_FLOAT16"]=4]="PACKED_2X2_FLOAT16"})(PhysicalTextureType||(PhysicalTextureType={}));function getUnpackedMatrixTextureShapeWidthHeight(rows,columns){return[columns,rows]}function getUnpackedArraySizeFromMatrixSize(matrixSize,channelsPerTexture){return matrixSize*channelsPerTexture}function getDenseTexShape(shape){const size=sizeFromShape(shape);const texelsNeeded=Math.ceil(size/4);return sizeToSquarishShape(texelsNeeded)}function getPackedMatrixTextureShapeWidthHeight(rows,columns){return[Math.max(1,Math.ceil(columns/2)),Math.max(1,Math.ceil(rows/2))]}function getPackedRGBAArraySizeFromMatrixShape(rows,columns){const[w,h]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return w*h*4}function getTextureConfig(gl,textureHalfFloatExtension){const glany=gl;let internalFormatFloat;let internalFormatHalfFloat;let internalFormatPackedHalfFloat;let internalFormatPackedFloat;let textureFormatFloat;let downloadTextureFormat;let downloadUnpackNumChannels;let defaultNumChannels;let textureTypeHalfFloat;let textureTypeFloat;if(env().getNumber("WEBGL_VERSION")===2){internalFormatFloat=glany.R32F;internalFormatHalfFloat=glany.R16F;internalFormatPackedHalfFloat=glany.RGBA16F;internalFormatPackedFloat=glany.RGBA32F;textureFormatFloat=glany.RED;downloadUnpackNumChannels=4;defaultNumChannels=1;textureTypeHalfFloat=glany.HALF_FLOAT;textureTypeFloat=glany.FLOAT}else{internalFormatFloat=gl.RGBA;internalFormatHalfFloat=gl.RGBA;internalFormatPackedHalfFloat=gl.RGBA;internalFormatPackedFloat=glany.RGBA;textureFormatFloat=gl.RGBA;downloadUnpackNumChannels=4;defaultNumChannels=4;textureTypeHalfFloat=textureHalfFloatExtension!=null?textureHalfFloatExtension.HALF_FLOAT_OES:null;textureTypeFloat=gl.FLOAT}downloadTextureFormat=gl.RGBA;return{internalFormatFloat:internalFormatFloat,internalFormatHalfFloat:internalFormatHalfFloat,internalFormatPackedHalfFloat:internalFormatPackedHalfFloat,internalFormatPackedFloat:internalFormatPackedFloat,textureFormatFloat:textureFormatFloat,downloadTextureFormat:downloadTextureFormat,downloadUnpackNumChannels:downloadUnpackNumChannels,defaultNumChannels:defaultNumChannels,textureTypeHalfFloat:textureTypeHalfFloat,textureTypeFloat:textureTypeFloat}}function callAndCheck(gl,func){const returnValue=func();if(env().getBool("DEBUG")){checkWebGLError(gl)}return returnValue}function checkWebGLError(gl){const error=gl.getError();if(error!==gl.NO_ERROR){throw new Error("WebGL Error: "+getWebGLErrorMessage(gl,error))}}const MIN_FLOAT16=5.96e-8;const MAX_FLOAT16=65504;function canBeRepresented(num){if(env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||num===0||MIN_FLOAT16<Math.abs(num)&&Math.abs(num)<MAX_FLOAT16){return true}return false}function getWebGLErrorMessage(gl,status){switch(status){case gl.NO_ERROR:return"NO_ERROR";case gl.INVALID_ENUM:return"INVALID_ENUM";case gl.INVALID_VALUE:return"INVALID_VALUE";case gl.INVALID_OPERATION:return"INVALID_OPERATION";case gl.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case gl.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case gl.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return`Unknown error code ${status}`}}function getExtensionOrThrow(gl,extensionName){return throwIfNull(gl,(()=>gl.getExtension(extensionName)),'Extension "'+extensionName+'" not supported on this browser.')}function createVertexShader$1(gl,vertexShaderSource){const vertexShader=throwIfNull(gl,(()=>gl.createShader(gl.VERTEX_SHADER)),"Unable to create vertex WebGLShader.");callAndCheck(gl,(()=>gl.shaderSource(vertexShader,vertexShaderSource)));callAndCheck(gl,(()=>gl.compileShader(vertexShader)));if(gl.getShaderParameter(vertexShader,gl.COMPILE_STATUS)===false){console.log(gl.getShaderInfoLog(vertexShader));throw new Error("Failed to compile vertex shader.")}return vertexShader}function createFragmentShader(gl,fragmentShaderSource){const fragmentShader=throwIfNull(gl,(()=>gl.createShader(gl.FRAGMENT_SHADER)),"Unable to create fragment WebGLShader.");callAndCheck(gl,(()=>gl.shaderSource(fragmentShader,fragmentShaderSource)));callAndCheck(gl,(()=>gl.compileShader(fragmentShader)));if(gl.getShaderParameter(fragmentShader,gl.COMPILE_STATUS)===false){logShaderSourceAndInfoLog(fragmentShaderSource,gl.getShaderInfoLog(fragmentShader));throw new Error("Failed to compile fragment shader.")}return fragmentShader}const lineNumberRegex=/ERROR: [0-9]+:([0-9]+):/g;function logShaderSourceAndInfoLog(shaderSource,shaderInfoLog){const lineNumberRegexResult=lineNumberRegex.exec(shaderInfoLog);if(lineNumberRegexResult==null){console.log(`Couldn't parse line number in error: ${shaderInfoLog}`);console.log(shaderSource);return}const lineNumber=+lineNumberRegexResult[1];const shaderLines=shaderSource.split("\n");const pad=shaderLines.length.toString().length+2;const linesWithLineNumbers=shaderLines.map(((line,lineNumber)=>rightPad((lineNumber+1).toString(),pad)+line));let maxLineLength=0;for(let i=0;i<linesWithLineNumbers.length;i++){maxLineLength=Math.max(linesWithLineNumbers[i].length,maxLineLength)}const beforeErrorLines=linesWithLineNumbers.slice(0,lineNumber-1);const errorLine=linesWithLineNumbers.slice(lineNumber-1,lineNumber);const afterErrorLines=linesWithLineNumbers.slice(lineNumber);console.log(beforeErrorLines.join("\n"));console.log(shaderInfoLog.split("\n")[0]);console.log(`%c ${rightPad(errorLine[0],maxLineLength)}`,"border:1px solid red; background-color:#e3d2d2; color:#a61717");console.log(afterErrorLines.join("\n"))}function createProgram(gl){return throwIfNull(gl,(()=>gl.createProgram()),"Unable to create WebGLProgram.")}function linkProgram(gl,program){callAndCheck(gl,(()=>gl.linkProgram(program)));if(gl.getProgramParameter(program,gl.LINK_STATUS)===false){console.log(gl.getProgramInfoLog(program));throw new Error("Failed to link vertex and fragment shaders.")}}function validateProgram(gl,program){callAndCheck(gl,(()=>gl.validateProgram(program)));if(gl.getProgramParameter(program,gl.VALIDATE_STATUS)===false){console.log(gl.getProgramInfoLog(program));throw new Error("Shader program validation failed.")}}function createStaticVertexBuffer(gl,data){const buffer=throwIfNull(gl,(()=>gl.createBuffer()),"Unable to create WebGLBuffer");callAndCheck(gl,(()=>gl.bindBuffer(gl.ARRAY_BUFFER,buffer)));callAndCheck(gl,(()=>gl.bufferData(gl.ARRAY_BUFFER,data,gl.STATIC_DRAW)));return buffer}function createStaticIndexBuffer(gl,data){const buffer=throwIfNull(gl,(()=>gl.createBuffer()),"Unable to create WebGLBuffer");callAndCheck(gl,(()=>gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER,buffer)));callAndCheck(gl,(()=>gl.bufferData(gl.ELEMENT_ARRAY_BUFFER,data,gl.STATIC_DRAW)));return buffer}function getNumChannels(){if(env().getNumber("WEBGL_VERSION")===2){return 1}return 4}function createTexture(gl){return throwIfNull(gl,(()=>gl.createTexture()),"Unable to create WebGLTexture.")}function validateTextureSize(width,height){const maxTextureSize=env().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(width<=0||height<=0){const requested=`[${width}x${height}]`;throw new Error("Requested texture size "+requested+" is invalid.")}if(width>maxTextureSize||height>maxTextureSize){const requested=`[${width}x${height}]`;const max=`[${maxTextureSize}x${maxTextureSize}]`;throw new Error("Requested texture size "+requested+" greater than WebGL maximum on this browser / GPU "+max+".")}}function createFramebuffer(gl){return throwIfNull(gl,(()=>gl.createFramebuffer()),"Unable to create WebGLFramebuffer.")}function bindVertexBufferToProgramAttribute(gl,program,attribute,buffer,arrayEntriesPerItem,itemStrideInBytes,itemOffsetInBytes){const loc=gl.getAttribLocation(program,attribute);if(loc===-1){return false}callAndCheck(gl,(()=>gl.bindBuffer(gl.ARRAY_BUFFER,buffer)));callAndCheck(gl,(()=>gl.vertexAttribPointer(loc,arrayEntriesPerItem,gl.FLOAT,false,itemStrideInBytes,itemOffsetInBytes)));callAndCheck(gl,(()=>gl.enableVertexAttribArray(loc)));return true}function bindTextureUnit(gl,texture,textureUnit){validateTextureUnit(gl,textureUnit);callAndCheck(gl,(()=>gl.activeTexture(gl.TEXTURE0+textureUnit)));callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,texture)))}function unbindTextureUnit(gl,textureUnit){validateTextureUnit(gl,textureUnit);callAndCheck(gl,(()=>gl.activeTexture(gl.TEXTURE0+textureUnit)));callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,null)))}function getProgramUniformLocationOrThrow(gl,program,uniformName){return throwIfNull(gl,(()=>gl.getUniformLocation(program,uniformName)),'uniform "'+uniformName+'" not present in program.')}function getProgramUniformLocation(gl,program,uniformName){return gl.getUniformLocation(program,uniformName)}function bindTextureToProgramUniformSampler(gl,texture,uniformSamplerLocation,textureUnit){callAndCheck(gl,(()=>bindTextureUnit(gl,texture,textureUnit)));callAndCheck(gl,(()=>gl.uniform1i(uniformSamplerLocation,textureUnit)))}function bindCanvasToFramebuffer(gl){callAndCheck(gl,(()=>gl.bindFramebuffer(gl.FRAMEBUFFER,null)));callAndCheck(gl,(()=>gl.viewport(0,0,gl.canvas.width,gl.canvas.height)));callAndCheck(gl,(()=>gl.scissor(0,0,gl.canvas.width,gl.canvas.height)))}function bindColorTextureToFramebuffer(gl,texture,framebuffer){callAndCheck(gl,(()=>gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)));callAndCheck(gl,(()=>gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0)))}function unbindColorTextureFromFramebuffer(gl,framebuffer){callAndCheck(gl,(()=>gl.bindFramebuffer(gl.FRAMEBUFFER,framebuffer)));callAndCheck(gl,(()=>gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,null,0)))}function validateFramebuffer(gl){const status=gl.checkFramebufferStatus(gl.FRAMEBUFFER);if(status!==gl.FRAMEBUFFER_COMPLETE){throw new Error("Error binding framebuffer: "+getFramebufferErrorMessage(gl,status))}}function getFramebufferErrorMessage(gl,status){switch(status){case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case gl.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return`unknown error ${status}`}}function throwIfNull(gl,returnTOrNull,failureMessage){const tOrNull=callAndCheck(gl,(()=>returnTOrNull()));if(tOrNull==null){throw new Error(failureMessage)}return tOrNull}function validateTextureUnit(gl,textureUnit){const maxTextureUnit=gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1;const glTextureUnit=textureUnit+gl.TEXTURE0;if(glTextureUnit<gl.TEXTURE0||glTextureUnit>maxTextureUnit){const textureUnitRange=`[gl.TEXTURE0, gl.TEXTURE${maxTextureUnit}]`;throw new Error(`textureUnit must be in ${textureUnitRange}.`)}}function getBatchDim(shape,dimsToSkip=2){return sizeFromShape(shape.slice(0,shape.length-dimsToSkip))}function getRowsCols(shape){if(shape.length===0){throw Error("Cannot get rows and columns of an empty shape array.")}return[shape.length>1?shape[shape.length-2]:1,shape[shape.length-1]]}function getShapeAs3D(shape){let shapeAs3D=[1,1,1];const isScalar=shape.length===0||shape.length===1&&shape[0]===1;if(!isScalar){shapeAs3D=[getBatchDim(shape),...getRowsCols(shape)]}return shapeAs3D}function getTextureShapeFromLogicalShape(logShape,isPacked=false){let maxTexSize=env().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(isPacked){maxTexSize=maxTexSize*2;logShape=logShape.map(((d,i)=>i>=logShape.length-2?nearestLargerEven(logShape[i]):logShape[i]));if(logShape.length===1){logShape=[2,logShape[0]]}}if(logShape.length!==2){const squeezeResult=squeezeShape(logShape);logShape=squeezeResult.newShape}let size=sizeFromShape(logShape);if(logShape.length<=1&&size<=maxTexSize){return[1,size]}else if(logShape.length===2&&logShape[0]<=maxTexSize&&logShape[1]<=maxTexSize){return logShape}else if(logShape.length===3&&logShape[0]*logShape[1]<=maxTexSize&&logShape[2]<=maxTexSize){return[logShape[0]*logShape[1],logShape[2]]}else if(logShape.length===3&&logShape[0]<=maxTexSize&&logShape[1]*logShape[2]<=maxTexSize){return[logShape[0],logShape[1]*logShape[2]]}else if(logShape.length===4&&logShape[0]*logShape[1]*logShape[2]<=maxTexSize&&logShape[3]<=maxTexSize){return[logShape[0]*logShape[1]*logShape[2],logShape[3]]}else if(logShape.length===4&&logShape[0]<=maxTexSize&&logShape[1]*logShape[2]*logShape[3]<=maxTexSize){return[logShape[0],logShape[1]*logShape[2]*logShape[3]]}else{if(isPacked){const batchDim=getBatchDim(logShape);let rows=2,cols=2;if(logShape.length){[rows,cols]=getRowsCols(logShape)}size=batchDim*(rows/2)*(cols/2);return sizeToSquarishShape(size).map((d=>d*2))}return sizeToSquarishShape(size)}}function isEven(n){return n%2===0}function isReshapeFree(shape1,shape2){shape1=shape1.slice(-2);shape2=shape2.slice(-2);if(arraysEqual(shape1,shape2)){return true}if(!shape1.length||!shape2.length){return true}if(shape1[0]===0||shape1[1]===0||shape2[0]===0||shape2[1]===0){return true}if(shape1.length!==shape2.length){const shape1Cols=shape1.slice(-1)[0];const shape2Cols=shape2.slice(-1)[0];if(shape1Cols===shape2Cols){return true}if(isEven(shape1Cols)&&isEven(shape2Cols)&&(shape1[0]===1||shape2[0]===1)){return true}}return shape1[1]===shape2[1]&&isEven(shape1[0])&&isEven(shape2[0])}let MAX_TEXTURE_SIZE;let MAX_TEXTURES_IN_SHADER;function getWebGLMaxTextureSize(webGLVersion){if(MAX_TEXTURE_SIZE==null){const gl=getWebGLContext(webGLVersion);MAX_TEXTURE_SIZE=gl.getParameter(gl.MAX_TEXTURE_SIZE)}return MAX_TEXTURE_SIZE}function resetMaxTextureSize(){MAX_TEXTURE_SIZE=null}function resetMaxTexturesInShader(){MAX_TEXTURES_IN_SHADER=null}function getMaxTexturesInShader(webGLVersion){if(MAX_TEXTURES_IN_SHADER==null){const gl=getWebGLContext(webGLVersion);MAX_TEXTURES_IN_SHADER=gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,MAX_TEXTURES_IN_SHADER)}function getWebGLDisjointQueryTimerVersion(webGLVersion){if(webGLVersion===0){return 0}let queryTimerVersion;const gl=getWebGLContext(webGLVersion);if(hasExtension(gl,"EXT_disjoint_timer_query_webgl2")&&webGLVersion===2){queryTimerVersion=2}else if(hasExtension(gl,"EXT_disjoint_timer_query")){queryTimerVersion=1}else{queryTimerVersion=0}return queryTimerVersion}function hasExtension(gl,extensionName){const ext=gl.getExtension(extensionName);return ext!=null}function isWebGLVersionEnabled(webGLVersion){try{const gl=getWebGLContext(webGLVersion);if(gl!=null){return true}}catch(e){console.log("Error when getting WebGL context: ",e);return false}return false}function isCapableOfRenderingToFloatTexture(webGLVersion){if(webGLVersion===0){return false}const gl=getWebGLContext(webGLVersion);if(webGLVersion===1){if(!hasExtension(gl,"OES_texture_float")){return false}}else{if(!hasExtension(gl,"EXT_color_buffer_float")){return false}}const isFrameBufferComplete=createFloatTextureAndBindToFramebuffer(gl);return isFrameBufferComplete}function isDownloadFloatTextureEnabled(webGLVersion){if(webGLVersion===0){return false}const gl=getWebGLContext(webGLVersion);if(webGLVersion===1){if(!hasExtension(gl,"OES_texture_float")){return false}if(!hasExtension(gl,"WEBGL_color_buffer_float")){return false}}else{if(hasExtension(gl,"EXT_color_buffer_float")){return createFloatTextureAndBindToFramebuffer(gl)}const COLOR_BUFFER_HALF_FLOAT="EXT_color_buffer_half_float";if(hasExtension(gl,COLOR_BUFFER_HALF_FLOAT)){const textureHalfFloatExtension=gl.getExtension(COLOR_BUFFER_HALF_FLOAT);return createHalfFloatTextureAndBindToFramebuffer(gl,textureHalfFloatExtension)}return false}const isFrameBufferComplete=createFloatTextureAndBindToFramebuffer(gl);return isFrameBufferComplete}function createFloatTextureAndBindToFramebuffer(gl){const texConfig=getTextureConfig(gl);const texture=gl.createTexture();gl.bindTexture(gl.TEXTURE_2D,texture);const width=1;const height=1;gl.texImage2D(gl.TEXTURE_2D,0,texConfig.internalFormatFloat,width,height,0,texConfig.textureFormatFloat,texConfig.textureTypeFloat,null);const frameBuffer=gl.createFramebuffer();gl.bindFramebuffer(gl.FRAMEBUFFER,frameBuffer);gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0);const isFrameBufferComplete=gl.checkFramebufferStatus(gl.FRAMEBUFFER)===gl.FRAMEBUFFER_COMPLETE;gl.bindTexture(gl.TEXTURE_2D,null);gl.bindFramebuffer(gl.FRAMEBUFFER,null);gl.deleteTexture(texture);gl.deleteFramebuffer(frameBuffer);return isFrameBufferComplete}function createHalfFloatTextureAndBindToFramebuffer(gl,textureHalfFloatExtension){const texConfig=getTextureConfig(gl,textureHalfFloatExtension);const texture=gl.createTexture();gl.bindTexture(gl.TEXTURE_2D,texture);const width=1;const height=1;gl.texImage2D(gl.TEXTURE_2D,0,texConfig.internalFormatHalfFloat,width,height,0,texConfig.textureFormatFloat,texConfig.textureTypeHalfFloat,null);const frameBuffer=gl.createFramebuffer();gl.bindFramebuffer(gl.FRAMEBUFFER,frameBuffer);gl.framebufferTexture2D(gl.FRAMEBUFFER,gl.COLOR_ATTACHMENT0,gl.TEXTURE_2D,texture,0);const isFrameBufferComplete=gl.checkFramebufferStatus(gl.FRAMEBUFFER)===gl.FRAMEBUFFER_COMPLETE;gl.bindTexture(gl.TEXTURE_2D,null);gl.bindFramebuffer(gl.FRAMEBUFFER,null);gl.deleteTexture(texture);gl.deleteFramebuffer(frameBuffer);return isFrameBufferComplete}function isWebGLFenceEnabled(webGLVersion){if(webGLVersion!==2){return false}const gl=getWebGLContext(webGLVersion);const isEnabled=gl.fenceSync!=null;return isEnabled}function assertNotComplex(tensor,opName){if(!Array.isArray(tensor)){tensor=[tensor]}tensor.forEach((t=>{if(t!=null){assert(t.dtype!=="complex64",(()=>`${opName} does not support complex64 tensors `+"in the WebGL backend."))}}))}var webgl_util=Object.freeze({__proto__:null,callAndCheck:callAndCheck,canBeRepresented:canBeRepresented,getWebGLErrorMessage:getWebGLErrorMessage,getExtensionOrThrow:getExtensionOrThrow,createVertexShader:createVertexShader$1,createFragmentShader:createFragmentShader,createProgram:createProgram,linkProgram:linkProgram,validateProgram:validateProgram,createStaticVertexBuffer:createStaticVertexBuffer,createStaticIndexBuffer:createStaticIndexBuffer,getNumChannels:getNumChannels,createTexture:createTexture,validateTextureSize:validateTextureSize,createFramebuffer:createFramebuffer,bindVertexBufferToProgramAttribute:bindVertexBufferToProgramAttribute,bindTextureUnit:bindTextureUnit,unbindTextureUnit:unbindTextureUnit,getProgramUniformLocationOrThrow:getProgramUniformLocationOrThrow,getProgramUniformLocation:getProgramUniformLocation,bindTextureToProgramUniformSampler:bindTextureToProgramUniformSampler,bindCanvasToFramebuffer:bindCanvasToFramebuffer,bindColorTextureToFramebuffer:bindColorTextureToFramebuffer,unbindColorTextureFromFramebuffer:unbindColorTextureFromFramebuffer,validateFramebuffer:validateFramebuffer,getFramebufferErrorMessage:getFramebufferErrorMessage,getBatchDim:getBatchDim,getRowsCols:getRowsCols,getShapeAs3D:getShapeAs3D,getTextureShapeFromLogicalShape:getTextureShapeFromLogicalShape,isReshapeFree:isReshapeFree,getWebGLMaxTextureSize:getWebGLMaxTextureSize,resetMaxTextureSize:resetMaxTextureSize,resetMaxTexturesInShader:resetMaxTexturesInShader,getMaxTexturesInShader:getMaxTexturesInShader,getWebGLDisjointQueryTimerVersion:getWebGLDisjointQueryTimerVersion,hasExtension:hasExtension,isWebGLVersionEnabled:isWebGLVersionEnabled,isCapableOfRenderingToFloatTexture:isCapableOfRenderingToFloatTexture,isDownloadFloatTextureEnabled:isDownloadFloatTextureEnabled,isWebGLFenceEnabled:isWebGLFenceEnabled,assertNotComplex:assertNotComplex});const ENV=env();ENV.registerFlag("HAS_WEBGL",(()=>ENV.getNumber("WEBGL_VERSION")>0));ENV.registerFlag("WEBGL_VERSION",(()=>{{return 1}}));ENV.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",(()=>false));ENV.registerFlag("WEBGL_BUFFER_SUPPORTED",(()=>ENV.get("WEBGL_VERSION")===2));ENV.registerFlag("WEBGL_CPU_FORWARD",(()=>true));ENV.registerFlag("WEBGL_FORCE_F16_TEXTURES",(()=>false));ENV.registerFlag("WEBGL_PACK",(()=>ENV.getBool("HAS_WEBGL")));ENV.registerFlag("WEBGL_PACK_NORMALIZATION",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_CLIP",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_DEPTHWISECONV",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_PACK_REDUCE",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_LAZILY_UNPACK",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_CONV_IM2COL",(()=>ENV.getBool("WEBGL_PACK")));ENV.registerFlag("WEBGL_MAX_TEXTURE_SIZE",(()=>getWebGLMaxTextureSize(ENV.getNumber("WEBGL_VERSION"))));ENV.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",(()=>getMaxTexturesInShader(ENV.getNumber("WEBGL_VERSION"))));ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",(()=>{const webGLVersion=ENV.getNumber("WEBGL_VERSION");if(webGLVersion===0){return 0}return getWebGLDisjointQueryTimerVersion(webGLVersion)}));ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",(()=>ENV.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!isMobile()));ENV.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",(()=>isCapableOfRenderingToFloatTexture(ENV.getNumber("WEBGL_VERSION"))));ENV.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",(()=>ENV.getBool("WEBGL_FORCE_F16_TEXTURES")?false:ENV.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")));ENV.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",(()=>isDownloadFloatTextureEnabled(ENV.getNumber("WEBGL_VERSION"))));ENV.registerFlag("WEBGL_FENCE_API_ENABLED",(()=>isWebGLFenceEnabled(ENV.getNumber("WEBGL_VERSION"))));ENV.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",(()=>{const useUniforms=ENV.getBool("WEBGL_RENDER_FLOAT32_ENABLED");return useUniforms?4:0}));ENV.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",(()=>-1),(threshold=>{if(threshold<0&&threshold!==-1){throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never `+`delete) or at least 0, but got ${threshold}.`)}}));ENV.registerFlag("WEBGL_FLUSH_THRESHOLD",(()=>isMobile()&&ENV.getBool("IS_CHROME")?1:-1),(threshold=>{if(threshold<0&&threshold!==-1){throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never `+`manual flush) or at least 0, but got ${threshold}.`)}}));function getGlslDifferences(){let version;let attribute;let varyingVs;let varyingFs;let texture2D;let output;let defineOutput;let defineSpecialNaN;let defineSpecialInf;let defineRound;if(env().getNumber("WEBGL_VERSION")===2){version="#version 300 es";attribute="in";varyingVs="out";varyingFs="in";texture2D="texture";output="outputColor";defineOutput="out vec4 outputColor;";defineSpecialNaN=`\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    `;defineSpecialInf=``;defineRound=`\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    `}else{version="";attribute="attribute";varyingVs="varying";varyingFs="varying";texture2D="texture2D";output="gl_FragColor";defineOutput="";defineSpecialNaN=`\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    `;defineSpecialInf=`\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    `;defineRound=`\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    `}return{version:version,attribute:attribute,varyingVs:varyingVs,varyingFs:varyingFs,texture2D:texture2D,output:output,defineOutput:defineOutput,defineSpecialNaN:defineSpecialNaN,defineSpecialInf:defineSpecialInf,defineRound:defineRound}}function getLogicalCoordinatesFromFlatIndex(coords,shape,index="index"){const strides=computeStrides(shape);return strides.map(((stride,i)=>{const line1=`int ${coords[i]} = ${index} / ${stride}`;const line2=i===strides.length-1?`int ${coords[i+1]} = ${index} - ${coords[i]} * ${stride}`:`index -= ${coords[i]} * ${stride}`;return`${line1}; ${line2};`})).join("")}function getFlatIndexFrom3D(shape){const strides=computeStrides(shape).map((d=>d.toString()));return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${strides[0]} + coords.y * ${strides[1]} + coords.z;\n  }\n`}const ENCODE_FLOAT_SNIPPET=`\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n`;class DecodeMatrixProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=false;this.packedOutput=true;this.outPackingScheme=PackingScheme.DENSE;const texShape=getDenseTexShape(outputShape);const glsl=getGlslDifferences();this.outputShape=outputShape;this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex(["r","c","d"],outputShape)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${texShape[0]}, ${texShape[1]}));\n        int index = 4 * (resTexRC.x * ${texShape[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}class DecodeMatrixPackedProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outPackingScheme=PackingScheme.DENSE;const texShape=getDenseTexShape(outputShape);const glsl=getGlslDifferences();this.outputShape=outputShape;this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex(["r","c","d"],outputShape)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${texShape[0]}, ${texShape[1]}));\n        int index = 4 * (resTexRC.x * ${texShape[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}class EncodeFloatProgram{constructor(outputShape){this.variableNames=["A"];this.outTexUsage=TextureUsage.DOWNLOAD;const glsl=getGlslDifferences();this.outputShape=outputShape;this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${glsl.output} = encode_float(x);\n      }\n    `}}class EncodeFloatPackedProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=false;this.outTexUsage=TextureUsage.DOWNLOAD;const glsl=getGlslDifferences();this.outputShape=outputShape;this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${glsl.output} = encode_float(x);\n      }\n    `}}class EncodeMatrixProgram{constructor(outputShape,texShape,inputIsUnsignedByte=false){this.variableNames=["A"];const glsl=getGlslDifferences();const[height,width]=texShape;this.outputShape=outputShape;let output=`result`;if(inputIsUnsignedByte){output=`floor(result * 255. + 0.5)`}this.userCode=`\n      ${getFlatIndexFrom3D(outputShape)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ${width};\n        int c = imod(flatIndex, ${width});\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(${width}.0, ${height}.0);\n        vec4 values = ${glsl.texture2D}(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ${glsl.output} = vec4(${output}, 0., 0., 0.);\n      }\n    `}}class EncodeMatrixPackedProgram{constructor(outputShape,texShape,inputIsUnsignedByte=false){this.variableNames=["A"];this.packedInputs=false;this.packedOutput=true;const glsl=getGlslDifferences();const[height,width]=texShape;this.outputShape=outputShape;let mainLoop="";let output="result";if(inputIsUnsignedByte){output="floor(result * 255. + 0.5)"}for(let row=0;row<=1;row++){for(let col=0;col<=1;col++){const channel=row*2+col;mainLoop+=`\n          localCoords = coords;\n          if(localCoords[2] + ${col} < ${outputShape[2]}) {\n            localCoords[2] += ${col};\n            if(localCoords[1] + ${row} < ${outputShape[1]}) {\n              localCoords[1] += ${row};\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ${width};\n              c = imod(flatIndex, ${width});\n              uv = (vec2(c, r) + halfCR) / vec2(${width}.0, ${height}.0);\n              values = ${glsl.texture2D}(A, uv);\n\n              if(offset == 0) {\n                result[${channel}] = values[0];\n              } else if(offset == 1) {\n                result[${channel}] = values[1];\n              } else if(offset == 2) {\n                result[${channel}] = values[2];\n              } else {\n                result[${channel}] = values[3];\n              }\n            }\n          }\n        `}}this.userCode=`\n      ${getFlatIndexFrom3D(outputShape)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ${mainLoop}\n\n        ${glsl.output} = ${output};\n      }\n    `}}function createVertexShader(gl){const glsl=getGlslDifferences();const vertexShaderSource=`${glsl.version}\n    precision highp float;\n    ${glsl.attribute} vec3 clipSpacePos;\n    ${glsl.attribute} vec2 uv;\n    ${glsl.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`;return createVertexShader$1(gl,vertexShaderSource)}function createVertexBuffer(gl){const vertexArray=new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]);return createStaticVertexBuffer(gl,vertexArray)}function createIndexBuffer(gl){const triangleVertexIndices=new Uint16Array([0,1,2,2,1,3]);return createStaticIndexBuffer(gl,triangleVertexIndices)}function createAndConfigureTexture(gl,width,height,internalFormat,textureFormat,textureType){validateTextureSize(width,height);const texture=createTexture(gl);const tex2d=gl.TEXTURE_2D;callAndCheck(gl,(()=>gl.bindTexture(tex2d,texture)));callAndCheck(gl,(()=>gl.texParameteri(tex2d,gl.TEXTURE_WRAP_S,gl.CLAMP_TO_EDGE)));callAndCheck(gl,(()=>gl.texParameteri(tex2d,gl.TEXTURE_WRAP_T,gl.CLAMP_TO_EDGE)));callAndCheck(gl,(()=>gl.texParameteri(tex2d,gl.TEXTURE_MIN_FILTER,gl.NEAREST)));callAndCheck(gl,(()=>gl.texParameteri(tex2d,gl.TEXTURE_MAG_FILTER,gl.NEAREST)));callAndCheck(gl,(()=>gl.texImage2D(tex2d,0,internalFormat,width,height,0,textureFormat,textureType,null)));callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,null)));return texture}function getInternalFormatForFloat32MatrixTexture(textureConfig){return textureConfig.internalFormatFloat}function createFloat32MatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat32MatrixTexture(textureConfig),textureConfig.textureFormatFloat,gl.FLOAT)}function getInternalFormatForFloat16MatrixTexture(textureConfig){return textureConfig.internalFormatHalfFloat}function createFloat16MatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat16MatrixTexture(textureConfig),textureConfig.textureFormatFloat,textureConfig.textureTypeHalfFloat)}function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig){return textureConfig.downloadTextureFormat}function createUnsignedBytesMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForUnsignedBytesMatrixTexture(textureConfig),gl.RGBA,gl.UNSIGNED_BYTE)}function getInternalFormatForPackedMatrixTexture(textureConfig){return textureConfig.internalFormatPackedFloat}function createPackedMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForPackedMatrixTexture(textureConfig),gl.RGBA,gl.FLOAT)}function getInternalFormatForFloat16PackedMatrixTexture(textureConfig){return textureConfig.internalFormatPackedHalfFloat}function createFloat16PackedMatrixTexture(gl,rows,columns,textureConfig){const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);return createAndConfigureTexture(gl,width,height,getInternalFormatForFloat16PackedMatrixTexture(textureConfig),gl.RGBA,textureConfig.textureTypeHalfFloat)}function bindVertexProgramAttributeStreams(gl,program,vertexBuffer){const posOffset=0;const uvOffset=3*4;const stride=3*4+2*4;callAndCheck(gl,(()=>gl.bindBuffer(gl.ARRAY_BUFFER,vertexBuffer)));const success=bindVertexBufferToProgramAttribute(gl,program,"clipSpacePos",vertexBuffer,3,stride,posOffset);return success&&bindVertexBufferToProgramAttribute(gl,program,"uv",vertexBuffer,2,stride,uvOffset)}function uploadDenseMatrixToTexture(gl,texture,width,height,data,textureConfig){callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,texture)));let dataForUpload,texelDataType,internalFormat;if(data instanceof Uint8Array){dataForUpload=new Uint8Array(width*height*4);texelDataType=gl.UNSIGNED_BYTE;internalFormat=gl.RGBA}else{dataForUpload=new Float32Array(width*height*4);texelDataType=gl.FLOAT;internalFormat=textureConfig.internalFormatPackedFloat}dataForUpload.set(data);callAndCheck(gl,(()=>gl.texImage2D(gl.TEXTURE_2D,0,internalFormat,width,height,0,gl.RGBA,texelDataType,dataForUpload)));callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,null)))}function uploadPixelDataToTexture(gl,texture,pixels){callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,texture)));if(pixels.data instanceof Uint8Array){callAndCheck(gl,(()=>gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,pixels.width,pixels.height,0,gl.RGBA,gl.UNSIGNED_BYTE,pixels.data)))}else{callAndCheck(gl,(()=>gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,gl.RGBA,gl.UNSIGNED_BYTE,pixels)))}callAndCheck(gl,(()=>gl.bindTexture(gl.TEXTURE_2D,null)))}function createBufferFromOutputTexture(gl2,rows,columns,textureConfig){const buffer=gl2.createBuffer();callAndCheck(gl2,(()=>gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer)));const bytesPerFloat=4;const valuesPerTexel=4;const bufferSizeBytes=bytesPerFloat*valuesPerTexel*rows*columns;callAndCheck(gl2,(()=>gl2.bufferData(gl2.PIXEL_PACK_BUFFER,bufferSizeBytes,gl2.STREAM_READ)));callAndCheck(gl2,(()=>gl2.readPixels(0,0,columns,rows,gl2.RGBA,gl2.FLOAT,0)));callAndCheck(gl2,(()=>gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null)));return buffer}function downloadFloat32MatrixFromBuffer(gl,buffer,size){const gl2=gl;const downloadTarget=new Float32Array(size);gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer);gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER,0,downloadTarget);gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null);return downloadTarget}function downloadByteEncodedFloatMatrixFromOutputTexture(gl,rows,columns,textureConfig){const[w,h]=getUnpackedMatrixTextureShapeWidthHeight(rows,columns);const numChannels=4;const downloadTarget=new Uint8Array(getUnpackedArraySizeFromMatrixSize(rows*columns,numChannels));callAndCheck(gl,(()=>gl.readPixels(0,0,w,h,textureConfig.downloadTextureFormat,gl.UNSIGNED_BYTE,downloadTarget)));return new Float32Array(downloadTarget.buffer)}function downloadPackedMatrixFromBuffer(gl,buffer,batch,rows,cols,physicalRows,physicalCols,textureConfig){const gl2=gl;const downloadTarget=new Float32Array(getPackedRGBAArraySizeFromMatrixShape(physicalRows,physicalCols));gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,buffer);gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER,0,downloadTarget);gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER,null);return downloadTarget}function downloadMatrixFromPackedOutputTexture(gl,physicalRows,physicalCols){const packedRGBA=new Float32Array(physicalRows*physicalCols*4);callAndCheck(gl,(()=>gl.readPixels(0,0,physicalCols,physicalRows,gl.RGBA,gl.FLOAT,packedRGBA)));return packedRGBA}var gpgpu_util=Object.freeze({__proto__:null,createVertexShader:createVertexShader,createVertexBuffer:createVertexBuffer,createIndexBuffer:createIndexBuffer,getInternalFormatForFloat32MatrixTexture:getInternalFormatForFloat32MatrixTexture,createFloat32MatrixTexture:createFloat32MatrixTexture,getInternalFormatForFloat16MatrixTexture:getInternalFormatForFloat16MatrixTexture,createFloat16MatrixTexture:createFloat16MatrixTexture,getInternalFormatForUnsignedBytesMatrixTexture:getInternalFormatForUnsignedBytesMatrixTexture,createUnsignedBytesMatrixTexture:createUnsignedBytesMatrixTexture,getInternalFormatForPackedMatrixTexture:getInternalFormatForPackedMatrixTexture,createPackedMatrixTexture:createPackedMatrixTexture,getInternalFormatForFloat16PackedMatrixTexture:getInternalFormatForFloat16PackedMatrixTexture,createFloat16PackedMatrixTexture:createFloat16PackedMatrixTexture,bindVertexProgramAttributeStreams:bindVertexProgramAttributeStreams,uploadDenseMatrixToTexture:uploadDenseMatrixToTexture,uploadPixelDataToTexture:uploadPixelDataToTexture,createBufferFromOutputTexture:createBufferFromOutputTexture,downloadFloat32MatrixFromBuffer:downloadFloat32MatrixFromBuffer,downloadByteEncodedFloatMatrixFromOutputTexture:downloadByteEncodedFloatMatrixFromOutputTexture,downloadPackedMatrixFromBuffer:downloadPackedMatrixFromBuffer,downloadMatrixFromPackedOutputTexture:downloadMatrixFromPackedOutputTexture});class GPGPUContext{constructor(gl){this.outputTexture=null;this.program=null;this.disposed=false;this.vertexAttrsAreBound=false;this.itemsToPoll=[];const glVersion=env().getNumber("WEBGL_VERSION");if(gl!=null){this.gl=gl;setWebGLContext(glVersion,gl)}else{this.gl=getWebGLContext(glVersion)}let COLOR_BUFFER_FLOAT="WEBGL_color_buffer_float";const COLOR_BUFFER_HALF_FLOAT="EXT_color_buffer_half_float";if(env().getNumber("WEBGL_VERSION")===1){const TEXTURE_FLOAT="OES_texture_float";const TEXTURE_HALF_FLOAT="OES_texture_half_float";this.textureFloatExtension=getExtensionOrThrow(this.gl,TEXTURE_FLOAT);if(hasExtension(this.gl,TEXTURE_HALF_FLOAT)){this.textureHalfFloatExtension=getExtensionOrThrow(this.gl,TEXTURE_HALF_FLOAT)}else if(env().get("WEBGL_FORCE_F16_TEXTURES")){throw new Error("GL context does not support half float textures, yet the "+"environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}this.colorBufferFloatExtension=this.gl.getExtension(COLOR_BUFFER_FLOAT);if(hasExtension(this.gl,COLOR_BUFFER_HALF_FLOAT)){this.colorBufferHalfFloatExtension=getExtensionOrThrow(this.gl,COLOR_BUFFER_HALF_FLOAT)}else if(env().get("WEBGL_FORCE_F16_TEXTURES")){throw new Error("GL context does not support color renderable half floats, yet "+"the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}}else{COLOR_BUFFER_FLOAT="EXT_color_buffer_float";if(hasExtension(this.gl,COLOR_BUFFER_FLOAT)){this.colorBufferFloatExtension=this.gl.getExtension(COLOR_BUFFER_FLOAT)}else if(hasExtension(this.gl,COLOR_BUFFER_HALF_FLOAT)){this.colorBufferHalfFloatExtension=this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT)}else{throw new Error("GL context does not support color renderable floats")}}this.vertexBuffer=createVertexBuffer(this.gl);this.indexBuffer=createIndexBuffer(this.gl);this.framebuffer=createFramebuffer(this.gl);this.textureConfig=getTextureConfig(this.gl,this.textureHalfFloatExtension)}get debug(){return env().getBool("DEBUG")}dispose(){if(this.disposed){return}if(this.program!=null){console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram."+" This is probably a resource leak, delete the program with "+"GPGPUContext.deleteProgram before disposing.")}if(this.outputTexture!=null){console.warn("Disposing a GPGPUContext that still has a bound output matrix "+"texture.  This is probably a resource leak, delete the output "+"matrix texture with GPGPUContext.deleteMatrixTexture before "+"disposing.")}const gl=this.gl;callAndCheck(gl,(()=>gl.finish()));callAndCheck(gl,(()=>gl.bindFramebuffer(gl.FRAMEBUFFER,null)));callAndCheck(gl,(()=>gl.deleteFramebuffer(this.framebuffer)));callAndCheck(gl,(()=>gl.bindBuffer(gl.ARRAY_BUFFER,null)));callAndCheck(gl,(()=>gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER,null)));callAndCheck(gl,(()=>gl.deleteBuffer(this.indexBuffer)));this.disposed=true}createFloat32MatrixTexture(rows,columns){this.throwIfDisposed();return createFloat32MatrixTexture(this.gl,rows,columns,this.textureConfig)}createFloat16MatrixTexture(rows,columns){this.throwIfDisposed();return createFloat16MatrixTexture(this.gl,rows,columns,this.textureConfig)}createUnsignedBytesMatrixTexture(rows,columns){this.throwIfDisposed();return createUnsignedBytesMatrixTexture(this.gl,rows,columns,this.textureConfig)}uploadPixelDataToTexture(texture,pixels){this.throwIfDisposed();uploadPixelDataToTexture(this.gl,texture,pixels)}uploadDenseMatrixToTexture(texture,width,height,data){this.throwIfDisposed();uploadDenseMatrixToTexture(this.gl,texture,width,height,data,this.textureConfig)}createFloat16PackedMatrixTexture(rows,columns){this.throwIfDisposed();return createFloat16PackedMatrixTexture(this.gl,rows,columns,this.textureConfig)}createPackedMatrixTexture(rows,columns){this.throwIfDisposed();return createPackedMatrixTexture(this.gl,rows,columns,this.textureConfig)}deleteMatrixTexture(texture){this.throwIfDisposed();if(this.outputTexture===texture){unbindColorTextureFromFramebuffer(this.gl,this.framebuffer);this.outputTexture=null}callAndCheck(this.gl,(()=>this.gl.deleteTexture(texture)))}downloadByteEncodedFloatMatrixFromOutputTexture(texture,rows,columns){return this.downloadMatrixDriver(texture,(()=>downloadByteEncodedFloatMatrixFromOutputTexture(this.gl,rows,columns,this.textureConfig)))}downloadPackedMatrixFromBuffer(buffer,batch,rows,columns,physicalRows,physicalCols){return downloadPackedMatrixFromBuffer(this.gl,buffer,batch,rows,columns,physicalRows,physicalCols,this.textureConfig)}downloadFloat32MatrixFromBuffer(buffer,size){return downloadFloat32MatrixFromBuffer(this.gl,buffer,size)}createBufferFromTexture(texture,rows,columns){this.bindTextureToFrameBuffer(texture);const result=createBufferFromOutputTexture(this.gl,rows,columns,this.textureConfig);this.unbindTextureToFrameBuffer();return result}createAndWaitForFence(){const fenceContext=this.createFence(this.gl);return this.pollFence(fenceContext)}createFence(gl){let query;let isFencePassed;if(env().getBool("WEBGL_FENCE_API_ENABLED")){const gl2=gl;const sync=gl2.fenceSync(gl2.SYNC_GPU_COMMANDS_COMPLETE,0);gl.flush();isFencePassed=()=>{const status=gl2.clientWaitSync(sync,0,0);return status===gl2.ALREADY_SIGNALED||status===gl2.CONDITION_SATISFIED};query=sync}else if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0){query=this.beginQuery();this.endQuery();isFencePassed=()=>this.isQueryAvailable(query,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}else{isFencePassed=()=>true}return{query:query,isFencePassed:isFencePassed}}downloadMatrixFromPackedTexture(texture,physicalRows,physicalCols){return this.downloadMatrixDriver(texture,(()=>downloadMatrixFromPackedOutputTexture(this.gl,physicalRows,physicalCols)))}createProgram(fragmentShaderSource){this.throwIfDisposed();const gl=this.gl;const fragmentShader=createFragmentShader(gl,fragmentShaderSource);if(this.vertexShader==null){this.vertexShader=createVertexShader(gl)}const program=createProgram(gl);callAndCheck(gl,(()=>gl.attachShader(program,this.vertexShader)));callAndCheck(gl,(()=>gl.attachShader(program,fragmentShader)));linkProgram(gl,program);if(this.debug){validateProgram(gl,program)}if(!this.vertexAttrsAreBound){this.setProgram(program);this.vertexAttrsAreBound=bindVertexProgramAttributeStreams(gl,this.program,this.vertexBuffer)}return program}deleteProgram(program){this.throwIfDisposed();if(program===this.program){this.program=null}if(program!=null){callAndCheck(this.gl,(()=>this.gl.deleteProgram(program)))}}setProgram(program){this.throwIfDisposed();this.program=program;if(this.program!=null&&this.debug){validateProgram(this.gl,this.program)}callAndCheck(this.gl,(()=>this.gl.useProgram(program)))}getUniformLocation(program,uniformName,shouldThrow=true){this.throwIfDisposed();if(shouldThrow){return getProgramUniformLocationOrThrow(this.gl,program,uniformName)}else{return getProgramUniformLocation(this.gl,program,uniformName)}}getAttributeLocation(program,attribute){this.throwIfDisposed();return callAndCheck(this.gl,(()=>this.gl.getAttribLocation(program,attribute)))}getUniformLocationNoThrow(program,uniformName){this.throwIfDisposed();return this.gl.getUniformLocation(program,uniformName)}setInputMatrixTexture(inputMatrixTexture,uniformLocation,textureUnit){this.throwIfDisposed();this.throwIfNoProgram();bindTextureToProgramUniformSampler(this.gl,inputMatrixTexture,uniformLocation,textureUnit)}setOutputMatrixTexture(outputMatrixTexture,rows,columns){this.setOutputMatrixTextureDriver(outputMatrixTexture,columns,rows)}setOutputPackedMatrixTexture(outputPackedMatrixTexture,rows,columns){this.throwIfDisposed();const[width,height]=getPackedMatrixTextureShapeWidthHeight(rows,columns);this.setOutputMatrixTextureDriver(outputPackedMatrixTexture,width,height)}setOutputMatrixWriteRegion(startRow,numRows,startColumn,numColumns){this.setOutputMatrixWriteRegionDriver(startColumn,startRow,numColumns,numRows)}setOutputPackedMatrixWriteRegion(startRow,numRows,startColumn,numColumns){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){if(this.program!=null){validateProgram(this.gl,this.program)}validateFramebuffer(this.gl)}executeProgram(){this.throwIfDisposed();this.throwIfNoProgram();const gl=this.gl;if(this.debug){this.debugValidate()}callAndCheck(gl,(()=>gl.drawElements(gl.TRIANGLES,6,gl.UNSIGNED_SHORT,0)))}blockUntilAllProgramsCompleted(){this.throwIfDisposed();callAndCheck(this.gl,(()=>this.gl.finish()))}getQueryTimerExtension(){if(this.disjointQueryTimerExtension==null){this.disjointQueryTimerExtension=getExtensionOrThrow(this.gl,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")===2?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")}return this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")===2){const gl2=this.gl;const ext=this.getQueryTimerExtensionWebGL2();const query=gl2.createQuery();gl2.beginQuery(ext.TIME_ELAPSED_EXT,query);return query}const ext=this.getQueryTimerExtensionWebGL1();const query=ext.createQueryEXT();ext.beginQueryEXT(ext.TIME_ELAPSED_EXT,query);return query}endQuery(){if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")===2){const gl2=this.gl;const ext=this.getQueryTimerExtensionWebGL2();gl2.endQuery(ext.TIME_ELAPSED_EXT);return}const ext=this.getQueryTimerExtensionWebGL1();ext.endQueryEXT(ext.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(query){await repeatedTry((()=>this.disposed||this.isQueryAvailable(query,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))));return this.getQueryTime(query,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(query,queryTimerVersion){if(queryTimerVersion===0){return null}if(queryTimerVersion===2){const gl2=this.gl;const timeElapsedNanos=gl2.getQueryParameter(query,gl2.QUERY_RESULT);return timeElapsedNanos/1e6}else{const ext=this.getQueryTimerExtensionWebGL1();const timeElapsedNanos=ext.getQueryObjectEXT(query,ext.QUERY_RESULT_EXT);return timeElapsedNanos/1e6}}isQueryAvailable(query,queryTimerVersion){if(queryTimerVersion===0){return true}if(queryTimerVersion===2){const gl2=this.gl;const ext=this.getQueryTimerExtensionWebGL2();const available=gl2.getQueryParameter(query,gl2.QUERY_RESULT_AVAILABLE);if(this.disjoint==null){this.disjoint=this.gl.getParameter(ext.GPU_DISJOINT_EXT)}return available&&!this.disjoint}else{const ext=this.getQueryTimerExtensionWebGL1();const available=ext.getQueryObjectEXT(query,ext.QUERY_RESULT_AVAILABLE_EXT);if(this.disjoint==null){this.disjoint=this.gl.getParameter(ext.GPU_DISJOINT_EXT)}return available&&!this.disjoint}}pollFence(fenceContext){return new Promise((resolve=>{this.addItemToPoll((()=>fenceContext.isFencePassed()),(()=>resolve()))}))}pollItems(){const index=linearSearchLastTrue(this.itemsToPoll.map((x=>x.isDoneFn)));for(let i=0;i<=index;++i){const{resolveFn:resolveFn}=this.itemsToPoll[i];resolveFn()}this.itemsToPoll=this.itemsToPoll.slice(index+1)}addItemToPoll(isDoneFn,resolveFn){this.itemsToPoll.push({isDoneFn:isDoneFn,resolveFn:resolveFn});if(this.itemsToPoll.length>1){return}repeatedTry((()=>{this.pollItems();return this.itemsToPoll.length===0}))}bindTextureToFrameBuffer(texture){this.throwIfDisposed();bindColorTextureToFramebuffer(this.gl,texture,this.framebuffer);if(this.debug){validateFramebuffer(this.gl)}}unbindTextureToFrameBuffer(){if(this.outputTexture!=null){bindColorTextureToFramebuffer(this.gl,this.outputTexture,this.framebuffer);if(this.debug){validateFramebuffer(this.gl)}}else{unbindColorTextureFromFramebuffer(this.gl,this.framebuffer)}}downloadMatrixDriver(texture,downloadAndDecode){this.bindTextureToFrameBuffer(texture);const result=downloadAndDecode();this.unbindTextureToFrameBuffer();return result}setOutputMatrixTextureDriver(outputMatrixTextureMaybePacked,width,height){this.throwIfDisposed();const gl=this.gl;bindColorTextureToFramebuffer(gl,outputMatrixTextureMaybePacked,this.framebuffer);if(this.debug){validateFramebuffer(gl)}this.outputTexture=outputMatrixTextureMaybePacked;callAndCheck(gl,(()=>gl.viewport(0,0,width,height)));callAndCheck(gl,(()=>gl.scissor(0,0,width,height)))}setOutputMatrixWriteRegionDriver(x,y,width,height){this.throwIfDisposed();callAndCheck(this.gl,(()=>this.gl.scissor(x,y,width,height)))}throwIfDisposed(){if(this.disposed){throw new Error("Attempted to use disposed GPGPUContext.")}}throwIfNoProgram(){if(this.program==null){throw new Error("No GPU program is currently set.")}}}function linearSearchLastTrue(arr){let i=0;for(;i<arr.length;++i){const isDone=arr[i]();if(!isDone){break}}return i-1}const{getBroadcastDims:getBroadcastDims}=backend_util;function makeShader(inputsInfo,outputShape,userCode,usesPackedTextures){const prefixSnippets=[];inputsInfo.forEach((x=>{const size=sizeFromShape(x.shapeInfo.logicalShape);if(x.shapeInfo.isUniform){prefixSnippets.push(`uniform float ${x.name}${size>1?`[${size}]`:""};`)}else{prefixSnippets.push(`uniform sampler2D ${x.name};`);prefixSnippets.push(`uniform int offset${x.name};`)}}));const inputPrefixSnippet=prefixSnippets.join("\n");const inputSamplingSnippet=inputsInfo.map((x=>getInputSamplingSnippet(x,outputShape,usesPackedTextures))).join("\n");const outTexShape=outputShape.texShape;const glsl=getGlslDifferences();const floatTextureSampleSnippet=getFloatTextureSampleSnippet(glsl);let outputSamplingSnippet;let floatTextureSetOutputSnippet;let shaderPrefix=getShaderPrefix(glsl);if(outputShape.isPacked){outputSamplingSnippet=getPackedOutputSamplingSnippet(outputShape.logicalShape,outTexShape);floatTextureSetOutputSnippet=getFloatTextureSetRGBASnippet(glsl)}else{outputSamplingSnippet=getOutputSamplingSnippet(outputShape.logicalShape,outTexShape);floatTextureSetOutputSnippet=getFloatTextureSetRSnippet(glsl)}if(usesPackedTextures){shaderPrefix+=SHADER_PACKED_PREFIX}const source=[shaderPrefix,floatTextureSampleSnippet,floatTextureSetOutputSnippet,inputPrefixSnippet,outputSamplingSnippet,inputSamplingSnippet,userCode].join("\n");return source}function getSamplerFromInInfo(inInfo){const shape=inInfo.shapeInfo.logicalShape;switch(shape.length){case 0:return getSamplerScalar(inInfo);case 1:return getSampler1D(inInfo);case 2:return getSampler2D(inInfo);case 3:return getSampler3D(inInfo);case 4:return getSampler4D(inInfo);case 5:return getSampler5D(inInfo);case 6:return getSampler6D(inInfo);default:throw new Error(`${shape.length}-D input sampling`+` is not yet supported`)}}function getPackedSamplerFromInInfo(inInfo){const shape=inInfo.shapeInfo.logicalShape;switch(shape.length){case 0:return getPackedSamplerScalar(inInfo);case 1:return getPackedSampler1D(inInfo);case 2:return getPackedSampler2D(inInfo);case 3:return getPackedSampler3D(inInfo);default:return getPackedSamplerND(inInfo)}}function getInputSamplingSnippet(inInfo,outShapeInfo,usesPackedTextures=false){let res="";if(usesPackedTextures){res+=getPackedSamplerFromInInfo(inInfo)}else{res+=getSamplerFromInInfo(inInfo)}const inShape=inInfo.shapeInfo.logicalShape;const outShape=outShapeInfo.logicalShape;if(inShape.length<=outShape.length){if(usesPackedTextures){res+=getPackedSamplerAtOutputCoords(inInfo,outShapeInfo)}else{res+=getSamplerAtOutputCoords(inInfo,outShapeInfo)}}return res}function getPackedOutputSamplingSnippet(outShape,outTexShape){switch(outShape.length){case 0:return getOutputScalarCoords();case 1:return getOutputPacked1DCoords(outShape,outTexShape);case 2:return getOutputPacked2DCoords(outShape,outTexShape);case 3:return getOutputPacked3DCoords(outShape,outTexShape);default:return getOutputPackedNDCoords(outShape,outTexShape)}}function getOutputSamplingSnippet(outShape,outTexShape){switch(outShape.length){case 0:return getOutputScalarCoords();case 1:return getOutput1DCoords(outShape,outTexShape);case 2:return getOutput2DCoords(outShape,outTexShape);case 3:return getOutput3DCoords(outShape,outTexShape);case 4:return getOutput4DCoords(outShape,outTexShape);case 5:return getOutput5DCoords(outShape,outTexShape);case 6:return getOutput6DCoords(outShape,outTexShape);default:throw new Error(`${outShape.length}-D output sampling is not yet supported`)}}function getFloatTextureSampleSnippet(glsl){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${glsl.texture2D}(textureSampler, uv).r;\n    }\n  `}function getFloatTextureSetRSnippet(glsl){return`\n    void setOutput(float val) {\n      ${glsl.output} = vec4(val, 0, 0, 0);\n    }\n  `}function getFloatTextureSetRGBASnippet(glsl){return`\n    void setOutput(vec4 val) {\n      ${glsl.output} = val;\n    }\n  `}function getShaderPrefix(glsl){const SHADER_PREFIX=`${glsl.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${glsl.varyingFs} vec2 resultUV;\n    ${glsl.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${glsl.defineSpecialNaN}\n    ${glsl.defineSpecialInf}\n    ${glsl.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${SAMPLE_1D_SNIPPET}\n    ${SAMPLE_2D_SNIPPET}\n    ${SAMPLE_3D_SNIPPET}\n  `;return SHADER_PREFIX}const SAMPLE_1D_SNIPPET=`\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n`;const SAMPLE_2D_SNIPPET=`\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n`;const SAMPLE_3D_SNIPPET=`\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n`;const SHADER_PACKED_PREFIX=`\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n`;function getOutputScalarCoords(){return`\n    int getOutputCoords() {\n      return 0;\n    }\n  `}function getOutputPacked1DCoords(shape,texShape){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(packedTexShape[0]===1){return`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${packedTexShape[1]}.0);\n      }\n    `}if(packedTexShape[1]===1){return`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${packedTexShape[0]}.0);\n      }\n    `}return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      return 2 * (resTexRC.x * ${packedTexShape[1]} + resTexRC.y);\n    }\n  `}function getOutput1DCoords(shape,texShape){if(texShape[0]===1){return`\n      int getOutputCoords() {\n        return int(resultUV.x * ${texShape[1]}.0);\n      }\n    `}if(texShape[1]===1){return`\n      int getOutputCoords() {\n        return int(resultUV.y * ${texShape[0]}.0);\n      }\n    `}return`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      return resTexRC.x * ${texShape[1]} + resTexRC.y;\n    }\n  `}function getOutputPacked3DCoords(shape,texShape){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];const texelsInLogicalRow=Math.ceil(shape[2]/2);const texelsInBatch=texelsInLogicalRow*Math.ceil(shape[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n\n      int b = index / ${texelsInBatch};\n      index -= b * ${texelsInBatch};\n\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}function getOutput3DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d"],shape);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      ${coordsFromIndexSnippet}\n      return ivec3(r, c, d);\n    }\n  `}function getOutputPackedNDCoords(shape,texShape){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];const texelsInLogicalRow=Math.ceil(shape[shape.length-1]/2);const texelsInBatch=texelsInLogicalRow*Math.ceil(shape[shape.length-2]/2);let texelsInBatchN=texelsInBatch;let batches=``;let coords="b, r, c";for(let b=2;b<shape.length-1;b++){texelsInBatchN*=shape[shape.length-b-1];batches=`\n      int b${b} = index / ${texelsInBatchN};\n      index -= b${b} * ${texelsInBatchN};\n    `+batches;coords=`b${b}, `+coords}return`\n    ivec${shape.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n\n      ${batches}\n\n      int b = index / ${texelsInBatch};\n      index -= b * ${texelsInBatch};\n\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec${shape.length}(${coords});\n    }\n  `}function getOutput4DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2"],shape);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      ${coordsFromIndexSnippet}\n      return ivec4(r, c, d, d2);\n    }\n  `}function getOutput5DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3"],shape);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${texShape[0]},\n                             ${texShape[1]}));\n\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n\n      ${coordsFromIndexSnippet}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}function getOutput6DCoords(shape,texShape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3","d4"],shape);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n\n      ${coordsFromIndexSnippet}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}function getOutputPacked2DCoords(shape,texShape){const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(arraysEqual(shape,texShape)){return`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n      }\n    `}const texelsInLogicalRow=Math.ceil(shape[1]/2);return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));\n\n      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;\n      int r = 2 * (index / ${texelsInLogicalRow});\n      int c = imod(index, ${texelsInLogicalRow}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}function getOutput2DCoords(shape,texShape){if(arraysEqual(shape,texShape)){return`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${texShape[0]}, ${texShape[1]}));\n      }\n    `}if(shape[1]===1){return`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${texShape[0]}, ${texShape[1]}));\n        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `}if(shape[0]===1){return`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${texShape[0]}, ${texShape[1]}));\n        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `}return`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${texShape[0]}, ${texShape[1]}));\n      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;\n      int r = index / ${shape[1]};\n      int c = index - r * ${shape[1]};\n      return ivec2(r, c);\n    }\n  `}function getFlatOffsetUniformName(texName){return`offset${texName}`}function getPackedSamplerScalar(inputInfo){const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const glsl=getGlslDifferences();return`\n    vec4 ${funcName}() {\n      return ${glsl.texture2D}(${texName}, halfCR);\n    }\n  `}function getSamplerScalar(inputInfo){const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);if(inputInfo.shapeInfo.isUniform){return`float ${funcName}() {return ${texName};}`}const[texNumR,texNumC]=inputInfo.shapeInfo.texShape;if(texNumR===1&&texNumC===1){return`\n      float ${funcName}() {\n        return sampleTexture(${texName}, halfCR);\n      }\n    `}const[tNumR,tNumC]=inputInfo.shapeInfo.texShape;const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}() {\n      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}function getPackedSampler1D(inputInfo){const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const texShape=inputInfo.shapeInfo.texShape;const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];const glsl=getGlslDifferences();return`\n    vec4 ${funcName}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${packedTexShape[0]}, ${packedTexShape[1]}, index);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}function getSampler1D(inputInfo){const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int index) {\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const texShape=inputInfo.shapeInfo.texShape;const tNumR=texShape[0];const tNumC=texShape[1];if(tNumC===1&&tNumR===1){return`\n      float ${funcName}(int index) {\n        return sampleTexture(${texName}, halfCR);\n      }\n    `}const offset=getFlatOffsetUniformName(texName);if(tNumC===1){return`\n      float ${funcName}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / ${tNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}if(tNumR===1){return`\n      float ${funcName}(int index) {\n        vec2 uv = vec2((float(index + ${offset}) + 0.5) / ${tNumC}.0, 0.5);\n        return sampleTexture(${texName}, uv);\n      }\n    `}return`\n    float ${funcName}(int index) {\n      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}function getPackedSampler2D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const texShape=inputInfo.shapeInfo.texShape;const texNumR=texShape[0];const texNumC=texShape[1];const glsl=getGlslDifferences();if(texShape!=null&&arraysEqual(shape,texShape)){return`\n      vec4 ${funcName}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);\n\n        return ${glsl.texture2D}(${texName}, uv);\n      }\n    `}const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];const valuesPerRow=Math.ceil(shape[1]/2);return`\n    vec4 ${funcName}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${valuesPerRow}, ${packedTexShape[0]}, ${packedTexShape[1]}, row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}function getSampler2D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const texShape=inputInfo.shapeInfo.texShape;if(texShape!=null&&arraysEqual(shape,texShape)){const texNumR=texShape[0];const texNumC=texShape[1];return`\n    float ${funcName}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `}const{newShape:newShape,keptDims:keptDims}=squeezeShape(shape);const squeezedShape=newShape;if(squeezedShape.length<shape.length){const newInputInfo=squeezeInputInfo(inputInfo,squeezedShape);const params=["row","col"];return`\n      ${getSamplerFromInInfo(newInputInfo)}\n      float ${funcName}(int row, int col) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${shape[1]}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const texNumR=texShape[0];const texNumC=texShape[1];const offset=getFlatOffsetUniformName(texName);if(texNumC===1){return`\n    float ${funcName}(int row, int col) {\n      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `}if(texNumR===1){return`\n    float ${funcName}(int row, int col) {\n      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${texNumC}.0, 0.5);\n      return sampleTexture(${texName}, uv);\n    }\n  `}return`\n  float ${funcName}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${shape[1]} + col + ${offset};\n    vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n    return sampleTexture(${texName}, uv);\n  }\n`}function getPackedSampler3D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const texShape=inputInfo.shapeInfo.texShape;const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];if(shape[0]===1){const squeezedShape=shape.slice(1);const keptDims=[1,2];const newInputInfo=squeezeInputInfo(inputInfo,squeezedShape);const params=["b","row","col"];return`\n        ${getPackedSamplerFromInInfo(newInputInfo)}\n        vec4 ${funcName}(int b, int row, int col) {\n          return ${funcName}(${getSqueezedParams(params,keptDims)});\n        }\n      `}const texNumR=packedTexShape[0];const texNumC=packedTexShape[1];const valuesPerRow=Math.ceil(shape[2]/2);const texelsInBatch=valuesPerRow*Math.ceil(shape[1]/2);const glsl=getGlslDifferences();return`\n    vec4 ${funcName}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${texNumR}, ${texNumC}, ${texelsInBatch}, ${valuesPerRow}, b, row, col);\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}function getSampler3D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const stride0=shape[1]*shape[2];const stride1=shape[2];const{newShape:newShape,keptDims:keptDims}=squeezeShape(shape);const squeezedShape=newShape;if(squeezedShape.length<shape.length){const newInputInfo=squeezeInputInfo(inputInfo,squeezedShape);const params=["row","col","depth"];return`\n        ${getSamplerFromInInfo(newInputInfo)}\n        float ${funcName}(int row, int col, int depth) {\n          return ${funcName}(${getSqueezedParams(params,keptDims)});\n        }\n      `}if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${stride0}, ${stride1}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const texShape=inputInfo.shapeInfo.texShape;const texNumR=texShape[0];const texNumC=texShape[1];const flatOffset=inputInfo.shapeInfo.flatOffset;if(texNumC===stride0&&flatOffset==null){return`\n        float ${funcName}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${stride1}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${texNumC}.0, ${texNumR}.0);\n          return sampleTexture(${texName}, uv);\n        }\n      `}if(texNumC===stride1&&flatOffset==null){return`\n    float ${funcName}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${shape[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);\n      return sampleTexture(${texName}, uv);\n    }\n  `}const offset=getFlatOffsetUniformName(texName);return`\n      float ${funcName}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${stride0} + col * ${stride1} + depth + ${offset};\n        vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n        return sampleTexture(${texName}, uv);\n      }\n  `}function getPackedSamplerND(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const rank=shape.length;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const texShape=inputInfo.shapeInfo.texShape;const packedTexShape=[Math.ceil(texShape[0]/2),Math.ceil(texShape[1]/2)];const texNumR=packedTexShape[0];const texNumC=packedTexShape[1];const valuesPerRow=Math.ceil(shape[rank-1]/2);let texelsInBatch=valuesPerRow*Math.ceil(shape[rank-2]/2);let params=`int b, int row, int col`;let index=`b * ${texelsInBatch} + (row / 2) * ${valuesPerRow} + (col / 2)`;for(let b=2;b<rank-1;b++){params=`int b${b}, `+params;texelsInBatch*=shape[rank-b-1];index=`b${b} * ${texelsInBatch} + `+index}const glsl=getGlslDifferences();return`\n    vec4 ${funcName}(${params}) {\n      int index = ${index};\n      int texR = index / ${texNumC};\n      int texC = index - texR * ${texNumC};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}, ${texNumR});\n      return ${glsl.texture2D}(${texName}, uv);\n    }\n  `}function getSampler4D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const stride2=shape[3];const stride1=shape[2]*stride2;const stride0=shape[1]*stride1;const{newShape:newShape,keptDims:keptDims}=squeezeShape(shape);if(newShape.length<shape.length){const newInputInfo=squeezeInputInfo(inputInfo,newShape);const params=["row","col","depth","depth2"];return`\n      ${getSamplerFromInInfo(newInputInfo)}\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${stride0}, ${stride1}, ${stride2}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const flatOffset=inputInfo.shapeInfo.flatOffset;const texShape=inputInfo.shapeInfo.texShape;const texNumR=texShape[0];const texNumC=texShape[1];if(texNumC===stride0&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${stride1}, ${stride2}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}if(texNumC===stride2&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${shape[1]*shape[2]}, ${shape[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} +\n          depth * ${stride2} + depth2;\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index + ${offset});\n      return sampleTexture(${texName}, uv);\n    }\n  `}function getSampler5D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const stride3=shape[4];const stride2=shape[3]*stride3;const stride1=shape[2]*stride2;const stride0=shape[1]*stride1;const{newShape:newShape,keptDims:keptDims}=squeezeShape(shape);if(newShape.length<shape.length){const newInputInfo=squeezeInputInfo(inputInfo,newShape);const params=["row","col","depth","depth2","depth3"];return`\n      ${getSamplerFromInInfo(newInputInfo)}\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +\n          depth3;\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const flatOffset=inputInfo.shapeInfo.flatOffset;const texShape=inputInfo.shapeInfo.texShape;const texNumR=texShape[0];const texNumC=texShape[1];if(texNumC===stride0&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${stride1}, ${stride2}, ${stride3}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}if(texNumC===stride3&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${shape[1]*shape[2]*shape[3]},\n               ${shape[2]*shape[3]}, ${shape[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +\n          depth2 * ${stride3} + depth3 + ${offset};\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n      return sampleTexture(${texName}, uv);\n    }\n  `}function getSampler6D(inputInfo){const shape=inputInfo.shapeInfo.logicalShape;const texName=inputInfo.name;const funcName="get"+texName.charAt(0).toUpperCase()+texName.slice(1);const{newShape:newShape,keptDims:keptDims}=squeezeShape(shape);if(newShape.length<shape.length){const newInputInfo=squeezeInputInfo(inputInfo,newShape);const params=["row","col","depth","depth2","depth3","depth4"];return`\n      ${getSamplerFromInInfo(newInputInfo)}\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${funcName}(${getSqueezedParams(params,keptDims)});\n      }\n    `}const stride4=shape[5];const stride3=shape[4]*stride4;const stride2=shape[3]*stride3;const stride1=shape[2]*stride2;const stride0=shape[1]*stride1;if(inputInfo.shapeInfo.isUniform){return`\n      float ${funcName}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${stride4}, 1)));\n        ${getUniformSampler(inputInfo)}\n      }\n    `}const flatOffset=inputInfo.shapeInfo.flatOffset;const texShape=inputInfo.shapeInfo.texShape;const texNumR=texShape[0];const texNumC=texShape[1];if(texNumC===stride0&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${stride1}, ${stride2}, ${stride3}, ${stride4})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}if(texNumC===stride4&&flatOffset==null){return`\n      float ${funcName}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${shape[1]*shape[2]*shape[3]*shape[4]},\n               ${shape[2]*shape[3]*shape[4]},\n               ${shape[3]*shape[4]},\n               ${shape[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${texNumC}.0, ${texNumR}.0);\n        return sampleTexture(${texName}, uv);\n      }\n    `}const offset=getFlatOffsetUniformName(texName);return`\n    float ${funcName}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +\n          depth2 * ${stride3} + depth3 * ${stride4} + depth4 + ${offset};\n      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);\n      return sampleTexture(${texName}, uv);\n    }\n  `}function getUniformSampler(inputInfo){const texName=inputInfo.name;const inSize=sizeFromShape(inputInfo.shapeInfo.logicalShape);if(inSize<2){return`return ${texName};`}return`\n    for (int i = 0; i < ${inSize}; i++) {\n      if (i == index) {\n        return ${texName}[i];\n      }\n    }\n  `}function getPackedSamplerAtOutputCoords(inputInfo,outShapeInfo){const texName=inputInfo.name;const texFuncSnippet=texName.charAt(0).toUpperCase()+texName.slice(1);const funcName="get"+texFuncSnippet+"AtOutCoords";const inRank=inputInfo.shapeInfo.logicalShape.length;const outRank=outShapeInfo.logicalShape.length;const broadcastDims=getBroadcastDims(inputInfo.shapeInfo.logicalShape,outShapeInfo.logicalShape);const type=getCoordsDataType(outRank);const rankDiff=outRank-inRank;let coordsSnippet;const fields=["x","y","z","w","u","v"];if(inRank===0){coordsSnippet=""}else if(outRank<2&&broadcastDims.length>=1){coordsSnippet="coords = 0;"}else{coordsSnippet=broadcastDims.map((d=>`coords.${fields[d+rankDiff]} = 0;`)).join("\n")}let unpackedCoordsSnippet="";if(outRank<2&&inRank>0){unpackedCoordsSnippet="coords"}else{unpackedCoordsSnippet=inputInfo.shapeInfo.logicalShape.map(((s,i)=>`coords.${fields[i+rankDiff]}`)).join(", ")}let output=`return outputValue;`;const inSize=sizeFromShape(inputInfo.shapeInfo.logicalShape);const isInputScalar=inSize===1;const outSize=sizeFromShape(outShapeInfo.logicalShape);const isOutputScalar=outSize===1;if(inRank===1&&!isInputScalar&&!isOutputScalar){output=`\n      return vec4(outputValue.xy, outputValue.xy);\n    `}else if(isInputScalar&&!isOutputScalar){if(outRank===1){output=`\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      `}else{output=`\n        return vec4(outputValue.x);\n      `}}else if(broadcastDims.length){const rows=inRank-2;const cols=inRank-1;if(broadcastDims.indexOf(rows)>-1&&broadcastDims.indexOf(cols)>-1){output=`return vec4(outputValue.x);`}else if(broadcastDims.indexOf(rows)>-1){output=`return vec4(outputValue.x, outputValue.y, `+`outputValue.x, outputValue.y);`}else if(broadcastDims.indexOf(cols)>-1){output=`return vec4(outputValue.xx, outputValue.zz);`}}return`\n    vec4 ${funcName}() {\n      ${type} coords = getOutputCoords();\n      ${coordsSnippet}\n      vec4 outputValue = get${texFuncSnippet}(${unpackedCoordsSnippet});\n      ${output}\n    }\n  `}function getSamplerAtOutputCoords(inputInfo,outShapeInfo){const texName=inputInfo.name;const texFuncSnippet=texName.charAt(0).toUpperCase()+texName.slice(1);const funcName="get"+texFuncSnippet+"AtOutCoords";const outTexShape=outShapeInfo.texShape;const inTexShape=inputInfo.shapeInfo.texShape;const inRank=inputInfo.shapeInfo.logicalShape.length;const outRank=outShapeInfo.logicalShape.length;if(!inputInfo.shapeInfo.isUniform&&inRank===outRank&&inputInfo.shapeInfo.flatOffset==null&&arraysEqual(inTexShape,outTexShape)){return`\n      float ${funcName}() {\n        return sampleTexture(${texName}, resultUV);\n      }\n    `}const type=getCoordsDataType(outRank);const broadcastDims=getBroadcastDims(inputInfo.shapeInfo.logicalShape,outShapeInfo.logicalShape);const rankDiff=outRank-inRank;let coordsSnippet;const fields=["x","y","z","w","u","v"];if(inRank===0){coordsSnippet=""}else if(outRank<2&&broadcastDims.length>=1){coordsSnippet="coords = 0;"}else{coordsSnippet=broadcastDims.map((d=>`coords.${fields[d+rankDiff]} = 0;`)).join("\n")}let unpackedCoordsSnippet="";if(outRank<2&&inRank>0){unpackedCoordsSnippet="coords"}else{unpackedCoordsSnippet=inputInfo.shapeInfo.logicalShape.map(((s,i)=>`coords.${fields[i+rankDiff]}`)).join(", ")}return`\n    float ${funcName}() {\n      ${type} coords = getOutputCoords();\n      ${coordsSnippet}\n      return get${texFuncSnippet}(${unpackedCoordsSnippet});\n    }\n  `}function getCoordsDataType(rank){if(rank<=1){return"int"}else if(rank===2){return"ivec2"}else if(rank===3){return"ivec3"}else if(rank===4){return"ivec4"}else if(rank===5){return"ivec5"}else if(rank===6){return"ivec6"}else{throw Error(`GPU for rank ${rank} is not yet supported`)}}function squeezeInputInfo(inInfo,squeezedShape){const newInputInfo=JSON.parse(JSON.stringify(inInfo));newInputInfo.shapeInfo.logicalShape=squeezedShape;return newInputInfo}function getSqueezedParams(params,keptDims){return keptDims.map((d=>params[d])).join(", ")}function compileProgram(gpgpu,program,inputs,output){const userCode=program.userCode;const inputInfos=inputs.map(((input,i)=>{const shapeInfo={logicalShape:input.shape,texShape:input.isUniform?null:input.texData.texShape,isUniform:input.isUniform,isPacked:input.isUniform?false:input.texData.isPacked,flatOffset:null};if(input.texData!=null&&input.texData.slice!=null&&input.texData.slice.flatOffset>0){shapeInfo.flatOffset=input.texData.slice.flatOffset}return{name:program.variableNames[i],shapeInfo:shapeInfo}}));const inShapeInfos=inputInfos.map((x=>x.shapeInfo));const outShapeInfo={logicalShape:output.shape,texShape:output.texData.texShape,isUniform:false,isPacked:output.texData.isPacked,flatOffset:null};const source=makeShader(inputInfos,outShapeInfo,userCode,program.packedInputs);const webGLProgram=gpgpu.createProgram(source);let infLoc=null;const nanLoc=gpgpu.getUniformLocation(webGLProgram,"NAN",false);if(env().getNumber("WEBGL_VERSION")===1){infLoc=gpgpu.getUniformLocation(webGLProgram,"INFINITY",false)}const uniformLocations={};for(let i=0;i<program.variableNames.length;i++){const varName=program.variableNames[i];const shouldThrow=false;uniformLocations[varName]=gpgpu.getUniformLocation(webGLProgram,varName,shouldThrow);uniformLocations[`offset${varName}`]=gpgpu.getUniformLocation(webGLProgram,`offset${varName}`,shouldThrow)}return{program:program,source:source,webGLProgram:webGLProgram,uniformLocations:uniformLocations,inShapeInfos:inShapeInfos,outShapeInfo:outShapeInfo,infLoc:infLoc,nanLoc:nanLoc}}function validateBinaryAndProgram(shapeInfos,inputs){if(shapeInfos.length!==inputs.length){throw Error(`Binary was compiled with ${shapeInfos.length} inputs, but `+`was executed with ${inputs.length} inputs`)}shapeInfos.forEach(((s,i)=>{const shapeA=s.logicalShape;const input=inputs[i];const shapeB=input.shape;if(!arraysEqual(shapeA,shapeB)){throw Error(`Binary was compiled with different shapes than `+`the current args. Shapes ${shapeA} and ${shapeB} must match`)}if(s.isUniform&&input.isUniform){return}const texShapeA=s.texShape;const texShapeB=input.isUniform?null:input.texData.texShape;if(!arraysEqual(texShapeA,texShapeB)){throw Error(`Binary was compiled with different texture shapes than the`+` current args. Shape ${texShapeA} and ${texShapeB} must match`)}}))}function runProgram(gpgpu,binary,inputs,output,customSetup){validateBinaryAndProgram(binary.inShapeInfos,inputs);validateBinaryAndProgram([binary.outShapeInfo],[output]);const outTex=output.texData.texture;const outTexShape=output.texData.texShape;if(output.texData.isPacked){gpgpu.setOutputPackedMatrixTexture(outTex,outTexShape[0],outTexShape[1])}else{gpgpu.setOutputMatrixTexture(outTex,outTexShape[0],outTexShape[1])}gpgpu.setProgram(binary.webGLProgram);if(env().getNumber("WEBGL_VERSION")===1){if(binary.infLoc!==null){gpgpu.gl.uniform1f(binary.infLoc,Infinity)}}if(binary.nanLoc!==null){gpgpu.gl.uniform1f(binary.nanLoc,NaN)}inputs.forEach(((input,i)=>{const varName=binary.program.variableNames[i];const varLoc=binary.uniformLocations[varName];const varOffsetLoc=binary.uniformLocations[`offset${varName}`];if(varLoc==null){return}if(input.isUniform){if(sizeFromShape(input.shape)<2){gpgpu.gl.uniform1f(varLoc,input.uniformValues[0])}else{let vals=input.uniformValues;if(!(vals instanceof Float32Array)){vals=new Float32Array(vals)}gpgpu.gl.uniform1fv(varLoc,vals)}return}if(input.texData.slice!=null&&varOffsetLoc!=null){gpgpu.gl.uniform1i(varOffsetLoc,input.texData.slice.flatOffset)}gpgpu.setInputMatrixTexture(input.texData.texture,varLoc,i)}));if(customSetup!=null){customSetup(gpgpu,binary.webGLProgram)}gpgpu.executeProgram()}function makeShaderKey(program,inputs,output){let keyInputs="";inputs.concat(output).forEach((x=>{const hasOffset=x.texData!=null&&x.texData.slice!=null&&x.texData.slice.flatOffset>0;const texShape=x.isUniform?"uniform":x.texData.texShape;keyInputs+=`${x.shape}_${texShape}_${hasOffset}`}));const keyUserCode=program.userCode;let key=program.constructor.name;key+="_"+keyInputs+"_"+keyUserCode;return key}function simpleAbsImpl(vals){const resultValues=new Float32Array(vals.length);for(let i=0;i<vals.length;++i){resultValues[i]=Math.abs(vals[i])}return resultValues}function createSimpleBinaryKernelImpl(op){return(aShape,bShape,aVals,bVals,dtype)=>{const newShape=assertAndGetBroadcastShape(aShape,bShape);const resultRank=newShape.length;const resultStrides=computeStrides(newShape);const resultSize=sizeFromShape(newShape);const result=getTypedArrayFromDType(dtype,resultSize);const aRank=aShape.length;const bRank=bShape.length;const aStrides=computeStrides(aShape);const bStrides=computeStrides(bShape);const aBroadcastDims=getBroadcastDims$1(aShape,newShape);const bBroadcastDims=getBroadcastDims$1(bShape,newShape);if(aBroadcastDims.length+bBroadcastDims.length===0){for(let i=0;i<result.length;++i){result[i]=op(aVals[i%aVals.length],bVals[i%bVals.length])}}else{for(let i=0;i<result.length;++i){const loc=indexToLoc(i,resultRank,resultStrides);const aLoc=loc.slice(-aRank);aBroadcastDims.forEach((d=>aLoc[d]=0));const aIndex=locToIndex(aLoc,aRank,aStrides);const bLoc=loc.slice(-bRank);bBroadcastDims.forEach((d=>bLoc[d]=0));const bIndex=locToIndex(bLoc,bRank,bStrides);result[i]=op(aVals[aIndex],bVals[bIndex])}}return[result,newShape]}}const addImpl=createSimpleBinaryKernelImpl(((a,b)=>a+b));function bincountImpl(xVals,weightsVals,weightsDtype,weightsShape,size){const weightsSize=sizeFromShape(weightsShape);const outVals=makeZerosTypedArray(size,weightsDtype);for(let i=0;i<xVals.length;i++){const value=xVals[i];if(value<0){throw new Error("Input x must be non-negative!")}if(value>=size){continue}if(weightsSize>0){outVals[value]+=weightsVals[i]}else{outVals[value]+=1}}return outVals}function bincountReduceImpl(xBuf,weightsBuf,size,binaryOutput=false){const numRows=xBuf.shape[0];const numCols=xBuf.shape[1];const outBuf=buffer([numRows,size],weightsBuf.dtype);for(let i=0;i<numRows;i++){for(let j=0;j<numCols;j++){const value=xBuf.get(i,j);if(value<0){throw new Error("Input x must be non-negative!")}if(value>=size){continue}if(binaryOutput){outBuf.set(1,i,value)}else{if(weightsBuf.size>0){outBuf.set(outBuf.get(i,value)+weightsBuf.get(i,j),i,value)}else{outBuf.set(outBuf.get(i,value)+1,i,value)}}}}return outBuf}function createSimpleUnaryImpl(op){return(values,dtype,attrs)=>{const newValues=getTypedArrayFromDType(dtype,values.length);for(let i=0;i<values.length;++i){newValues[i]=op(values[i],attrs)}return newValues}}const ceilImpl=createSimpleUnaryImpl((xi=>Math.ceil(xi)));function concatImpl$1(inputs,outShape,dtype,simplyConcat){const outVals=getArrayFromDType(dtype,sizeFromShape(outShape));if(simplyConcat&&dtype!=="string"){let offset=0;inputs.forEach((input=>{const size=sizeFromShape(input.shape);outVals.set(input.vals,offset);offset+=size}))}else{let colOffset=0;inputs.forEach((input=>{const decodedData=dtype==="string"?fromUint8ToStringArray(input.vals):input.vals;let tIdx=0;for(let row=0;row<input.shape[0];++row){const resIdx=row*outShape[1]+colOffset;for(let col=0;col<input.shape[1];++col){outVals[resIdx+col]=decodedData[tIdx++]}}colOffset+=input.shape[1]}))}return outVals}const expImpl=createSimpleUnaryImpl((xi=>Math.exp(xi)));const expm1Impl=createSimpleUnaryImpl((xi=>Math.expm1(xi)));const floorImpl=createSimpleUnaryImpl((xi=>Math.floor(xi)));function gatherV2Impl(xBuf,indicesBuf,flattenOutputShape){const outBuf=buffer(flattenOutputShape,xBuf.dtype);for(let i=0;i<outBuf.size;++i){const newLoc=outBuf.indexToLoc(i);const originalLoc=newLoc.slice();const batchIdx=originalLoc[0];const indicesIdx=originalLoc[2];const indicesIndex=indicesBuf.locToIndex([batchIdx,indicesIdx]);originalLoc[2]=indicesBuf.values[indicesIndex];const originalIndex=xBuf.locToIndex(originalLoc);outBuf.values[i]=xBuf.values[originalIndex]}return outBuf}const greaterImpl=createSimpleBinaryKernelImpl(((a,b)=>a>b?1:0));const lessImpl=createSimpleBinaryKernelImpl(((a,b)=>a<b?1:0));function linSpaceImpl(start,stop,num){const step=(stop-start)/(num-1);const values=makeZerosTypedArray(num,"float32");values[0]=start;for(let i=1;i<values.length;i++){values[i]=values[i-1]+step}return values}const logImpl=createSimpleUnaryImpl((xi=>Math.log(xi)));function maxImpl$1(aVals,reduceSize,outShape,dtype){const vals=getTypedArrayFromDType(dtype,sizeFromShape(outShape));for(let i=0;i<vals.length;++i){const offset=i*reduceSize;let max=aVals[offset];for(let j=0;j<reduceSize;++j){const value=aVals[offset+j];if(value>max){max=value}}vals[i]=max}return vals}const maximumImpl=createSimpleBinaryKernelImpl(((aValue,bValue)=>Math.max(aValue,bValue)));const minimumImpl=createSimpleBinaryKernelImpl(((aValue,bValue)=>Math.min(aValue,bValue)));const multiplyImpl=createSimpleBinaryKernelImpl(((aValue,bValue)=>aValue*bValue));function negImpl(xVals,xShape,xDtype){const minusOne=createScalarValue(-1,xDtype);return multiplyImpl([],xShape,minusOne,xVals,xDtype)}const notEqualImpl=createSimpleBinaryKernelImpl(((a,b)=>a!==b?1:0));function transposeImpl$1(xVals,xShape,dtype,perm,newShape){const xRank=xShape.length;const xSize=sizeFromShape(xShape);const xStrides=computeStrides(xShape);const newStrides=computeStrides(newShape);const result=getTypedArrayFromDType(dtype,sizeFromShape(newShape));for(let i=0;i<xSize;++i){const loc=indexToLoc(i,xRank,xStrides);const newLoc=new Array(loc.length);for(let i=0;i<newLoc.length;i++){newLoc[i]=loc[perm[i]]}const newIndex=locToIndex(newLoc,xRank,newStrides);result[newIndex]=xVals[i]}return result}function prodImpl(xShape,xDtype,xVals,reductionAxes){const[outShape,reduceShape]=computeOutAndReduceShapes(xShape,reductionAxes);const outDtype=upcastType(xDtype,"int32");const outVals=makeZerosTypedArray(sizeFromShape(outShape),outDtype);const reduceSize=sizeFromShape(reduceShape);for(let i=0;i<outVals.length;++i){const offset=i*reduceSize;let prod=1;for(let j=0;j<reduceSize;++j){prod*=xVals[offset+j]}outVals[i]=prod}return{outVals:outVals,outShape:outShape,outDtype:outDtype}}function rangeImpl(start,stop,step,dtype){const sameStartStop=start===stop;const increasingRangeNegativeStep=start<stop&&step<0;const decreasingRangePositiveStep=stop<start&&step>1;if(sameStartStop||increasingRangeNegativeStep||decreasingRangePositiveStep){return makeZerosTypedArray(0,dtype)}const numElements=Math.abs(Math.ceil((stop-start)/step));const values=makeZerosTypedArray(numElements,dtype);if(stop<start&&step===1){step=-1}values[0]=start;for(let i=1;i<values.length;i++){values[i]=values[i-1]+step}return values}const rsqrtImpl=createSimpleUnaryImpl((xi=>1/Math.sqrt(xi)));function sliceImpl(vals,begin,size,shape,dtype){const isContinous=isSliceContinous(shape,begin,size);const length=sizeFromShape(size);const xStrides=computeStrides(shape);if(isContinous){const flatOffset=computeFlatOffset(begin,xStrides);if(dtype==="string"){return vals.slice(flatOffset,flatOffset+length)}return vals.subarray(flatOffset,flatOffset+length)}const decodedData=dtype==="string"?fromUint8ToStringArray(vals):vals;const inBuf=buffer(shape,dtype,decodedData);const outBuf=buffer(size,dtype);for(let i=0;i<outBuf.size;++i){const outLoc=outBuf.indexToLoc(i);const inLoc=outLoc.map(((idx,j)=>idx+begin[j]));outBuf.set(inBuf.get(...inLoc),...outLoc)}if(dtype==="string"){return fromStringArrayToUint8(outBuf.values)}return outBuf.values}function sparseFillEmptyRowsImpl(indices,indicesShape,indicesDType,values,valuesDType,denseShape,defaultValue){const indicesCount=indicesShape[0];const denseRows=denseShape[0];const emptyRowIndicator=new Array(denseRows);const reverseIndexMap=new Array(indicesCount);const rank=indicesShape[1];if(denseRows===0){if(indicesCount!==0){throw new Error(`Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ${indicesCount}`)}const outputIndices=getArrayFromDType(indicesDType,0);const outputValues=getArrayFromDType(valuesDType,0);return[outputIndices,[0,rank],outputValues,emptyRowIndicator,reverseIndexMap]}let rowsAreOrdered=true;let lastIndicesRow=0;const csrOffset=new Array(denseRows).fill(0);for(let i=0;i<indicesCount;++i){const row=indices[i*rank];if(row<0){throw new Error(`indices(${i}, 0) is invalid: ${row} < 0`)}if(row>=denseRows){throw new Error(`indices(${i}, 0) is invalid: ${row} >= ${denseRows}`)}++csrOffset[row];rowsAreOrdered=rowsAreOrdered&&row>=lastIndicesRow;lastIndicesRow=row}let allRowsFull=true;for(let row=0;row<denseRows;++row){const rowEmpty=csrOffset[row]===0;emptyRowIndicator[row]=rowEmpty;allRowsFull=allRowsFull&&!rowEmpty;csrOffset[row]=Math.max(csrOffset[row],1);if(row>0){csrOffset[row]+=csrOffset[row-1]}}if(allRowsFull&&rowsAreOrdered){const outputIndices=indices;const outputValues=values;for(let i=0;i<indicesCount;++i){reverseIndexMap[i]=i}return[outputIndices,[indicesCount,rank],outputValues,emptyRowIndicator,reverseIndexMap]}else{const fullIndicesCount=csrOffset[denseRows-1];const outputIndices=getArrayFromDType(indicesDType,fullIndicesCount*rank);const outputValues=getArrayFromDType(valuesDType,fullIndicesCount);const filledCount=new Array(denseRows).fill(0);for(let i=0;i<indicesCount;++i){const row=indices[i*rank];const offset=filledCount[row];const outputI=(row===0?0:csrOffset[row-1])+offset;filledCount[row]++;for(let j=0;j<rank;++j){outputIndices[outputI*rank+j]=indices[i*rank+j]}outputValues[outputI]=values[i];reverseIndexMap[i]=outputI}for(let row=0;row<denseRows;++row){const rowCount=filledCount[row];if(rowCount===0){const startingIndex=row===0?0:csrOffset[row-1];outputIndices[startingIndex*rank+0]=row;for(let col=1;col<rank;++col){outputIndices[startingIndex*rank+col]=0}outputValues[startingIndex]=defaultValue}}return[outputIndices,[indicesCount,rank],outputValues,emptyRowIndicator,reverseIndexMap]}}function sparseReshapeImpl(inputIndices,inputIndicesShape,inputDType,inputShape,targetShape){const denseSize=sizeFromShape(inputShape);const nnz=inputIndicesShape[0];const outputRank=targetShape.length;const outputShape=[];let product=1;let unknownIndex=-1;for(let d=0;d<outputRank;++d){const size=targetShape[d];if(size===-1){if(unknownIndex!==-1){throw new Error(`only one output dimension may be -1, not both ${unknownIndex} and ${d}`)}unknownIndex=d;outputShape.push(1)}else{if(size<0){throw new Error(`size ${d} must be non-negative, not ${size}`)}product*=size;outputShape.push(size)}}if(unknownIndex!==-1){if(product<=0){throw new Error("reshape cannot infer the missing "+"input size for an empty tensor unless all "+"specified input sizes are non-zero")}const missing=Math.trunc(denseSize/product);if(product*missing!==denseSize){throw new Error(`Input to reshape is a SparseTensor with ${denseSize}\n          dense values, but the requested shape requires a multiple of ${product}. inputShape=${inputShape} outputShape= ${outputShape}`)}outputShape[unknownIndex]=missing}const outputSize=sizeFromShape(outputShape);if(outputSize!==denseSize){throw new Error(`Input to reshape is a tensor with ${denseSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`)}const inputRank=inputShape.length;const inputStrides=[];if(inputRank>0){inputStrides[inputRank-1]=1;for(let d=inputRank-2;d>=0;--d){inputStrides[d]=inputStrides[d+1]*inputShape[d+1]}}const outputStrides=[];if(outputRank>0){outputStrides[outputRank-1]=1;for(let d=outputRank-2;d>=0;--d){outputStrides[d]=outputStrides[d+1]*outputShape[d+1]}}const newIndices=getArrayFromDType(inputDType,nnz*outputRank);for(let i=0;i<nnz;++i){let id=0;for(let j=0;j<inputRank;++j){id+=inputIndices[i*inputRank+j]*inputStrides[j]}for(let j=0;j<outputRank;++j){newIndices[i*outputRank+j]=Math.trunc(id/outputStrides[j]);id%=outputStrides[j]}}return[newIndices,[nnz,outputRank],outputShape]}const squaredDifferenceImpl=createSimpleBinaryKernelImpl(((a,b)=>{const diff=a-b;return diff*diff}));function stridedSliceImpl(outShape,xBuf,strides,begin){const outBuf=buffer(outShape,xBuf.dtype);for(let i=0;i<outBuf.size;i++){const loc=outBuf.indexToLoc(i);const newLoc=new Array(loc.length);for(let j=0;j<newLoc.length;j++){newLoc[j]=loc[j]*strides[j]+begin[j]}outBuf.set(xBuf.get(...newLoc),...loc)}return outBuf}const subImpl=createSimpleBinaryKernelImpl(((aValue,bValue)=>aValue-bValue));function tileImpl(xBuf,reps){const newShape=new Array(xBuf.rank);for(let i=0;i<newShape.length;i++){newShape[i]=xBuf.shape[i]*reps[i]}const result=buffer(newShape,xBuf.dtype);for(let i=0;i<result.values.length;++i){const newLoc=result.indexToLoc(i);const originalLoc=new Array(xBuf.rank);for(let j=0;j<originalLoc.length;j++){originalLoc[j]=newLoc[j]%xBuf.shape[j]}const originalIndex=xBuf.locToIndex(originalLoc);result.values[i]=xBuf.values[originalIndex]}return result}function topKImpl(x,xShape,xDtype,k,sorted){const lastDim=xShape[xShape.length-1];const[batch,size]=[x.length/lastDim,lastDim];const allTopKVals=getTypedArrayFromDType(xDtype,batch*k);const allTopKIndices=getTypedArrayFromDType("int32",batch*k);for(let b=0;b<batch;b++){const offset=b*size;const vals=x.subarray(offset,offset+size);const valAndInd=[];for(let i=0;i<vals.length;i++){valAndInd.push({value:vals[i],index:i})}valAndInd.sort(((a,b)=>b.value-a.value));const outOffset=b*k;const topKVals=allTopKVals.subarray(outOffset,outOffset+k);const topKIndices=allTopKIndices.subarray(outOffset,outOffset+k);for(let i=0;i<k;i++){topKVals[i]=valAndInd[i].value;topKIndices[i]=valAndInd[i].index}}const outputShape=xShape.slice();outputShape[outputShape.length-1]=k;return[buffer(outputShape,xDtype,allTopKVals),buffer(outputShape,"int32",allTopKIndices)]}function uniqueImpl(values,axis,shape,dtype){const $axis=parseAxisParam(axis,shape)[0];const newShape=[1,shape[0],1];for(let i=0;i<$axis;i++){newShape[0]*=shape[i]}newShape[1]=shape[$axis];for(let i=$axis+1;i<shape.length;i++){newShape[2]*=shape[i]}const uniqueElements={};const indices=new Int32Array(shape[$axis]);const inputBuffer=new TensorBuffer(newShape,dtype,values);const uniqueIndices=[];const is1DTensor=newShape[0]===1&&newShape[2]===1;for(let i=0;i<shape[$axis];i++){let element;if(is1DTensor){element=values[i].toString()}else{const axisValues=[];for(let m=0;m<newShape[0];m++){for(let n=0;n<newShape[2];n++){axisValues.push(inputBuffer.get(m,i,n))}}element=axisValues.join(",")}if(uniqueElements[element]!==undefined){indices[i]=uniqueElements[element]}else{const uniqueIndex=Object.keys(uniqueElements).length;uniqueElements[element]=uniqueIndex;indices[i]=uniqueIndex;uniqueIndices.push(i)}}const outputTmpShape=newShape.slice();outputTmpShape[1]=Object.keys(uniqueElements).length;const outputBuffer=new TensorBuffer(outputTmpShape,dtype);uniqueIndices.forEach(((uniqueElementIndex,i)=>{for(let m=0;m<newShape[0];m++){for(let n=0;n<newShape[2];n++){outputBuffer.set(inputBuffer.get(m,uniqueElementIndex,n),m,i,n)}}}));const outputShape=shape.slice();outputShape[$axis]=outputTmpShape[1];return{outputValues:outputBuffer.values,outputShape:outputShape,indices:indices}}var shared=Object.freeze({__proto__:null,simpleAbsImpl:simpleAbsImpl,addImpl:addImpl,bincountImpl:bincountImpl,bincountReduceImpl:bincountReduceImpl,ceilImpl:ceilImpl,concatImpl:concatImpl$1,expImpl:expImpl,expm1Impl:expm1Impl,floorImpl:floorImpl,gatherV2Impl:gatherV2Impl,greaterImpl:greaterImpl,lessImpl:lessImpl,linSpaceImpl:linSpaceImpl,logImpl:logImpl,maxImpl:maxImpl$1,maximumImpl:maximumImpl,minimumImpl:minimumImpl,multiplyImpl:multiplyImpl,negImpl:negImpl,notEqualImpl:notEqualImpl,prodImpl:prodImpl,rangeImpl:rangeImpl,rsqrtImpl:rsqrtImpl,sliceImpl:sliceImpl,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImpl,sparseReshapeImpl:sparseReshapeImpl,squaredDifferenceImpl:squaredDifferenceImpl,stridedSliceImpl:stridedSliceImpl,subImpl:subImpl,tileImpl:tileImpl,topKImpl:topKImpl,transposeImpl:transposeImpl$1,uniqueImpl:uniqueImpl});const{addImpl:addImplCPU,bincountImpl:bincountImplCPU,bincountReduceImpl:bincountReduceImplCPU,ceilImpl:ceilImplCPU,concatImpl:concatImplCPU,expImpl:expImplCPU,expm1Impl:expm1ImplCPU,floorImpl:floorImplCPU,gatherV2Impl:gatherV2ImplCPU,greaterImpl:greaterImplCPU,lessImpl:lessImplCPU,linSpaceImpl:linSpaceImplCPU,logImpl:logImplCPU,maxImpl:maxImplCPU,maximumImpl:maximumImplCPU,minimumImpl:minimumImplCPU,multiplyImpl:multiplyImplCPU,negImpl:negImplCPU,prodImpl:prodImplCPU,rangeImpl:rangeImplCPU,rsqrtImpl:rsqrtImplCPU,simpleAbsImpl:simpleAbsImplCPU,sliceImpl:sliceImplCPU,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImplCPU,sparseReshapeImpl:sparseReshapeImplCPU,stridedSliceImpl:stridedSliceImplCPU,subImpl:subImplCPU,tileImpl:tileImplCPU,topKImpl:topKImplCPU,transposeImpl:transposeImplCPU,uniqueImpl:uniqueImplCPU}=shared;function getVecChannels(name,rank){return["x","y","z","w","u","v"].slice(0,rank).map((d=>`${name}.${d}`))}function getChannels(name,rank){if(rank===1){return[name]}return getVecChannels(name,rank)}function getSourceCoords$2(rank,dims){if(rank===1){return"rc"}let coords="";for(let i=0;i<rank;i++){coords+=dims[i];if(i<rank-1){coords+=","}}return coords}class PackProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=false;this.packedOutput=true;this.outputShape=outputShape;const rank=outputShape.length;if(rank===0){this.userCode=`\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      `}else{const channels=getChannels("rc",rank);const dtype=getCoordsDataType(rank);const outOfBoundsCondition=getOutOfBoundsCondition(rank,outputShape,channels);const setup=getSetup(rank,outputShape[outputShape.length-1],outputShape[outputShape.length-2],channels);const output=getOutput(outputShape,channels);this.userCode=`\n        void main() {\n          ${dtype} rc = getOutputCoords();\n\n          if(${outOfBoundsCondition}) {\n            setOutput(vec4(0));\n          } else {\n            ${setup}\n\n            setOutput(vec4(${output}));\n          }\n        }\n      `}}}function getSourceCoordsArr(rank,dims){const coords=[];for(let row=0;row<=1;row++){for(let col=0;col<=1;col++){let coord=`${row===0?"r":"rp1"}, ${col===0?"c":"cp1"}`;for(let d=2;d<rank;d++){coord=`${dims[dims.length-1-d]},`+coord}coords.push(coord)}}return coords}function getOutOfBoundsCondition(rank,shape,dims){if(rank===1){return`rc > ${shape[0]}`}let cond="";for(let i=rank-2;i<rank;i++){cond+=`${dims[i]} >= ${shape[i]}`;if(i<rank-1){cond+="||"}}return cond}function getSetup(rank,cols,rows,dims){if(rank===1){return""}const innerDims=dims.slice(-2);return`\n    int r = ${innerDims[0]};\n    int c = ${innerDims[1]};\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ${cols};\n    bool rEdge = rp1 >= ${rows};\n  `}function getOutput(shape,dims){const rank=shape.length;const sourceCoords=getSourceCoordsArr(rank,dims);if(rank===1){return`getA(rc),\n            rc + 1 >= ${shape[0]} ? 0. : getA(rc + 1),\n            0, 0`}return`getA(${sourceCoords[0]}),\n          cEdge ? 0. : getA(${sourceCoords[1]}),\n          rEdge ? 0. : getA(${sourceCoords[2]}),\n          rEdge || cEdge ? 0. : getA(${sourceCoords[3]})`}class ReshapePackedProgram{constructor(outputShape,inputShape){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=outputShape;let mainLoop=``;for(let i=0;i<4;i++){let thisRC=`thisRC = rc;`;if(i%2===1){thisRC+=`thisRC.z += 1;`}if(i>1){thisRC+=`thisRC.y += 1;`}mainLoop+=`\n        ${thisRC}\n        ${i>0?`if(thisRC.y < rows && thisRC.z < cols){`:""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${i}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${i>0?"}":""}\n      `}this.userCode=`\n      ${getReshapedInputCoords(inputShape)}\n      ${getFlatIndexFrom3D(outputShape)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${outputShape[1]};\n        int cols = ${outputShape[2]};\n\n        ${mainLoop}\n\n        setOutput(result);\n      }\n    `}}function getReshapedInputCoords(shape){const coordsFromIndexSnippet=getLogicalCoordinatesFromFlatIndex(["r","c","d"],shape);return`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${coordsFromIndexSnippet}\n      return ivec3(r, c, d);\n    }\n  `}class TextureManager{constructor(gpgpu){this.gpgpu=gpgpu;this.numUsedTextures=0;this.numFreeTextures=0;this._numBytesAllocated=0;this._numBytesFree=0;this.freeTextures={};this.logEnabled=false;this.usedTextures={}}acquireTexture(shapeRC,usage,isPacked){const physicalTexType=getPhysicalFromLogicalTextureType(usage,isPacked);const shapeKey=getKeyFromTextureShape(shapeRC,physicalTexType,isPacked);if(!(shapeKey in this.freeTextures)){this.freeTextures[shapeKey]=[]}if(!(shapeKey in this.usedTextures)){this.usedTextures[shapeKey]=[]}const texBytes=computeBytes(shapeRC,physicalTexType,this.gpgpu.gl,this.gpgpu.textureConfig,isPacked);if(this.freeTextures[shapeKey].length>0){this.numFreeTextures--;this.numUsedTextures++;this._numBytesFree-=texBytes;this.log();const newTexture=this.freeTextures[shapeKey].shift();this.usedTextures[shapeKey].push(newTexture);return newTexture}let newTexture;if(physicalTexType===PhysicalTextureType.PACKED_2X2_FLOAT32){newTexture=this.gpgpu.createPackedMatrixTexture(shapeRC[0],shapeRC[1])}else if(physicalTexType===PhysicalTextureType.PACKED_2X2_FLOAT16){newTexture=this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0],shapeRC[1])}else if(physicalTexType===PhysicalTextureType.UNPACKED_FLOAT32){newTexture=this.gpgpu.createFloat32MatrixTexture(shapeRC[0],shapeRC[1])}else if(physicalTexType===PhysicalTextureType.UNPACKED_FLOAT16){newTexture=this.gpgpu.createFloat16MatrixTexture(shapeRC[0],shapeRC[1])}else if(physicalTexType===PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE){newTexture=this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0],shapeRC[1])}this.usedTextures[shapeKey].push(newTexture);this.numUsedTextures++;this._numBytesAllocated+=texBytes;this.log();return newTexture}releaseTexture(texture,shape,logicalTexType,isPacked){if(this.freeTextures==null){return}const physicalTexType=getPhysicalFromLogicalTextureType(logicalTexType,isPacked);const shapeKey=getKeyFromTextureShape(shape,physicalTexType,isPacked);if(!(shapeKey in this.freeTextures)){this.freeTextures[shapeKey]=[]}const texBytes=computeBytes(shape,physicalTexType,this.gpgpu.gl,this.gpgpu.textureConfig,isPacked);const deleteTexThreshold=env().get("WEBGL_DELETE_TEXTURE_THRESHOLD");if(deleteTexThreshold!==-1&&this._numBytesAllocated>deleteTexThreshold){this.gpgpu.deleteMatrixTexture(texture);this._numBytesAllocated-=texBytes}else{this.freeTextures[shapeKey].push(texture);this.numFreeTextures++;this._numBytesFree+=texBytes}this.numUsedTextures--;const texList=this.usedTextures[shapeKey];const texIndex=texList.indexOf(texture);if(texIndex<0){throw new Error("Cannot release a texture that was never provided by this "+"texture manager")}texList.splice(texIndex,1);this.log()}log(){if(!this.logEnabled){return}const total=this.numFreeTextures+this.numUsedTextures;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${total})`);const freeRatio=this._numBytesFree/this._numBytesAllocated;console.log(`Bytes allocated: ${this._numBytesAllocated}`);console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*freeRatio)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(this.freeTextures==null){return}for(const texShape in this.freeTextures){this.freeTextures[texShape].forEach((tex=>{this.gpgpu.deleteMatrixTexture(tex)}))}for(const texShape in this.usedTextures){this.usedTextures[texShape].forEach((tex=>{this.gpgpu.deleteMatrixTexture(tex)}))}this.freeTextures=null;this.usedTextures=null;this.numUsedTextures=0;this.numFreeTextures=0;this._numBytesAllocated=0;this._numBytesFree=0}}function numBytesForInternalFormat(gl,internalFormat){const glany=gl;if(internalFormat===glany.R32F){return 4}else if(internalFormat===glany.R16F){return 2}else if(internalFormat===glany.RGBA32F){return 16}else if(internalFormat===gl.RGBA){return 16}else if(internalFormat===glany.RGBA16F){return 8}throw new Error(`Unknown internal format ${internalFormat}`)}function computeBytes(shape,physicalTexType,gl,textureConfig,isPacked){const internalFormat=internalFormatForPhysicalTexType(physicalTexType,textureConfig);let numElements;if(isPacked){const[packedWidth,packedHeight]=getPackedMatrixTextureShapeWidthHeight(shape[0],shape[1]);numElements=packedWidth*packedHeight}else{const[width,height]=getUnpackedMatrixTextureShapeWidthHeight(shape[0],shape[1]);numElements=width*height}const bytesPerElement=numBytesForInternalFormat(gl,internalFormat);return numElements*bytesPerElement}function internalFormatForPhysicalTexType(physicalTexType,textureConfig){switch(physicalTexType){case PhysicalTextureType.PACKED_2X2_FLOAT32:return getInternalFormatForPackedMatrixTexture(textureConfig);case PhysicalTextureType.PACKED_2X2_FLOAT16:return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);case PhysicalTextureType.UNPACKED_FLOAT32:return getInternalFormatForFloat32MatrixTexture(textureConfig);case PhysicalTextureType.UNPACKED_FLOAT16:return getInternalFormatForFloat16MatrixTexture(textureConfig);case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);default:throw new Error(`Unknown physical texture type ${physicalTexType}`)}}function getPhysicalTextureForRendering(isPacked){if(env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")){if(isPacked){return PhysicalTextureType.PACKED_2X2_FLOAT32}return PhysicalTextureType.UNPACKED_FLOAT32}if(isPacked){return PhysicalTextureType.PACKED_2X2_FLOAT16}return PhysicalTextureType.UNPACKED_FLOAT16}function getPhysicalFromLogicalTextureType(logicalTexType,isPacked){if(logicalTexType===TextureUsage.UPLOAD){return PhysicalTextureType.PACKED_2X2_FLOAT32}else if(logicalTexType===TextureUsage.RENDER||logicalTexType==null){return getPhysicalTextureForRendering(isPacked)}else if(logicalTexType===TextureUsage.DOWNLOAD||logicalTexType===TextureUsage.PIXELS){return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE}throw new Error(`Unknown logical texture type ${logicalTexType}`)}function getKeyFromTextureShape(shapeRowsCol,physicalTexType,isPacked){return`${shapeRowsCol[0]}_${shapeRowsCol[1]}_${physicalTexType}_${isPacked}`}class UnaryOpProgram{constructor(aShape,opSnippet){this.variableNames=["A"];this.outputShape=aShape;this.userCode=`\n      float unaryOperation(float x) {\n        ${opSnippet}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const CHECK_NAN_SNIPPET$2=`if (isnan(x)) return x;`;const LINEAR$1=`return x;`;const ABS$1=`return abs(x);`;const ELU$2=`return (x >= 0.0) ? x : (exp(x) - 1.0);`;const RELU$2=CHECK_NAN_SNIPPET$2+`\n  return (x < 0.0) ? 0.0 : x;\n`;const RELU6$2=CHECK_NAN_SNIPPET$2+`\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n`;const CLONE="return x;";const SIGMOID$2=`return 1.0 / (1.0 + exp(-1.0 * x));`;const LINEAR=`return x;`;const ELU$1=`\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n`;const RELU$1=`\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n`;const RELU6$1=`\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n`;const SIGMOID$1=`return 1.0 / (1.0 + exp(-1.0 * x));`;class UnaryOpPackedProgram{constructor(aShape,opSnippet){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=aShape;this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${opSnippet}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class UnpackProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=false;this.outputShape=outputShape;const rank=outputShape.length;const channels=getChannels("rc",rank);const dtype=getCoordsDataType(rank);const sourceCoords=getSourceCoords$2(rank,channels);const innerDims=channels.slice(-2);const coords=rank<=1?"rc":`vec2(${innerDims.join(",")})`;this.userCode=`\n      void main() {\n        ${dtype} rc = getOutputCoords();\n        vec4 packedInput = getA(${sourceCoords});\n\n        setOutput(getChannel(packedInput, ${coords}));\n      }\n    `}}const whereImpl=whereImpl$1;const EPSILON_FLOAT32=1e-7;const EPSILON_FLOAT16=1e-4;const binaryCaches={};function getBinaryCache(webGLVersion){if(webGLVersion in binaryCaches){return binaryCaches[webGLVersion]}binaryCaches[webGLVersion]={};return binaryCaches[webGLVersion]}const CPU_HANDOFF_SIZE_THRESHOLD=128;const BEFORE_PAGING_CONSTANT=600;function numMBBeforeWarning(){if(env().global.screen==null){return 1024}return env().global.screen.height*env().global.screen.width*window.devicePixelRatio*BEFORE_PAGING_CONSTANT/1024/1024}class MathBackendWebGL extends KernelBackend{constructor(gpgpu){super();this.pendingRead=new WeakMap;this.pendingDisposal=new WeakSet;this.dataRefCount=new WeakMap;this.numBytesInGPU=0;this.uploadWaitMs=0;this.downloadWaitMs=0;this.lastGlFlushTime=0;this.warnedAboutMemory=false;this.pendingDeletes=0;this.disposed=false;if(!env().getBool("HAS_WEBGL")){throw new Error("WebGL is not supported on this device")}if(gpgpu==null){const gl=getWebGLContext(env().getNumber("WEBGL_VERSION"));this.binaryCache=getBinaryCache(env().getNumber("WEBGL_VERSION"));this.gpgpu=new GPGPUContext(gl);this.canvas=gl.canvas;this.gpgpuCreatedLocally=true}else{this.gpgpu=gpgpu;this.binaryCache={};this.gpgpuCreatedLocally=false;this.canvas=gpgpu.gl.canvas}this.textureManager=new TextureManager(this.gpgpu);this.numMBBeforeWarning=numMBBeforeWarning();this.texData=new DataStorage(this,engine())}nextDataId(){return MathBackendWebGL.nextDataId++}numDataIds(){return this.texData.numDataIds()-this.pendingDeletes}write(values,shape,dtype){if(env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||env().getBool("DEBUG")){this.checkNumericalProblems(values)}if(dtype==="complex64"&&values!=null){throw new Error(`Cannot write to a complex64 dtype. `+`Please use tf.complex(real, imag).`)}const dataId={id:this.nextDataId()};this.texData.set(dataId,{shape:shape,dtype:dtype,values:values,usage:TextureUsage.UPLOAD,refCount:1});return dataId}refCount(dataId){if(this.texData.has(dataId)){const tensorData=this.texData.get(dataId);return tensorData.refCount}return 0}incRef(dataId){const texData=this.texData.get(dataId);texData.refCount++}decRef(dataId){if(this.texData.has(dataId)){const texData=this.texData.get(dataId);texData.refCount--}}move(dataId,values,shape,dtype,refCount){if(env().getBool("DEBUG")){this.checkNumericalProblems(values)}if(dtype==="complex64"){throw new Error(`Cannot write to a complex64 dtype. `+`Please use tf.complex(real, imag).`)}this.texData.set(dataId,{shape:shape,dtype:dtype,values:values,usage:TextureUsage.UPLOAD,refCount:refCount})}disposeIntermediateTensorInfo(tensorInfo){this.disposeData(tensorInfo.dataId)}readSync(dataId){const texData=this.texData.get(dataId);const{values:values,dtype:dtype,complexTensorInfos:complexTensorInfos,slice:slice,shape:shape,isPacked:isPacked}=texData;if(slice!=null){let program;if(isPacked){program=new UnaryOpPackedProgram(shape,CLONE)}else{program=new UnaryOpProgram(shape,CLONE)}const res=this.runWebGLProgram(program,[{dataId:dataId,shape:shape,dtype:dtype}],dtype);const data=this.readSync(res.dataId);this.disposeIntermediateTensorInfo(res);return data}if(values!=null){return this.convertAndCacheOnCPU(dataId)}if(dtype==="string"){return values}const shouldTimeProgram=this.activeTimers!=null;let start;if(shouldTimeProgram){start=now()}let result;if(dtype==="complex64"){const realValues=this.readSync(complexTensorInfos.real.dataId);const imagValues=this.readSync(complexTensorInfos.imag.dataId);result=mergeRealAndImagArrays(realValues,imagValues)}else{result=this.getValuesFromTexture(dataId)}if(shouldTimeProgram){this.downloadWaitMs+=now()-start}return this.convertAndCacheOnCPU(dataId,result)}async read(dataId){if(this.pendingRead.has(dataId)){const subscribers=this.pendingRead.get(dataId);return new Promise((resolve=>subscribers.push(resolve)))}const texData=this.texData.get(dataId);const{values:values,shape:shape,slice:slice,dtype:dtype,complexTensorInfos:complexTensorInfos,isPacked:isPacked}=texData;if(slice!=null){let program;if(isPacked){program=new UnaryOpPackedProgram(shape,CLONE)}else{program=new UnaryOpProgram(shape,CLONE)}const res=this.runWebGLProgram(program,[{dataId:dataId,shape:shape,dtype:dtype}],dtype);const data=this.read(res.dataId);this.disposeIntermediateTensorInfo(res);return data}if(values!=null){return this.convertAndCacheOnCPU(dataId)}if(!env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&env().getNumber("WEBGL_VERSION")===2){throw new Error(`tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and `+`WEBGL_VERSION=2 not yet supported.`)}let buffer=null;let tmpDownloadTarget;if(dtype!=="complex64"&&env().get("WEBGL_BUFFER_SUPPORTED")){tmpDownloadTarget=this.decode(dataId);const tmpData=this.texData.get(tmpDownloadTarget.dataId);buffer=this.gpgpu.createBufferFromTexture(tmpData.texture,...getDenseTexShape(shape))}this.pendingRead.set(dataId,[]);if(dtype!=="complex64"){await this.gpgpu.createAndWaitForFence()}let vals;if(dtype==="complex64"){const ps=await Promise.all([this.read(complexTensorInfos.real.dataId),this.read(complexTensorInfos.imag.dataId)]);const realValues=ps[0];const imagValues=ps[1];vals=mergeRealAndImagArrays(realValues,imagValues)}else if(buffer==null){vals=this.getValuesFromTexture(dataId)}else{const size=sizeFromShape(shape);vals=this.gpgpu.downloadFloat32MatrixFromBuffer(buffer,size)}if(tmpDownloadTarget!=null){this.disposeIntermediateTensorInfo(tmpDownloadTarget)}const dTypeVals=this.convertAndCacheOnCPU(dataId,vals);const subscribers=this.pendingRead.get(dataId);this.pendingRead.delete(dataId);subscribers.forEach((resolve=>resolve(dTypeVals)));if(this.pendingDisposal.has(dataId)){this.pendingDisposal.delete(dataId);if(this.disposeData(dataId)){engine().removeDataId(dataId,this)}this.pendingDeletes--}return dTypeVals}bufferSync(t){const data=this.readSync(t.dataId);let decodedData=data;if(t.dtype==="string"){try{decodedData=data.map((d=>decodeString(d)))}catch(_a){throw new Error("Failed to decode encoded string bytes into utf-8")}}return buffer(t.shape,t.dtype,decodedData)}checkNumericalProblems(values){if(values==null){return}for(let i=0;i<values.length;i++){const num=values[i];if(!canBeRepresented(num)){if(env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")){throw Error(`The value ${num} cannot be represented with your `+`current settings. Consider enabling float32 rendering: `+`'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`)}throw Error(`The value ${num} cannot be represented on this device.`)}}}getValuesFromTexture(dataId){const{shape:shape,dtype:dtype,isPacked:isPacked}=this.texData.get(dataId);const size=sizeFromShape(shape);if(env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const tmpTarget=this.decode(dataId);const tmpData=this.texData.get(tmpTarget.dataId);const vals=this.gpgpu.downloadMatrixFromPackedTexture(tmpData.texture,...getDenseTexShape(shape)).subarray(0,size);this.disposeIntermediateTensorInfo(tmpTarget);return vals}const shouldUsePackedProgram=env().getBool("WEBGL_PACK")&&isPacked===true;const outputShape=shouldUsePackedProgram?getShapeAs3D(shape):shape;const program=shouldUsePackedProgram?new EncodeFloatPackedProgram(outputShape):new EncodeFloatProgram(outputShape);const output=this.runWebGLProgram(program,[{shape:outputShape,dtype:dtype,dataId:dataId}],"float32");const tmpData=this.texData.get(output.dataId);const vals=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture,tmpData.texShape[0],tmpData.texShape[1]).subarray(0,size);this.disposeIntermediateTensorInfo(output);return vals}timerAvailable(){return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0}async time(f){const oldActiveTimers=this.activeTimers;const newActiveTimers=[];let outerMostTime=false;if(this.programTimersStack==null){this.programTimersStack=newActiveTimers;outerMostTime=true}else{this.activeTimers.push(newActiveTimers)}this.activeTimers=newActiveTimers;f();const flattenedActiveTimerQueries=flatten(this.activeTimers.map((d=>d.query))).filter((d=>d!=null));const flattenedActiveTimerNames=flatten(this.activeTimers.map((d=>d.name))).filter((d=>d!=null));this.activeTimers=oldActiveTimers;if(outerMostTime){this.programTimersStack=null}const res={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const kernelMs=await Promise.all(flattenedActiveTimerQueries);res["kernelMs"]=sum$2(kernelMs);res["getExtraProfileInfo"]=()=>kernelMs.map(((d,i)=>({name:flattenedActiveTimerNames[i],ms:d}))).map((d=>`${d.name}: ${d.ms}`)).join(", ")}else{res["kernelMs"]={error:"WebGL query timers are not supported in this environment."}}this.uploadWaitMs=0;this.downloadWaitMs=0;return res}memory(){return{unreliable:false,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){return this.gpgpu.beginQuery()}return{startMs:now(),endMs:null}}endTimer(query){if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){this.gpgpu.endQuery();return query}query.endMs=now();return query}async getQueryTime(query){if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){return this.gpgpu.waitForQueryAndGetTime(query)}const timerQuery=query;return timerQuery.endMs-timerQuery.startMs}disposeData(dataId,force=false){if(this.pendingDisposal.has(dataId)){return false}if(!this.texData.has(dataId)){return true}if(force){this.texData.get(dataId).refCount=0}else{this.texData.get(dataId).refCount--}if(!force&&this.texData.get(dataId).refCount>0){return false}if(this.pendingRead.has(dataId)){this.pendingDisposal.add(dataId);this.pendingDeletes++;return false}this.releaseGPUData(dataId);const{complexTensorInfos:complexTensorInfos}=this.texData.get(dataId);if(complexTensorInfos!=null){this.disposeData(complexTensorInfos.real.dataId,force);this.disposeData(complexTensorInfos.imag.dataId,force)}this.texData.delete(dataId);return true}releaseGPUData(dataId){const{texture:texture,dtype:dtype,texShape:texShape,usage:usage,isPacked:isPacked,slice:slice}=this.texData.get(dataId);const key=slice&&slice.origDataId||dataId;const refCount=this.dataRefCount.get(key);if(refCount>1){this.dataRefCount.set(key,refCount-1)}else{this.dataRefCount.delete(key);if(texture!=null){this.numBytesInGPU-=this.computeBytes(texShape,dtype);this.textureManager.releaseTexture(texture,texShape,usage,isPacked)}}const texData=this.texData.get(dataId);texData.texture=null;texData.texShape=null;texData.isPacked=false;texData.slice=null}getTexture(dataId){this.uploadToGPU(dataId);return this.texData.get(dataId).texture}getDataInfo(dataId){return this.texData.get(dataId)}shouldExecuteOnCPU(inputs,sizeThreshold=CPU_HANDOFF_SIZE_THRESHOLD){return env().getBool("WEBGL_CPU_FORWARD")&&inputs.every((input=>this.texData.get(input.dataId).texture==null&&sizeFromShape(input.shape)<sizeThreshold))}getGPGPUContext(){return this.gpgpu}where(condition){warn("tf.where() in webgl locks the UI thread. "+"Call tf.whereAsync() instead");const condVals=condition.dataSync();return whereImpl(condition.shape,condVals)}packedUnaryOp(x,op,dtype){const program=new UnaryOpPackedProgram(x.shape,op);const outInfo=this.compileAndRun(program,[x],dtype);return engine().makeTensorFromDataId(outInfo.dataId,outInfo.shape,outInfo.dtype)}abs(x){if(this.shouldExecuteOnCPU([x])&&x.dtype!=="complex64"){const outValues=simpleAbsImplCPU(this.texData.get(x.dataId).values);return this.makeOutput(x.shape,x.dtype,outValues)}if(env().getBool("WEBGL_PACK_UNARY_OPERATIONS")){return this.packedUnaryOp(x,ABS$1,x.dtype)}const program=new UnaryOpProgram(x.shape,ABS$1);const outInfo=this.compileAndRun(program,[x]);return engine().makeTensorFromDataId(outInfo.dataId,outInfo.shape,outInfo.dtype)}makeTensorInfo(shape,dtype,values){let dataId;if(dtype==="string"&&values!=null&&values.length>0&&isString(values[0])){const encodedValues=values.map((d=>encodeString(d)));dataId=this.write(encodedValues,shape,dtype)}else{dataId=this.write(values,shape,dtype)}this.texData.get(dataId).usage=null;return{dataId:dataId,shape:shape,dtype:dtype}}makeOutput(shape,dtype,values){const{dataId:dataId}=this.makeTensorInfo(shape,dtype,values);return engine().makeTensorFromDataId(dataId,shape,dtype,this)}unpackTensor(input){const program=new UnpackProgram(input.shape);return this.runWebGLProgram(program,[input],input.dtype)}packTensor(input){const program=new PackProgram(input.shape);const preventEagerUnpackingOutput=true;return this.runWebGLProgram(program,[input],input.dtype,null,preventEagerUnpackingOutput)}packedReshape(input,afterShape){const input3DShape=[getBatchDim(input.shape),...getRowsCols(input.shape)];const input3D={dtype:input.dtype,shape:input3DShape,dataId:input.dataId};const afterShapeAs3D=[getBatchDim(afterShape),...getRowsCols(afterShape)];const program=new ReshapePackedProgram(afterShapeAs3D,input3DShape);const preventEagerUnpackingOfOutput=true;const output=this.runWebGLProgram(program,[input3D],input.dtype,null,preventEagerUnpackingOfOutput);return{dataId:output.dataId,shape:afterShape,dtype:output.dtype}}decode(dataId){const texData=this.texData.get(dataId);const{isPacked:isPacked,shape:shape,dtype:dtype}=texData;const shapeAs3D=getShapeAs3D(shape);let program;if(isPacked){program=new DecodeMatrixPackedProgram(shapeAs3D)}else{program=new DecodeMatrixProgram(shapeAs3D)}const preventEagerUnpackingOfOutput=true;const out=this.runWebGLProgram(program,[{shape:shapeAs3D,dtype:dtype,dataId:dataId}],dtype,null,preventEagerUnpackingOfOutput);return{dtype:dtype,shape:shape,dataId:out.dataId}}runWebGLProgram(program,inputs,outputDtype,customSetup,preventEagerUnpackingOfOutput=false){const output=this.makeTensorInfo(program.outputShape,outputDtype);const outData=this.texData.get(output.dataId);if(program.packedOutput){outData.isPacked=true}if(program.outPackingScheme===PackingScheme.DENSE){const texelShape=getDenseTexShape(program.outputShape);outData.texShape=texelShape.map((d=>d*2))}if(program.outTexUsage!=null){outData.usage=program.outTexUsage}if(sizeFromShape(output.shape)===0){outData.values=getTypedArrayFromDType(output.dtype,0);return output}const dataToDispose=[];const inputsData=inputs.map((input=>{if(input.dtype==="complex64"){throw new Error(`GPGPUProgram does not support complex64 input. For complex64 `+`dtypes, please separate the program into real and imaginary `+`parts.`)}let texData=this.texData.get(input.dataId);if(texData.texture==null){if(!program.packedInputs&&sizeFromShape(input.shape)<=env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")){return{shape:input.shape,texData:null,isUniform:true,uniformValues:texData.values}}if(program.packedInputs){texData.isPacked=true;texData.shape=input.shape}}else if(!!texData.isPacked!==!!program.packedInputs){input=texData.isPacked?this.unpackTensor(input):this.packTensor(input);dataToDispose.push(input);texData=this.texData.get(input.dataId)}else if(texData.isPacked&&!isReshapeFree(texData.shape,input.shape)){const savedInput=input;const targetShape=input.shape;input.shape=texData.shape;input=this.packedReshape(input,targetShape);dataToDispose.push(input);texData=this.texData.get(input.dataId);savedInput.shape=targetShape}this.uploadToGPU(input.dataId);return{shape:input.shape,texData:texData,isUniform:false}}));this.uploadToGPU(output.dataId);const outputData={shape:output.shape,texData:outData,isUniform:false};const key=makeShaderKey(program,inputsData,outputData);const binary=this.getAndSaveBinary(key,(()=>compileProgram(this.gpgpu,program,inputsData,outputData)));const shouldTimeProgram=this.activeTimers!=null;let query;if(shouldTimeProgram){query=this.startTimer()}runProgram(this.gpgpu,binary,inputsData,outputData,customSetup);dataToDispose.forEach((info=>this.disposeIntermediateTensorInfo(info)));if(shouldTimeProgram){query=this.endTimer(query);this.activeTimers.push({name:program.constructor.name,query:this.getQueryTime(query)})}const glFlushThreshold=env().get("WEBGL_FLUSH_THRESHOLD");if(glFlushThreshold>0){const time=now();if(time-this.lastGlFlushTime>glFlushThreshold){this.gpgpu.gl.flush();this.lastGlFlushTime=time}}if(!env().getBool("WEBGL_LAZILY_UNPACK")&&outData.isPacked&&preventEagerUnpackingOfOutput===false){const unpacked=this.unpackTensor(output);this.disposeIntermediateTensorInfo(output);return unpacked}return output}compileAndRun(program,inputs,outputDtype,customSetup,preventEagerUnpackingOfOutput=false){outputDtype=outputDtype||inputs[0].dtype;const outInfo=this.runWebGLProgram(program,inputs,outputDtype,customSetup,preventEagerUnpackingOfOutput);return outInfo}getAndSaveBinary(key,getBinary){if(!(key in this.binaryCache)){this.binaryCache[key]=getBinary()}return this.binaryCache[key]}getTextureManager(){return this.textureManager}dispose(){if(this.disposed){return}if(!env().getBool("IS_TEST")){const allKeys=Object.keys(this.binaryCache);allKeys.forEach((key=>{this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram);delete this.binaryCache[key]}))}this.textureManager.dispose();if(this.canvas!=null&&(typeof HTMLCanvasElement!=="undefined"&&this.canvas instanceof HTMLCanvasElement)){this.canvas.remove()}else{this.canvas=null}if(this.gpgpuCreatedLocally){this.gpgpu.program=null;this.gpgpu.dispose()}this.disposed=true}floatPrecision(){if(this.floatPrecisionValue==null){this.floatPrecisionValue=tidy((()=>{if(!env().get("WEBGL_RENDER_FLOAT32_ENABLED")){const debugFlag=env().getBool("DEBUG");env().set("DEBUG",false);const underflowCheckValue=this.abs(scalar(1e-8)).dataSync()[0];env().set("DEBUG",debugFlag);if(underflowCheckValue>0){return 32}}return 16}))}return this.floatPrecisionValue}epsilon(){return this.floatPrecision()===32?EPSILON_FLOAT32:EPSILON_FLOAT16}uploadToGPU(dataId){const texData=this.texData.get(dataId);const{shape:shape,dtype:dtype,values:values,texture:texture,usage:usage,isPacked:isPacked}=texData;if(texture!=null){return}const shouldTimeProgram=this.activeTimers!=null;let start;if(shouldTimeProgram){start=now()}let texShape=texData.texShape;if(texShape==null){texShape=getTextureShapeFromLogicalShape(shape,isPacked);texData.texShape=texShape}if(values!=null){const shapeAs3D=getShapeAs3D(shape);let program;let width=texShape[1],height=texShape[0];const isByteArray=values instanceof Uint8Array;if(isPacked){[width,height]=getPackedMatrixTextureShapeWidthHeight(texShape[0],texShape[1]);program=new EncodeMatrixPackedProgram(shapeAs3D,[height,width],isByteArray)}else{program=new EncodeMatrixProgram(shapeAs3D,[height,width],isByteArray)}const tempDenseInputHandle=this.makeTensorInfo([height,width],dtype);if(isByteArray){this.texData.get(tempDenseInputHandle.dataId).usage=TextureUsage.PIXELS}else{this.texData.get(tempDenseInputHandle.dataId).usage=TextureUsage.UPLOAD}this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId),width,height,values);const preventEagerUnpacking=true;const encodedOutputTarget=this.runWebGLProgram(program,[tempDenseInputHandle],dtype,null,preventEagerUnpacking);const outputTexData=this.texData.get(encodedOutputTarget.dataId);texData.texture=outputTexData.texture;texData.texShape=outputTexData.texShape;texData.isPacked=outputTexData.isPacked;texData.usage=outputTexData.usage;this.disposeIntermediateTensorInfo(tempDenseInputHandle);this.texData.delete(encodedOutputTarget.dataId);texData.values=null;if(shouldTimeProgram){this.uploadWaitMs+=now()-start}}else{const newTexture=this.acquireTexture(texShape,usage,dtype,isPacked);texData.texture=newTexture}}convertAndCacheOnCPU(dataId,float32Values){const texData=this.texData.get(dataId);const{dtype:dtype}=texData;this.releaseGPUData(dataId);if(float32Values!=null){texData.values=float32ToTypedArray(float32Values,dtype)}return texData.values}acquireTexture(texShape,texType,dtype,isPacked){this.numBytesInGPU+=this.computeBytes(texShape,dtype);if(!this.warnedAboutMemory&&this.numBytesInGPU>this.numMBBeforeWarning*1024*1024){const mb=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=true;console.warn(`High memory usage in GPU: ${mb} MB, `+`most likely due to a memory leak`)}return this.textureManager.acquireTexture(texShape,texType,isPacked)}computeBytes(shape,dtype){return shape[0]*shape[1]*bytesPerElement(dtype)}}MathBackendWebGL.nextDataId=0;function float32ToTypedArray(a,dtype){if(dtype==="float32"||dtype==="complex64"){return a}else if(dtype==="int32"||dtype==="bool"){const result=dtype==="int32"?new Int32Array(a.length):new Uint8Array(a.length);for(let i=0;i<result.length;++i){result[i]=Math.round(a[i])}return result}else{throw new Error(`Unknown dtype ${dtype}`)}}const version="3.6.0";function forceHalfFloat(){env().set("WEBGL_FORCE_F16_TEXTURES",true)}if(isBrowser()){registerBackend("webgl",(()=>new MathBackendWebGL),2)}const webgl$1={forceHalfFloat:forceHalfFloat};const CHECK_NAN_SNIPPET$1=`\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;class BinaryOpProgram{constructor(op,aShape,bShape){this.variableNames=["A","B"];this.outputShape=assertAndGetBroadcastShape(aShape,bShape);this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${op}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const CHECK_NAN_SNIPPET=`\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;class BinaryOpPackedProgram{constructor(op,aShape,bShape,checkOutOfBounds=false){this.variableNames=["A","B"];this.supportsBroadcasting=true;this.packedInputs=true;this.packedOutput=true;this.outputShape=assertAndGetBroadcastShape(aShape,bShape);const rank=this.outputShape.length;let checkOutOfBoundsString="";if(checkOutOfBounds){if(rank===0||sizeFromShape(this.outputShape)===1){checkOutOfBoundsString=`\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        `}else{const dtype=getCoordsDataType(rank);checkOutOfBoundsString=`\n          ${dtype} coords = getOutputCoords();\n        `;if(rank===1){checkOutOfBoundsString+=`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `}else{const channels=getChannels("coords",rank);checkOutOfBoundsString+=`\n            bool nextRowOutOfBounds =\n              (${channels[rank-2]} + 1) >= ${this.outputShape[rank-2]};\n            bool nextColOutOfBounds =\n              (${channels[rank-1]} + 1) >= ${this.outputShape[rank-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}}}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${op}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${checkOutOfBoundsString}\n\n        setOutput(result);\n      }\n    `}}function identity(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;backend.incRef(x.dataId);return{dataId:x.dataId,shape:x.shape,dtype:x.dtype}}const identityConfig={kernelName:Identity,backendName:"webgl",kernelFunc:identity};function complex(args){const{inputs:inputs,backend:backend}=args;const{real:real,imag:imag}=inputs;const complexInfo=backend.makeTensorInfo(real.shape,"complex64");const complex=backend.texData.get(complexInfo.dataId);const realTensorInfo=identity({inputs:{x:real},backend:backend});const imagTensorInfo=identity({inputs:{x:imag},backend:backend});complex.complexTensorInfos={real:realTensorInfo,imag:imagTensorInfo};return complexInfo}const complexConfig={kernelName:Complex,backendName:"webgl",kernelFunc:complex};const LEAKYRELU=`return (a < 0.) ? b * a : a;`;const LEAKYRELU_PACKED=`\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n`;function leakyRelu(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{alpha:alpha}=attrs;const $alpha=backend.makeTensorInfo([],"float32",createScalarValue(alpha,"float32"));const program=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(LEAKYRELU_PACKED,x.shape,$alpha.shape):new BinaryOpProgram(LEAKYRELU,x.shape,$alpha.shape);const result=backend.runWebGLProgram(program,[x,$alpha],x.dtype);backend.disposeIntermediateTensorInfo($alpha);return result}const leakyReluConfig={kernelName:LeakyRelu,backendName:"webgl",kernelFunc:leakyRelu};const PRELU=`return (a < 0.) ? b * a : a;`;const PRELU_PACKED=`\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n`;function prelu(args){const{inputs:inputs,backend:backend}=args;const{x:x,alpha:alpha}=inputs;const program=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(PRELU_PACKED,x.shape,alpha.shape):new BinaryOpProgram(PRELU,x.shape,alpha.shape);return backend.runWebGLProgram(program,[x,alpha],x.dtype)}const preluConfig={kernelName:Prelu,backendName:"webgl",kernelFunc:prelu};const CHECK_NAN_SNIPPET_UNARY=`if (isnan(x)) return x;`;const CHECK_NAN_SNIPPET_BINARY=`\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;const CHECK_NAN_SNIPPET_BINARY_PACKED=`\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;function unaryKernelFunc({opSnippet:opSnippet,packedOpSnippet:packedOpSnippet,cpuKernelImpl:cpuKernelImpl,dtype:dtype}){return({inputs:inputs,backend:backend})=>{const{x:x}=inputs;const webglBackend=backend;const $dtype=dtype||x.dtype;if(webglBackend.shouldExecuteOnCPU([x])&&cpuKernelImpl!=null){const xData=webglBackend.texData.get(x.dataId);const outValues=cpuKernelImpl(xData.values,$dtype);return webglBackend.makeTensorInfo(x.shape,$dtype,outValues)}const shouldUsePackedProgram=env().getBool("WEBGL_PACK_UNARY_OPERATIONS")&&packedOpSnippet!=null;let program;if(shouldUsePackedProgram){program=new UnaryOpPackedProgram(x.shape,packedOpSnippet)}else{program=new UnaryOpProgram(x.shape,opSnippet)}return webglBackend.runWebGLProgram(program,[x],$dtype)}}function binaryKernelFunc({opSnippet:opSnippet,packedOpSnippet:packedOpSnippet,checkOutOfBounds:checkOutOfBounds=false,supportsComplex:supportsComplex=false,cpuKernelImpl:cpuKernelImpl,dtype:dtype}){return({inputs:inputs,backend:backend})=>{const{a:a,b:b}=inputs;const webglBackend=backend;if(supportsComplex&&a.dtype==="complex64"){const aData=webglBackend.texData.get(a.dataId);const bData=webglBackend.texData.get(b.dataId);const[real,imag]=[[aData.complexTensorInfos.real,bData.complexTensorInfos.real],[aData.complexTensorInfos.imag,bData.complexTensorInfos.imag]].map((complexParts=>{const[aPart,bPart]=complexParts;const aHandle={dataId:aPart.dataId,dtype:aPart.dtype,shape:a.shape};const bHandle={dataId:bPart.dataId,dtype:bPart.dtype,shape:b.shape};const program=new BinaryOpProgram(opSnippet,a.shape,b.shape);return webglBackend.runWebGLProgram(program,[aHandle,bHandle],upcastType(aPart.dtype,bPart.dtype))}));const complexOutput=complex({inputs:{real:real,imag:imag},backend:webglBackend});webglBackend.disposeIntermediateTensorInfo(real);webglBackend.disposeIntermediateTensorInfo(imag);return complexOutput}const $dtype=dtype||upcastType(a.dtype,b.dtype);if(webglBackend.shouldExecuteOnCPU([a,b])&&cpuKernelImpl!=null){const aData=webglBackend.texData.get(a.dataId);const bData=webglBackend.texData.get(b.dataId);const[outValues,outShape]=cpuKernelImpl(a.shape,b.shape,aData.values,bData.values,$dtype);const out=webglBackend.makeTensorInfo(outShape,$dtype);const outData=webglBackend.texData.get(out.dataId);outData.values=outValues;return out}const shouldUsePackedProgram=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&packedOpSnippet!=null;let program;if(shouldUsePackedProgram){program=new BinaryOpPackedProgram(packedOpSnippet,a.shape,b.shape,checkOutOfBounds)}else{program=new BinaryOpProgram(opSnippet,a.shape,b.shape)}return webglBackend.runWebGLProgram(program,[a,b],$dtype)}}function mapActivationToShaderProgram(activation,packed=false){if(activation==="linear"){if(packed){return LINEAR}return LINEAR$1}else if(activation==="relu"){if(packed){return RELU$1}return RELU$2}else if(activation==="elu"){if(packed){return ELU$1}return ELU$2}else if(activation==="relu6"){if(packed){return RELU6$1}return RELU6$2}else if(activation==="prelu"){if(packed){return PRELU_PACKED}return PRELU}else if(activation==="leakyrelu"){if(packed){return LEAKYRELU_PACKED}return LEAKYRELU}else if(activation==="sigmoid"){if(packed){return SIGMOID$1}return SIGMOID$2}throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`)}class MatMulPackedProgram{constructor(aShape,bShape,outputShape,transposeA=false,transposeB=false,addBias=false,activation=null,hasPreluActivation=false,hasLeakyreluActivation=false){this.variableNames=["matrixA","matrixB"];this.packedInputs=true;this.packedOutput=true;this.outputShape=outputShape;const sharedDim=transposeA?aShape[1]:aShape[2];const sharedDimensionPacked=Math.ceil(sharedDim/2);const aSample=transposeA?"i * 2, rc.y":"rc.y, i * 2";const bSample=transposeB?"rc.z, i * 2":"i * 2, rc.z";const aSwizzle=transposeA?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"];const bSwizzle=transposeB?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let activationSnippet="",applyActivationSnippet="";if(activation){if(hasPreluActivation){activationSnippet=`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`}else if(hasLeakyreluActivation){activationSnippet=`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`}else{activationSnippet=`vec4 activation(vec4 x) {\n          ${activation}\n        }`}applyActivationSnippet=`result = activation(result);`}const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";if(addBias){this.variableNames.push("bias")}if(hasPreluActivation){this.variableNames.push("preluActivationWeights")}if(hasLeakyreluActivation){this.variableNames.push("leakyreluAlpha")}let batchASnippet="rc.x";let batchBSnippet="rc.x";if(aShape[0]<bShape[0]){batchASnippet=`int(min(float(rc.x), ${aShape[0]-1}.))`}else if(bShape[0]<aShape[0]){batchBSnippet=`int(min(float(rc.x), ${bShape[0]-1}.))`}this.userCode=`\n      ${activationSnippet}\n\n      const float sharedDimension = ${sharedDimensionPacked}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ${sharedDimensionPacked}; i++) {\n          int batchA = ${batchASnippet};\n          int batchB = ${batchBSnippet};\n          vec4 a = getMatrixA(batchA, ${aSample});\n          vec4 b = getMatrixB(batchB, ${bSample});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${aSwizzle[0]} * ${bSwizzle[0]});\n          result += (${aSwizzle[1]} * ${bSwizzle[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${addBiasSnippet}\n\n        ${applyActivationSnippet}\n\n        setOutput(result);\n      }\n    `}}const COMPLEX_MULTIPLY={REAL:"return areal * breal - aimag * bimag;",IMAG:"return areal * bimag + aimag * breal;"};class BinaryOpComplexProgram{constructor(op,aShape,bShape){this.variableNames=["AReal","AImag","BReal","BImag"];this.outputShape=assertAndGetBroadcastShape(aShape,bShape);this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${op}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const MUL="return a * b;";function multiply(args){const{inputs:inputs,backend:backend}=args;const{a:a,b:b}=inputs;const dtype=upcastType(a.dtype,b.dtype);if(a.dtype==="complex64"){const aData=backend.texData.get(a.dataId);const bData=backend.texData.get(b.dataId);const realProgram=new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL,a.shape,b.shape);const imagProgram=new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG,a.shape,b.shape);const inputs=[{dataId:aData.complexTensorInfos.real.dataId,dtype:aData.complexTensorInfos.real.dtype,shape:a.shape},{dataId:aData.complexTensorInfos.imag.dataId,dtype:aData.complexTensorInfos.imag.dtype,shape:a.shape},{dataId:bData.complexTensorInfos.real.dataId,dtype:bData.complexTensorInfos.real.dtype,shape:b.shape},{dataId:bData.complexTensorInfos.imag.dataId,dtype:bData.complexTensorInfos.imag.dtype,shape:b.shape}];const realPart=backend.runWebGLProgram(realProgram,inputs,"float32");const imagPart=backend.runWebGLProgram(imagProgram,inputs,"float32");const complexOutput=complex({inputs:{real:realPart,imag:imagPart},backend:backend});backend.disposeIntermediateTensorInfo(realPart);backend.disposeIntermediateTensorInfo(imagPart);return complexOutput}if(backend.shouldExecuteOnCPU([a,b])){const aData=backend.texData.get(a.dataId);const bData=backend.texData.get(b.dataId);const[outValues,outShape]=multiplyImplCPU(a.shape,b.shape,aData.values,bData.values,dtype);const out=backend.makeTensorInfo(outShape,dtype);const outData=backend.texData.get(out.dataId);outData.values=outValues;return out}let program;if(env().getBool("WEBGL_PACK_BINARY_OPERATIONS")){program=new BinaryOpPackedProgram(MUL,a.shape,b.shape)}else{program=new BinaryOpProgram(MUL,a.shape,b.shape)}return backend.runWebGLProgram(program,[a,b],dtype)}const multiplyConfig={kernelName:Multiply,backendName:"webgl",kernelFunc:multiply};function packedReshape(input,afterShape,backend){const input3DShape=[getBatchDim(input.shape),...getRowsCols(input.shape)];const input3D={dtype:input.dtype,shape:input3DShape,dataId:input.dataId};const afterShapeAs3D=[getBatchDim(afterShape),...getRowsCols(afterShape)];const program=new ReshapePackedProgram(afterShapeAs3D,input3DShape);const preventEagerUnpackingOfOutput=true;const output=backend.runWebGLProgram(program,[input3D],input.dtype,null,preventEagerUnpackingOfOutput);return{dataId:output.dataId,shape:afterShape,dtype:output.dtype}}function reshape(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{shape:shape}=attrs;const webglBackend=backend;const xSize=sizeFromShape(x.shape);const $shape=inferFromImplicitShape(shape,xSize);const $xSize=sizeFromShape($shape);assert(xSize===$xSize,(()=>`The new shape (${$shape}) has ${$xSize} elements and the old `+`shape (${x.shape}) has ${xSize} elements. The new shape and old `+`shape must have the same number of elements.`));const xTexData=webglBackend.texData.get(x.dataId);if(xTexData.isPacked&&!isReshapeFree(x.shape,$shape)&&!(xTexData.texture!==null&&isReshapeFree(xTexData.shape,$shape))){return packedReshape(x,$shape,webglBackend)}webglBackend.incRef(x.dataId);return{dataId:x.dataId,shape:$shape,dtype:x.dtype}}const reshapeConfig={kernelName:Reshape,backendName:"webgl",kernelFunc:reshape};class MeanProgram{constructor(reduceInfo,divisor){this.variableNames=["x"];const{windowSize:windowSize,batchSize:batchSize,inSize:inSize,outSize:outSize}=reduceInfo;this.outputShape=[batchSize,outSize];const windowSizeNearestVec4=Math.floor(windowSize/4)*4;const windowSizeVec4Remainder=windowSize%4;let updateSnippet=`sumValue += dot(values, ones);`;if(divisor!=null){const denominator=1/divisor;updateSnippet=`sumValue += dot(values * ${isInt(denominator)?denominator.toPrecision(2):denominator}, ones);`}let checkOutOfBounds="";if(inSize%windowSize>0){checkOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return 0.0;\n        }\n      `}this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${checkOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${windowSizeVec4Remainder===1}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===2}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===3}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${updateSnippet}\n        }\n        setOutput(sumValue);\n      }\n    `}}class ReduceProgram{constructor(reduceInfo,reduceType){this.variableNames=["x"];const{windowSize:windowSize,batchSize:batchSize,inSize:inSize,outSize:outSize}=reduceInfo;this.outputShape=[batchSize,outSize];let initializationValue="0.0";let compareOp=``;if(reduceType==="prod"){initializationValue="1.0"}else if(reduceType==="min"){initializationValue="1.0 / 1e-20";compareOp=`min`}else if(reduceType==="max"){initializationValue="-1.0 / 1e-20";compareOp=`max`}let returnValue=`${reduceType}(${reduceType}(${reduceType}(`+"minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";if(reduceType==="sum"){returnValue=`sumValue`}else if(reduceType==="prod"){returnValue=`prodValue`}else if(reduceType==="all"){returnValue=`allValue`}else if(reduceType==="any"){returnValue=`anyValue`}const windowSizeNearestVec4=Math.floor(windowSize/4)*4;const windowSizeVec4Remainder=windowSize%4;let updateSnippet=`\n      if (${reduceType==="sum"}) {\n        sumValue += dot(values, ones);\n      } else if (${reduceType==="prod"}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${compareOp}(values, minMaxValue);\n      }\n    `;let vecType=`vec4`;if(reduceType==="all"){initializationValue="1.0";updateSnippet=`\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      `;vecType=`bvec4`}else if(reduceType==="any"){initializationValue="0.0";updateSnippet=`\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      `;vecType=`bvec4`}let checkOutOfBounds="";if(inSize%windowSize>0){checkOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return initializationValue;\n        }\n      `}this.userCode=`\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${checkOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        vec4 minMaxValue = vec4(${initializationValue});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${windowSizeVec4Remainder===1}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===2}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===3}) {\n          ${vecType} values = ${vecType}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${updateSnippet}\n        }\n        setOutput(${returnValue});\n      }\n    `}}function getReductionStages(inShape){const stages=[];while(stages.length===0||stages[stages.length-1].outSize!==1){const outSize=stages.length?stages[stages.length-1].outSize:inShape[1];const windowSize=computeOptimalWindowSize(outSize);stages.push({inSize:outSize,windowSize:windowSize,outSize:Math.ceil(outSize/windowSize)})}return stages}function reduce(x,dtype,reductionType,backend){const reductionStages=getReductionStages(x.shape);let result=x;for(let i=0;i<reductionStages.length;i++){const{inSize:inSize,windowSize:windowSize,outSize:outSize}=reductionStages[i];let program;let previousResult;if(reductionType==="mean"){program=i===0?new MeanProgram({windowSize:windowSize,inSize:inSize,batchSize:x.shape[0],outSize:outSize},inSize):new MeanProgram({windowSize:windowSize,inSize:inSize,batchSize:x.shape[0],outSize:outSize})}else{program=new ReduceProgram({windowSize:windowSize,inSize:inSize,batchSize:x.shape[0],outSize:outSize},reductionType)}previousResult=result;result=backend.runWebGLProgram(program,[result],dtype);if(previousResult.dataId!==x.dataId){backend.disposeIntermediateTensorInfo(previousResult)}}return result}class TransposeProgram{constructor(aShape,newDim){this.variableNames=["A"];const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++){outputShape[i]=aShape[newDim[i]]}this.outputShape=outputShape;this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank);const switched=getSwitchedCoords(newDim);this.userCode=`\n    void main() {\n      ${dtype} resRC = getOutputCoords();\n      setOutput(getA(${switched}));\n    }\n    `}}function getSwitchedCoords(newDim){const rank=newDim.length;if(rank>6){throw Error(`Transpose for rank ${rank} is not yet supported`)}const originalOrder=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"];const switchedCoords=new Array(rank);for(let i=0;i<newDim.length;i++){switchedCoords[newDim[i]]=originalOrder[i]}return switchedCoords.join()}class TransposePackedProgram{constructor(aShape,newDim){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++){outputShape[i]=aShape[newDim[i]]}this.outputShape=outputShape;this.rank=outputShape.length;if(this.rank>6){throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`)}const dtype=getCoordsDataType(this.rank);const outputOrder=getVecChannels("rc",this.rank);const switchedOrder=new Array(this.rank);for(let i=0;i<newDim.length;i++){switchedOrder[newDim[i]]=outputOrder[i]}const innerDims=`vec2(${switchedOrder.slice(-2).join()})`;const nextColumn=`++${outputOrder[this.rank-1]} < ${outputShape[this.rank-1]}`;const getc=`getChannel(getA(${switchedOrder.join()}), ${innerDims})`;this.userCode=`\n    void main() {\n      ${dtype} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${getc};\n      if(${nextColumn}) {\n        result[1] = ${getc};\n      }\n      --${outputOrder[this.rank-1]};\n      if(++${outputOrder[this.rank-2]} < ${outputShape[this.rank-2]}) {\n        result[2] = ${getc};\n        if(${nextColumn}) {\n          result[3] = ${getc};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function transposeImpl(x,perm,backend){const program=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new TransposePackedProgram(x.shape,perm):new TransposeProgram(x.shape,perm);return backend.runWebGLProgram(program,[x],x.dtype)}function sumImpl(x,axis,keepDims,backend){const reductionIndices=axis;const xRank=x.shape.length;const origAxes=parseAxisParam(reductionIndices,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);const sumInputIsTransposed=permutedAxes!=null;let sumInput=x;if(sumInputIsTransposed){sumInput=transposeImpl(x,permutedAxes,backend);axes=getInnerMostAxes(axes.length,xRank)}assertAxesAreInnerMostDims("sum",axes,xRank);const[sumOutShape,reduceShape]=computeOutAndReduceShapes(sumInput.shape,axes);let outShape=sumOutShape;if(keepDims){outShape=expandShapeToKeepDim(sumOutShape,origAxes)}const inSize=sizeFromShape(reduceShape);const xSize=sizeFromShape(x.shape);const batchSize=xSize/inSize;const reshapedInput=reshape({inputs:{x:sumInput},attrs:{shape:[batchSize,inSize]},backend:backend});const outType=sumOutType(x.dtype);const reduced=reduce(reshapedInput,outType,"sum",backend);const out=reshape({inputs:{x:reduced},attrs:{shape:outShape},backend:backend});backend.disposeIntermediateTensorInfo(reshapedInput);backend.disposeIntermediateTensorInfo(reduced);if(sumInputIsTransposed){backend.disposeIntermediateTensorInfo(sumInput)}return out}function sum(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,keepDims:keepDims}=attrs;return sumImpl(x,axis,keepDims,backend)}const sumConfig={kernelName:Sum,backendName:"webgl",kernelFunc:sum};function transpose(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{perm:perm}=attrs;const webglBackend=backend;const xRank=x.shape.length;const newShape=new Array(xRank);for(let i=0;i<newShape.length;i++){newShape[i]=x.shape[perm[i]]}let out;if(webglBackend.shouldExecuteOnCPU([x])){const xTexData=webglBackend.texData.get(x.dataId);const values=xTexData.values;const outValues=transposeImplCPU(values,x.shape,x.dtype,perm,newShape);out=webglBackend.makeTensorInfo(newShape,x.dtype);const outData=webglBackend.texData.get(out.dataId);outData.values=outValues}else{out=transposeImpl(x,perm,webglBackend)}return out}const transposeConfig={kernelName:Transpose,backendName:"webgl",kernelFunc:transpose};const MATMUL_SHARED_DIM_THRESHOLD=1e3;function batchMatMulImpl({a:a,b:b,transposeA:transposeA,transposeB:transposeB,backend:backend,bias:bias=null,preluActivationWeights:preluActivationWeights=null,leakyreluAlpha:leakyreluAlpha=0,activation:activation=null}){const aRank=a.shape.length;const bRank=b.shape.length;const innerShapeA=transposeA?a.shape[aRank-2]:a.shape[aRank-1];const innerShapeB=transposeB?b.shape[bRank-1]:b.shape[bRank-2];const outerShapeA=transposeA?a.shape[aRank-1]:a.shape[aRank-2];const outerShapeB=transposeB?b.shape[bRank-2]:b.shape[bRank-1];const outerDimsA=a.shape.slice(0,-2);const outerDimsB=b.shape.slice(0,-2);const batchDimA=sizeFromShape(outerDimsA);const batchDimB=sizeFromShape(outerDimsB);const batchDimsCompatible=batchDimA===batchDimB||batchDimA===1||batchDimB===1;assert(aRank>=2&&bRank>=2&&batchDimsCompatible,(()=>`Error in matMul: the input batch dimensions must either be the `+`same or at least one input batch dimension must be 1. Got input `+`batch dimensions of (${outerDimsA}) and (${outerDimsB}).`));const outShapeOuterDims=batchDimA>batchDimB?a.shape.slice(0,-2):b.shape.slice(0,-2);const outShape=outShapeOuterDims.concat([outerShapeA,outerShapeB]);assert(innerShapeA===innerShapeB,(()=>`Error in matMul: inner shapes (${innerShapeA}) and (`+`${innerShapeB}) of Tensors with shapes ${a.shape} and `+`${b.shape} and transposeA=${transposeA}`+` and transposeB=${transposeB} must match.`));const a3dShape=transposeA?[batchDimA,innerShapeA,outerShapeA]:[batchDimA,outerShapeA,innerShapeA];const b3dShape=transposeB?[batchDimB,outerShapeB,innerShapeB]:[batchDimB,innerShapeB,outerShapeB];const a3d=reshape({inputs:{x:a},backend:backend,attrs:{shape:a3dShape}});const b3d=reshape({inputs:{x:b},backend:backend,attrs:{shape:b3dShape}});const intermediates=[a3d,b3d];const batchDim=Math.max(batchDimA,batchDimB);const sharedDim=transposeA?a3d.shape[1]:a3d.shape[2];const hasBias=bias!=null;const hasPreluActivationWeights=preluActivationWeights!=null;const hasLeakyreluAlpha=activation==="leakyrelu";const fusedActivation=activation!=null?mapActivationToShaderProgram(activation,true):null;const containsFusedOps=hasBias||hasPreluActivationWeights||hasLeakyreluAlpha||fusedActivation!=null;let out;if((outerShapeA===1||outerShapeB===1)&&sharedDim>MATMUL_SHARED_DIM_THRESHOLD&&containsFusedOps===false){let aVec=a3d;let bVec=b3d;if(transposeA){aVec=transpose({inputs:{x:a3d},backend:backend,attrs:{perm:[0,2,1]}});intermediates.push(aVec)}if(transposeB){bVec=transpose({inputs:{x:b3d},backend:backend,attrs:{perm:[0,2,1]}});intermediates.push(bVec)}const shouldReshapeA=outerShapeB!==1;const shouldReshapeB=outerShapeB===1;let aVec3d=aVec;if(shouldReshapeA){aVec3d=reshape({inputs:{x:aVec},backend:backend,attrs:{shape:[batchDim,sharedDim,1]}});intermediates.push(aVec3d)}const axis=outerShapeB===1?2:1;let bVec3d=bVec;if(shouldReshapeB){bVec3d=reshape({inputs:{x:bVec},backend:backend,attrs:{shape:[batchDim,1,sharedDim]}});intermediates.push(bVec3d)}const product=multiply({inputs:{a:aVec3d,b:bVec3d},backend:backend});out=sum({inputs:{x:product},backend:backend,attrs:{axis:axis,keepDims:true}});intermediates.push(product)}else{const dtype=upcastType(a.dtype,b.dtype);const program=new MatMulPackedProgram(a3dShape,b3dShape,[batchDim,outerShapeA,outerShapeB],transposeA,transposeB,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha);const inputs=[a3d,b3d];if(bias!=null){inputs.push(bias)}if(hasPreluActivationWeights){inputs.push(preluActivationWeights)}if(hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha);intermediates.push($leakyreluAlpha)}out=backend.runWebGLProgram(program,inputs,dtype)}const outReshaped=reshape({inputs:{x:out},backend:backend,attrs:{shape:outShape}});intermediates.push(out);for(const i of intermediates){backend.disposeIntermediateTensorInfo(i)}return outReshaped}function _fusedMatMul(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{a:a,b:b,bias:bias,preluActivationWeights:preluActivationWeights}=inputs;const{transposeA:transposeA,transposeB:transposeB,activation:activation,leakyreluAlpha:leakyreluAlpha}=attrs;return batchMatMulImpl({a:a,b:b,transposeA:transposeA,transposeB:transposeB,backend:backend,bias:bias,preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha,activation:activation})}const _fusedMatMulConfig={kernelName:_FusedMatMul,backendName:"webgl",kernelFunc:_fusedMatMul};const ABS=`return abs(x);`;function abs(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;if(backend.shouldExecuteOnCPU([x])&&x.dtype!=="complex64"){const xData=backend.texData.get(x.dataId);const outValues=simpleAbsImplCPU(xData.values);return backend.makeTensorInfo(x.shape,x.dtype,outValues)}let program;if(env().getBool("WEBGL_PACK_UNARY_OPERATIONS")){program=new UnaryOpPackedProgram(x.shape,ABS)}else{program=new UnaryOpProgram(x.shape,ABS)}return backend.runWebGLProgram(program,[x],x.dtype)}const absConfig={kernelName:Abs,backendName:"webgl",kernelFunc:abs};const ACOS=CHECK_NAN_SNIPPET$2+`\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n`;const acos=unaryKernelFunc({opSnippet:ACOS});const acosConfig={kernelName:Acos,backendName:"webgl",kernelFunc:acos};const ACOSH=CHECK_NAN_SNIPPET$2+`\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));`;const acosh=unaryKernelFunc({opSnippet:ACOSH});const acoshConfig={kernelName:Acosh,backendName:"webgl",kernelFunc:acosh};const ADD="return a + b;";const addKernelFunc=binaryKernelFunc({opSnippet:ADD,packedOpSnippet:ADD,supportsComplex:true,cpuKernelImpl:addImplCPU});const addConfig={kernelName:Add,backendName:"webgl",kernelFunc:addKernelFunc};class AddNProgram{constructor(outputShape,shapes){this.outputShape=[];this.outputShape=outputShape;this.variableNames=shapes.map(((_,i)=>`T${i}`));const snippets=[];this.variableNames.forEach((variable=>{snippets.push(`float v${variable} = get${variable}AtOutCoords();`)}));const operation=this.variableNames.map((variable=>`v${variable}`)).join(" + ");this.userCode=`\n      void main() {\n        ${snippets.join("\n        ")}\n\n        float result = ${operation};\n        setOutput(result);\n      }\n    `}}class AddNPackedProgram{constructor(outputShape,shapes){this.outputShape=[];this.packedInputs=true;this.packedOutput=true;this.outputShape=outputShape;this.variableNames=shapes.map(((_,i)=>`T${i}`));const snippets=[];this.variableNames.forEach((variable=>{snippets.push(`vec4 v${variable} = get${variable}AtOutCoords();`)}));const operation=this.variableNames.map((variable=>`v${variable}`)).join(" + ");this.userCode=`\n      void main() {\n        ${snippets.join("\n        ")}\n\n        vec4 result = ${operation};\n        setOutput(result);\n      }\n    `}}function addN(args){const{inputs:inputs,backend:backend}=args;const tensors=inputs;if(tensors.length===1){return identity({inputs:{x:tensors[0]},backend:backend})}if(tensors.length>env().get("WEBGL_MAX_TEXTURES_IN_SHADER")){const midIndex=Math.floor(tensors.length/2);const leftSide=addN({inputs:tensors.slice(0,midIndex),backend:backend});const rightSide=addN({inputs:tensors.slice(midIndex),backend:backend});return addN({inputs:[leftSide,rightSide],backend:backend})}const dtype=tensors.map((t=>t.dtype)).reduce(((d1,d2)=>upcastType(d1,d2)));const shapes=tensors.map((t=>t.shape));const usePackedOp=env().getBool("WEBGL_PACK");const program=usePackedOp?new AddNPackedProgram(tensors[0].shape,shapes):new AddNProgram(tensors[0].shape,shapes);return backend.runWebGLProgram(program,tensors,dtype)}const addNConfig={kernelName:AddN,backendName:"webgl",kernelFunc:addN};function all(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,keepDims:keepDims}=attrs;const xRank=x.shape.length;const origAxes=parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);let permutedX=x;if(permutedAxes!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});axes=getInnerMostAxes(axes.length,xRank)}assertAxesAreInnerMostDims("all",axes,xRank);const[outShape,reduceShape]=computeOutAndReduceShapes(permutedX.shape,axes);const inSize=sizeFromShape(reduceShape);const a2D=reshape({inputs:{x:permutedX},backend:backend,attrs:{shape:[-1,inSize]}});const reduced=reduce(a2D,a2D.dtype,"all",backend);let res;if(keepDims){const newShape=expandShapeToKeepDim(outShape,origAxes);res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:newShape}})}else{res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:outShape}})}backend.disposeIntermediateTensorInfo(a2D);backend.disposeIntermediateTensorInfo(reduced);if(permutedAxes!=null){backend.disposeIntermediateTensorInfo(permutedX)}return res}const allConfig={kernelName:All,backendName:"webgl",kernelFunc:all};function any(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,keepDims:keepDims}=attrs;const xRank=x.shape.length;const origAxes=parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);let permutedX=x;if(permutedAxes!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});axes=getInnerMostAxes(axes.length,xRank)}assertAxesAreInnerMostDims("any",axes,xRank);const[outShape,reduceShape]=computeOutAndReduceShapes(permutedX.shape,axes);const inSize=sizeFromShape(reduceShape);const a2D=reshape({inputs:{x:permutedX},backend:backend,attrs:{shape:[-1,inSize]}});const reduced=reduce(a2D,a2D.dtype,"any",backend);let res;if(keepDims){const newShape=expandShapeToKeepDim(outShape,origAxes);res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:newShape}})}else{res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:outShape}})}backend.disposeIntermediateTensorInfo(a2D);backend.disposeIntermediateTensorInfo(reduced);if(permutedAxes!=null){backend.disposeIntermediateTensorInfo(permutedX)}return res}const anyConfig={kernelName:Any,backendName:"webgl",kernelFunc:any};class ArgMinMaxProgram{constructor(reduceInfo,op,firstPass){this.variableNames=["A"];const{windowSize:windowSize,batchSize:batchSize,outSize:outSize}=reduceInfo;if(!firstPass){this.variableNames.push("bestIndicesA")}this.outputShape=[batchSize,outSize];const compOp=op==="max"?">":"<";const indexSnippet=firstPass?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));";this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${windowSize};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${windowSize}; i++) {\n          int inIdx = ${indexSnippet};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${compOp} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}class ArgMinMaxPackedProgram{constructor(shape,windowSize,op,firstPass){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;assert(shape.length>2,(()=>`Packed arg${op.charAt(0).toUpperCase()+op.slice(1)} supports only inputs with rank above 2.`));const inSize=shape[shape.length-1];const outSize=Math.ceil(inSize/windowSize);this.outputShape=shape.slice(0,-1);if(outSize>1){this.outputShape.push(outSize)}if(!firstPass){this.variableNames.push("bestIndicesA")}const outShape=this.outputShape;const rank=outShape.length;const dtype=getCoordsDataType(rank);const coords=getChannels("coords",rank);let sourceLocSetup;let sourceRank;if(outSize===1){sourceRank=rank+1;const sourceLocDType=getCoordsDataType(sourceRank);sourceLocSetup=`\n        ${sourceLocDType} sourceLocR = ${sourceLocDType}(${coords.join()}, 0);\n        ++${coords[rank-1]};\n        ${sourceLocDType} sourceLocG = ${sourceLocDType}(${coords.join()}, 0);\n        ++${coords[rank-2]};\n        ${sourceLocDType} sourceLocA = ${sourceLocDType}(${coords.join()}, 0);\n        --${coords[rank-1]};\n        ${sourceLocDType} sourceLocB = ${sourceLocDType}(${coords.join()}, 0);\n        --${coords[rank-2]};`}else{sourceRank=rank;sourceLocSetup=`\n        ${dtype} sourceLocR = coords;\n        ++${coords[rank-1]};\n        ${dtype} sourceLocG = coords;\n        ++${coords[rank-2]};\n        ${dtype} sourceLocA = coords;\n        --${coords[rank-1]};\n        ${dtype} sourceLocB = coords;\n        --${coords[rank-2]};`}const channels=["x","y","z","w","u","v"].slice(0,sourceRank);const inChannel="."+channels[sourceRank-1];const intChannels=channels.map((x=>"int "+x));const srcRCoords=getChannels("sourceLocR",sourceRank-1).concat("inIdx.r");const srcGCoords=getChannels("sourceLocG",sourceRank-1).concat("inIdx.g");const srcBCoords=getChannels("sourceLocB",sourceRank-1).concat("inIdx.b");const srcACoords=getChannels("sourceLocA",sourceRank-1).concat("inIdx.a");const compOp=op==="max"?"greaterThan":"lessThan";const fetchCandidateIdx=firstPass?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${srcRCoords.join()}),\n                             getBestIndicesAChannel(${srcGCoords.join()}),\n                             getBestIndicesAChannel(${srcBCoords.join()}),\n                             getBestIndicesAChannel(${srcACoords.join()})));`;const fetchValue=`vec4(\n            getAChannel(${srcRCoords.join()}),\n            hasNextCol ? getAChannel(${srcGCoords.join()}) : 0.,\n            hasNextRow ? getAChannel(${srcBCoords.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${srcACoords.join()}) : 0.)`;const getBestIndicesAChannelSnippet=firstPass?"":`\n      float getBestIndicesAChannel(${intChannels.join()}) {\n        return getChannel(getBestIndicesA(${channels.join()}),\n                                          vec2(${channels.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${intChannels.join()}) {\n        return getChannel(getA(${channels.join()}),\n                               vec2(${channels.slice(-2).join()}));\n      }\n      ${getBestIndicesAChannelSnippet}\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        bool hasNextCol = ${coords[rank-1]} < ${outShape[rank-1]-1};\n        bool hasNextRow = ${coords[rank-2]} < ${outShape[rank-2]-1};\n        ${sourceLocSetup}\n        ivec4 srcIdx = ivec4(sourceLocR${inChannel}, sourceLocG${inChannel},\n          sourceLocB${inChannel}, sourceLocA${inChannel}) * ${windowSize};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${fetchValue};\n\n        for (int i = 0; i < ${windowSize}; i++) {\n          inIdx = srcIdx;\n          ${fetchCandidateIdx}\n          vec4 candidate = ${fetchValue};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${compOp}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}function argReduce(backend,x,reduceType,bestIndicesA=null){let batchSize=x.shape[0];let inSize=x.shape[1];if(bestIndicesA!=null){batchSize=bestIndicesA.shape[0];inSize=bestIndicesA.shape[1]}const windowSize=computeOptimalWindowSize(inSize);const reduceInfo={windowSize:windowSize,inSize:inSize,batchSize:batchSize,outSize:Math.ceil(inSize/windowSize)};const program=new ArgMinMaxProgram(reduceInfo,reduceType,bestIndicesA==null);const inputs=[x];if(bestIndicesA!=null){inputs.push(bestIndicesA)}const output=backend.runWebGLProgram(program,inputs,"int32");if(output.shape[1]===1){return output}const result=argReduce(backend,x,reduceType,output);backend.disposeIntermediateTensorInfo(output);return result}function argReducePacked(backend,x,reduceType,bestIndicesA=null){const inShape=bestIndicesA!=null?bestIndicesA.shape:x.shape;const inSize=inShape[inShape.length-1];const windowSize=computeOptimalWindowSize(inSize);const program=new ArgMinMaxPackedProgram(inShape,windowSize,reduceType,bestIndicesA==null);const inputs=bestIndicesA==null?[x]:[x,bestIndicesA];const output=backend.runWebGLProgram(program,inputs,"int32");if(output.shape.length===x.shape.length){const result=argReducePacked(backend,x,reduceType,output);backend.disposeIntermediateTensorInfo(output);return result}return output}function argMinMaxReduce(backend,x,axis,reduceType){const axes=[axis];assertAxesAreInnerMostDims("arg"+reduceType.charAt(0).toUpperCase()+reduceType.slice(1),axes,x.shape.length);if(!env().getBool("WEBGL_PACK_REDUCE")||x.shape.length<=2){const intermediateTensorInfos=[];const[outShape,reduceShape]=computeOutAndReduceShapes(x.shape,axes);const inSize=sizeFromShape(reduceShape);const a2D=reshape({inputs:{x:x},backend:backend,attrs:{shape:[-1,inSize]}});intermediateTensorInfos.push(a2D);const reduced=argReduce(backend,a2D,reduceType);intermediateTensorInfos.push(reduced);const reshaped=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:outShape}});intermediateTensorInfos.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return reshaped}return argReducePacked(backend,x,reduceType)}function argMax(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis}=attrs;let axes=parseAxisParam(axis,x.shape);const permutedAxes=getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];if(permutedAxes!=null){$x=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});intermediateTensorInfos.push($x);axes=getInnerMostAxes(axes.length,$x.shape.length)}assertAxesAreInnerMostDims("argMax",[axes[0]],$x.shape.length);const out=argMinMaxReduce(backend,$x,axes[0],"max");intermediateTensorInfos.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return out}const argMaxConfig={kernelName:ArgMax,backendName:"webgl",kernelFunc:argMax};function argMin(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis}=attrs;let axes=parseAxisParam(axis,x.shape);const permutedAxes=getAxesPermutation(axes,x.shape.length);let $x=x;const intermediateTensorInfos=[];if(permutedAxes!=null){$x=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});intermediateTensorInfos.push($x);axes=getInnerMostAxes(axes.length,$x.shape.length)}assertAxesAreInnerMostDims("argMin",[axes[0]],$x.shape.length);const out=argMinMaxReduce(backend,$x,axes[0],"min");intermediateTensorInfos.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return out}const argMinConfig={kernelName:ArgMin,backendName:"webgl",kernelFunc:argMin};const ASIN=CHECK_NAN_SNIPPET$2+`\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n`;const asin=unaryKernelFunc({opSnippet:ASIN});const asinConfig={kernelName:Asin,backendName:"webgl",kernelFunc:asin};const ASINH=CHECK_NAN_SNIPPET$2+`return log(x + sqrt(x * x + 1.0));`;const asinh=unaryKernelFunc({opSnippet:ASINH});const asinhConfig={kernelName:Asinh,backendName:"webgl",kernelFunc:asinh};const ATAN=CHECK_NAN_SNIPPET$2+`\n  return atan(x);\n`;const atan=unaryKernelFunc({opSnippet:ATAN});const atanConfig={kernelName:Atan,backendName:"webgl",kernelFunc:atan};const ATAN2=CHECK_NAN_SNIPPET_BINARY+`\n  return atan(a, b);\n`;const ATAN2_PACKED=`\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  `+CHECK_NAN_SNIPPET_BINARY_PACKED+`\n  return result;\n`;const atan2=binaryKernelFunc({opSnippet:ATAN2,packedOpSnippet:ATAN2_PACKED});const atan2Config={kernelName:Atan2,backendName:"webgl",kernelFunc:atan2};const ATANH=CHECK_NAN_SNIPPET$2+`\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;`;const atanh=unaryKernelFunc({opSnippet:ATANH});const atanhConfig={kernelName:Atanh,backendName:"webgl",kernelFunc:atanh};class Pool2DProgram{constructor(convInfo,poolType,computePositions,flattenPositions=false,includeBatchInIndex=false){this.variableNames=["x"];if(poolType==="avg"&&computePositions){throw new Error("Cannot compute positions for average pool.")}const filterWidth=convInfo.filterWidth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;this.outputShape=convInfo.outShape;const isAvgPool=poolType==="avg";const batchFlattenPositionStr=`((batch  * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;const flattenPositionStr=`(xR * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;let initializationValue="0.0";if(!isAvgPool){initializationValue="-1.0 / 1e-20"}if(computePositions){const compareOp=">=";this.userCode=`\n        const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n        const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${compareOp} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${flattenPositions?includeBatchInIndex?batchFlattenPositionStr:flattenPositionStr:`wR * ${effectiveFilterWidth} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `;return}const compareOp="max";let returnValue=`${poolType}(${poolType}(${poolType}(`+"minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";if(poolType==="avg"){returnValue=`avgValue / count`}const filterWidthNearestVec4=Math.floor(filterWidth/4)*4;const filterWidthVec4Remainder=filterWidth%4;const updateSnippet=`\n      if (${isAvgPool}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = ${compareOp}(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${convInfo.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${initializationValue});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${convInfo.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {\n            int xC = xCCorner + wC * ${dilationWidth};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),\n              getValue(batch, xR, xC + 3 * ${dilationWidth}, d)\n            );\n\n            ${updateSnippet}\n          }\n\n          int xC = xCCorner + ${filterWidthNearestVec4};\n          if (${filterWidthVec4Remainder===1}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${updateSnippet}\n          } else if (${filterWidthVec4Remainder===2}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${updateSnippet}\n          } else if (${filterWidthVec4Remainder===3}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${dilationWidth}, d),\n              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),\n              initializationValue\n            );\n\n            ${updateSnippet}\n          }\n        }\n        setOutput(${returnValue});\n      }\n    `}}class Pool3DProgram{constructor(convInfo,poolType,computePositions,flattenPositions=false,includeBatchInIndex=false){this.variableNames=["x"];if(poolType==="avg"&&computePositions){throw new Error("Cannot compute positions for average pool.")}const filterWidth=convInfo.filterWidth;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationDepth=convInfo.dilationDepth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const effectiveFilterDepth=convInfo.effectiveFilterDepth;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padFront=convInfo.padInfo.front;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;this.outputShape=convInfo.outShape;const isAvgPool=poolType==="avg";let initializationValue="0.0";if(!isAvgPool){initializationValue="-1.0 / 1e-20"}if(computePositions){const compareOp=">=";this.userCode=`\n        const ivec3 strides =\n            ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n        const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${effectiveFilterDepth};\n              wD += ${dilationDepth}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${convInfo.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${effectiveFilterHeight};\n                wR += ${dilationHeight}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${convInfo.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${effectiveFilterWidth};\n                  wC += ${dilationWidth}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${compareOp} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${flattenPositions?includeBatchInIndex?`(((batch * ${convInfo.inDepth} + xD) * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch`:`((xD * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch`:`wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +\n                      wR * ${effectiveFilterWidth} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `;return}const compareOp="max";let returnValue=`${poolType}(${poolType}(${poolType}(`+"minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";if(poolType==="avg"){returnValue=`avgValue / count`}const filterWidthNearestVec4=Math.floor(filterWidth/4)*4;const filterWidthVec4Remainder=filterWidth%4;const updateSnippet=`\n      if (${isAvgPool}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = ${compareOp}(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n      const float initializationValue = ${initializationValue};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${convInfo.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${initializationValue});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n            wD += ${dilationDepth}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${convInfo.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {\n              int xC = xCCorner + wC * ${dilationWidth};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${dilationWidth}, ch)\n              );\n\n              ${updateSnippet}\n            }\n\n            int xC = xCCorner + ${filterWidthNearestVec4};\n            if (${filterWidthVec4Remainder===1}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${updateSnippet}\n            } else if (${filterWidthVec4Remainder===2}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${updateSnippet}\n            } else if (${filterWidthVec4Remainder===3}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),\n                initializationValue\n              );\n\n              ${updateSnippet}\n            }\n          }\n          setOutput(${returnValue});\n        }\n      }\n    `}}function avgPool(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;assertNotComplex(x,"avgPool");const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode}=attrs;const dilations=1;assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in avgPool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));const convInfo=computePool2DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode);if(convInfo.filterWidth===1&&convInfo.filterHeight===1&&arraysEqual(convInfo.inShape,convInfo.outShape)){return identity({inputs:{x:x},backend:backend})}const avgPoolProgram=new Pool2DProgram(convInfo,"avg",false);return backend.runWebGLProgram(avgPoolProgram,[x],"float32")}const avgPoolConfig={kernelName:AvgPool,backendName:"webgl",kernelFunc:avgPool};function avgPool3D(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode,dataFormat:dataFormat}=attrs;const dilations=[1,1,1];const convInfo=computePool3DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode,dataFormat);const avgPoolProgram=new Pool3DProgram(convInfo,"avg",false);return backend.runWebGLProgram(avgPoolProgram,[x],"float32")}const avgPool3DConfig={kernelName:AvgPool3D,backendName:"webgl",kernelFunc:avgPool3D};class AvgPool2DBackpropProgram{constructor(convInfo){this.variableNames=["dy"];this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padTop=effectiveFilterHeight-1-convInfo.padInfo.top;const padLeft=effectiveFilterWidth-1-convInfo.padInfo.left;const avgMultiplier=1/(filterHeight*filterWidth);this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float avgMultiplier = float(${avgMultiplier});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n            wR += ${dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${effectiveFilterWidth};\n            wC+= ${dilationWidth}) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class AvgPool3DBackpropProgram{constructor(convInfo){this.variableNames=["dy"];this.outputShape=convInfo.inShape;const filterDepth=convInfo.filterDepth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationDepth=convInfo.dilationDepth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const effectiveFilterDepth=convInfo.effectiveFilterDepth;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padFront=effectiveFilterDepth-1-convInfo.padInfo.front;const padTop=effectiveFilterHeight-1-convInfo.padInfo.top;const padLeft=effectiveFilterWidth-1-convInfo.padInfo.left;const avgMultiplier=1/(filterDepth*filterHeight*filterWidth);this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n      const float avgMultiplier = float(${avgMultiplier});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n            wD += ${dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function avgPool3DGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,input:input}=inputs;const x=input;const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode}=attrs;const dilations=[1,1,1];const convInfo=computePool3DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode);const avgPoolBackpropProgram=new AvgPool3DBackpropProgram(convInfo);return backend.runWebGLProgram(avgPoolBackpropProgram,[dy],x.dtype)}const avgPoolGrad3DConfig={kernelName:AvgPool3DGrad,backendName:"webgl",kernelFunc:avgPool3DGrad};function avgPoolGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,input:input}=inputs;const x=input;assertNotComplex([dy,input],"avgPoolGrad");const{filterSize:filterSize,strides:strides,pad:pad}=attrs;const convInfo=computePool2DInfo(x.shape,filterSize,strides,1,pad);const avgPoolBackpropProgram=new AvgPool2DBackpropProgram(convInfo);return backend.runWebGLProgram(avgPoolBackpropProgram,[dy],x.dtype)}const avgPoolGradConfig={kernelName:AvgPoolGrad,backendName:"webgl",kernelFunc:avgPoolGrad};function batchMatMul(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{a:a,b:b}=inputs;const{transposeA:transposeA,transposeB:transposeB}=attrs;return batchMatMulImpl({a:a,b:b,transposeA:transposeA,transposeB:transposeB,backend:backend})}const batchMatMulConfig={kernelName:BatchMatMul,backendName:"webgl",kernelFunc:batchMatMul};class BatchNormProgram{constructor(xShape,meanShape,varianceShape,offsetShape,scaleShape,varianceEpsilon){this.outputShape=[];this.variableNames=["x","mean","variance"];assertAndGetBroadcastShape(xShape,meanShape);assertAndGetBroadcastShape(xShape,varianceShape);let offsetSnippet="0.0";if(offsetShape!=null){assertAndGetBroadcastShape(xShape,offsetShape);this.variableNames.push("offset");offsetSnippet="getOffsetAtOutCoords()"}let scaleSnippet="1.0";if(scaleShape!=null){assertAndGetBroadcastShape(xShape,scaleShape);this.variableNames.push("scale");scaleSnippet="getScaleAtOutCoords()"}this.outputShape=xShape;this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${offsetSnippet};\n        float scale = ${scaleSnippet};\n        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class BatchNormPackedProgram{constructor(xShape,meanShape,varianceShape,offsetShape,scaleShape,varianceEpsilon){this.packedInputs=true;this.packedOutput=true;this.variableNames=["x","mean","variance"];assertAndGetBroadcastShape(xShape,meanShape);assertAndGetBroadcastShape(xShape,varianceShape);let offsetSnippet="vec4(0.0)";if(offsetShape!=null){assertAndGetBroadcastShape(xShape,offsetShape);this.variableNames.push("offset");offsetSnippet="getOffsetAtOutCoords()"}let scaleSnippet="vec4(1.0)";if(scaleShape!=null){assertAndGetBroadcastShape(xShape,scaleShape);this.variableNames.push("scale");scaleSnippet="getScaleAtOutCoords()"}this.outputShape=xShape;this.userCode=`\n      void main() {\n        vec4 offset = ${offsetSnippet};\n        vec4 scale = ${scaleSnippet};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${varianceEpsilon}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const batchNorm=({inputs:inputs,backend:backend,attrs:attrs})=>{const{x:x,mean:mean,variance:variance,offset:offset,scale:scale}=inputs;assert(mean.shape.length===variance.shape.length,(()=>"Batch normalization gradient requires mean and variance to have "+"equal ranks."));assert(offset==null||mean.shape.length===offset.shape.length,(()=>"Batch normalization gradient requires mean and offset to have "+"equal ranks."));assert(scale==null||mean.shape.length===scale.shape.length,(()=>"Batch normalization gradient requires mean and scale to have "+"equal ranks."));let{varianceEpsilon:varianceEpsilon}=attrs;if(varianceEpsilon==null){varianceEpsilon=.001}const finalInputs=[x,mean,variance];let offsetShape=null;if(offset!=null){offsetShape=offset.shape;finalInputs.push(offset)}let scaleShape=null;if(scale!=null){scaleShape=scale.shape;finalInputs.push(scale)}const program=env().getBool("WEBGL_PACK_NORMALIZATION")?new BatchNormPackedProgram(x.shape,mean.shape,variance.shape,offsetShape,scaleShape,varianceEpsilon):new BatchNormProgram(x.shape,mean.shape,variance.shape,offsetShape,scaleShape,varianceEpsilon);const output=backend.runWebGLProgram(program,finalInputs,finalInputs[0].dtype);return output};const batchNormConfig={kernelName:FusedBatchNorm,backendName:"webgl",kernelFunc:batchNorm};class SliceProgram{constructor(destSize){this.variableNames=["source"];this.outputShape=destSize;this.rank=destSize.length;const dtype=getCoordsDataType(this.rank);const uniformPart=`uniform int start[${this.rank}];`;const sourceCoords=getCoords$1(this.rank);let body;const coordSum=destSize.map(((_,i)=>`sourceLoc.${coords[i]} = start[${i}] + coords.${coords[i]};`));body=`\n        ${dtype} sourceLoc;\n        ${dtype} coords = getOutputCoords();\n        ${coordSum.join("\n")}\n      `;this.userCode=`\n      ${uniformPart}\n      void main() {\n        ${body}\n        setOutput(getSource(${sourceCoords}));\n      }\n    `}getCustomSetupFunc(start){if(start.length!==this.rank){throw Error(`The rank (${this.rank}) of the program must match the `+`length of start (${start.length})`)}return(gpgpu,webGLProgram)=>{if(this.startLoc==null){this.startLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"start");if(this.startLoc==null){return}}gpgpu.gl.uniform1iv(this.startLoc,start)}}}const coords=["x","y","z","w","u","v"];function getCoords$1(rank){if(rank===1){return"sourceLoc"}else if(rank<=6){return coords.slice(0,rank).map((x=>"sourceLoc."+x)).join(",")}else{throw Error(`Slicing for rank ${rank} is not yet supported`)}}class SlicePackedProgram{constructor(destSize){this.variableNames=["source"];this.packedInputs=true;this.packedOutput=true;this.outputShape=destSize;this.rank=destSize.length;const dtype=getCoordsDataType(this.rank);const coords=getChannels("coords",this.rank);const sourceLoc=getChannels("sourceLoc",this.rank);const innerDims=this.rank===1?"sourceLoc":`vec2(${sourceLoc.slice(-2).join()})`;const getChannel=`getChannel(getSource(${sourceLoc.join()}), ${innerDims})`;const upperRow=`\n      result.x = ${getChannel};\n      if (++${coords[this.rank-1]} < ${destSize[this.rank-1]}) {\n        ++${sourceLoc[this.rank-1]};\n        result.y = ${getChannel};\n        --${sourceLoc[this.rank-1]};\n      }\n    `;const lowerRow=this.rank===1?"":`\n      --${coords[this.rank-1]};\n      if (++${coords[this.rank-2]} < ${destSize[this.rank-2]}) {\n        ++${sourceLoc[this.rank-2]};\n        result.z = ${getChannel};\n        if (++${coords[this.rank-1]} < ${destSize[this.rank-1]}) {\n          ++${sourceLoc[this.rank-1]};\n          result.w = ${getChannel};\n        }\n      }\n    `;const sourceLocSetup=this.rank<=4?`sourceLoc = coords +\n            ${dtype}(${destSize.map(((_,i)=>`start[${i}]`)).join()});`:destSize.map(((_,i)=>`${sourceLoc[i]} = ${coords[i]} + start[${i}];`)).join("\n");this.userCode=`\n      uniform int start[${this.rank}];\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        ${dtype} sourceLoc;\n        ${sourceLocSetup}\n        vec4 result = vec4(0.);\n        ${upperRow}\n        ${lowerRow}\n        setOutput(result);\n      }\n    `}getCustomSetupFunc(start){if(start.length!==this.rank){throw Error(`The rank (${this.rank}) of the program must match the `+`length of start (${start.length})`)}return(gpgpu,webGLProgram)=>{if(this.startLoc==null){this.startLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"start");if(this.startLoc==null){return}}gpgpu.gl.uniform1iv(this.startLoc,start)}}}function shallowSlice(x,begin,size,backend){const xTexData=backend.texData.get(x.dataId);const t=backend.makeTensorInfo(size,x.dtype);const newTexData=backend.texData.get(t.dataId);Object.assign(newTexData,xTexData);newTexData.refCount=1;newTexData.shape=size;newTexData.dtype=x.dtype;let flatOffset=computeFlatOffset(begin,computeStrides(x.shape));if(xTexData.slice){flatOffset+=xTexData.slice.flatOffset}newTexData.slice={flatOffset:flatOffset,origDataId:xTexData.slice&&xTexData.slice.origDataId||x.dataId};const refCount=backend.dataRefCount.get(newTexData.slice.origDataId)||1;backend.dataRefCount.set(newTexData.slice.origDataId,refCount+1);return t}function slice(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{begin:begin,size:size}=attrs;const[$begin,$size]=parseSliceParams(x,begin,size);assertParamsValid(x,$begin,$size);if(sizeFromShape($size)===0){return backend.makeTensorInfo($size,x.dtype,[])}if(backend.shouldExecuteOnCPU([x])||x.dtype==="string"){const xTexData=backend.texData.get(x.dataId);const outValues=sliceImplCPU(xTexData.values,$begin,$size,x.shape,x.dtype);return backend.makeTensorInfo($size,x.dtype,outValues)}const{isPacked:isPacked}=backend.texData.get(x.dataId);const isContinous=isSliceContinous(x.shape,$begin,$size);if(isPacked||!isContinous){const program=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new SlicePackedProgram($size):new SliceProgram($size);const customSetup=program.getCustomSetupFunc($begin);return backend.runWebGLProgram(program,[x],x.dtype,customSetup)}backend.uploadToGPU(x.dataId);return shallowSlice(x,$begin,$size,backend)}const sliceConfig={kernelName:Slice,backendName:"webgl",kernelFunc:slice};const batchToSpaceND=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{blockShape:blockShape,crops:crops}=attrs;assert(x.shape.length<=4,(()=>"batchToSpaceND for rank > 4 with a WebGL backend not "+"implemented yet"));const prod=blockShape.reduce(((a,b)=>a*b));const reshaped=getReshaped(x.shape,blockShape,prod);const permuted=getPermuted(reshaped.length,blockShape.length);const reshapedPermuted=getReshapedPermuted(x.shape,blockShape,prod);const sliceBeginCoords=getSliceBeginCoords(crops,blockShape.length);const sliceSize=getSliceSize(reshapedPermuted,crops,blockShape.length);const toDispose=[];const reshapedIntermediate=reshape({inputs:{x:x},backend:backend,attrs:{shape:reshaped}});const transposedIntermediate=transpose({inputs:{x:reshapedIntermediate},backend:backend,attrs:{perm:permuted}});const reshapedIntermediate2=reshape({inputs:{x:transposedIntermediate},backend:backend,attrs:{shape:reshapedPermuted}});const sliced=slice({inputs:{x:reshapedIntermediate2},backend:backend,attrs:{begin:sliceBeginCoords,size:sliceSize}});toDispose.push(reshapedIntermediate);toDispose.push(transposedIntermediate);toDispose.push(reshapedIntermediate2);toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return sliced};const batchToSpaceNDConfig={kernelName:BatchToSpaceND,backendName:"webgl",kernelFunc:batchToSpaceND};function bincount(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,weights:weights}=inputs;const{size:size}=attrs;const xVals=backend.readSync(x.dataId);const weightsVals=backend.readSync(weights.dataId);const outVals=bincountImplCPU(xVals,weightsVals,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}const bincountConfig={kernelName:Bincount,backendName:"webgl",kernelFunc:bincount};const NOT_EQUAL=`return float(a != b);`;const notEqual=binaryKernelFunc({opSnippet:NOT_EQUAL,dtype:"bool"});const notEqualConfig={kernelName:NotEqual,backendName:"webgl",kernelFunc:notEqual};function real(args){const{inputs:inputs,backend:backend}=args;const{input:input}=inputs;const inputData=backend.texData.get(input.dataId);return identity({inputs:{x:inputData.complexTensorInfos.real},backend:backend})}const realConfig={kernelName:Real,backendName:"webgl",kernelFunc:real};const TO_INT=`return float(int(x));`;function int(input,backend){const program=new UnaryOpProgram(input.shape,TO_INT);const output=backend.runWebGLProgram(program,[input],"int32");return{dataId:output.dataId,shape:output.shape,dtype:output.dtype}}function cast(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{dtype:dtype}=attrs;if(dtype==="complex64"){if(x.dtype==="complex64"){return identity({inputs:{x:x},backend:backend})}const zerosTensor=zeros(x.shape);const floatX=cast({inputs:{x:x},backend:backend,attrs:{dtype:"float32"}});const result=complex({inputs:{real:floatX,imag:zerosTensor},backend:backend});zerosTensor.dispose();backend.disposeIntermediateTensorInfo(floatX);return result}if(x.dtype==="complex64"){const realPart=real({inputs:{input:x},backend:backend});const result=cast({inputs:{x:realPart},backend:backend,attrs:{dtype:dtype}});backend.disposeIntermediateTensorInfo(realPart);return result}if(!hasEncodingLoss(x.dtype,dtype)){const result=identity({inputs:{x:x},backend:backend});return{dataId:result.dataId,shape:result.shape,dtype:dtype}}if(dtype==="int32"){return int(x,backend)}if(dtype==="bool"){const zerosTensorInfo=backend.makeTensorInfo([],"bool",getTypedArrayFromDType("bool",1));const binaryInputs={a:x,b:zerosTensorInfo};const result=notEqual({inputs:binaryInputs,backend:backend});backend.disposeIntermediateTensorInfo(zerosTensorInfo);return result}throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`)}const castConfig={kernelName:Cast,backendName:"webgl",kernelFunc:cast};const CEIL=`return ceil(x);`;const ceil=unaryKernelFunc({opSnippet:CEIL,packedOpSnippet:CEIL,cpuKernelImpl:ceilImplCPU});const ceilConfig={kernelName:Ceil,backendName:"webgl",kernelFunc:ceil};class ClipProgram{constructor(aShape){this.variableNames=["A"];this.outputShape=aShape;this.userCode=`\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    `}getCustomSetupFunc(min,max){return(gpgpu,webGLProgram)=>{if(this.minLoc==null){this.minLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"minVal");this.maxLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"maxVal")}gpgpu.gl.uniform1f(this.minLoc,min);gpgpu.gl.uniform1f(this.maxLoc,max)}}}class ClipPackedProgram{constructor(aShape){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=aShape;this.userCode=`\n      uniform float minVal;\n      uniform float maxVal;\n\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    `}getCustomSetupFunc(min,max){return(gpgpu,webGLProgram)=>{if(this.minLoc==null){this.minLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"minVal");this.maxLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"maxVal")}gpgpu.gl.uniform1f(this.minLoc,min);gpgpu.gl.uniform1f(this.maxLoc,max)}}}function clipByValue(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{clipValueMin:clipValueMin,clipValueMax:clipValueMax}=attrs;let program;if(env().getBool("WEBGL_PACK_CLIP")){program=new ClipPackedProgram(x.shape)}else{program=new ClipProgram(x.shape)}const customSetup=program.getCustomSetupFunc(clipValueMin,clipValueMax);return backend.runWebGLProgram(program,[x],x.dtype,customSetup)}const clipByValueConfig={kernelName:ClipByValue,backendName:"webgl",kernelFunc:clipByValue};class ComplexAbsProgram{constructor(shape){this.variableNames=["real","imag"];this.outputShape=shape;this.userCode=`\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    `}}function makeComplexComponentTensorInfo(complexTensor,complexPart){return{dataId:complexPart.dataId,dtype:complexPart.dtype,shape:complexTensor.shape}}function complexAbs(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;const xData=backend.texData.get(x.dataId);const program=new ComplexAbsProgram(x.shape);const programInputs=[makeComplexComponentTensorInfo(x,xData.complexTensorInfos.real),makeComplexComponentTensorInfo(x,xData.complexTensorInfos.imag)];return backend.runWebGLProgram(program,programInputs,programInputs[0].dtype)}const complexAbsConfig={kernelName:ComplexAbs,backendName:"webgl",kernelFunc:complexAbs};class ConcatProgram{constructor(shapes){this.outputShape=[];this.outputShape=computeOutShape$1(shapes,1);this.variableNames=shapes.map(((_,i)=>`T${i}`));const offsets=new Array(shapes.length-1);offsets[0]=shapes[0][1];for(let i=1;i<offsets.length;i++){offsets[i]=offsets[i-1]+shapes[i][1]}const snippets=[`if (yC < ${offsets[0]}) setOutput(getT0(yR, yC));`];for(let i=1;i<offsets.length;i++){const shift=offsets[i-1];snippets.push(`else if (yC < ${offsets[i]}) `+`setOutput(getT${i}(yR, yC-${shift}));`)}const lastIndex=offsets.length;const lastShift=offsets[offsets.length-1];snippets.push(`else setOutput(getT${lastIndex}(yR, yC-${lastShift}));`);this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${snippets.join("\n        ")}\n      }\n    `}}class ConcatPackedProgram{constructor(shapes,axis){this.packedInputs=true;this.packedOutput=true;this.outputShape=[];this.outputShape=computeOutShape$1(shapes,axis);const shape=this.outputShape;const rank=shape.length;const dtype=getCoordsDataType(rank);const coords=getChannels("coords",rank);const channels=["x","y","z","w","u","v"].slice(0,rank);this.variableNames=shapes.map(((_,i)=>`T${i}`));const offsets=new Array(shapes.length-1);offsets[0]=shapes[0][axis];for(let i=1;i<offsets.length;i++){offsets[i]=offsets[i-1]+shapes[i][axis]}const channel=channels[axis];const lastChannels=channels.slice(-2);const allChannels=channels.join();let getValueSnippet=`if (${channel} < ${offsets[0]}) {\n        return getChannel(\n            getT0(${allChannels}), vec2(${lastChannels.join()}));\n        }`;for(let i=1;i<offsets.length;i++){const shift=offsets[i-1];getValueSnippet+=`\n        if (${channel} < ${offsets[i]}  && ${channel} >= ${offsets[i-1]}) {\n          return getChannel(\n            getT${i}(${shiftedChannels(channels,channel,shift)}),\n            vec2(${shiftedChannels(lastChannels,channel,shift)}));\n        }`}const lastIndex=offsets.length;const shift=offsets[offsets.length-1];getValueSnippet+=`\n        return getChannel(\n          getT${lastIndex}(${shiftedChannels(channels,channel,shift)}),\n          vec2(${shiftedChannels(lastChannels,channel,shift)}));`;this.userCode=`\n      float getValue(${channels.map((x=>"int "+x))}) {\n        ${getValueSnippet}\n      }\n\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${coords}), 0., 0., 0.);\n\n        ${coords[rank-1]} = ${coords[rank-1]} + 1;\n        if (${coords[rank-1]} < ${shape[rank-1]}) {\n          result.g = getValue(${coords});\n        }\n\n        ${coords[rank-2]} = ${coords[rank-2]} + 1;\n        if (${coords[rank-2]} < ${shape[rank-2]}) {\n          result.a = getValue(${coords});\n        }\n\n        ${coords[rank-1]} = ${coords[rank-1]} - 1;\n        if (${coords[rank-2]} < ${shape[rank-2]} &&\n            ${coords[rank-1]} < ${shape[rank-1]}) {\n          result.b = getValue(${coords});\n        }\n        setOutput(result);\n      }\n    `}}function shiftedChannels(channels,channel,shift){const channelIdx=channels.indexOf(channel);const res=channels.map(((c,idx)=>{if(idx===channelIdx){return`${c} - ${shift}`}else{return c}}));return res.join()}function imag(args){const{inputs:inputs,backend:backend}=args;const{input:input}=inputs;const inputData=backend.texData.get(input.dataId);return identity({inputs:{x:inputData.complexTensorInfos.imag},backend:backend})}const imagConfig={kernelName:Imag,backendName:"webgl",kernelFunc:imag};function concatImpl(inputs,axis,backend){const dtype=inputs[0].dtype;if(dtype==="complex64"){const reals=inputs.map((t=>real({inputs:{input:t},backend:backend})));const imags=inputs.map((t=>imag({inputs:{input:t},backend:backend})));const realConcated=concatImpl(reals,axis,backend);const imagConcated=concatImpl(imags,axis,backend);const result=complex({inputs:{real:realConcated,imag:imagConcated},backend:backend});reals.forEach((r=>backend.disposeIntermediateTensorInfo(r)));imags.forEach((i=>backend.disposeIntermediateTensorInfo(i)));backend.disposeIntermediateTensorInfo(realConcated);backend.disposeIntermediateTensorInfo(imagConcated);return result}let runOnCpu=backend.shouldExecuteOnCPU(inputs);if(dtype==="string"){runOnCpu=true}if(runOnCpu){const tensors2D=inputs.map((t=>{const innerSize=sizeFromShape(t.shape.slice(axis));const shape=[-1,innerSize];return reshape({inputs:{x:t},backend:backend,attrs:{shape:shape}})}));const inputsValShapes=tensors2D.map((t=>({vals:backend.readSync(t.dataId),shape:t.shape})));const outShape=computeOutShape$1(tensors2D.map((t=>t.shape)),1);const simplyConcat=tensors2D[0].shape[0]===1;const outVals=concatImplCPU(inputsValShapes,outShape,dtype,simplyConcat);const finalOutShape=computeOutShape$1(inputs.map((t=>t.shape)),axis);const outInfo=backend.makeTensorInfo(finalOutShape,dtype,outVals);tensors2D.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return outInfo}if(inputs.length>env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const midIndex=Math.floor(inputs.length/2);const leftSide=concatImpl(inputs.slice(0,midIndex),axis,backend);const rightSide=concatImpl(inputs.slice(midIndex),axis,backend);const result=concatImpl([leftSide,rightSide],axis,backend);backend.disposeIntermediateTensorInfo(leftSide);backend.disposeIntermediateTensorInfo(rightSide);return result}if(env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&inputs[0].shape.length>1){const program=new ConcatPackedProgram(inputs.map((t=>t.shape)),axis);return backend.runWebGLProgram(program,inputs,dtype)}const{tensors2D:tensors2D,outShape:outShape}=computeTensors2D(inputs,axis,backend);const program=new ConcatProgram(tensors2D.map((t=>t.shape)));const result=backend.runWebGLProgram(program,tensors2D,dtype);tensors2D.forEach((r=>backend.disposeIntermediateTensorInfo(r)));const reshapedResult=reshape({inputs:{x:result},attrs:{shape:outShape},backend:backend});backend.disposeIntermediateTensorInfo(result);return reshapedResult}function computeTensors2D(inputs,axis,backend){const outShape=computeOutShape$1(inputs.map((t=>t.shape)),axis);const tensors2D=inputs.map((x=>reshape({inputs:{x:x},attrs:{shape:[-1,sizeFromShape(x.shape.slice(axis))]},backend:backend})));return{tensors2D:tensors2D,outShape:outShape}}function concat(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{axis:axis}=attrs;const $axis=parseAxisParam(axis,inputs[0].shape)[0];const outShape=computeOutShape$1(inputs.map((t=>t.shape)),$axis);if(sizeFromShape(outShape)===0){return backend.makeTensorInfo(outShape,inputs[0].dtype,[])}const $inputs=inputs.filter((t=>sizeFromShape(t.shape)>0));if($inputs.length===1){return identity({inputs:{x:$inputs[0]},backend:backend})}const shapes=$inputs.map((t=>t.shape));assertParamsConsistent(shapes,$axis);return concatImpl($inputs,$axis,backend)}const concatConfig={kernelName:Concat,backendName:"webgl",kernelFunc:concat};class Conv2DProgram{constructor(convInfo,addBias=false,activation=null,hasPreluActivationWeights=false,hasLeakyreluAlpha=false){this.variableNames=["x","W"];this.outputShape=convInfo.outShape;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const inputDepthNearestVec4=Math.floor(convInfo.inChannels/4)*4;const inputDepthVec4Remainder=convInfo.inChannels%4;const isChannelsLast=convInfo.dataFormat==="channelsLast";const rowDim=isChannelsLast?1:2;const colDim=isChannelsLast?2:3;const channelDim=isChannelsLast?3:1;let activationSnippet="",applyActivationSnippet="";if(activation){if(hasPreluActivationWeights){activationSnippet=`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`}else if(hasLeakyreluAlpha){activationSnippet=`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`}else{activationSnippet=`\n          float activation(float x) {\n            ${activation}\n          }\n        `}applyActivationSnippet=`result = activation(result);`}const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";if(addBias){this.variableNames.push("bias")}if(hasPreluActivationWeights){this.variableNames.push("preluActivationWeights")}if(hasLeakyreluAlpha){this.variableNames.push("leakyreluAlpha")}this.userCode=`\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${channelDim}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${rowDim}], coords[${colDim}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          int xR = xRCorner + wR * ${dilationHeight};\n\n          if (xR < 0 || xR >= ${convInfo.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            int xC = xCCorner + wC * ${dilationWidth};\n\n            if (xC < 0 || xC >= ${convInfo.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${inputDepthVec4Remainder===1}) {\n\n              if (${isChannelsLast}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${inputDepthNearestVec4}) *\n                    getW(wR, wC, ${inputDepthNearestVec4}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${inputDepthNearestVec4}, xR, xC) *\n                    getW(wR, wC, ${inputDepthNearestVec4}, d2);\n              }\n\n            } else if (${inputDepthVec4Remainder===2}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${inputDepthNearestVec4}, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${inputDepthNearestVec4}, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${inputDepthVec4Remainder===3}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${inputDepthNearestVec4}, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2),\n                getW(wR, wC, ${inputDepthNearestVec4} + 2, d2)\n              );\n\n              if (${isChannelsLast}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1),\n                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${inputDepthNearestVec4}, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC),\n                  getX(batch, ${inputDepthNearestVec4} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}class Conv3DProgram{constructor(convInfo){this.variableNames=["x","W"];this.outputShape=convInfo.outShape;const padFront=convInfo.padInfo.front;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationDepth=convInfo.dilationDepth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const filterDepth=convInfo.filterDepth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const inputDepthNearestVec4=Math.floor(convInfo.inChannels/4)*4;const inputDepthVec4Remainder=convInfo.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${filterDepth}; wF++) {\n          int xF = xFCorner + wF * ${dilationDepth};\n\n          if (xF < 0 || xF >= ${convInfo.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${filterHeight}; wR++) {\n            int xR = xRCorner + wR * ${dilationHeight};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${filterWidth}; wC++) {\n              int xC = xCCorner + wC * ${dilationWidth};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${inputDepthVec4Remainder===1}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}) *\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2);\n              } else if (${inputDepthVec4Remainder===2}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${inputDepthVec4Remainder===3}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1),\n                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2),\n                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Im2ColPackedProgram{constructor(outputShape,inputShape,convInfo){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=outputShape;const{filterWidth:filterWidth,inChannels:inChannels,strideWidth:strideWidth,strideHeight:strideHeight,padInfo:padInfo,outWidth:outWidth,dilationWidth:dilationWidth,dilationHeight:dilationHeight,dataFormat:dataFormat}=convInfo;const{left:left,top:top}=padInfo;const itemsPerBlockRow=inChannels*filterWidth;const glsl=getGlslDifferences();const isChannelsLast=dataFormat==="channelsLast";const rowDim=isChannelsLast?0:1;const colDim=isChannelsLast?1:2;let unrolled=``;for(let row=0;row<=1;row++){for(let col=0;col<=1;col++){unrolled+=`\n          blockIndex = rc.y + ${col};\n          pos = rc.x + ${row};\n\n          if(blockIndex < ${outputShape[1]} && pos < ${outputShape[0]}) {\n            offsetY = int(blockIndex / (${outWidth})) * ${strideHeight} - ${top};\n            d0 = offsetY + ${dilationHeight} * (pos / ${itemsPerBlockRow});\n\n            if(d0 < ${inputShape[rowDim]} && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ${outWidth}.) * ${strideWidth}. - ${left}.);\n              d1 = offsetX + ${dilationWidth} * (int(mod(float(pos), ${itemsPerBlockRow}.) / ${inChannels}.));\n\n              if(d1 < ${inputShape[colDim]} && d1 >= 0) {\n\n                ch = int(mod(float(pos), ${inChannels}.));\n\n                if (${isChannelsLast}) {\n                  innerDims = vec2(d1, ch);\n                  result[${row*2+col}] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${row*2+col}] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `}}this.userCode=`\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${unrolled}\n\n        ${glsl.output} = result;\n      }\n    `}}function conv2dByMatMul({x:x,filter:filter,convInfo:convInfo,backend:backend,bias:bias=null,preluActivationWeights:preluActivationWeights=null,leakyreluAlpha:leakyreluAlpha=0,activation:activation=null}){const xShape=x.shape;const xTexData=backend.texData.get(x.dataId);const sharedMatMulDim=convInfo.inChannels;const outerShapeX=xShape[0]*xShape[1]*xShape[2];const outerShapeFilter=convInfo.outChannels;const isChannelsLast=convInfo.dataFormat==="channelsLast";const transposeA=false;const transposeB=false;let out;const intermediates=[];const batchMatMulWillBeUnpacked=(outerShapeX===1||outerShapeFilter===1)&&sharedMatMulDim>MATMUL_SHARED_DIM_THRESHOLD;const reshapeWillBeExpensive=xShape[2]%2!==0&&!!xTexData.isPacked;if(batchMatMulWillBeUnpacked||!env().getBool("WEBGL_LAZILY_UNPACK")||!env().getBool("WEBGL_PACK_BINARY_OPERATIONS")||!reshapeWillBeExpensive){const targetShape=isChannelsLast?xShape[0]*xShape[1]*xShape[2]:xShape[0]*xShape[2]*xShape[3];const xReshaped=reshape({inputs:{x:x},backend:backend,attrs:{shape:[1,targetShape,convInfo.inChannels]}});const filterReshaped=reshape({inputs:{x:filter},backend:backend,attrs:{shape:[1,convInfo.inChannels,convInfo.outChannels]}});const result=batchMatMulImpl({a:xReshaped,b:filterReshaped,transposeA:transposeA,transposeB:transposeB,backend:backend,bias:bias,activation:activation,preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha});out=reshape({inputs:{x:result},backend:backend,attrs:{shape:convInfo.outShape}});intermediates.push(xReshaped);intermediates.push(filterReshaped);intermediates.push(result)}else{const targetShape=isChannelsLast?xShape[0]*xShape[1]*(xShape[2]+1):xShape[0]*xShape[2]*(xShape[3]+1);const xReshaped={dataId:x.dataId,shape:[1,targetShape,convInfo.inChannels],dtype:x.dtype};const originalXTexDataShape=xTexData.shape;xTexData.shape=xTexData.shape.slice();xTexData.shape[xTexData.shape.length-2]++;assert(isReshapeFree(xTexData.shape,xReshaped.shape),(()=>`packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`));const filterReshaped=reshape({inputs:{x:filter},backend:backend,attrs:{shape:[1,convInfo.inChannels,convInfo.outChannels]}});intermediates.push(filterReshaped);const pointwiseConv=batchMatMulImpl({a:xReshaped,b:filterReshaped,backend:backend,transposeA:transposeA,transposeB:transposeB,bias:bias,activation:activation,preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha});const pointwiseConvTexData=backend.texData.get(pointwiseConv.dataId);assert(pointwiseConvTexData.isPacked,(()=>"batchMatMul result is expected to be packed"));xTexData.shape=originalXTexDataShape;pointwiseConvTexData.shape=convInfo.outShape;out=identity({inputs:{x:pointwiseConv},backend:backend});out.shape=convInfo.outShape;intermediates.push(pointwiseConv)}for(const i of intermediates){backend.disposeIntermediateTensorInfo(i)}return out}function conv2dWithIm2Row({x:x,filter:filter,convInfo:convInfo,backend:backend,bias:bias=null,preluActivationWeights:preluActivationWeights=null,leakyreluAlpha:leakyreluAlpha=0,activation:activation=null}){const{filterWidth:filterWidth,filterHeight:filterHeight,inChannels:inChannels,outWidth:outWidth,outHeight:outHeight,dataFormat:dataFormat}=convInfo;const isChannelsLast=dataFormat==="channelsLast";const sharedDim=filterWidth*filterHeight*inChannels;const numCols=outHeight*outWidth;const x2ColShape=[sharedDim,numCols];const transposeA=true;const transposeB=false;const intermediates=[];const xSqueezed=reshape({inputs:{x:x},backend:backend,attrs:{shape:x.shape.slice(1)}});const w2Row=reshape({inputs:{x:filter},backend:backend,attrs:{shape:[1,sharedDim,sizeFromShape(filter.shape)/sharedDim]}});intermediates.push(xSqueezed);intermediates.push(w2Row);const im2ColProgram=new Im2ColPackedProgram(x2ColShape,xSqueezed.shape,convInfo);const im2Col=backend.runWebGLProgram(im2ColProgram,[xSqueezed],"float32");const im2ColReshaped=reshape({inputs:{x:im2Col},backend:backend,attrs:{shape:[1,x2ColShape[0],x2ColShape[1]]}});intermediates.push(im2Col);intermediates.push(im2ColReshaped);const hasBias=bias!=null;const hasPreluActivationWeights=preluActivationWeights!=null;const hasLeakyreluAlpha=activation==="leakyrelu";const fusedActivation=activation?mapActivationToShaderProgram(activation,true):null;const matmulProgram=new MatMulPackedProgram(im2ColReshaped.shape,w2Row.shape,[1,numCols,convInfo.outChannels],transposeA,transposeB,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha);const inputs=[im2ColReshaped,w2Row];if(bias){inputs.push(bias)}if(hasPreluActivationWeights){inputs.push(preluActivationWeights)}if(hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha);intermediates.push($leakyreluAlpha)}const product=backend.runWebGLProgram(matmulProgram,inputs,"float32");const outShape=isChannelsLast?[1,outHeight,outWidth,convInfo.outChannels]:[1,convInfo.outChannels,outHeight,outWidth];const out=reshape({inputs:{x:product},backend:backend,attrs:{shape:outShape}});intermediates.push(product);for(const i of intermediates){backend.disposeIntermediateTensorInfo(i)}return out}function conv2d(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter}=inputs;const{strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode}=attrs;const $dataFormat=convertConv2DDataFormat(dataFormat);const convInfo=computeConv2DInfo(x.shape,filter.shape,strides,dilations,pad,dimRoundingMode,false,$dataFormat);let out;if(convInfo.filterHeight===1&&convInfo.filterWidth===1&&convInfo.dilationHeight===1&&convInfo.dilationWidth===1&&convInfo.strideHeight===1&&convInfo.strideWidth===1&&(convInfo.padInfo.type==="SAME"||convInfo.padInfo.type==="VALID")){out=conv2dByMatMul({x:x,filter:filter,convInfo:convInfo,backend:backend})}else if(env().getBool("WEBGL_CONV_IM2COL")&&x.shape[0]===1){out=conv2dWithIm2Row({x:x,filter:filter,convInfo:convInfo,backend:backend})}else{const program=new Conv2DProgram(convInfo);out=backend.runWebGLProgram(program,[x,filter],"float32")}const outReshaped=reshape({inputs:{x:out},backend:backend,attrs:{shape:convInfo.outShape}});backend.disposeIntermediateTensorInfo(out);return outReshaped}const conv2DConfig={kernelName:Conv2D,backendName:"webgl",kernelFunc:conv2d};class Conv2DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"];this.outputShape=convInfo.filterShape;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const isChannelsLast=convInfo.dataFormat==="channelsLast";this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n            int xR = wR + yR * ${strideHeight} - ${padTop};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n              int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              if (${isChannelsLast}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv2DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"];this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const isChannelsLast=convInfo.dataFormat==="channelsLast";const padTop=filterHeight-1-convInfo.padInfo.top;const padLeft=filterWidth-1-convInfo.padInfo.left;const rowDim=isChannelsLast?1:2;const colDim=isChannelsLast?2:3;const channelDim=isChannelsLast?3:1;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${channelDim}];\n\n        ivec2 dyCorner = ivec2(coords[${rowDim}], coords[${colDim}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${filterHeight} - 1 - wR;\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${filterWidth} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {\n\n              if (${isChannelsLast}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"];this.outputShape=convInfo.filterShape;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const padFront=convInfo.padInfo.front;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yF = 0; yF < ${convInfo.outDepth}; yF++) {\n            int xF = wF + yF * ${strideDepth} - ${padFront};\n\n            if (xF < 0 || xF >= ${convInfo.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n              int xR = wR + yR * ${strideHeight} - ${padTop};\n\n              if (xR < 0 || xR >= ${convInfo.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n                int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n                if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"];this.outputShape=convInfo.inShape;const filterDepth=convInfo.filterDepth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const padFront=filterDepth-1-convInfo.padInfo.front;const padTop=filterHeight-1-convInfo.padInfo.top;const padLeft=filterWidth-1-convInfo.padInfo.left;this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${filterDepth}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${strideDepth}.0;\n\n          if (dyF < 0.0 || dyF >= ${convInfo.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${filterDepth} - 1 - wF;\n\n          for (int wR = 0; wR < ${filterHeight}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${filterHeight} - 1 - wR;\n\n            for (int wC = 0; wC < ${filterWidth}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${filterWidth} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function conv2DBackpropFilter(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,dy:dy}=inputs;const{strides:strides,pad:pad,dataFormat:dataFormat,dimRoundingMode:dimRoundingMode,filterShape:filterShape}=attrs;const $dataFormat=convertConv2DDataFormat(dataFormat);const convInfo=computeConv2DInfo(x.shape,filterShape,strides,1,pad,dimRoundingMode,false,$dataFormat);const program=new Conv2DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}const conv2DBackpropFilterConfig={kernelName:Conv2DBackpropFilter,backendName:"webgl",kernelFunc:conv2DBackpropFilter};function conv2DBackpropInput(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,filter:filter}=inputs;const{inputShape:inputShape,strides:strides,pad:pad,dataFormat:dataFormat,dimRoundingMode:dimRoundingMode}=attrs;const $dataFormat=convertConv2DDataFormat(dataFormat);const convInfo=computeConv2DInfo(inputShape,filter.shape,strides,1,pad,dimRoundingMode,false,$dataFormat);const program=new Conv2DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}const conv2DBackpropInputConfig={kernelName:Conv2DBackpropInput,backendName:"webgl",kernelFunc:conv2DBackpropInput};function conv3D(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter}=inputs;const{strides:strides,pad:pad,dilations:dilations}=attrs;const convInfo=computeConv3DInfo(x.shape,filter.shape,strides,dilations,pad);const program=new Conv3DProgram(convInfo);return backend.runWebGLProgram(program,[x,filter],"float32")}const conv3DConfig={kernelName:Conv3D,backendName:"webgl",kernelFunc:conv3D};function conv3DBackpropFilterV2(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,dy:dy}=inputs;const{strides:strides,pad:pad,filterShape:filterShape}=attrs;const convInfo=computeConv3DInfo(x.shape,filterShape,strides,1,pad);const program=new Conv3DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}const conv3DBackpropFilterV2Config={kernelName:Conv3DBackpropFilterV2,backendName:"webgl",kernelFunc:conv3DBackpropFilterV2};function conv3DBackpropInput(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,filter:filter}=inputs;const{pad:pad,strides:strides,inputShape:inputShape}=attrs;const convInfo=computeConv3DInfo(inputShape,filter.shape,strides,1,pad);const program=new Conv3DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}const conv3DBackpropInputConfig={kernelName:Conv3DBackpropInputV2,backendName:"webgl",kernelFunc:conv3DBackpropInput};const COS=CHECK_NAN_SNIPPET_UNARY+`\n  return cos(x);\n`;const cos=unaryKernelFunc({opSnippet:COS});const cosConfig={kernelName:Cos,backendName:"webgl",kernelFunc:cos};const COSH=`\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n`;const cosh=unaryKernelFunc({opSnippet:COSH});const coshConfig={kernelName:Cosh,backendName:"webgl",kernelFunc:cosh};class CropAndResizeProgram{constructor(imageShape,boxShape,cropSize,method,extrapolationValue){this.variableNames=["Image","Boxes","BoxInd"];this.outputShape=[];const[batch,imageHeight,imageWidth,depth]=imageShape;const[numBoxes]=boxShape;const[cropHeight,cropWidth]=cropSize;this.outputShape=[numBoxes,cropHeight,cropWidth,depth];const methodId=method==="bilinear"?1:0;const[inputHeightFloat,inputWidthFloat]=[`${imageHeight-1}.0`,`${imageWidth-1}.0`];const[heightRatio,heightScale,inY]=cropHeight>1?[`${(imageHeight-1)/(cropHeight-1)}`,"(y2-y1) * height_ratio",`y1*${inputHeightFloat} + float(y)*(height_scale)`]:["0.0","0.0",`0.5 * (y1+y2) * ${inputHeightFloat}`];const[widthRatio,widthScale,inX]=cropWidth>1?[`${(imageWidth-1)/(cropWidth-1)}`,"(x2-x1) * width_ratio",`x1*${inputWidthFloat} + float(x)*(width_scale)`]:["0.0","0.0",`0.5 * (x1+x2) * ${inputWidthFloat}`];this.userCode=`\n      const float height_ratio = float(${heightRatio});\n      const float width_ratio = float(${widthRatio});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${batch}) {\n          return;\n        }\n\n        float height_scale = ${heightScale};\n        float width_scale = ${widthScale};\n\n        float in_y = ${inY};\n        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {\n          setOutput(float(${extrapolationValue}));\n          return;\n        }\n        float in_x = ${inX};\n        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {\n          setOutput(float(${extrapolationValue}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${methodId} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}const cropAndResize=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{image:image,boxes:boxes,boxInd:boxInd}=inputs;const{cropSize:cropSize,method:method,extrapolationValue:extrapolationValue}=attrs;const program=new CropAndResizeProgram(image.shape,boxes.shape,cropSize,method,extrapolationValue);return backend.runWebGLProgram(program,[image,boxes,boxInd],"float32")};const cropAndResizeConfig={kernelName:CropAndResize,backendName:"webgl",kernelFunc:cropAndResize};class CumSumProgram{constructor(shape,exclusive,reverse){this.variableNames=["x"];this.outputShape=shape;const rank=shape.length;const val=exclusive?"0.0":`getX(${getCoords(rank,"coords")})`;const length=shape[shape.length-1];let condition="";let idxString="";if(exclusive){condition=reverse?`end != ${length-1}`:"end != 0";idxString=reverse?"end + 1":"end - 1"}else{condition=reverse?`end + pow2 < ${length}`:"end >= pow2";idxString=reverse?"end + pow2":"end - pow2"}this.userCode=`\n      uniform float index;\n      void main() {\n        ${getCoordsDataType(rank)} coords = getOutputCoords();\n        int end = ${getFinalCoord(rank,"coords")};\n        float val = ${val};\n        int pow2 = int(pow(2.0, index));\n        if (${condition}) {\n          int idx = ${idxString};\n          ${getFinalCoord(rank,"coords")} = idx;\n          val += getX(${getCoords(rank,"coords")});\n        }\n        setOutput(val);\n      }\n    `}getCustomSetupFunc(index){return(gpgpu,webGLProgram)=>{if(this.index==null){this.index=gpgpu.getUniformLocation(webGLProgram,"index")}gpgpu.gl.uniform1f(this.index,index)}}}function getCoords(rank,name){if(rank===1){return`${name}`}else if(rank===2){return`${name}.x, ${name}.y`}else if(rank===3){return`${name}.x, ${name}.y, ${name}.z`}else if(rank===4){return`${name}.x, ${name}.y, ${name}.z, ${name}.w`}else{throw Error(`Cumulative sum for rank ${rank} is not yet supported`)}}function getFinalCoord(rank,name){if(rank===1){return`${name}`}else if(rank===2){return`${name}.y`}else if(rank===3){return`${name}.z`}else if(rank===4){return`${name}.w`}else{throw Error(`Cumulative sum for rank ${rank} is not yet supported`)}}function cumsum(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,exclusive:exclusive,reverse:reverse}=attrs;const xRank=x.shape.length;const permutation=getAxesPermutation([axis],xRank);let permutedX=x;if(permutation!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutation}})}const permutedAxis=getInnerMostAxes(1,xRank)[0];if(permutedAxis!==xRank-1){throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length-1} `+`but got axis=${axis}`)}const size=permutedX.shape[permutedAxis];let result=identity({inputs:{x:permutedX},backend:backend});for(let i=0;i<=Math.ceil(Math.log2(size))-1;i++){const program=new CumSumProgram(permutedX.shape,false,reverse);const customSetup=program.getCustomSetupFunc(i);const prevResult=result;result=backend.runWebGLProgram(program,[result],result.dtype,customSetup);backend.disposeIntermediateTensorInfo(prevResult)}if(exclusive){const program=new CumSumProgram(permutedX.shape,exclusive,reverse);const prevResult=result;result=backend.runWebGLProgram(program,[result],result.dtype);backend.disposeIntermediateTensorInfo(prevResult)}if(permutation!=null){const reversePermutation=getUndoAxesPermutation(permutation);const reverseTransposedResult=transpose({inputs:{x:result},backend:backend,attrs:{perm:reversePermutation}});backend.disposeIntermediateTensorInfo(result);backend.disposeIntermediateTensorInfo(permutedX);return reverseTransposedResult}return result}const cumsumConfig={kernelName:Cumsum,backendName:"webgl",kernelFunc:cumsum};function denseBincount(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,weights:weights}=inputs;const{size:size,binaryOutput:binaryOutput}=attrs;if(x.shape.length===1){const xVals=backend.readSync(x.dataId);const weightsVals=backend.readSync(weights.dataId);const outVals=bincountImplCPU(xVals,weightsVals,weights.dtype,weights.shape,size);return backend.makeTensorInfo([size],weights.dtype,outVals)}else if(x.shape.length===2){const xBuf=backend.bufferSync(x);const weightsBuf=backend.bufferSync(weights);const outBuf=bincountReduceImplCPU(xBuf,weightsBuf,size,binaryOutput);return backend.makeTensorInfo(outBuf.shape,weights.dtype,outBuf.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank`+`${x.shape.length}.`)}const denseBincountConfig={kernelName:DenseBincount,backendName:"webgl",kernelFunc:denseBincount};class DepthToSpaceProgram{constructor(outputShape,blockSize,dataFormat){this.variableNames=["x"];this.outputShape=[];this.outputShape=outputShape;this.blockSize=blockSize;this.dataFormat=dataFormat;this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${blockSize};\n      int offset_h = imod(h, ${blockSize});\n      int in_w = w / ${blockSize};\n      int offset_w = imod(w, ${blockSize});\n      int offset_d = (offset_h * ${blockSize} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){if(this.dataFormat==="NHWC"){return`coords[1]`}else{return`coords[2]`}}getWidthCoordString(){if(this.dataFormat==="NHWC"){return`coords[2]`}else{return`coords[3]`}}getDepthCoordString(){if(this.dataFormat==="NHWC"){return`coords[3]`}else{return`coords[1]`}}getOutputDepthSize(){if(this.dataFormat==="NHWC"){return this.outputShape[3]}else{return this.outputShape[1]}}getInputSamplingString(){if(this.dataFormat==="NHWC"){return`getX(b, in_h, in_w, in_d)`}else{return`getX(b, in_d, in_h, in_w)`}}}function depthToSpace(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{blockSize:blockSize,dataFormat:dataFormat}=attrs;assert(blockSize>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${blockSize}`));const batchSize=x.shape[0];const inputHeight=dataFormat==="NHWC"?x.shape[1]:x.shape[2];const inputWidth=dataFormat==="NHWC"?x.shape[2]:x.shape[3];const inputDepth=dataFormat==="NHWC"?x.shape[3]:x.shape[1];const outputHeight=inputHeight*blockSize;const outputWidth=inputWidth*blockSize;const outputDepth=inputDepth/(blockSize*blockSize);const outputShape=dataFormat==="NHWC"?[batchSize,outputHeight,outputWidth,outputDepth]:[batchSize,outputDepth,outputHeight,outputWidth];const program=new DepthToSpaceProgram(outputShape,blockSize,dataFormat);return backend.runWebGLProgram(program,[x],x.dtype)}const depthToSpaceConfig={kernelName:DepthToSpace,backendName:"webgl",kernelFunc:depthToSpace};class DepthwiseConv2DProgram{constructor(convInfo,addBias=false,activation=null,hasPreluActivation=false,hasLeakyReluAlpha=false){this.variableNames=["x","W"];this.outputShape=convInfo.outShape;const xNumRows=convInfo.inHeight;const xNumCols=convInfo.inWidth;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const channelMul=convInfo.outChannels/convInfo.inChannels;let activationSnippet="",applyActivationSnippet="";if(activation){if(hasPreluActivation){activationSnippet=`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`}else if(hasLeakyReluAlpha){activationSnippet=`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`}else{activationSnippet=`\n          float activation(float x) {\n            ${activation}\n          }\n        `}applyActivationSnippet=`result = activation(result);`}const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";if(addBias){this.variableNames.push("bias")}if(hasPreluActivation){this.variableNames.push("preluActivationWeights")}if(hasLeakyReluAlpha){this.variableNames.push("leakyreluAlpha")}this.userCode=`\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          int xR = xRCorner + wR * ${dilationHeight};\n\n          if (xR < 0 || xR >= ${xNumRows}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            int xC = xCCorner + wC * ${dilationWidth};\n\n            if (xC < 0 || xC >= ${xNumCols}) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}class DepthwiseConvPacked2DProgram{constructor(convInfo,addBias=false,activation=null,hasPreluActivation=false,hasLeakyReluAlpha=false){this.variableNames=["x","W"];this.packedInputs=true;this.packedOutput=true;this.outputShape=convInfo.outShape;const channelMul=convInfo.outChannels/convInfo.inChannels;const xNumRows=convInfo.inHeight;const xNumCols=convInfo.inWidth;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const texelsAcross=filterWidth;let mainLoop=`\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;`;for(let c=0;c<filterWidth;c++){mainLoop+=`\n          vec4 xTexelC${c*2};\n          int xTexelC${c*2}Ready;\n          vec4 xC${c};`}for(let r=0;r<filterHeight;r++){for(let c=0;c<filterWidth;c++){mainLoop+=`\n          xTexelC${c*2} = vec4(0.0);\n          xTexelC${c*2}Ready = 0;\n          xC${c} = vec4(0.0);`}mainLoop+=`\n        xR = xRCorner + ${r*dilationHeight};\n        if (xR >=0 && xR < ${xNumRows}) {\n      `;for(let texelC=0;texelC<(texelsAcross+1)/2;texelC++){const colIndex=texelC*2;const c=colIndex*dilationWidth;mainLoop+=`\n          xC = xCCorner + ${c};\n          `;if(strideWidth===1){if(colIndex<filterWidth){if(padLeft%2===1){mainLoop+=`\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n              `;if(dilationWidth===1&&c>0){mainLoop+=`\n                xC${colIndex} = vec4(xTexelC${c-2}.zw, xTexelC${c}.xy);\n                `}else{mainLoop+=`\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${colIndex} = vec4(previous.zw, xTexelC${c}.xy);\n                  } else {\n                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${c}.xy);\n                  }\n                  `}}else{mainLoop+=`\n                if (xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xC${colIndex} = xTexelC${c};\n                `}if(c+1<filterWidth){const nextTexelOffset=padLeft%2===0?nearestLargerEven(dilationWidth):dilationWidth;if(dilationWidth%2===0&&padLeft%2===1||dilationWidth%2!==0&&padLeft%2!==1){mainLoop+=`\n                  xCOffset = xC + ${padLeft%2} + ${nextTexelOffset};\n\n                  if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c+2}Ready == 0) {\n                    xTexelC${c+2} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${xNumCols}) {\n                      xTexelC${c+2}.zw = vec2(0.0);\n                    }\n                    xTexelC${c+2}Ready = 1;\n                  }\n                  `;if(dilationWidth>1){mainLoop+=`\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {\n                      xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${c}Ready = 1;\n                    }\n                    `}mainLoop+=`\n                  xC${colIndex+1} = vec4(xTexelC${c}.zw, xTexelC${c+2}.xy);\n                  `}else{if(nextTexelOffset===1){mainLoop+=`\n                    xC${colIndex+1} = xTexelC${c};\n                    `}else{mainLoop+=`\n                    xCOffset = xC + ${nextTexelOffset};\n\n                    if (xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c+2}Ready == 0) {\n                      xTexelC${c+2} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ${xNumCols}) {\n                        xTexelC${c+2}.zw = vec2(0.0);\n                      }\n                      xTexelC${c+2}Ready = 1;\n                    }\n\n                    xC${colIndex+1} = xTexelC${c+2};\n                    `}}}}}else{if(c<filterWidth){if(padLeft%2===1){mainLoop+=`\n                xCOffset = xC + 1 - ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${xNumCols} && xTexelC${c+2}Ready == 0) {\n                  xTexelC${c+2} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ${xNumCols}) {\n                    xTexelC${c+2}.zw = vec2(0.0);\n                  }\n                  xTexelC${c+2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(xTexelC${c}.zw, xTexelC${c+2}.zw);\n              `;if(c+1<filterWidth){mainLoop+=`\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ${strideWidth};\n                  if(xCOffset >= 0 && xCOffset < ${xNumCols}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${colIndex+1} = vec4(xTexelC${c+2}.xy, final.xy);\n                `}}else{mainLoop+=`\n                if(xC >= 0 && xC < ${xNumCols} && xTexelC${c}Ready == 0) {\n                  xTexelC${c} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${xNumCols}) {\n                    xTexelC${c}.zw = vec2(0.0);\n                  }\n                  xTexelC${c}Ready = 1;\n                }\n\n                xCOffset = xC + ${strideWidth};\n                if(xCOffset >= 0 && xCOffset < ${xNumCols} && xTexelC${c+2}Ready == 0) {\n                  xTexelC${c+2} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ${xNumCols}) {\n                    xTexelC${c+2}.zw = vec2(0.);\n                  }\n                  xTexelC${c+2}Ready = 1;\n                }\n\n                xC${colIndex} = vec4(\n                  xTexelC${c}.xy, xTexelC${c+2}.xy);\n              `;if(c+1<filterWidth){mainLoop+=`\n                  xC${colIndex+1} = vec4(xTexelC${c}.zw, xTexelC${c+2}.zw);\n                `}}}}if(colIndex<filterWidth){mainLoop+=`\n            wTexel = getW(${r}, ${c}, d1, q);\n            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);\n          `;if(c+1<filterWidth){mainLoop+=`\n              wTexel = getW(${r}, ${c+1}, d1, q);\n              dotProd += xC${colIndex+1} * vec4(wTexel.xz, wTexel.xz);\n            `}}}mainLoop+=`\n        }\n      `}let activationSnippet="",applyActivationSnippet="";if(activation){if(hasPreluActivation){activationSnippet=`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${activation}\n        }`}else if(hasLeakyReluAlpha){activationSnippet=`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${activation}\n        }`}else{activationSnippet=`vec4 activation(vec4 x) {\n          ${activation}\n        }`}applyActivationSnippet=`result = activation(result);`}const addBiasSnippet=addBias?"result += getBiasAtOutCoords();":"";if(addBias){this.variableNames.push("bias")}if(hasPreluActivation){this.variableNames.push("preluActivationWeights")}if(hasLeakyReluAlpha){this.variableNames.push("leakyreluAlpha")}this.userCode=`\n      ${activationSnippet}\n\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${channelMul};\n        int q = d2 - d1 * ${channelMul};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${mainLoop}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${addBiasSnippet}\n        ${applyActivationSnippet}\n        setOutput(result);\n      }\n    `}}function depthwiseConv2dNative(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter}=inputs;const{strides:strides,pad:pad,dilations:dilations,dimRoundingMode:dimRoundingMode}=attrs;let $dilations=dilations;if($dilations==null){$dilations=[1,1]}assert(eitherStridesOrDilationsAreOne(strides,$dilations),(()=>"Error in depthwiseConv2d: Either strides or dilations must be "+`1. Got strides ${strides} and dilations '${$dilations}'`));const convInfo=computeConv2DInfo(x.shape,filter.shape,strides,$dilations,pad,dimRoundingMode,true);let program;if(env().getBool("WEBGL_PACK_DEPTHWISECONV")&&convInfo.strideWidth<=2&&convInfo.outChannels/convInfo.inChannels===1){program=new DepthwiseConvPacked2DProgram(convInfo)}else{program=new DepthwiseConv2DProgram(convInfo)}return backend.runWebGLProgram(program,[x,filter],"float32")}const depthwiseConv2dNativeConfig={kernelName:DepthwiseConv2dNative,backendName:"webgl",kernelFunc:depthwiseConv2dNative};class DepthwiseConv2DDerFilterProgram{constructor(convInfo){this.variableNames=["x","dy"];this.outputShape=convInfo.filterShape;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const padTop=convInfo.padInfo.top;const padLeft=convInfo.padInfo.left;const channelMul=convInfo.outChannels/convInfo.inChannels;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${channelMul} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${convInfo.batchSize}; b++) {\n          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {\n            int xR = wR + yR * ${strideHeight} - ${padTop};\n\n            if (xR < 0 || xR >= ${convInfo.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {\n              int xC = wC + yC * ${strideWidth} - ${padLeft};\n\n              if (xC < 0 || xC >= ${convInfo.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DepthwiseConv2DDerInputProgram{constructor(convInfo){this.variableNames=["dy","W"];this.outputShape=convInfo.inShape;const filterHeight=convInfo.filterHeight;const filterWidth=convInfo.filterWidth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const padTop=filterHeight-1-convInfo.padInfo.top;const padLeft=filterWidth-1-convInfo.padInfo.left;const channelMul=convInfo.outChannels/convInfo.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${filterHeight}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${filterHeight} - 1 - wR;\n\n          for (int wC = 0; wC < ${filterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${filterWidth} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${channelMul}; dm++) {\n              int d2 = d1 * ${channelMul} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function depthwiseConv2dNativeBackpropFilter(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,dy:dy}=inputs;const{strides:strides,dilations:dilations,pad:pad,dimRoundingMode:dimRoundingMode,filterShape:filterShape}=attrs;const convInfo=computeConv2DInfo(x.shape,filterShape,strides,dilations,pad,dimRoundingMode,true);const program=new DepthwiseConv2DDerFilterProgram(convInfo);return backend.runWebGLProgram(program,[x,dy],"float32")}const depthwiseConv2dNativeBackpropFilterConfig={kernelName:DepthwiseConv2dNativeBackpropFilter,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropFilter};function depthwiseConv2dNativeBackpropInput(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,filter:filter}=inputs;const{strides:strides,dilations:dilations,pad:pad,dimRoundingMode:dimRoundingMode,inputShape:inputShape}=attrs;const convInfo=computeConv2DInfo(inputShape,filter.shape,strides,dilations,pad,dimRoundingMode,true);const program=new DepthwiseConv2DDerInputProgram(convInfo);return backend.runWebGLProgram(program,[dy,filter],"float32")}const depthwiseConv2dNativeBackpropInputConfig={kernelName:DepthwiseConv2dNativeBackpropInput,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropInput};class DiagProgram{constructor(size){this.variableNames=["X"];this.outputShape=[size,size];this.userCode=`\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    `}}function diag(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;const outShape=[...x.shape,...x.shape];const xSize=sizeFromShape(x.shape);const flat=reshape({inputs:{x:x},backend:backend,attrs:{shape:[xSize]}});const program=new DiagProgram(xSize);const res=backend.runWebGLProgram(program,[flat],flat.dtype);const out=reshape({inputs:{x:res},backend:backend,attrs:{shape:outShape}});backend.disposeIntermediateTensorInfo(flat);backend.disposeIntermediateTensorInfo(res);return out}const diagConfig={kernelName:Diag,backendName:"webgl",kernelFunc:diag};class Dilation2DProgram{constructor(convInfo){this.variableNames=["x","W"];this.outputShape=convInfo.outShape;const{inHeight:inHeight,inWidth:inWidth,padInfo:padInfo,strideHeight:strideHeight,strideWidth:strideWidth,filterHeight:filterHeight,filterWidth:filterWidth,dilationHeight:dilationHeight,dilationWidth:dilationWidth}=convInfo;const{top:padTop,left:padLeft}=padInfo;this.userCode=`\n      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${filterHeight}; h++) {\n          int hIn = hBeg + h * ${dilationHeight};\n\n          if (hIn >= 0 && hIn < ${inHeight}) {\n            for (int w = 0; w < ${filterWidth}; w++) {\n              int wIn = wBeg + w * ${dilationWidth};\n\n              if (wIn >= 0 && wIn < ${inWidth}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `}}function dilation2D(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter}=inputs;const{strides:strides,pad:pad,dilations:dilations}=attrs;const convInfo=computeDilation2DInfo(x.shape,filter.shape,strides,pad,"NHWC",dilations);let out;const program=new Dilation2DProgram(convInfo);out=backend.runWebGLProgram(program,[x,filter],"float32");const outReshaped=reshape({inputs:{x:out},backend:backend,attrs:{shape:convInfo.outShape}});backend.disposeIntermediateTensorInfo(out);return outReshaped}const dilation2DConfig={kernelName:Dilation2D,backendName:"webgl",kernelFunc:dilation2D};function einsum(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{equation:equation}=attrs;const tensors=inputs;const{allDims:allDims,summedDims:summedDims,idDims:idDims}=decodeEinsumEquation(equation,tensors.length);checkEinsumDimSizes(allDims.length,idDims,tensors);const{path:path,steps:steps}=getEinsumComputePath(summedDims,idDims);const nSteps=steps.length;let out=null;let numDimsRemaining=allDims.length;const tensorsToDispose=[];for(let i=0;i<nSteps;++i){for(const idTerm of steps[i]){const{permutationIndices:perm,expandDims:dimsToExpand}=getEinsumPermutation(numDimsRemaining,idDims[idTerm]);let x;if(isIdentityPermutation(perm)){x=tensors[idTerm]}else{x=transpose({inputs:{x:tensors[idTerm]},backend:backend,attrs:{perm:perm}});tensorsToDispose.push(x)}const targetShape=x.shape.slice();for(let k=0;k<dimsToExpand.length;++k){targetShape.splice(dimsToExpand[k],0,1)}if(!arraysEqual(x.shape,targetShape)){x=reshape({inputs:{x:x},backend:backend,attrs:{shape:targetShape}});tensorsToDispose.push(x)}if(out===null){out=x}else{out=multiply({inputs:{a:x,b:out},backend:backend});tensorsToDispose.push(out)}}if(i<nSteps-1){if(path[i]>=0){out=sum({inputs:{x:out},backend:backend,attrs:{axis:path[i]-(allDims.length-numDimsRemaining),keepDims:false}});tensorsToDispose.push(out)}numDimsRemaining--}}for(const tensorInfo of tensorsToDispose){if(tensorInfo===out){continue}backend.disposeIntermediateTensorInfo(tensorInfo)}return out}const einsumConfig={kernelName:Einsum,backendName:"webgl",kernelFunc:einsum};const ELU=`return (x >= 0.0) ? x : (exp(x) - 1.0);`;const ELU_PACKED=`\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n`;const elu=unaryKernelFunc({opSnippet:ELU,packedOpSnippet:ELU_PACKED});const eluConfig={kernelName:Elu,backendName:"webgl",kernelFunc:elu};const ELU_DER=`return (b >= 1.0) ? a : a * (b + 1.0);`;const ELU_DER_PACKED=`\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n`;const eluGrad=args=>{const{inputs:inputs,backend:backend}=args;const{dy:dy,y:y}=inputs;const program=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(ELU_DER_PACKED,dy.shape,y.shape):new BinaryOpProgram(ELU_DER,dy.shape,y.shape);return backend.runWebGLProgram(program,[dy,y],dy.dtype)};const eluGradConfig={kernelName:EluGrad,backendName:"webgl",kernelFunc:eluGrad};const PACKED_EQUAL=`\n  return vec4(equal(a, b));\n`;const EQUAL=`return float(a == b);`;const equal=binaryKernelFunc({opSnippet:EQUAL,packedOpSnippet:PACKED_EQUAL,dtype:"bool"});const equalConfig={kernelName:Equal,backendName:"webgl",kernelFunc:equal};const ERF=`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${ERF_P};\n  float a1 = ${ERF_A1};\n  float a2 = ${ERF_A2};\n  float a3 = ${ERF_A3};\n  float a4 = ${ERF_A4};\n  float a5 = ${ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`;const erf=unaryKernelFunc({opSnippet:ERF});const erfConfig={kernelName:Erf,backendName:"webgl",kernelFunc:erf};const EXP=`return exp(x);`;const exp=unaryKernelFunc({opSnippet:EXP,packedOpSnippet:EXP,cpuKernelImpl:expImplCPU});const expConfig={kernelName:Exp,backendName:"webgl",kernelFunc:exp};function expandDims(args){const{inputs:inputs,attrs:attrs,backend:backend}=args;const{dim:dim}=attrs;const{input:input}=inputs;const inputRank=input.shape.length;const newShape=input.shape.slice();let $dim=dim;if(dim<0){assert(-(inputRank+1)<=dim,(()=>`Axis must be in the interval [${-(inputRank+1)}, ${inputRank}]`));$dim=inputRank+dim+1}newShape.splice($dim,0,1);return reshape({inputs:{x:input},backend:backend,attrs:{shape:newShape}})}const expandDimsConfig={kernelName:ExpandDims,backendName:"webgl",kernelFunc:expandDims};const EXPM1=`return exp(x) - 1.0;`;const expm1=unaryKernelFunc({opSnippet:EXPM1,packedOpSnippet:EXPM1,cpuKernelImpl:expm1ImplCPU});const expm1Config={kernelName:Expm1,backendName:"webgl",kernelFunc:expm1};class FFTProgram{constructor(component,inputShape,inverse){this.variableNames=["real","imag"];const innerDim=inputShape[1];this.outputShape=inputShape;const exponentMultiplierSnippet=inverse?`2.0 * ${Math.PI}`:`-2.0 * ${Math.PI}`;const resultDenominator=inverse?`${innerDim}.0`:"1.0";let opString;if(component==="real"){opString="return real * expR - imag * expI;"}else if(component==="imag"){opString="return real * expI + imag * expR;"}else{throw new Error(`FFT component must be either "real" or "imag", got ${component}.`)}this.userCode=`\n      const float exponentMultiplier = ${exponentMultiplierSnippet};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${opString}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${innerDim});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${innerDim}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${resultDenominator};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function fftImpl(x,inverse,backend){const xData=backend.texData.get(x.dataId);const inputSize=sizeFromShape(x.shape);const innerDimensionSize=x.shape[x.shape.length-1];const batch=inputSize/innerDimensionSize;const input2D=reshape({inputs:{x:x},backend:backend,attrs:{shape:[batch,innerDimensionSize]}});const xShape=input2D.shape;const realProgram=new FFTProgram("real",xShape,inverse);const imagProgram=new FFTProgram("imag",xShape,inverse);const inputs=[{dataId:xData.complexTensorInfos.real.dataId,dtype:xData.complexTensorInfos.real.dtype,shape:xShape},{dataId:xData.complexTensorInfos.imag.dataId,dtype:xData.complexTensorInfos.imag.dtype,shape:xShape}];const realPart=backend.runWebGLProgram(realProgram,inputs,"float32");const imagPart=backend.runWebGLProgram(imagProgram,inputs,"float32");const complexOutput=complex({inputs:{real:realPart,imag:imagPart},backend:backend});backend.disposeIntermediateTensorInfo(realPart);backend.disposeIntermediateTensorInfo(imagPart);const complexOutputReshaped=reshape({inputs:{x:complexOutput},backend:backend,attrs:{shape:x.shape}});backend.disposeIntermediateTensorInfo(input2D);backend.disposeIntermediateTensorInfo(complexOutput);return complexOutputReshaped}function fft(args){const{inputs:inputs,backend:backend}=args;const{input:input}=inputs;return fftImpl(input,false,backend)}const fftConfig={kernelName:FFT,backendName:"webgl",kernelFunc:fft};class FillProgram{constructor(shape,value){this.outputShape=[];this.variableNames=["x"];this.outputShape=shape;this.userCode=`\n      uniform float value;\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    `}getCustomSetupFunc(value){return(gpgpu,webGLProgram)=>{if(this.valueLoc==null){this.valueLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"value")}gpgpu.gl.uniform1f(this.valueLoc,value)}}}function fill(args){const{backend:backend,attrs:attrs}=args;const{shape:shape,value:value}=attrs;let{dtype:dtype}=attrs;dtype=dtype||inferDtype(value);if(dtype==="string"){const values=getArrayFromDType(dtype,sizeFromShape(shape));values.fill(value);return backend.makeTensorInfo(shape,dtype,values)}else{const program=new FillProgram(shape,value);const customSetup=program.getCustomSetupFunc(value);return backend.runWebGLProgram(program,[],dtype,customSetup)}}const fillConfig={kernelName:Fill,backendName:"webgl",kernelFunc:fill};class FlipLeftRightProgram{constructor(imageShape){this.variableNames=["Image"];this.outputShape=[];const imageWidth=imageShape[2];this.outputShape=imageShape;this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${imageWidth} - x;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${imageWidth}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const flipLeftRightConfig={kernelName:FlipLeftRight,backendName:"webgl",kernelFunc:({inputs:inputs,backend:backend})=>{const{image:image}=inputs;const webglBackend=backend;const program=new FlipLeftRightProgram(image.shape);const output=webglBackend.runWebGLProgram(program,[image],image.dtype);return output}};const FLOOR=`return floor(x);`;const floor=unaryKernelFunc({opSnippet:FLOOR,packedOpSnippet:FLOOR,cpuKernelImpl:floorImplCPU});const floorConfig={kernelName:Floor,backendName:"webgl",kernelFunc:floor};const INT_DIV=`\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n`;const INT_DIV_PACKED=`\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n`;const floorDiv=binaryKernelFunc({opSnippet:INT_DIV,packedOpSnippet:INT_DIV_PACKED,dtype:"int32"});const floorDivConfig={kernelName:FloorDiv,backendName:"webgl",kernelFunc:floorDiv};class FromPixelsProgram{constructor(outputShape){this.variableNames=["A"];const glsl=getGlslDifferences();const[height,width]=outputShape;this.outputShape=outputShape;this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);\n\n        vec4 values = ${glsl.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class FromPixelsPackedProgram{constructor(outputShape){this.variableNames=["A"];this.packedInputs=false;this.packedOutput=true;const glsl=getGlslDifferences();const[height,width]=outputShape;this.outputShape=outputShape;this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${width}.0, ${height}.0);\n            vec4 values = ${glsl.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${glsl.output} = result;\n      }\n    `}}const fromPixelsConfig={kernelName:FromPixels,backendName:"webgl",kernelFunc:fromPixels};let fromPixels2DContext;function fromPixels(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;let{pixels:pixels}=inputs;const{numChannels:numChannels}=attrs;const isVideo=typeof HTMLVideoElement!=="undefined"&&pixels instanceof HTMLVideoElement;const isImage=typeof HTMLImageElement!=="undefined"&&pixels instanceof HTMLImageElement;const[width,height]=isVideo?[pixels.videoWidth,pixels.videoHeight]:[pixels.width,pixels.height];const texShape=[height,width];const outShape=[height,width,numChannels];if(isImage||isVideo){if(fromPixels2DContext==null){fromPixels2DContext=document.createElement("canvas").getContext("2d")}fromPixels2DContext.canvas.width=width;fromPixels2DContext.canvas.height=height;fromPixels2DContext.drawImage(pixels,0,0,width,height);pixels=fromPixels2DContext.canvas}const tempPixelHandle=backend.makeTensorInfo(texShape,"int32");backend.texData.get(tempPixelHandle.dataId).usage=TextureUsage.PIXELS;backend.gpgpu.uploadPixelDataToTexture(backend.getTexture(tempPixelHandle.dataId),pixels);const program=env().getBool("WEBGL_PACK")?new FromPixelsPackedProgram(outShape):new FromPixelsProgram(outShape);const res=backend.runWebGLProgram(program,[tempPixelHandle],"int32");backend.disposeData(tempPixelHandle.dataId);return res}function fusedConv2d(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter,bias:bias,preluActivationWeights:preluActivationWeights}=inputs;const{strides:strides,pad:pad,dataFormat:dataFormat,dilations:dilations,dimRoundingMode:dimRoundingMode,activation:activation,leakyreluAlpha:leakyreluAlpha}=attrs;const $dataFormat=convertConv2DDataFormat(dataFormat);const convInfo=computeConv2DInfo(x.shape,filter.shape,strides,dilations,pad,dimRoundingMode,false,$dataFormat);let out;const intermediates=[];if(convInfo.filterHeight===1&&convInfo.filterWidth===1&&convInfo.dilationHeight===1&&convInfo.dilationWidth===1&&convInfo.strideHeight===1&&convInfo.strideWidth===1&&(convInfo.padInfo.type==="SAME"||convInfo.padInfo.type==="VALID")){out=conv2dByMatMul({x:x,filter:filter,convInfo:convInfo,backend:backend,bias:bias,activation:activation,preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha})}else if(env().getBool("WEBGL_CONV_IM2COL")&&x.shape[0]===1){out=conv2dWithIm2Row({x:x,filter:filter,convInfo:convInfo,backend:backend,bias:bias,activation:activation,preluActivationWeights:preluActivationWeights,leakyreluAlpha:leakyreluAlpha})}else{const hasBias=bias!=null;const hasPreluActivationWeights=preluActivationWeights!=null;const hasLeakyreluAlpha=activation==="leakyrelu";const fusedActivation=activation?mapActivationToShaderProgram(activation,false):null;const program=new Conv2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha);const inputs=[x,filter];if(bias){inputs.push(bias)}if(preluActivationWeights){inputs.push(preluActivationWeights)}if(hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",createScalarValue(leakyreluAlpha,"float32"));inputs.push($leakyreluAlpha);intermediates.push($leakyreluAlpha)}out=backend.runWebGLProgram(program,inputs,"float32")}const outReshaped=reshape({inputs:{x:out},backend:backend,attrs:{shape:convInfo.outShape}});intermediates.push(out);intermediates.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return outReshaped}const fusedConv2DConfig={kernelName:FusedConv2D,backendName:"webgl",kernelFunc:fusedConv2d};function fusedDepthwiseConv2D(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,filter:filter,bias:bias,preluActivationWeights:preluActivationWeights}=inputs;const{strides:strides,pad:pad,dilations:dilations,dimRoundingMode:dimRoundingMode,activation:activation,leakyreluAlpha:leakyreluAlpha}=attrs;const intermediates=[];let $dilations=dilations;if($dilations==null){$dilations=[1,1]}assert(eitherStridesOrDilationsAreOne(strides,$dilations),(()=>"Error in depthwiseConv2d: Either strides or dilations must be "+`1. Got strides ${strides} and dilations '${$dilations}'`));const convInfo=computeConv2DInfo(x.shape,filter.shape,strides,$dilations,pad,dimRoundingMode,true);const shouldPackDepthwiseConv=env().getBool("WEBGL_PACK_DEPTHWISECONV")&&convInfo.strideWidth<=2&&convInfo.outChannels/convInfo.inChannels===1;const fusedActivation=activation?mapActivationToShaderProgram(activation,shouldPackDepthwiseConv):null;const programInputs=[x,filter];const hasBias=bias!=null;const hasPreluActivationWeights=preluActivationWeights!=null;const hasLeakyreluAlpha=activation==="leakyrelu";if(hasBias){programInputs.push(bias)}if(hasPreluActivationWeights){programInputs.push(preluActivationWeights)}if(hasLeakyreluAlpha){const $leakyreluAlpha=backend.makeTensorInfo([],"float32",createScalarValue(leakyreluAlpha,"float32"));programInputs.push($leakyreluAlpha);intermediates.push($leakyreluAlpha)}let program;if(shouldPackDepthwiseConv){program=new DepthwiseConvPacked2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha)}else{program=new DepthwiseConv2DProgram(convInfo,hasBias,fusedActivation,hasPreluActivationWeights,hasLeakyreluAlpha)}const result=backend.runWebGLProgram(program,programInputs,"float32");intermediates.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return result}const fusedDepthwiseConv2DConfig={kernelName:FusedDepthwiseConv2D,backendName:"webgl",kernelFunc:fusedDepthwiseConv2D};class GatherNDProgram{constructor(sliceDim,strides,shape){this.sliceDim=sliceDim;this.strides=strides;this.variableNames=["x","indices"];this.outputShape=shape;const stridesType=getCoordsDataType(strides.length);const dtype=getCoordsDataType(shape.length);const strideString=this.sliceDim>1?"strides[j]":"strides";this.userCode=`\n        ${stridesType} strides = ${stridesType}(${this.strides});\n         void main() {\n          ${dtype} coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ${this.sliceDim}; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ${strideString};\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      `}}function gatherNd(args){const{inputs:inputs,backend:backend}=args;const{params:params,indices:indices}=inputs;const indicesShape=indices.shape;const sliceRank=indicesShape[indicesShape.length-1];const[resultShape,numSlices,sliceSize,strides]=prepareAndValidate(params,indices);const flattenIndices=reshape({inputs:{x:indices},backend:backend,attrs:{shape:[numSlices,sliceRank]}});const flattenX=reshape({inputs:{x:params},backend:backend,attrs:{shape:[sizeFromShape(params.shape)/sliceSize,sliceSize]}});const program=new GatherNDProgram(sliceRank,strides,[numSlices,sliceSize]);const res=backend.runWebGLProgram(program,[flattenX,flattenIndices],flattenX.dtype);const reshaped=reshape({inputs:{x:res},backend:backend,attrs:{shape:resultShape}});backend.disposeIntermediateTensorInfo(flattenIndices);backend.disposeIntermediateTensorInfo(flattenX);backend.disposeIntermediateTensorInfo(res);return reshaped}const gatherNdConfig={kernelName:GatherNd,backendName:"webgl",kernelFunc:gatherNd};class GatherProgram{constructor(aShape,outputShape){this.variableNames=["A","indices"];this.outputShape=outputShape;this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank);const sourceCoords=getSourceCoords$1(aShape);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        setOutput(getA(${sourceCoords}));\n      }\n    `}}function getSourceCoords$1(aShape,axis){const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w"];const sourceCoords=[];for(let i=0;i<aShape.length;i++){if(i===2){sourceCoords.push("int(getIndices(resRC.x, resRC.z))")}else{sourceCoords.push(`${currentCoords[i]}`)}}return sourceCoords.join()}function gatherV2(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,indices:indices}=inputs;const{axis:axis,batchDims:batchDims}=attrs;const parsedAxis=parseAxisParam(axis,x.shape)[0];const shapeInfo=collectGatherOpShapeInfo(x,indices,parsedAxis,batchDims);const indicesSize=sizeFromShape(indices.shape);const toDispose=[];const flattenX=reshape({inputs:{x:x},backend:backend,attrs:{shape:[shapeInfo.batchSize,shapeInfo.outerSize,shapeInfo.dimSize,shapeInfo.sliceSize]}});const flattenIndex=reshape({inputs:{x:indices},backend:backend,attrs:{shape:[shapeInfo.batchSize,indicesSize/shapeInfo.batchSize]}});toDispose.push(flattenX);toDispose.push(flattenIndex);const flattenOutputShape=[shapeInfo.batchSize,shapeInfo.outerSize,indicesSize/shapeInfo.batchSize,shapeInfo.sliceSize];if(backend.shouldExecuteOnCPU([x,indices])||x.dtype==="string"){const indicesBuf=backend.bufferSync(flattenIndex);const xBuf=backend.bufferSync(flattenX);const outBuf=gatherV2ImplCPU(xBuf,indicesBuf,flattenOutputShape);toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return backend.makeTensorInfo(shapeInfo.outputShape,outBuf.dtype,outBuf.values)}const program=new GatherProgram(flattenX.shape,flattenOutputShape);const res=backend.runWebGLProgram(program,[flattenX,flattenIndex],flattenX.dtype);toDispose.push(res);const reshaped=reshape({inputs:{x:res},backend:backend,attrs:{shape:shapeInfo.outputShape}});toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return reshaped}const gatherV2Config={kernelName:GatherV2,backendName:"webgl",kernelFunc:gatherV2};const GREATER=`return float(a > b);`;const GREATER_PACKED=`\n  return vec4(greaterThan(a, b));\n`;const greater=binaryKernelFunc({opSnippet:GREATER,packedOpSnippet:GREATER_PACKED,cpuKernelImpl:greaterImplCPU,dtype:"bool"});const greaterConfig={kernelName:Greater,backendName:"webgl",kernelFunc:greater};const GREATER_EQUAL=`return float(a >= b);`;const GREATER_EQUAL_PACKED=`\n  return vec4(greaterThanEqual(a, b));\n`;const greaterEqual=binaryKernelFunc({opSnippet:GREATER_EQUAL,packedOpSnippet:GREATER_EQUAL_PACKED,dtype:"bool"});const greaterEqualConfig={kernelName:GreaterEqual,backendName:"webgl",kernelFunc:greaterEqual};function ifft(args){const{inputs:inputs,backend:backend}=args;const{input:input}=inputs;return fftImpl(input,true,backend)}const ifftConfig={kernelName:IFFT,backendName:"webgl",kernelFunc:ifft};const IS_FINITE=`return float(!isnan(x) && !isinf(x));`;const isFinite$1=unaryKernelFunc({opSnippet:IS_FINITE,dtype:"bool"});const isFiniteConfig={kernelName:IsFinite,backendName:"webgl",kernelFunc:isFinite$1};const IS_INF=`return float(isinf(x));`;const isInf=unaryKernelFunc({opSnippet:IS_INF,dtype:"bool"});const isInfConfig={kernelName:IsInf,backendName:"webgl",kernelFunc:isInf};const IS_NAN=`return float(isnan(x));`;const isNaN$1=unaryKernelFunc({opSnippet:IS_NAN,dtype:"bool"});const isNaNConfig={kernelName:IsNan,backendName:"webgl",kernelFunc:isNaN$1};const LESS=`return float(a < b);`;const LESS_PACKED=`\n  return vec4(lessThan(a, b));\n`;const less=binaryKernelFunc({opSnippet:LESS,packedOpSnippet:LESS_PACKED,cpuKernelImpl:lessImplCPU,dtype:"bool"});const lessConfig={kernelName:Less,backendName:"webgl",kernelFunc:less};const LESS_EQUAL=`return float(a <= b);`;const LESS_EQUAL_PACKED=`\n  return vec4(lessThanEqual(a, b));\n`;const lessEqual=binaryKernelFunc({opSnippet:LESS_EQUAL,packedOpSnippet:LESS_EQUAL_PACKED,dtype:"bool"});const lessEqualConfig={kernelName:LessEqual,backendName:"webgl",kernelFunc:lessEqual};function linSpace(args){const{backend:backend,attrs:attrs}=args;const{start:start,stop:stop,num:num}=attrs;const outVals=linSpaceImplCPU(start,stop,num);return backend.makeTensorInfo([outVals.length],"float32",outVals)}const linSpaceConfig={kernelName:LinSpace,backendName:"webgl",kernelFunc:linSpace};const LOG=`if (x < 0.0) return NAN;\n  return log(x);`;const LOG_PACKED=`\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n`;const log=unaryKernelFunc({opSnippet:LOG,packedOpSnippet:LOG_PACKED,cpuKernelImpl:logImplCPU});const logConfig={kernelName:Log,backendName:"webgl",kernelFunc:log};const LOG1P=`return log(1.0 + x);`;const log1p=unaryKernelFunc({opSnippet:LOG1P});const log1pConfig={kernelName:Log1p,backendName:"webgl",kernelFunc:log1p};const LOGICAL_AND=`return float(a >= 1.0 && b >= 1.0);`;const LOGICAL_AND_PACKED=`\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n`;const logicalAnd=binaryKernelFunc({opSnippet:LOGICAL_AND,packedOpSnippet:LOGICAL_AND_PACKED,dtype:"bool"});const logicalAndConfig={kernelName:LogicalAnd,backendName:"webgl",kernelFunc:logicalAnd};const LOGICAL_NOT=`return float(!(x >= 1.0));`;const logicalNot=unaryKernelFunc({opSnippet:LOGICAL_NOT});const logicalNotConfig={kernelName:LogicalNot,backendName:"webgl",kernelFunc:logicalNot};const LOGICAL_OR=`return float(a >= 1.0 || b >= 1.0);`;const LOGICAL_OR_PACKED=`\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n`;const logicalOr=binaryKernelFunc({opSnippet:LOGICAL_OR,packedOpSnippet:LOGICAL_OR_PACKED,dtype:"bool"});const logicalOrConfig={kernelName:LogicalOr,backendName:"webgl",kernelFunc:logicalOr};class LRNProgram{constructor(xShape,radius,bias,alpha,beta){this.variableNames=["x"];this.outputShape=[];const rad=radius;const maxD=xShape[3]-1;this.outputShape=xShape;let powOperator;const basis=`float(${bias}) + float(${alpha}) * sum`;if(beta===.5){powOperator=`inversesqrt(${basis})`}else if(beta===1){powOperator=`1.0/(${basis})`}else{powOperator=`exp(log(${basis}) * float(-${beta}));`}this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${rad}; j <= ${rad}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${maxD}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${powOperator};\n        setOutput(val);\n      }\n    `}}class LRNPackedProgram{constructor(xShape,radius,bias,alpha,beta){this.variableNames=["x"];this.outputShape=[];this.packedInputs=true;this.packedOutput=true;const rad=radius;const maxD=xShape[3]-1;this.outputShape=xShape;let powOperator;const basis=`float(${bias}) + float(${alpha}) * sum`;if(beta===.5){powOperator=`inversesqrt(${basis})`}else if(beta===1){powOperator=`1.0/(${basis})`}else{powOperator=`exp(log(${basis}) * float(-${beta}));`}this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${rad};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${rad}; j <= ${rad}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${maxD}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${powOperator};\n        setOutput(result);\n      }\n    `}}const lrn=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{depthRadius:depthRadius,bias:bias,alpha:alpha,beta:beta}=attrs;const program=env().getBool("WEBGL_PACK_NORMALIZATION")?new LRNPackedProgram(x.shape,depthRadius,bias,alpha,beta):new LRNProgram(x.shape,depthRadius,bias,alpha,beta);return backend.runWebGLProgram(program,[x],x.dtype)};const LRNConfig={kernelName:LRN,backendName:"webgl",kernelFunc:lrn};class LRNGradProgram{constructor(inputShape,depthRadius,bias,alpha,beta){this.variableNames=["inputImage","outputImage","dy"];this.outputShape=[];this.outputShape=inputShape;this.depth=inputShape[3];this.depthRadius=depthRadius;this.bias=bias;this.alpha=alpha;this.beta=beta;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${depthRadius})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${depthRadius} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${alpha}) * norm + float(${bias});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${alpha})\n                * float(${beta})\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${beta});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}const lrnGrad=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,y:y,dy:dy}=inputs;const{depthRadius:depthRadius,bias:bias,alpha:alpha,beta:beta}=attrs;const program=new LRNGradProgram(x.shape,depthRadius,bias,alpha,beta);return backend.runWebGLProgram(program,[x,y,dy],x.dtype)};const LRNGradConfig={kernelName:LRNGrad,backendName:"webgl",kernelFunc:lrnGrad};function maxImpl(x,reduceShape,outShape,backend){const inSize=sizeFromShape(reduceShape);const xSize=sizeFromShape(x.shape);const batchSize=xSize/inSize;const reshapedInput=reshape({inputs:{x:x},attrs:{shape:[batchSize,inSize]},backend:backend});const reduced=reduce(reshapedInput,x.dtype,"max",backend);const reshapedOutput=reshape({inputs:{x:reduced},attrs:{shape:outShape},backend:backend});backend.disposeIntermediateTensorInfo(reshapedInput);backend.disposeIntermediateTensorInfo(reduced);return reshapedOutput}function max(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{reductionIndices:reductionIndices,keepDims:keepDims}=attrs;const xRank=x.shape.length;const origAxes=parseAxisParam(reductionIndices,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);const maxInputIsTransposed=permutedAxes!=null;const shouldExecuteOnCPU=backend.shouldExecuteOnCPU([x]);let maxInput=x;if(maxInputIsTransposed){if(shouldExecuteOnCPU){const xTexData=backend.texData.get(maxInput.dataId);const values=xTexData.values;const newShape=new Array(xRank);for(let i=0;i<newShape.length;i++){newShape[i]=x.shape[permutedAxes[i]]}const maxInputValues=transposeImplCPU(values,x.shape,x.dtype,permutedAxes,newShape);maxInput=backend.makeTensorInfo(newShape,x.dtype);const maxInputData=backend.texData.get(maxInput.dataId);maxInputData.values=maxInputValues}else{maxInput=transposeImpl(x,permutedAxes,backend)}axes=getInnerMostAxes(axes.length,xRank)}assertAxesAreInnerMostDims("max",axes,xRank);const[maxOutShape,reduceShape]=computeOutAndReduceShapes(maxInput.shape,axes);let outShape=maxOutShape;if(keepDims){outShape=expandShapeToKeepDim(maxOutShape,origAxes)}let out;if(shouldExecuteOnCPU){const xTexData=backend.texData.get(maxInput.dataId);const values=xTexData.values;const outValues=maxImplCPU(values,sizeFromShape(reduceShape),outShape,x.dtype);out=backend.makeTensorInfo(outShape,x.dtype);const outData=backend.texData.get(out.dataId);outData.values=outValues}else{out=maxImpl(maxInput,reduceShape,outShape,backend)}if(maxInputIsTransposed){backend.disposeIntermediateTensorInfo(maxInput)}return out}const maxConfig={kernelName:Max,backendName:"webgl",kernelFunc:max};const MAXIMUM=CHECK_NAN_SNIPPET$1+`\n  return max(a, b);\n`;const MAXIMUM_PACKED=`\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  `+CHECK_NAN_SNIPPET+`\n  return result;\n`;const maximum=binaryKernelFunc({opSnippet:MAXIMUM,packedOpSnippet:MAXIMUM_PACKED,cpuKernelImpl:maximumImplCPU});const maximumConfig={kernelName:Maximum,backendName:"webgl",kernelFunc:maximum};function maxPool(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;assertNotComplex(x,"maxPool");const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode}=attrs;const dilations=1;assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in maxPool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));const convInfo=computePool2DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode);if(convInfo.filterWidth===1&&convInfo.filterHeight===1&&arraysEqual(convInfo.inShape,convInfo.outShape)){return identity({inputs:{x:x},backend:backend})}const maxPoolProgram=new Pool2DProgram(convInfo,"max",false);return backend.runWebGLProgram(maxPoolProgram,[x],x.dtype)}const maxPoolConfig={kernelName:MaxPool,backendName:"webgl",kernelFunc:maxPool};function maxPool3d(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{filterSize:filterSize,strides:strides,pad:pad,dataFormat:dataFormat,dimRoundingMode:dimRoundingMode}=attrs;const dilations=[1,1,1];const convInfo=computePool3DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode,dataFormat);const maxPoolProgram=new Pool3DProgram(convInfo,"max",false);return backend.runWebGLProgram(maxPoolProgram,[x],x.dtype)}const maxPool3DConfig={kernelName:MaxPool3D,backendName:"webgl",kernelFunc:maxPool3d};class MaxPool2DBackpropProgram{constructor(convInfo){this.variableNames=["dy","maxPos"];this.outputShape=convInfo.inShape;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationHeight=convInfo.dilationHeight;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padTop=effectiveFilterHeight-1-convInfo.padInfo.top;const padLeft=effectiveFilterWidth-1-convInfo.padInfo.left;const lastIndex=effectiveFilterHeight*effectiveFilterWidth-1;this.userCode=`\n      const ivec2 pads = ivec2(${padTop}, ${padLeft});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${effectiveFilterHeight};\n          wR += ${dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${effectiveFilterWidth}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${lastIndex} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${effectiveFilterWidth} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class MaxPool3DBackpropProgram{constructor(convInfo){this.variableNames=["dy","maxPos"];this.outputShape=convInfo.inShape;const strideDepth=convInfo.strideDepth;const strideHeight=convInfo.strideHeight;const strideWidth=convInfo.strideWidth;const dilationDepth=convInfo.dilationDepth;const dilationHeight=convInfo.dilationHeight;const dilationWidth=convInfo.dilationWidth;const effectiveFilterDepth=convInfo.effectiveFilterDepth;const effectiveFilterHeight=convInfo.effectiveFilterHeight;const effectiveFilterWidth=convInfo.effectiveFilterWidth;const padFront=effectiveFilterDepth-1-convInfo.padInfo.front;const padTop=effectiveFilterHeight-1-convInfo.padInfo.top;const padLeft=effectiveFilterWidth-1-convInfo.padInfo.left;const lastIndex=effectiveFilterDepth*effectiveFilterHeight*effectiveFilterWidth-1;this.userCode=`\n      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${effectiveFilterDepth};\n           wD += ${dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${effectiveFilterHeight};\n              wR += ${dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${effectiveFilterWidth};\n                wC += ${dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${lastIndex} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +\n                  wR * ${effectiveFilterWidth} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function maxPool3DGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,input:input}=inputs;const x=input;const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode}=attrs;const dilations=[1,1,1];const convInfo=computePool3DInfo(x.shape,filterSize,strides,dilations,pad,dimRoundingMode);const maxPool3dPositionsProgram=new Pool3DProgram(convInfo,"max",true);const maxPool3dPositions=backend.runWebGLProgram(maxPool3dPositionsProgram,[x],x.dtype);const maxPoolBackpropProgram=new MaxPool3DBackpropProgram(convInfo);const result=backend.runWebGLProgram(maxPoolBackpropProgram,[dy,maxPool3dPositions],x.dtype);backend.disposeIntermediateTensorInfo(maxPool3dPositions);return result}const maxPoolGrad3DConfig={kernelName:MaxPool3DGrad,backendName:"webgl",kernelFunc:maxPool3DGrad};function maxPoolGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{dy:dy,input:input,output:output}=inputs;const x=input;assertNotComplex([input,output],"maxPoolGrad");const{filterSize:filterSize,strides:strides,pad:pad,dimRoundingMode:dimRoundingMode}=attrs;const convInfo=computePool2DInfo(x.shape,filterSize,strides,1,pad,dimRoundingMode);const getPositions=true;const maxPoolPositionsProgram=new Pool2DProgram(convInfo,"max",getPositions);const maxPoolPositions=backend.runWebGLProgram(maxPoolPositionsProgram,[x],x.dtype);const maxPoolBackPropProgram=new MaxPool2DBackpropProgram(convInfo);const result=backend.runWebGLProgram(maxPoolBackPropProgram,[dy,maxPoolPositions],x.dtype);backend.disposeIntermediateTensorInfo(maxPoolPositions);return result}const maxPoolGradConfig={kernelName:MaxPoolGrad,backendName:"webgl",kernelFunc:maxPoolGrad};function maxPoolWithArgmaxImpl(x,includeBatchInIndex,convInfo,backend){let program=new Pool2DProgram(convInfo,"max",false);const poolOutput=backend.runWebGLProgram(program,[x],"float32");program=new Pool2DProgram(convInfo,"max",true,true,includeBatchInIndex);const indexOutput=backend.runWebGLProgram(program,[x],"float32");return[poolOutput,indexOutput]}const maxPoolWithArgmaxConfig={kernelName:MaxPoolWithArgmax,backendName:"webgl",kernelFunc:({inputs:inputs,attrs:attrs,backend:backend})=>{const{x:x}=inputs;const{filterSize:filterSize,strides:strides,pad:pad,includeBatchInIndex:includeBatchInIndex}=attrs;const webglBackend=backend;assert(x.shape.length===4,(()=>`Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`));const dilations=[1,1];assert(eitherStridesOrDilationsAreOne(strides,dilations),(()=>"Error in maxPool: Either strides or dilations must be 1. "+`Got strides ${strides} and dilations '${dilations}'`));const convInfo=computePool2DInfo(x.shape,filterSize,strides,dilations,pad);const[result,indexes]=maxPoolWithArgmaxImpl(x,includeBatchInIndex,convInfo,webglBackend);return[result,indexes]}};function meanImpl(x,reduceShape,outShape,backend){const inSize=sizeFromShape(reduceShape);const xSize=sizeFromShape(x.shape);const batchSize=xSize/inSize;const reshapedInput=reshape({inputs:{x:x},attrs:{shape:[batchSize,inSize]},backend:backend});const reduced=reduce(reshapedInput,"float32","mean",backend);const reshapedOutput=reshape({inputs:{x:reduced},attrs:{shape:outShape},backend:backend});backend.disposeIntermediateTensorInfo(reshapedInput);backend.disposeIntermediateTensorInfo(reduced);return reshapedOutput}const meanConfig={kernelName:Mean,backendName:"webgl",kernelFunc:({inputs:inputs,attrs:attrs,backend:backend})=>{const{x:x}=inputs;const{keepDims:keepDims,axis:axis}=attrs;const webglBackend=backend;const xRank=x.shape.length;const origAxes=parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);const meanInputIsTransposed=permutedAxes!=null;const shouldExecuteOnCPU=webglBackend.shouldExecuteOnCPU([x]);const intermediates=[];let meanInput=x;if(meanInputIsTransposed){if(shouldExecuteOnCPU){const xTexData=webglBackend.texData.get(meanInput.dataId);const values=xTexData.values;const newShape=new Array(xRank);for(let i=0;i<newShape.length;i++){newShape[i]=x.shape[permutedAxes[i]]}const meanInputValues=transposeImplCPU(values,x.shape,x.dtype,permutedAxes,newShape);meanInput=webglBackend.makeTensorInfo(newShape,x.dtype);const meanInputData=webglBackend.texData.get(meanInput.dataId);meanInputData.values=meanInputValues}else{meanInput=transposeImpl(x,permutedAxes,webglBackend)}intermediates.push(meanInput);axes=getInnerMostAxes(axes.length,xRank)}assertAxesAreInnerMostDims("sum",axes,xRank);const[meanOutShape,reduceShape]=computeOutAndReduceShapes(meanInput.shape,axes);let outShape=meanOutShape;if(keepDims){outShape=expandShapeToKeepDim(meanOutShape,origAxes)}const out=meanImpl(meanInput,reduceShape,outShape,webglBackend);for(const i of intermediates){webglBackend.disposeIntermediateTensorInfo(i)}return out}};function min(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,keepDims:keepDims}=attrs;const xRank=x.shape.length;const origAxes=parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);let permutedX=x;if(permutedAxes!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});axes=getInnerMostAxes(axes.length,x.shape.length)}assertAxesAreInnerMostDims("min",axes,xRank);const[outShape,reduceShape]=computeOutAndReduceShapes(permutedX.shape,axes);const inSize=sizeFromShape(reduceShape);const a2D=reshape({inputs:{x:permutedX},backend:backend,attrs:{shape:[-1,inSize]}});const reduced=reduce(a2D,a2D.dtype,"min",backend);let res;if(keepDims){const newShape=expandShapeToKeepDim(outShape,origAxes);res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:newShape}})}else{res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:outShape}})}backend.disposeIntermediateTensorInfo(a2D);backend.disposeIntermediateTensorInfo(reduced);if(permutedAxes!=null){backend.disposeIntermediateTensorInfo(permutedX)}return res}const minConfig={kernelName:Min,backendName:"webgl",kernelFunc:min};const MINIMUM=CHECK_NAN_SNIPPET$1+`\n  return min(a, b);\n`;const MINIMUM_PACKED=`\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  `+CHECK_NAN_SNIPPET+`\n  return result;\n`;const minimum=binaryKernelFunc({opSnippet:MINIMUM,packedOpSnippet:MINIMUM_PACKED,cpuKernelImpl:minimumImplCPU});const minimumConfig={kernelName:Minimum,backendName:"webgl",kernelFunc:minimum};class MirrorPadProgram{constructor(xShape,paddings,mode){this.variableNames=["x"];this.outputShape=paddings.map(((p,i)=>p[0]+xShape[i]+p[1]));const rank=xShape.length;const dtype=getCoordsDataType(rank);const start=paddings.map((p=>p[0])).join(",");const end=paddings.map(((p,i)=>p[0]+xShape[i])).join(",");const unpackedCoords=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,rank);const offset=mode==="reflect"?0:1;if(rank===1){this.userCode=`\n        int start = ${start};\n        int end = ${end};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${offset};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${offset};\n          }\n          setOutput(getX(outC - start));\n        }\n      `;return}this.userCode=`\n      ${dtype} start = ${dtype}(${start});\n      ${dtype} end = ${dtype}(${end});\n\n      void main() {\n        ${dtype} outC = getOutputCoords();\n        for (int i = 0; i < ${rank}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${offset};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${offset};\n          }\n        }\n        ${dtype} coords = outC - start;\n        setOutput(getX(${unpackedCoords}));\n      }\n    `}}class MirrorPadPackedProgram{constructor(xShape,paddings,mode){this.variableNames=["x"];this.packedInputs=true;this.packedOutput=true;this.outputShape=paddings.map(((p,i)=>p[0]+xShape[i]+p[1]));const rank=xShape.length;const dtype=getCoordsDataType(rank);const start=paddings.map((p=>p[0])).join(",");const end=paddings.map(((p,i)=>p[0]+xShape[i])).join(",");const coords=getChannels("rc",rank);const source=getChannels("source",rank);const cLimit=`${coords[rank-1]} < ${this.outputShape[rank-1]}`;const innerDims=rank===1?"source":`vec2(${source.slice(-2).join()})`;const offset=mode==="reflect"?0:1;let mainLoop="";if(rank===1){const padSetup=`\n        ${dtype} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${offset};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${offset};\n        }\n        source -= start;\n      `;mainLoop=`\n        ${dtype} rc = outputLoc;\n        ${padSetup}\n        result[0] = getChannel(getX(${source.join()}), ${innerDims});\n        ${coords[rank-1]} += 1;\n        if(${cLimit}) {\n          ${padSetup}\n          result[1] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n      `}else{const padSetup=`\n        ${dtype} source = rc;\n        ${dtype} lt = ${dtype}(lessThan(source, start));\n        ${dtype} gte = ${dtype}(greaterThanEqual(source, end));\n        ${dtype} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${offset}) +\n                gte * ((end - 1) * 2 - source + ${offset});\n        source -= start;\n      `;mainLoop=`\n        ${dtype} rc = outputLoc;\n        ${padSetup}\n        result[0] = getChannel(getX(${source.join()}), ${innerDims});\n        ${coords[rank-1]} += 1;\n        if(${cLimit}) {\n          ${padSetup}\n          result[1] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n        rc = outputLoc;\n        ${coords[rank-2]} += 1;\n        if(${coords[rank-2]} < ${this.outputShape[rank-2]}) {\n          ${padSetup}\n          result[2] = getChannel(getX(${source.join()}), ${innerDims});\n          ${coords[rank-1]} += 1;\n          if(${cLimit}) {\n            ${padSetup}\n            result[3] = getChannel(getX(${source.join()}), ${innerDims});\n          }\n        }\n      `}this.userCode=`\n      const ${dtype} start = ${dtype}(${start});\n      const ${dtype} end = ${dtype}(${end});\n\n      void main() {\n        ${dtype} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${mainLoop}\n        setOutput(result);\n      }\n    `}}const mirrorPadKernelFunc=({inputs:inputs,backend:backend,attrs:attrs})=>{const{x:x}=inputs;const{paddings:paddings,mode:mode}=attrs;const program=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new MirrorPadPackedProgram(x.shape,paddings,mode):new MirrorPadProgram(x.shape,paddings,mode);const output=backend.runWebGLProgram(program,[x],x.dtype);return output};const mirrorPadConfig={kernelName:MirrorPad,backendName:"webgl",kernelFunc:mirrorPadKernelFunc};const MOD=`if (b == 0.0) return NAN;\n  return mod(a, b);`;const MOD_PACKED=`\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  `+CHECK_NAN_SNIPPET+`\n  return result;\n`;const mod=binaryKernelFunc({opSnippet:MOD,packedOpSnippet:MOD_PACKED});const modConfig={kernelName:Mod,backendName:"webgl",kernelFunc:mod};class MultinomialProgram{constructor(batchSize,numOutcomes,numSamples){this.variableNames=["probs"];this.outputShape=[batchSize,numSamples];this.userCode=`\n      uniform float seed;\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${numOutcomes-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${numOutcomes-1}));\n      }\n    `}getCustomSetupFunc(seed){return(gpgpu,webGLProgram)=>{if(this.seedLoc==null){this.seedLoc=gpgpu.getUniformLocation(webGLProgram,"seed")}gpgpu.gl.uniform1f(this.seedLoc,seed)}}}const DIV=`\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;`;const DIV_PACKED=`\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n`;const realDiv=binaryKernelFunc({opSnippet:DIV,packedOpSnippet:DIV_PACKED,checkOutOfBounds:true});const realDivConfig={kernelName:RealDiv,backendName:"webgl",kernelFunc:realDiv};const SUB="return a - b;";const sub=binaryKernelFunc({opSnippet:SUB,packedOpSnippet:SUB,supportsComplex:true,cpuKernelImpl:subImplCPU});const subConfig={kernelName:Sub,backendName:"webgl",kernelFunc:sub};function softmax(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{logits:logits}=inputs;const{dim:dim}=attrs;const axes=parseAxisParam([dim],logits.shape);const maxLogit=max({inputs:{x:logits},backend:backend,attrs:{reductionIndices:axes,keepDims:false}});const expandedShape=expandShapeToKeepDim(maxLogit.shape,axes);const maxLogitsReshaped=reshape({inputs:{x:maxLogit},backend:backend,attrs:{shape:expandedShape}});const a=sub({inputs:{a:logits,b:maxLogitsReshaped},backend:backend});const b=exp({inputs:{x:a},backend:backend});const sumExp=sum({inputs:{x:b},backend:backend,attrs:{axis:axes,keepDims:false}});const sumExpReshaped=reshape({inputs:{x:sumExp},backend:backend,attrs:{shape:expandedShape}});const res=realDiv({inputs:{a:b,b:sumExpReshaped},backend:backend});backend.disposeIntermediateTensorInfo(maxLogit);backend.disposeIntermediateTensorInfo(maxLogitsReshaped);backend.disposeIntermediateTensorInfo(a);backend.disposeIntermediateTensorInfo(b);backend.disposeIntermediateTensorInfo(sumExp);backend.disposeIntermediateTensorInfo(sumExpReshaped);return res}const softmaxConfig={kernelName:Softmax,backendName:"webgl",kernelFunc:softmax};function multinomial(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{logits:logits}=inputs;const{numSamples:numSamples,seed:seed,normalized:normalized}=attrs;const probs=normalized?logits:softmax({inputs:{logits:logits},backend:backend,attrs:{dim:logits.shape.length-1}});const batchSize=probs.shape[0];const numOutcomes=probs.shape[1];const program=new MultinomialProgram(batchSize,numOutcomes,numSamples);const customSetup=program.getCustomSetupFunc(seed);const res=backend.runWebGLProgram(program,[probs],"int32",customSetup);if(!normalized){backend.disposeIntermediateTensorInfo(probs)}return res}const multinomialConfig={kernelName:Multinomial,backendName:"webgl",kernelFunc:multinomial};const NEG=`return -x;`;function neg(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;if(backend.shouldExecuteOnCPU([x])){const xData=backend.texData.get(x.dataId);const[outValues,newShape]=negImplCPU(xData.values,x.shape,x.dtype);return backend.makeTensorInfo(newShape,x.dtype,outValues)}let program;if(env().getBool("WEBGL_PACK_UNARY_OPERATIONS")){program=new UnaryOpPackedProgram(x.shape,NEG)}else{program=new UnaryOpProgram(x.shape,NEG)}return backend.runWebGLProgram(program,[x],x.dtype)}const negConfig={kernelName:Neg,backendName:"webgl",kernelFunc:neg};const nonMaxSuppressionV3Impl=nonMaxSuppressionV3Impl$1;function nonMaxSuppressionV3(args){warn("tf.nonMaxSuppression() in webgl locks the UI thread. "+"Call tf.nonMaxSuppressionAsync() instead");const{inputs:inputs,backend:backend,attrs:attrs}=args;const{boxes:boxes,scores:scores}=inputs;const{maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold}=attrs;const boxesVals=backend.readSync(boxes.dataId);const scoresVals=backend.readSync(scores.dataId);const{selectedIndices:selectedIndices}=nonMaxSuppressionV3Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold);return backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices))}const nonMaxSuppressionV3Config={kernelName:NonMaxSuppressionV3,backendName:"webgl",kernelFunc:nonMaxSuppressionV3};const nonMaxSuppressionV4Impl=nonMaxSuppressionV4Impl$1;function nonMaxSuppressionV4(args){warn("tf.nonMaxSuppression() in webgl locks the UI thread. "+"Call tf.nonMaxSuppressionAsync() instead");const{inputs:inputs,backend:backend,attrs:attrs}=args;const{boxes:boxes,scores:scores}=inputs;const{maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,padToMaxOutputSize:padToMaxOutputSize}=attrs;const boxesVals=backend.readSync(boxes.dataId);const scoresVals=backend.readSync(scores.dataId);const{selectedIndices:selectedIndices,validOutputs:validOutputs}=nonMaxSuppressionV4Impl(boxesVals,scoresVals,maxOutputSize,iouThreshold,scoreThreshold,padToMaxOutputSize);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([],"int32",new Int32Array([validOutputs]))]}const nonMaxSuppressionV4Config={kernelName:NonMaxSuppressionV4,backendName:"webgl",kernelFunc:nonMaxSuppressionV4};const nonMaxSuppressionV5Impl=nonMaxSuppressionV5Impl$1;function nonMaxSuppressionV5(args){warn("tf.nonMaxSuppression() in webgl locks the UI thread. "+"Call tf.nonMaxSuppressionAsync() instead");const{inputs:inputs,backend:backend,attrs:attrs}=args;const{boxes:boxes,scores:scores}=inputs;const{maxOutputSize:maxOutputSize,iouThreshold:iouThreshold,scoreThreshold:scoreThreshold,softNmsSigma:softNmsSigma}=attrs;const boxesVals=backend.readSync(boxes.dataId);const scoresVals=backend.readSync(scores.dataId);const maxOutputSizeVal=maxOutputSize;const iouThresholdVal=iouThreshold;const scoreThresholdVal=scoreThreshold;const softNmsSigmaVal=softNmsSigma;const{selectedIndices:selectedIndices,selectedScores:selectedScores}=nonMaxSuppressionV5Impl(boxesVals,scoresVals,maxOutputSizeVal,iouThresholdVal,scoreThresholdVal,softNmsSigmaVal);return[backend.makeTensorInfo([selectedIndices.length],"int32",new Int32Array(selectedIndices)),backend.makeTensorInfo([selectedScores.length],"float32",new Float32Array(selectedScores))]}const nonMaxSuppressionV5Config={kernelName:NonMaxSuppressionV5,backendName:"webgl",kernelFunc:nonMaxSuppressionV5};class OneHotProgram{constructor(numIndices,depth,onValue,offValue){this.variableNames=["indices"];this.outputShape=[numIndices,depth];this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${offValue}), float(${onValue}),\n                      float(index == coords.y)));\n      }\n    `}}const oneHot=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{indices:indices}=inputs;const{depth:depth,onValue:onValue,offValue:offValue}=attrs;const indicesSize=sizeFromShape(indices.shape);const program=new OneHotProgram(indicesSize,depth,onValue,offValue);const reshaped=reshape({inputs:{x:indices},backend:backend,attrs:{shape:[indicesSize]}});const result=backend.runWebGLProgram(program,[reshaped],indices.dtype);backend.disposeIntermediateTensorInfo(reshaped);const outShape=[...indices.shape,depth];const out=reshape({inputs:{x:result},backend:backend,attrs:{shape:outShape}});backend.disposeIntermediateTensorInfo(result);return out};const oneHotConfig={kernelName:OneHot,backendName:"webgl",kernelFunc:oneHot};function zerosLike(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;if(x.dtype==="complex64"){const realPart=real({inputs:{input:x},backend:backend});const r=zerosLike({inputs:{x:realPart},backend:backend});const imagPart=imag({inputs:{input:x},backend:backend});const i=zerosLike({inputs:{x:imagPart},backend:backend});const result=complex({inputs:{real:r,imag:i},backend:backend});backend.disposeIntermediateTensorInfo(realPart);backend.disposeIntermediateTensorInfo(r);backend.disposeIntermediateTensorInfo(imagPart);backend.disposeIntermediateTensorInfo(i);return result}else{return fill({attrs:{shape:x.shape,dtype:x.dtype,value:x.dtype==="string"?"":0},backend:backend})}}const zerosLikeConfig={kernelName:ZerosLike,backendName:"webgl",kernelFunc:zerosLike};function onesLike(args){const{inputs:inputs,backend:backend}=args;const{x:x}=inputs;if(x.dtype==="string"){throw new Error("onesLike is not supported under string dtype")}else if(x.dtype==="complex64"){const realPart=real({inputs:{input:x},backend:backend});const r=onesLike({inputs:{x:realPart},backend:backend});const imagPart=imag({inputs:{input:x},backend:backend});const i=zerosLike({inputs:{x:imagPart},backend:backend});const result=complex({inputs:{real:r,imag:i},backend:backend});backend.disposeIntermediateTensorInfo(realPart);backend.disposeIntermediateTensorInfo(r);backend.disposeIntermediateTensorInfo(imagPart);backend.disposeIntermediateTensorInfo(i);return result}else{return fill({attrs:{shape:x.shape,dtype:x.dtype,value:1},backend:backend})}}const onesLikeConfig={kernelName:OnesLike,backendName:"webgl",kernelFunc:onesLike};function pack(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{axis:axis}=attrs;if(inputs.length===1){return expandDims({inputs:{input:inputs[0]},backend:backend,attrs:{dim:axis}})}const shape=inputs[0].shape;const dtype=inputs[0].dtype;inputs.forEach((t=>{assertShapesMatch(shape,t.shape,"All tensors passed to stack must have matching shapes");assert(dtype===t.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const intermediateTensorInfos=[];const expandedTensors=inputs.map((t=>{const expandedT=expandDims({inputs:{input:t},backend:backend,attrs:{dim:axis}});intermediateTensorInfos.push(expandedT);return expandedT}));const result=concat({inputs:expandedTensors,backend:backend,attrs:{axis:axis}});intermediateTensorInfos.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return result}const packConfig={kernelName:Pack,backendName:"webgl",kernelFunc:pack};class PadProgram{constructor(xShape,paddings,constantValue){this.variableNames=["x"];this.outputShape=paddings.map(((p,i)=>p[0]+xShape[i]+p[1]));const rank=xShape.length;const type=getCoordsDataType(rank);const start=paddings.map((p=>p[0])).join(",");const end=paddings.map(((p,i)=>p[0]+xShape[i])).join(",");const unpackedCoords=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,rank);if(rank===1){this.userCode=`\n        int start = ${start};\n        int end = ${end};\n        uniform float value;\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `;return}this.userCode=`\n      ${type} start = ${type}(${start});\n      ${type} end = ${type}(${end});\n      uniform float value;\n\n      void main() {\n        ${type} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${type} coords = outC - start;\n          setOutput(getX(${unpackedCoords}));\n        }\n      }\n    `}getCustomSetupFunc(value){return(gpgpu,webGLProgram)=>{if(this.valueLoc==null){this.valueLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"value")}gpgpu.gl.uniform1f(this.valueLoc,value)}}}class PadPackedProgram{constructor(xShape,paddings,constantValue){this.variableNames=["x"];this.packedInputs=true;this.packedOutput=true;this.outputShape=paddings.map(((p,i)=>p[0]+xShape[i]+p[1]));const rank=xShape.length;const dtype=getCoordsDataType(rank);const start=paddings.map((p=>p[0])).join(",");const end=paddings.map(((p,i)=>p[0]+xShape[i])).join(",");const coords=getChannels("rc",rank);const source=getChannels("source",rank);const cLimit=`${coords[rank-1]} < ${this.outputShape[rank-1]}`;const innerDims=rank===1?"source":`vec2(${source.slice(-2).join()})`;const componentSetup=[`${dtype} rc = outputLoc;`,`${coords[rank-1]} += 1;\n       if(${cLimit}) {\n      `,rank===1?"":`}\n       rc = outputLoc;\n       ${coords[rank-2]} += 1;\n       if(${coords[rank-2]} < ${this.outputShape[rank-2]}) {`,rank===1?"":`  ${coords[rank-1]} += 1;\n         if(${cLimit}) {`];const paddingArea=rank===1?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let mainLoop="";for(let i=0,j=rank===1?2:4;i<j;i++){mainLoop+=`\n        ${componentSetup[i]}\n        if (${paddingArea}) {\n          result[${i}] = float(value);\n        } else {\n          ${dtype} source = rc - start;\n          result[${i}] = getChannel(getX(${source.join()}), ${innerDims});\n        }\n      `}mainLoop+=rank===1?`} `:`}}`;this.userCode=`\n      const ${dtype} start = ${dtype}(${start});\n      const ${dtype} end = ${dtype}(${end});\n      uniform float value;\n\n      void main() {\n        ${dtype} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${mainLoop}\n        setOutput(result);\n      }\n    `}getCustomSetupFunc(value){return(gpgpu,webGLProgram)=>{if(this.valueLoc==null){this.valueLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"value")}gpgpu.gl.uniform1f(this.valueLoc,value)}}}const padV2=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{paddings:paddings,constantValue:constantValue}=attrs;const program=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new PadPackedProgram(x.shape,paddings,constantValue):new PadProgram(x.shape,paddings,constantValue);const customSetup=program.getCustomSetupFunc(constantValue);return backend.runWebGLProgram(program,[x],x.dtype,customSetup)};const padV2Config={kernelName:PadV2,backendName:"webgl",kernelFunc:padV2};const POW=`\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n`;const POW_PACKED=`\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  `+CHECK_NAN_SNIPPET+`\n  return result;\n`;const pow=binaryKernelFunc({opSnippet:POW,packedOpSnippet:POW_PACKED});const powConfig={kernelName:Pow,backendName:"webgl",kernelFunc:pow};function prod(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{axis:axis,keepDims:keepDims}=attrs;const xRank=x.shape.length;const toDispose=[];const origAxes=parseAxisParam(axis,x.shape);let axes=origAxes;const permutedAxes=getAxesPermutation(axes,xRank);let permutedX=x;if(permutedAxes!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutedAxes}});axes=getInnerMostAxes(axes.length,xRank);toDispose.push(permutedX)}assertAxesAreInnerMostDims("prod",axes,xRank);let res;if(backend.shouldExecuteOnCPU([permutedX])){const xVals=backend.texData.get(permutedX.dataId).values;const{outVals:outVals,outShape:outShape,outDtype:outDtype}=prodImplCPU(permutedX.shape,permutedX.dtype,xVals,axes);res=backend.makeTensorInfo(outShape,outDtype,outVals)}else{const[outShape,reduceShape]=computeOutAndReduceShapes(permutedX.shape,axes);const inSize=sizeFromShape(reduceShape);const a2D=reshape({inputs:{x:permutedX},backend:backend,attrs:{shape:[-1,inSize]}});const outputDType=sumOutType(x.dtype);const reduced=reduce(a2D,outputDType,"prod",backend);res=reshape({inputs:{x:reduced},backend:backend,attrs:{shape:outShape}});toDispose.push(a2D);toDispose.push(reduced)}if(keepDims){toDispose.push(res);const newShape=expandShapeToKeepDim(res.shape,origAxes);res=reshape({inputs:{x:res},backend:backend,attrs:{shape:newShape}})}toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return res}const prodConfig={kernelName:Prod,backendName:"webgl",kernelFunc:prod};const range=args=>{const{backend:backend,attrs:attrs}=args;const{start:start,stop:stop,step:step,dtype:dtype}=attrs;const values=rangeImplCPU(start,stop,step,dtype);return backend.makeTensorInfo([values.length],dtype,values)};const rangeConfig={kernelName:Range,backendName:"webgl",kernelFunc:range};const RECIPROCAL=`return 1.0 / x;`;const reciprocal=unaryKernelFunc({opSnippet:RECIPROCAL});const reciprocalConfig={kernelName:Reciprocal,backendName:"webgl",kernelFunc:reciprocal};const RELU=CHECK_NAN_SNIPPET$2+`\n  return (x < 0.0) ? 0.0 : x;\n`;const RELU_PACKED=`\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n`;const relu=unaryKernelFunc({opSnippet:RELU,packedOpSnippet:RELU_PACKED});const reluConfig={kernelName:Relu,backendName:"webgl",kernelFunc:relu};const RELU6=CHECK_NAN_SNIPPET$2+`\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n`;const RELU6_PACKED=`\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n`;const relu6=unaryKernelFunc({opSnippet:RELU6,packedOpSnippet:RELU6_PACKED});const relu6Config={kernelName:Relu6,backendName:"webgl",kernelFunc:relu6};class ResizeBilinearProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"];this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth];const effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];let sourceFracIndexRC;if(halfPixelCenters){sourceFracIndexRC=`(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC`+` - vec2(0.5)`}else{sourceFracIndexRC=`vec2(yRC) * effectiveInputOverOutputRatioRC`}this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class ResizeBilinearPackedProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth];const effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];let sourceFracIndexRC;if(halfPixelCenters){sourceFracIndexRC=`(vec3(yRC) + vec3(0.5)) * `+`effectiveInputOverOutputRatioRC - vec3(0.5)`}else{sourceFracIndexRC=`vec3(yRC) * effectiveInputOverOutputRatioRC`}this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,\n                                     ${oldWidth}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${depth-1};\n        bool hasNextRow = coords.z < ${newWidth-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}function resizeBilinear(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{images:images}=inputs;const{alignCorners:alignCorners,halfPixelCenters:halfPixelCenters,size:size}=attrs;const[newHeight,newWidth]=size;const program=env().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeBilinearPackedProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters):new ResizeBilinearProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters);return backend.runWebGLProgram(program,[images],"float32")}const resizeBilinearConfig={kernelName:ResizeBilinear,backendName:"webgl",kernelFunc:resizeBilinear};class ResizeBilinearBackpropProgram{constructor(dyShape,inputShape,alignCorners){this.variableNames=["dy"];this.outputShape=[];this.outputShape=inputShape;const[,xHeight,xWidth]=inputShape;const[,yHeight,yWidth]=dyShape;const effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth];const effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth];const heightScale=effectiveXSize[0]/effectiveYSize[0];const widthScale=effectiveXSize[1]/effectiveYSize[1];const invHeightScale=1/heightScale;const invWidthScale=1/widthScale;const winHeight=Math.ceil(invHeightScale)*2+2;const winWidth=Math.ceil(invWidthScale)*2+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${heightScale});\n        const float widthScale = float(${widthScale});\n\n        const float invHeightScale = float(${invHeightScale});\n        const float invWidthScale = float(${invWidthScale});\n\n        const int winHeight = int(${winHeight});\n        const int winWidth = int(${winWidth});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${yHeight}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${yWidth}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${xHeight-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${xWidth-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeBilinearGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{images:images,dy:dy}=inputs;const{alignCorners:alignCorners}=attrs;const program=new ResizeBilinearBackpropProgram(dy.shape,images.shape,alignCorners);return backend.runWebGLProgram(program,[dy],dy.dtype)}const resizeBilinearGradConfig={kernelName:ResizeBilinearGrad,backendName:"webgl",kernelFunc:resizeBilinearGrad};class ResizeNearestNeighborProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"];this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth];const effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];const roundBase=alignCorners?"0.5":"0.0";let sourceFracIndexRC;if(halfPixelCenters){sourceFracIndexRC=`max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC`+`, vec2(0.0))`}else{sourceFracIndexRC=`vec2(yRC) * effectiveInputOverOutputRatioRC`}this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class ResizeNearestNeighborPackedProgram{constructor(inputShape,newHeight,newWidth,alignCorners,halfPixelCenters){this.variableNames=["A"];this.packedInputs=true;this.packedOutput=true;this.outputShape=[];const[batch,oldHeight,oldWidth,depth]=inputShape;this.outputShape=[batch,newHeight,newWidth,depth];const effectiveInSize=[alignCorners&&newHeight>1?oldHeight-1:oldHeight,alignCorners&&newWidth>1?oldWidth-1:oldWidth];const effectiveOutSize=[alignCorners&&newHeight>1?newHeight-1:newHeight,alignCorners&&newWidth>1?newWidth-1:newWidth];const roundBase=alignCorners?"0.5":"0.0";let sourceFracIndexRC;if(halfPixelCenters){sourceFracIndexRC=`max((vec3(yRC) + vec3(0.5)) * `+`effectiveInputOverOutputRatioRC, vec3(0.0))`}else{sourceFracIndexRC=`vec3(yRC) * effectiveInputOverOutputRatioRC`}this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${effectiveInSize[0]/effectiveOutSize[0]},\n          ${effectiveInSize[1]/effectiveOutSize[1]},\n          ${effectiveInSize[1]/effectiveOutSize[1]});\n      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,\n                                     ${oldWidth}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${sourceFracIndexRC};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${depth-1};\n        bool hasNextRow = coords.z < ${newWidth-1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `}}function resizeNearestNeighbor(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{images:images}=inputs;const{alignCorners:alignCorners,halfPixelCenters:halfPixelCenters,size:size}=attrs;const[newHeight,newWidth]=size;const program=env().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeNearestNeighborPackedProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters):new ResizeNearestNeighborProgram(images.shape,newHeight,newWidth,alignCorners,halfPixelCenters);return backend.runWebGLProgram(program,[images],images.dtype)}const resizeNearestNeighborConfig={kernelName:ResizeNearestNeighbor,backendName:"webgl",kernelFunc:resizeNearestNeighbor};class ResizeNearestNeigborBackpropProgram{constructor(dyShape,inputShape,alignCorners){this.variableNames=["dy"];this.outputShape=[];this.outputShape=inputShape;const[,xHeight,xWidth]=inputShape;const[,yHeight,yWidth]=dyShape;const effectiveXSize=[alignCorners&&yHeight>1?xHeight-1:xHeight,alignCorners&&yWidth>1?xWidth-1:xWidth];const effectiveYSize=[alignCorners&&yHeight>1?yHeight-1:yHeight,alignCorners&&yWidth>1?yWidth-1:yWidth];const heightScale=effectiveXSize[0]/effectiveYSize[0];const widthScale=effectiveXSize[1]/effectiveYSize[1];const invHeightScale=1/heightScale;const invWidthScale=1/widthScale;const winHeight=Math.ceil(invHeightScale)*2+2;const winWidth=Math.ceil(invWidthScale)*2+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${heightScale});\n        const float widthScale = float(${widthScale});\n\n        const float invHeightScale = float(${invHeightScale});\n        const float invWidthScale = float(${invWidthScale});\n\n        const int winHeight = int(${winHeight});\n        const int winWidth = int(${winWidth});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${yHeight}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${yWidth}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${effectiveXSize[0]}) *\n                (float(dyR) / float(${effectiveYSize[0]}));\n\n            float sourceFracCol =\n                float(${effectiveXSize[1]}) *\n                  (float(dyC) / float(${effectiveYSize[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${xHeight}) - 1),\n                ${alignCorners} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${xWidth}) - 1),\n                ${alignCorners} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeNearestNeighborGrad(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{images:images,dy:dy}=inputs;const{alignCorners:alignCorners}=attrs;const program=new ResizeNearestNeigborBackpropProgram(dy.shape,images.shape,alignCorners);return backend.runWebGLProgram(program,[dy],dy.dtype)}const resizeNearestNeighborGradConfig={kernelName:ResizeNearestNeighborGrad,backendName:"webgl",kernelFunc:resizeNearestNeighborGrad};class ReverseProgram{constructor(xShape,axis){this.variableNames=["x"];const rank=xShape.length;if(rank>4){throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`)}this.outputShape=xShape;if(rank===1){this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${xShape[0]} - coord - 1));\n        }\n      `;return}const getInCoord=i=>{if(axis.indexOf(i)!==-1&&xShape[i]!==1){return`${xShape[i]} - coords[${i}] - 1`}return`coords[${i}]`};const inCoords=xShape.map(((_,i)=>getInCoord(i))).join(",");const type=getCoordsDataType(rank);this.userCode=`\n      void main() {\n        ${type} coords = getOutputCoords();\n        setOutput(getX(${inCoords}));\n      }\n    `}}class ReversePackedProgram{constructor(xShape,axis){this.variableNames=["x"];this.packedInputs=true;this.packedOutput=true;const rank=xShape.length;if(rank>4){throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`)}this.outputShape=xShape;const channels=getChannels("rc",rank);const nextColumn=`${channels[rank-1]} + 1 < ${this.outputShape[rank-1]}`;const nextRow=`${channels[rank-2]} + 1 < ${this.outputShape[rank-2]}`;const type=getCoordsDataType(rank);if(rank===1){this.userCode=`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${xShape[0]} - rc - 1),\n            ${xShape[0]} - rc - 1);\n          if(${nextColumn}){\n              result.g = getChannel(getX(${xShape[0]} - (rc  + 1) - 1),\n                ${xShape[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `}else{this.userCode=`\n        void main() {\n          ${type} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${getR(channels.slice())};\n          if(${nextColumn}){\n            result.g = ${getG(channels.slice())};\n          }\n          if(${nextRow}) {\n            result.b = ${getB(channels.slice())};\n            if(${nextColumn}) {\n              result.a = ${getA(channels.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}function getR(channels){return getChannel(channels)}function getG(channels){channels[rank-1]="("+channels[rank-1]+` + 1)`;return getChannel(channels)}function getB(channels){channels[rank-2]="("+channels[rank-2]+` + 1)`;return getChannel(channels)}function getA(channels){channels[rank-1]="("+channels[rank-1]+` + 1)`;channels[rank-2]="("+channels[rank-2]+` + 1)`;return getChannel(channels)}function getChannel(channels){const inCoordsArray=xShape.map(((_,i)=>getInCoord(i,channels)));const inCoords=inCoordsArray.join(",");const innerDims=inCoordsArray.slice(-2).join(",");return`getChannel(getX(${inCoords}), vec2(${innerDims}))`}function getInCoord(i,channels1){if(axis.indexOf(i)!==-1&&xShape[i]!==1){return`${xShape[i]} - ${channels1[i]} - 1`}else{return`${channels1[i]}`}}}}function reverse(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{dims:dims}=attrs;const xRank=x.shape.length;const $dims=parseAxisParam(dims,x.shape);if(xRank===0){return identity({inputs:{x:x},backend:backend})}const program=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new ReversePackedProgram(x.shape,$dims):new ReverseProgram(x.shape,$dims);return backend.runWebGLProgram(program,[x],x.dtype)}const reverseConfig={kernelName:Reverse,backendName:"webgl",kernelFunc:reverse};class RotateProgram{constructor(imageShape,fillValue){this.variableNames=["Image"];this.outputShape=[];const imageHeight=imageShape[1];const imageWidth=imageShape[2];this.outputShape=imageShape;let fillSnippet="";if(typeof fillValue==="number"){fillSnippet=`float outputValue = ${fillValue.toFixed(2)};`}else{fillSnippet=`\n        vec3 fill = vec3(${fillValue.join(",")});\n        float outputValue = fill[coords[3]];`}this.userCode=`\n        uniform vec4 params;\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${fillSnippet}\n          if(coordX >= 0 && coordX < ${imageWidth} && coordY >= 0 && coordY < ${imageHeight}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}getCustomSetupFunc(centerX,centerY,sinFactor,cosFactor){return(gpgpu,webGLProgram)=>{if(this.paramsLoc==null){this.paramsLoc=gpgpu.getUniformLocationNoThrow(webGLProgram,"params")}gpgpu.gl.uniform4f(this.paramsLoc,centerX,centerY,sinFactor,cosFactor)}}}const rotateWithOffsetConfig={kernelName:RotateWithOffset,backendName:"webgl",kernelFunc:({inputs:inputs,attrs:attrs,backend:backend})=>{const{image:image}=inputs;const{radians:radians,fillValue:fillValue,center:center}=attrs;const webglBackend=backend;const program=new RotateProgram(image.shape,fillValue);const[centerX,centerY]=getImageCenter(center,image.shape[1],image.shape[2]);const customSetup=program.getCustomSetupFunc(centerX,centerY,Math.sin(radians),Math.cos(radians));const output=webglBackend.runWebGLProgram(program,[image],image.dtype,customSetup);return output}};const ROUND=`\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n`;const round=unaryKernelFunc({opSnippet:ROUND});const roundConfig={kernelName:Round,backendName:"webgl",kernelFunc:round};const RSQRT=`return inversesqrt(x);`;const rsqrt=unaryKernelFunc({opSnippet:RSQRT,cpuKernelImpl:rsqrtImplCPU});const rsqrtConfig={kernelName:Rsqrt,backendName:"webgl",kernelFunc:rsqrt};class ScatterProgram{constructor(updateSize,sliceDim,indicesRank,updatesRank,strides,shape,summingDupeIndex=true){this.variableNames=["updates","indices","defaultValue"];this.outputShape=shape;const stridesType=getCoordsDataType(strides.length);const dtype=getCoordsDataType(shape.length);let indicesString="";if(indicesRank===1){indicesString="i"}else if(indicesRank===2){indicesString="i, j"}const indicesSnippet=`getIndices(${indicesString})`;let updatesString="";if(updatesRank===1){updatesString="i"}else if(updatesRank===2){updatesString="i, coords[1]"}const updatesSnippet=`getUpdates(${updatesString})`;const strideString=sliceDim>1?"strides[j]":"strides";this.userCode=`\n        ${stridesType} strides = ${stridesType}(${strides});\n\n        void main() {\n          ${dtype} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${updateSize}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${sliceDim}; j++) {\n              int index = round(${indicesSnippet});\n              flattenedIndex += index * ${strideString};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${updatesSnippet};\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `}}function scatterNd(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{indices:indices,updates:updates}=inputs;const{shape:shape}=attrs;const{sliceRank:sliceRank,numUpdates:numUpdates,sliceSize:sliceSize,strides:strides,outputSize:outputSize}=calculateShapes(updates,indices,shape);const flattenShape=[outputSize/sliceSize,sliceSize];if(outputSize===0){return backend.makeTensorInfo(shape,indices.dtype)}const flattenIndices=reshape({inputs:{x:indices},backend:backend,attrs:{shape:[numUpdates,sliceRank]}});const flattenX=reshape({inputs:{x:updates},backend:backend,attrs:{shape:[numUpdates,sliceSize]}});const defaultValue=backend.makeTensorInfo([],"float32",new Float32Array([0]));const program=new ScatterProgram(numUpdates,sliceRank,flattenIndices.shape.length,flattenX.shape.length,strides,flattenShape);const res=backend.runWebGLProgram(program,[flattenX,flattenIndices,defaultValue],flattenX.dtype);const reshaped=reshape({inputs:{x:res},backend:backend,attrs:{shape:shape}});backend.disposeIntermediateTensorInfo(flattenIndices);backend.disposeIntermediateTensorInfo(flattenX);backend.disposeIntermediateTensorInfo(res);backend.disposeIntermediateTensorInfo(defaultValue);return reshaped}const scatterNdConfig={kernelName:ScatterNd,backendName:"webgl",kernelFunc:scatterNd};class SelectProgram{constructor(cRank,shape,rank){this.variableNames=["c","a","b"];this.outputShape=shape;let cCoords;let abCoords;if(rank>4){throw Error(`Where for rank ${rank} is not yet supported`)}if(rank===1){abCoords=`resRC`;cCoords=`resRC`}else{const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w"];const cCoordVars=[];const abCoordVars=[];for(let i=0;i<shape.length;i++){abCoordVars.push(`${currentCoords[i]}`);if(i<cRank){cCoordVars.push(`${currentCoords[i]}`)}}cCoords=cCoordVars.join();abCoords=abCoordVars.join()}const dtype=getCoordsDataType(rank);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        float cVal = getC(${cCoords});\n        if (cVal >= 1.0) {\n          setOutput(getA(${abCoords}));\n        } else {\n          setOutput(getB(${abCoords}));\n        }\n      }\n    `}}function select(args){const{inputs:inputs,backend:backend}=args;const{condition:condition,t:t,e:e}=inputs;const program=new SelectProgram(condition.shape.length,t.shape,t.shape.length);return backend.runWebGLProgram(program,[condition,t,e],upcastType(t.dtype,e.dtype))}const selectConfig={kernelName:Select,backendName:"webgl",kernelFunc:select};const SELU=`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${SELU_SCALEALPHA};\n  float scale = ${SELU_SCALE};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`;const selu=unaryKernelFunc({opSnippet:SELU});const seluConfig={kernelName:Selu,backendName:"webgl",kernelFunc:selu};const SIGMOID=`return 1.0 / (1.0 + exp(-1.0 * x));`;const sigmoid=unaryKernelFunc({opSnippet:SIGMOID});const sigmoidConfig={kernelName:Sigmoid,backendName:"webgl",kernelFunc:sigmoid};const SIGN=`\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n`;const sign=unaryKernelFunc({opSnippet:SIGN});const signConfig={kernelName:Sign,backendName:"webgl",kernelFunc:sign};const SIN=CHECK_NAN_SNIPPET_UNARY+`\n  return sin(x);\n`;const sin=unaryKernelFunc({opSnippet:SIN});const sinConfig={kernelName:Sin,backendName:"webgl",kernelFunc:sin};const SINH=`\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n`;const sinh=unaryKernelFunc({opSnippet:SINH});const sinhConfig={kernelName:Sinh,backendName:"webgl",kernelFunc:sinh};const SOFTPLUS=`\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n`;const softplus=unaryKernelFunc({opSnippet:SOFTPLUS});const softplusConfig={kernelName:Softplus,backendName:"webgl",kernelFunc:softplus};const spaceToBatchND=args=>{const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{blockShape:blockShape,paddings:paddings}=attrs;assert(x.shape.length<=4,(()=>"spaceToBatchND for rank > 4 with a WebGL backend not "+"implemented yet"));const prod=blockShape.reduce(((a,b)=>a*b));const completePaddings=[[0,0]];completePaddings.push(...paddings);for(let i=1+blockShape.length;i<x.shape.length;++i){completePaddings.push([0,0])}const toDispose=[];const paddedX=padV2({inputs:{x:x},backend:backend,attrs:{paddings:completePaddings,constantValue:0}});const reshapedPaddedShape=getReshaped(paddedX.shape,blockShape,prod,false);const permutedReshapedPaddedPermutation=getPermuted(reshapedPaddedShape.length,blockShape.length,false);const flattenShape=getReshapedPermuted(paddedX.shape,blockShape,prod,false);const reshapedPaddedX=reshape({inputs:{x:paddedX},backend:backend,attrs:{shape:reshapedPaddedShape}});const paddedXT=transpose({inputs:{x:reshapedPaddedX},backend:backend,attrs:{perm:permutedReshapedPaddedPermutation}});const result=reshape({inputs:{x:paddedXT},backend:backend,attrs:{shape:flattenShape}});toDispose.push(paddedX);toDispose.push(reshapedPaddedX);toDispose.push(paddedXT);toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return result};const spaceToBatchNDConfig={kernelName:SpaceToBatchND,backendName:"webgl",kernelFunc:spaceToBatchND};function sparseFillEmptyRows(args){const{inputs:inputs,backend:backend}=args;const{indices:indices,values:values,denseShape:denseShape,defaultValue:defaultValue}=inputs;if(denseShape.shape.length!==1){throw new Error(`Dense shape must be a vector, saw:\n         ${denseShape.shape}`)}if(indices.shape.length!==2){throw new Error(`Indices must be a matrix, saw:\n         ${indices.shape}`)}if(values.shape.length!==1){throw new Error(`Values must be a vector, saw:\n         ${values.shape}`)}if(defaultValue.shape.length!==0){throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`)}const $indices=backend.readSync(indices.dataId);const $values=backend.readSync(values.dataId);const $denseShape=backend.readSync(denseShape.dataId);const $defaultValue=backend.readSync(defaultValue.dataId)[0];const[outputIndices,outputIndicesShape,outputValues,emptyRowIndicator,reverseIndexMap]=sparseFillEmptyRowsImplCPU($indices,indices.shape,indices.dtype,$values,values.dtype,$denseShape,$defaultValue);return[backend.makeTensorInfo(outputIndicesShape,indices.dtype,outputIndices),backend.makeTensorInfo([outputIndicesShape[0]],values.dtype,outputValues),backend.makeTensorInfo([emptyRowIndicator.length],"bool",new Uint8Array(emptyRowIndicator.map((value=>Number(value))))),backend.makeTensorInfo([reverseIndexMap.length],indices.dtype,new Int32Array(reverseIndexMap))]}const sparseFillEmptyRowsConfig={kernelName:SparseFillEmptyRows,backendName:"webgl",kernelFunc:sparseFillEmptyRows};function sparseReshape(args){const{inputs:inputs,backend:backend}=args;const{inputIndices:inputIndices,inputShape:inputShape,newShape:newShape}=inputs;if(inputIndices.shape.length!==2){throw new Error(`Input indices should be a matrix but received shape ${inputIndices.shape}`)}if(inputShape.shape.length!==1){throw new Error(`Input shape should be a vector but received shape ${inputShape.shape}`)}if(newShape.shape.length!==1){throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`)}const $inputShape=Array.from(backend.readSync(inputShape.dataId));const $inputIndices=backend.readSync(inputIndices.dataId);const targetShape=Array.from(backend.readSync(newShape.dataId));const[newIndices,indicesShape,outputShape]=sparseReshapeImplCPU($inputIndices,inputIndices.shape,inputIndices.dtype,$inputShape,targetShape);return[backend.makeTensorInfo(indicesShape,inputIndices.dtype,newIndices),backend.makeTensorInfo([outputShape.length],newShape.dtype,new Int32Array(outputShape))]}const sparseReshapeConfig={kernelName:SparseReshape,backendName:"webgl",kernelFunc:sparseReshape};function sparseToDense(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{sparseIndices:sparseIndices,sparseValues:sparseValues,defaultValue:defaultValue}=inputs;const{outputShape:outputShape}=attrs;const{sliceRank:sliceRank,numUpdates:numUpdates,strides:strides,outputSize:outputSize}=calculateShapes(sparseValues,sparseIndices,outputShape);const sumDupeIndices=false;const program=new ScatterProgram(numUpdates,sliceRank,sparseIndices.shape.length,sparseValues.shape.length,strides,[outputSize,1],sumDupeIndices);const res=backend.runWebGLProgram(program,[sparseValues,sparseIndices,defaultValue],sparseValues.dtype);const reshaped=reshape({inputs:{x:res},backend:backend,attrs:{shape:outputShape}});backend.disposeIntermediateTensorInfo(res);return reshaped}const sparseToDenseConfig={kernelName:SparseToDense,backendName:"webgl",kernelFunc:sparseToDense};function splitV(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{numOrSizeSplits:numOrSizeSplits,axis:axis}=attrs;const $axis=parseAxisParam(axis,x.shape)[0];const splitSizes=prepareSplitSize(x,numOrSizeSplits,$axis);const xRank=x.shape.length;const begin=new Array(xRank).fill(0);const size=x.shape.slice();return splitSizes.map((s=>{const sliceSize=[...size];sliceSize[$axis]=s;const sliceT=slice({inputs:{x:x},backend:backend,attrs:{begin:begin,size:sliceSize}});begin[$axis]+=s;return sliceT}))}const splitVConfig={kernelName:SplitV,backendName:"webgl",kernelFunc:splitV};const SQRT=`return sqrt(x);`;const sqrt=unaryKernelFunc({opSnippet:SQRT});const sqrtConfig={kernelName:Sqrt,backendName:"webgl",kernelFunc:sqrt};const SQUARE=`return x * x;`;const square=unaryKernelFunc({opSnippet:SQUARE});const squareConfig={kernelName:Square,backendName:"webgl",kernelFunc:square};const SQUARED_DIFFERENCE="return (a - b) * (a - b);";const squaredDifference=binaryKernelFunc({opSnippet:SQUARED_DIFFERENCE,packedOpSnippet:SQUARED_DIFFERENCE});const squaredDifferenceConfig={kernelName:SquaredDifference,backendName:"webgl",kernelFunc:squaredDifference};function step({inputs:inputs,attrs:attrs,backend:backend}){const{x:x}=inputs;const opSnippet=CHECK_NAN_SNIPPET$2+`\n    return x > 0.0 ? 1.0 : float(${attrs.alpha});\n  `;const program=new UnaryOpProgram(x.shape,opSnippet);return backend.runWebGLProgram(program,[x],x.dtype)}const stepConfig={kernelName:Step,backendName:"webgl",kernelFunc:step};class StridedSliceProgram{constructor(begin,strides,size){this.variableNames=["x"];this.outputShape=size;const rank=size.length;const inputDtype=getCoordsDataType(size.length);const dtype=getCoordsDataType(size.length);let newCoords="";if(rank===1){newCoords="coords * strides + begin"}else{let outputAxis=0;newCoords=size.map(((_,i)=>{outputAxis++;return size.length===1?`coords * strides[${i}] + begin[${i}]`:`coords[${outputAxis-1}] * strides[${i}] + begin[${i}]`})).join(",")}this.userCode=`\n      ${inputDtype} begin = ${inputDtype}(${begin});\n      ${inputDtype} strides = ${inputDtype}(${strides});\n\n      void main() {\n        ${dtype} coords = getOutputCoords();\n        setOutput(getX(${newCoords}));\n      }\n    `}}function stridedSlice(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{begin:begin,end:end,strides:strides,beginMask:beginMask,endMask:endMask,ellipsisMask:ellipsisMask,newAxisMask:newAxisMask,shrinkAxisMask:shrinkAxisMask}=attrs;const{nonStrided:nonStrided,$begin:$begin,$strides:$strides,size:size,newShape:newShape,outShape:outShape}=sliceInfo(x.shape,begin,end,strides,beginMask,endMask,ellipsisMask,newAxisMask,shrinkAxisMask);const $x=reshape({inputs:{x:x},backend:backend,attrs:{shape:newShape}});let result;if(nonStrided){const sliced=slice({inputs:{x:$x},backend:backend,attrs:{begin:$begin,size:size}});result=reshape({inputs:{x:sliced},backend:backend,attrs:{shape:outShape}});backend.disposeIntermediateTensorInfo(sliced)}else if(outShape.some((axis=>axis===0))){result=backend.makeTensorInfo(outShape,x.dtype,[])}else{const shouldExecuteOnCPU=backend.shouldExecuteOnCPU([$x]);if(shouldExecuteOnCPU){const xTexData=backend.texData.get($x.dataId);const values=xTexData.values;const xBuf=buffer($x.shape,$x.dtype,values);const resultValues=stridedSliceImplCPU(outShape,xBuf,$strides,$begin);result=backend.makeTensorInfo(outShape,$x.dtype,resultValues.values)}else{const program=new StridedSliceProgram($begin,$strides,outShape);result=backend.runWebGLProgram(program,[$x],$x.dtype)}}const resultReshaped=reshape({inputs:{x:result},backend:backend,attrs:{shape:outShape}});backend.disposeIntermediateTensorInfo($x);backend.disposeIntermediateTensorInfo(result);return resultReshaped}const stridedSliceConfig={kernelName:StridedSlice,backendName:"webgl",kernelFunc:stridedSlice};const TAN=`return tan(x);`;const tan=unaryKernelFunc({opSnippet:TAN});const tanConfig={kernelName:Tan,backendName:"webgl",kernelFunc:tan};const TANH=`\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n`;const tanh=unaryKernelFunc({opSnippet:TANH});const tanhConfig={kernelName:Tanh,backendName:"webgl",kernelFunc:tanh};class TileProgram{constructor(aShape,reps){this.variableNames=["A"];const outputShape=new Array(aShape.length);for(let i=0;i<outputShape.length;i++){outputShape[i]=aShape[i]*reps[i]}this.outputShape=outputShape;this.rank=outputShape.length;const dtype=getCoordsDataType(this.rank);const sourceCoords=getSourceCoords(aShape);this.userCode=`\n      void main() {\n        ${dtype} resRC = getOutputCoords();\n        setOutput(getA(${sourceCoords}));\n      }\n    `}}function getSourceCoords(aShape){const rank=aShape.length;if(rank>5){throw Error(`Tile for rank ${rank} is not yet supported`)}if(rank===1){return`imod(resRC, ${aShape[0]})`}const currentCoords=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"];const sourceCoords=[];for(let i=0;i<aShape.length;i++){sourceCoords.push(`imod(${currentCoords[i]}, ${aShape[i]})`)}return sourceCoords.join()}function tile(params){const{inputs:inputs,backend:backend,attrs:attrs}=params;const{x:x}=inputs;const{reps:reps}=attrs;if(x.dtype==="string"||x.shape.length>5){const data=backend.readSync(x.dataId);const value=x.dtype==="string"?data.map((d=>decodeString(d))):data;const buf=buffer(x.shape,x.dtype,value);const outBuf=tileImplCPU(buf,reps);return backend.makeTensorInfo(outBuf.shape,outBuf.dtype,outBuf.values)}const program=new TileProgram(x.shape,reps);const output=backend.runWebGLProgram(program,[x],x.dtype);return output}const tileConfig={kernelName:Tile,backendName:"webgl",kernelFunc:tile};function topK(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x}=inputs;const{k:k,sorted:sorted}=attrs;const xVals=backend.readSync(x.dataId);const[allTopKVals,allTopKIndices]=topKImplCPU(xVals,x.shape,x.dtype,k,sorted);return[backend.makeTensorInfo(allTopKVals.shape,allTopKVals.dtype,allTopKVals.values),backend.makeTensorInfo(allTopKIndices.shape,allTopKIndices.dtype,allTopKIndices.values)]}const topKConfig={kernelName:TopK,backendName:"webgl",kernelFunc:topK};class TransformProgram{constructor(imageHeight,imageWidth,interpolation,fillMode,fillValue,outShape){this.variableNames=["Image","Transforms"];this.outputShape=outShape;const interpolationModeId=interpolation==="nearest"?1:2;let fillModeId;switch(fillMode){case"constant":fillModeId=1;break;case"reflect":fillModeId=2;break;case"wrap":fillModeId=3;break;case"nearest":fillModeId=4;break;default:fillModeId=1;break}this.userCode=`\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${fillModeId} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${fillModeId} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${fillModeId} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${imageHeight} && 0 <= coordX && coordX < ${imageWidth}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${fillValue});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${fillValue});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${imageWidth}));\n                float mapY = mapCoord(inY, float(${imageHeight}));\n\n                if (${interpolationModeId} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `}}function transform(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{image:image,transforms:transforms}=inputs;const{interpolation:interpolation,fillMode:fillMode,fillValue:fillValue,outputShape:outputShape}=attrs;const[batch,imageHeight,imageWidth,numChannels]=image.shape;const[outHeight,outWidth]=outputShape!=null?outputShape:[imageHeight,imageWidth];const outShape=[batch,outHeight,outWidth,numChannels];const program=new TransformProgram(imageHeight,imageWidth,interpolation,fillMode,fillValue,outShape);return backend.runWebGLProgram(program,[image,transforms],"float32")}const transformConfig={kernelName:Transform,backendName:"webgl",kernelFunc:transform};function unique(args){const{inputs:inputs,attrs:attrs,backend:backend}=args;const{axis:axis}=attrs;const{x:x}=inputs;assertNotComplex(x,"unique");console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const values=backend.readSync(x.dataId);const{outputValues:outputValues,outputShape:outputShape,indices:indices}=uniqueImplCPU(values,axis,x.shape,x.dtype);return[backend.makeTensorInfo(outputShape,x.dtype,outputValues),backend.makeTensorInfo([indices.length],"int32",indices)]}const uniqueConfig={kernelName:Unique,backendName:"webgl",kernelFunc:unique};function unpack(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{value:value}=inputs;let{axis:axis}=attrs;if(axis<0){axis+=value.shape.length}const x=value;const xRank=x.shape.length;const num=value.shape[axis];const outShape=new Array(xRank-1);let outIndex=0;for(let i=0;i<xRank;i++){if(i!==axis){outShape[outIndex++]=x.shape[i]}}const toDispose=[];const begin=new Array(xRank).fill(0);const size=x.shape.slice();size[axis]=1;const res=new Array(num);for(let i=0;i<res.length;i++){begin[axis]=i;const sliced=slice({inputs:{x:x},backend:backend,attrs:{begin:begin,size:size}});const reshaped=reshape({inputs:{x:sliced},backend:backend,attrs:{shape:outShape}});res[i]=reshaped;toDispose.push(sliced)}toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return res}const unpackConfig={kernelName:Unpack,backendName:"webgl",kernelFunc:unpack};class SegmentOpProgram{constructor(segOpInfo,segOpType){this.variableNames=["x","segmentIds"];const windowSize=segOpInfo.windowSize;const batchSize=segOpInfo.batchSize;const inSize=segOpInfo.inSize;const numSegments=segOpInfo.numSegments;const outSize=numSegments*Math.ceil(inSize/windowSize);this.outputShape=[batchSize,outSize];const initializationValue="0.0";const returnValue=`sumValue`;const windowSizeNearestVec4=Math.floor(windowSize/4)*4;const windowSizeVec4Remainder=windowSize%4;const updateSnippet=`\n        sumValue += dot(values, segFilter);\n    `;let checkValueOutOfBounds="";if(inSize%windowSize>0){checkValueOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return initializationValue;\n        }\n      `}let checkSegmentIdOutOfBounds="";if(inSize%windowSize>0){checkSegmentIdOutOfBounds=`\n        if (inIdx < 0 || inIdx >= ${inSize}) {\n          return -1.0;\n        }\n      `}this.userCode=`\n      const float initializationValue = ${initializationValue};\n\n      float getValue(int batch, int inIdx) {\n        ${checkValueOutOfBounds}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${checkSegmentIdOutOfBounds}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${numSegments})) * float(${windowSize}));\n        int currentSeg = int(mod(float(outIdx), float(${numSegments})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${updateSnippet}\n        }\n\n        int inIdx = inOffset + ${windowSizeNearestVec4};\n        if (${windowSizeVec4Remainder===1}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===2}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${updateSnippet}\n        } else if (${windowSizeVec4Remainder===3}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${updateSnippet}\n        }\n        setOutput(${returnValue});\n      }\n    `}}function unsortedSegmentSum(args){const{inputs:inputs,backend:backend,attrs:attrs}=args;const{x:x,segmentIds:segmentIds}=inputs;const{numSegments:numSegments}=attrs;const xRank=x.shape.length;const toDispose=[];let axis=0;const permutation=getAxesPermutation([axis],xRank);let permutedX=x;if(permutation!=null){permutedX=transpose({inputs:{x:x},backend:backend,attrs:{perm:permutation}});toDispose.push(permutedX);axis=getInnerMostAxes(1,xRank)[0]}const outShape=computeOutShape(permutedX.shape,axis,numSegments);const inSize=sizeFromShape([permutedX.shape[axis]]);const a2D=reshape({inputs:{x:permutedX},backend:backend,attrs:{shape:[-1,inSize]}});toDispose.push(a2D);const outputDType=sumOutType(x.dtype);const segOpCompute=(x,segOpType,segmentIds,dtype,numSegments)=>{const batchSize=x.shape[0];const inSize=x.shape[1];const windowSize=segOpComputeOptimalWindowSize(inSize,numSegments);const segOpInfo={windowSize:windowSize,inSize:inSize,batchSize:batchSize,numSegments:numSegments};const program=new SegmentOpProgram(segOpInfo,segOpType);const output=backend.compileAndRun(program,[x,segmentIds],dtype);toDispose.push(output);if(output.shape[1]===numSegments){return output}const rangeInfo=range({backend:backend,attrs:{start:0,stop:numSegments,step:1,dtype:"float32"}});const tileInfo=tile({inputs:{x:rangeInfo},backend:backend,attrs:{reps:[inSize/windowSize]}});toDispose.push(rangeInfo);toDispose.push(tileInfo);const result=segOpCompute(output,segOpType,tileInfo,dtype,numSegments);return result};const segOpResult=segOpCompute(a2D,"unsortedSegmentSum",segmentIds,outputDType,numSegments);const reshaped=reshape({inputs:{x:segOpResult},backend:backend,attrs:{shape:outShape}});let result=reshaped;if(permutation!=null){toDispose.push(reshaped);const perm=getUndoAxesPermutation(permutation);result=transpose({inputs:{x:result},backend:backend,attrs:{perm:perm}})}toDispose.forEach((t=>backend.disposeIntermediateTensorInfo(t)));return result}const unsortedSegmentSumConfig={kernelName:UnsortedSegmentSum,backendName:"webgl",kernelFunc:unsortedSegmentSum};const kernelConfigs=[LRNConfig,LRNGradConfig,_fusedMatMulConfig,absConfig,acosConfig,acoshConfig,addConfig,addNConfig,allConfig,anyConfig,argMaxConfig,argMinConfig,asinConfig,asinhConfig,atan2Config,atanConfig,atanhConfig,avgPool3DConfig,avgPoolConfig,avgPoolGrad3DConfig,avgPoolGradConfig,batchMatMulConfig,batchNormConfig,batchToSpaceNDConfig,bincountConfig,castConfig,ceilConfig,clipByValueConfig,complexAbsConfig,complexConfig,concatConfig,conv2DBackpropFilterConfig,conv2DBackpropInputConfig,conv2DConfig,conv3DBackpropFilterV2Config,conv3DBackpropInputConfig,conv3DConfig,cosConfig,coshConfig,cropAndResizeConfig,cumsumConfig,denseBincountConfig,depthToSpaceConfig,depthwiseConv2dNativeBackpropFilterConfig,depthwiseConv2dNativeBackpropInputConfig,depthwiseConv2dNativeConfig,diagConfig,dilation2DConfig,einsumConfig,eluConfig,eluGradConfig,equalConfig,erfConfig,expConfig,expandDimsConfig,expm1Config,fftConfig,fillConfig,flipLeftRightConfig,floorConfig,floorDivConfig,fromPixelsConfig,fusedConv2DConfig,fusedDepthwiseConv2DConfig,gatherNdConfig,gatherV2Config,greaterConfig,greaterEqualConfig,identityConfig,ifftConfig,imagConfig,isFiniteConfig,isInfConfig,isNaNConfig,leakyReluConfig,lessConfig,lessEqualConfig,linSpaceConfig,log1pConfig,logConfig,logicalAndConfig,logicalNotConfig,logicalOrConfig,maxConfig,maxPool3DConfig,maxPoolConfig,maxPoolGrad3DConfig,maxPoolGradConfig,maxPoolWithArgmaxConfig,maximumConfig,meanConfig,minConfig,minimumConfig,mirrorPadConfig,modConfig,multinomialConfig,multiplyConfig,negConfig,nonMaxSuppressionV3Config,nonMaxSuppressionV4Config,nonMaxSuppressionV5Config,notEqualConfig,oneHotConfig,onesLikeConfig,packConfig,padV2Config,powConfig,preluConfig,prodConfig,rangeConfig,realConfig,realDivConfig,reciprocalConfig,relu6Config,reluConfig,reshapeConfig,resizeBilinearConfig,resizeBilinearGradConfig,resizeNearestNeighborConfig,resizeNearestNeighborGradConfig,reverseConfig,rotateWithOffsetConfig,roundConfig,rsqrtConfig,scatterNdConfig,selectConfig,seluConfig,sigmoidConfig,signConfig,sinConfig,sinhConfig,sliceConfig,softmaxConfig,softplusConfig,spaceToBatchNDConfig,sparseFillEmptyRowsConfig,sparseReshapeConfig,sparseToDenseConfig,splitVConfig,sqrtConfig,squareConfig,squaredDifferenceConfig,stepConfig,stridedSliceConfig,subConfig,sumConfig,tanConfig,tanhConfig,tileConfig,topKConfig,transformConfig,transposeConfig,uniqueConfig,unpackConfig,unsortedSegmentSumConfig,zerosLikeConfig];for(const kernelConfig of kernelConfigs){registerKernel(kernelConfig)}var webgl=Object.freeze({__proto__:null,version_webgl:version,MathBackendWebGL:MathBackendWebGL,setWebGLContext:setWebGLContext,GPGPUContext:GPGPUContext,gpgpu_util:gpgpu_util,webgl_util:webgl_util,forceHalfFloat:forceHalfFloat,webgl:webgl$1});exports.Abs=Abs;exports.Add=Add;exports.AddN=AddN;exports.All=All;exports.Any=Any;exports.ArgMax=ArgMax;exports.AvgPool=AvgPool;exports.BatchMatMul=BatchMatMul;exports.Cast=Cast;exports.Ceil=Ceil;exports.ClipByValue=ClipByValue;exports.Concat=Concat;exports.Conv2D=Conv2D;exports.Conv2DBackpropInput=Conv2DBackpropInput;exports.Cos=Cos;exports.CropAndResize=CropAndResize;exports.Cumsum=Cumsum;exports.DataStorage=DataStorage;exports.DepthToSpace=DepthToSpace;exports.DepthwiseConv2dNative=DepthwiseConv2dNative;exports.Equal=Equal;exports.Exp=Exp;exports.ExpandDims=ExpandDims;exports.Fill=Fill;exports.FlipLeftRight=FlipLeftRight;exports.Floor=Floor;exports.FloorDiv=FloorDiv;exports.FusedBatchNorm=FusedBatchNorm;exports.FusedConv2D=FusedConv2D;exports.FusedDepthwiseConv2D=FusedDepthwiseConv2D;exports.GatherNd=GatherNd;exports.GatherV2=GatherV2;exports.Greater=Greater;exports.GreaterEqual=GreaterEqual;exports.Identity=Identity;exports.KernelBackend=KernelBackend;exports.LeakyRelu=LeakyRelu;exports.Less=Less;exports.LessEqual=LessEqual;exports.Log=Log;exports.LogicalAnd=LogicalAnd;exports.Max=Max;exports.MaxPool=MaxPool;exports.Maximum=Maximum;exports.Mean=Mean;exports.Min=Min;exports.Minimum=Minimum;exports.MirrorPad=MirrorPad;exports.Multiply=Multiply;exports.Neg=Neg;exports.NonMaxSuppressionV3=NonMaxSuppressionV3;exports.NonMaxSuppressionV4=NonMaxSuppressionV4;exports.NonMaxSuppressionV5=NonMaxSuppressionV5;exports.NotEqual=NotEqual;exports.OneHot=OneHot;exports.OnesLike=OnesLike;exports.Pack=Pack;exports.PadV2=PadV2;exports.Pow=Pow;exports.Prelu=Prelu;exports.Prod=Prod;exports.Range=Range;exports.RealDiv=RealDiv;exports.Relu=Relu;exports.Relu6=Relu6;exports.Reshape=Reshape;exports.ResizeBilinear=ResizeBilinear;exports.Reverse=Reverse;exports.RotateWithOffset=RotateWithOffset;exports.Round=Round;exports.Rsqrt=Rsqrt;exports.ScatterNd=ScatterNd;exports.Select=Select;exports.Sigmoid=Sigmoid;exports.Sin=Sin;exports.Slice=Slice;exports.Softmax=Softmax;exports.SplitV=SplitV;exports.Sqrt=Sqrt;exports.Square=Square;exports.SquaredDifference=SquaredDifference;exports.Step=Step;exports.StridedSlice=StridedSlice;exports.Sub=Sub;exports.Sum=Sum;exports.Tan=Tan;exports.Tanh=Tanh;exports.Tensor=Tensor;exports.Tile=Tile;exports.TopK=TopK;exports.Transform=Transform;exports.Transpose=Transpose;exports.Unpack=Unpack;exports.ZerosLike=ZerosLike;exports._FusedMatMul=_FusedMatMul;exports.add=add;exports.assert=assert;exports.assertAndGetBroadcastShape=assertAndGetBroadcastShape;exports.assertAxesAreInnerMostDims=assertAxesAreInnerMostDims;exports.assertParamsConsistent=assertParamsConsistent;exports.assertShapesMatch=assertShapesMatch;exports.bytesPerElement=bytesPerElement;exports.calculateShapes=calculateShapes;exports.cast=cast$1;exports.collectGatherOpShapeInfo=collectGatherOpShapeInfo;exports.commonjsGlobal=commonjsGlobal;exports.computeConv2DInfo=computeConv2DInfo;exports.computeFlatOffset=computeFlatOffset;exports.computeOutAndReduceShapes=computeOutAndReduceShapes;exports.computeOutShape=computeOutShape$1;exports.computeOutShape$1=computeOutShape$2;exports.computePool2DInfo=computePool2DInfo;exports.computeStrides=computeStrides;exports.concat=concat$1;exports.concat2d=concat2d;exports.concatImpl=concatImpl$1;exports.convertConv2DDataFormat=convertConv2DDataFormat;exports.createCommonjsModule=createCommonjsModule;exports.div=div;exports.engine=engine;exports.env=env;exports.expandDims=expandDims$1;exports.expandShapeToKeepDim=expandShapeToKeepDim;exports.fromPixels=fromPixels$1;exports.fromStringArrayToUint8=fromStringArrayToUint8;exports.getAugmentedNamespace=getAugmentedNamespace;exports.getAxesPermutation=getAxesPermutation;exports.getBackend=getBackend;exports.getBroadcastDims=getBroadcastDims$1;exports.getImageCenter=getImageCenter;exports.getInnerMostAxes=getInnerMostAxes;exports.getNormalizedAxes=getNormalizedAxes;exports.getUndoAxesPermutation=getUndoAxesPermutation;exports.image=image$1;exports.inferFromImplicitShape=inferFromImplicitShape;exports.isSliceContinous=isSliceContinous;exports.loadGraphModel=loadGraphModel;exports.maskToAxes=maskToAxes;exports.mul=mul;exports.now=now;exports.parseAxisParam=parseAxisParam;exports.parseSliceParams=parseSliceParams;exports.prepareAndValidate=prepareAndValidate;exports.prepareSplitSize=prepareSplitSize;exports.rangeImpl=rangeImpl;exports.ready=ready;exports.registerBackend=registerBackend;exports.registerKernel=registerKernel;exports.require$$1=require$$1;exports.reshape=reshape$1;exports.setBackend=setBackend;exports.sigmoid=sigmoid$1;exports.sizeFromShape=sizeFromShape;exports.slice=slice$1;exports.sliceImpl=sliceImpl;exports.squeeze=squeeze;exports.sub=sub$1;exports.tensor1d=tensor1d;exports.tensor2d=tensor2d;exports.tf=tf;exports.tidy=tidy;exports.webgl=webgl;
